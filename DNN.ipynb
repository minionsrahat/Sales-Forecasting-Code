{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert2matrix(data_arr, look_back):\n",
    " X, Y =[], []\n",
    " for i in range(len(data_arr)-look_back):\n",
    "  d=i+look_back  \n",
    "  X.append(data_arr[i:d,0])\n",
    "  Y.append(data_arr[d,0])\n",
    " return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def model_dnn(look_back):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(units=32, input_dim=look_back, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',  optimizer='adam')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Splited Data s-1 to s-5/STEST/S_1__I_582865.csv\",parse_dates=['date'],index_col='date')\n",
    "\n",
    "#convert date field from string to datetime\n",
    "#df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','store_nbr','item_nbr','onpromotion'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(len(df) * 0.8)\n",
    "train,test = df.values[0:k,:], df.values[k:len(df.values),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 20\n",
    "#convert dataset into right shape in order to input into the DNN\n",
    "trainX, trainY = convert2matrix(train, look_back)\n",
    "testX, testY = convert2matrix(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190 samples, validate on 70 samples\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 426.5268 - mse: 426.5268 - mae: 19.9106 - val_loss: 295.4115 - val_mse: 295.4115 - val_mae: 16.4745\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 0s 140us/step - loss: 201.3668 - mse: 201.3668 - mae: 13.1043 - val_loss: 126.4246 - val_mse: 126.4246 - val_mae: 10.1150\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 0s 172us/step - loss: 82.1728 - mse: 82.1728 - mae: 7.6500 - val_loss: 51.0640 - val_mse: 51.0640 - val_mae: 5.8347\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 0s 199us/step - loss: 37.1113 - mse: 37.1113 - mae: 4.8340 - val_loss: 33.2184 - val_mse: 33.2184 - val_mae: 4.3778\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 0s 211us/step - loss: 31.0724 - mse: 31.0724 - mae: 4.3461 - val_loss: 34.9477 - val_mse: 34.9477 - val_mae: 4.4205\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 0s 182us/step - loss: 33.2719 - mse: 33.2719 - mae: 4.5265 - val_loss: 34.7393 - val_mse: 34.7393 - val_mae: 4.3997\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 0s 157us/step - loss: 31.8784 - mse: 31.8784 - mae: 4.4359 - val_loss: 32.4432 - val_mse: 32.4432 - val_mae: 4.2185\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 0s 178us/step - loss: 29.7346 - mse: 29.7346 - mae: 4.2787 - val_loss: 31.5180 - val_mse: 31.5180 - val_mae: 4.1774\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 0s 196us/step - loss: 28.9910 - mse: 28.9910 - mae: 4.2047 - val_loss: 31.7261 - val_mse: 31.7261 - val_mae: 4.2408\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 0s 201us/step - loss: 28.9933 - mse: 28.9933 - mae: 4.2019 - val_loss: 31.7804 - val_mse: 31.7804 - val_mae: 4.2613\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 0s 174us/step - loss: 28.8731 - mse: 28.8731 - mae: 4.1919 - val_loss: 31.3394 - val_mse: 31.3394 - val_mae: 4.2208\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 0s 151us/step - loss: 28.5574 - mse: 28.5574 - mae: 4.1670 - val_loss: 30.7698 - val_mse: 30.7698 - val_mae: 4.1668\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 0s 192us/step - loss: 28.2371 - mse: 28.2371 - mae: 4.1446 - val_loss: 30.3175 - val_mse: 30.3175 - val_mae: 4.1189\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 0s 174us/step - loss: 27.9947 - mse: 27.9947 - mae: 4.1266 - val_loss: 29.9979 - val_mse: 29.9979 - val_mae: 4.0867\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 0s 193us/step - loss: 27.7924 - mse: 27.7924 - mae: 4.1097 - val_loss: 29.7757 - val_mse: 29.7757 - val_mae: 4.0687\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 0s 192us/step - loss: 27.5992 - mse: 27.5992 - mae: 4.0921 - val_loss: 29.6005 - val_mse: 29.6005 - val_mae: 4.0568\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 0s 186us/step - loss: 27.4122 - mse: 27.4122 - mae: 4.0743 - val_loss: 29.4205 - val_mse: 29.4205 - val_mae: 4.0455\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 0s 168us/step - loss: 27.2318 - mse: 27.2318 - mae: 4.0577 - val_loss: 29.2297 - val_mse: 29.2297 - val_mae: 4.0316\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 0s 216us/step - loss: 27.0534 - mse: 27.0534 - mae: 4.0428 - val_loss: 29.0155 - val_mse: 29.0155 - val_mae: 4.0140\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 0s 207us/step - loss: 26.8701 - mse: 26.8701 - mae: 4.0275 - val_loss: 28.7796 - val_mse: 28.7796 - val_mae: 3.9949\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 0s 187us/step - loss: 26.6925 - mse: 26.6925 - mae: 4.0123 - val_loss: 28.5149 - val_mse: 28.5149 - val_mae: 3.9748\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 0s 207us/step - loss: 26.5165 - mse: 26.5165 - mae: 3.9971 - val_loss: 28.2363 - val_mse: 28.2363 - val_mae: 3.9544\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 0s 243us/step - loss: 26.3462 - mse: 26.3462 - mae: 3.9824 - val_loss: 27.9739 - val_mse: 27.9739 - val_mae: 3.9352\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 0s 181us/step - loss: 26.1774 - mse: 26.1774 - mae: 3.9675 - val_loss: 27.7382 - val_mse: 27.7382 - val_mae: 3.9186\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 0s 176us/step - loss: 26.0139 - mse: 26.0139 - mae: 3.9529 - val_loss: 27.4958 - val_mse: 27.4958 - val_mae: 3.9013\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 0s 217us/step - loss: 25.8570 - mse: 25.8570 - mae: 3.9387 - val_loss: 27.2778 - val_mse: 27.2778 - val_mae: 3.8858\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 0s 229us/step - loss: 25.6969 - mse: 25.6969 - mae: 3.9238 - val_loss: 27.0869 - val_mse: 27.0869 - val_mae: 3.8725\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 0s 151us/step - loss: 25.5390 - mse: 25.5390 - mae: 3.9087 - val_loss: 26.8971 - val_mse: 26.8971 - val_mae: 3.8586\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 0s 215us/step - loss: 25.3861 - mse: 25.3861 - mae: 3.8938 - val_loss: 26.6801 - val_mse: 26.6801 - val_mae: 3.8401\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 0s 161us/step - loss: 25.2310 - mse: 25.2310 - mae: 3.8790 - val_loss: 26.4819 - val_mse: 26.4819 - val_mae: 3.8235\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 0s 171us/step - loss: 25.0772 - mse: 25.0772 - mae: 3.8640 - val_loss: 26.3152 - val_mse: 26.3152 - val_mae: 3.8097\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 0s 173us/step - loss: 24.9268 - mse: 24.9268 - mae: 3.8502 - val_loss: 26.1589 - val_mse: 26.1589 - val_mae: 3.7969\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 0s 207us/step - loss: 24.7817 - mse: 24.7817 - mae: 3.8370 - val_loss: 25.9908 - val_mse: 25.9908 - val_mae: 3.7833\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 0s 203us/step - loss: 24.6411 - mse: 24.6411 - mae: 3.8245 - val_loss: 25.8099 - val_mse: 25.8099 - val_mae: 3.7684\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 0s 140us/step - loss: 24.4974 - mse: 24.4974 - mae: 3.8113 - val_loss: 25.6583 - val_mse: 25.6583 - val_mae: 3.7560\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 0s 155us/step - loss: 24.3515 - mse: 24.3515 - mae: 3.7977 - val_loss: 25.5165 - val_mse: 25.5165 - val_mae: 3.7452\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 0s 181us/step - loss: 24.2096 - mse: 24.2096 - mae: 3.7849 - val_loss: 25.3699 - val_mse: 25.3699 - val_mae: 3.7348\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 0s 221us/step - loss: 24.0724 - mse: 24.0724 - mae: 3.7728 - val_loss: 25.2215 - val_mse: 25.2215 - val_mae: 3.7242\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 0s 243us/step - loss: 23.9383 - mse: 23.9383 - mae: 3.7609 - val_loss: 25.0611 - val_mse: 25.0611 - val_mae: 3.7111\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 0s 184us/step - loss: 23.7996 - mse: 23.7996 - mae: 3.7483 - val_loss: 24.9159 - val_mse: 24.9159 - val_mae: 3.7005\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 0s 183us/step - loss: 23.6667 - mse: 23.6667 - mae: 3.7360 - val_loss: 24.7859 - val_mse: 24.7859 - val_mae: 3.6919\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 0s 197us/step - loss: 23.5340 - mse: 23.5340 - mae: 3.7243 - val_loss: 24.6634 - val_mse: 24.6634 - val_mae: 3.6843\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 0s 167us/step - loss: 23.3980 - mse: 23.3980 - mae: 3.7126 - val_loss: 24.5423 - val_mse: 24.5423 - val_mae: 3.6752\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 0s 179us/step - loss: 23.2651 - mse: 23.2651 - mae: 3.6998 - val_loss: 24.4020 - val_mse: 24.4020 - val_mae: 3.6645\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 0s 180us/step - loss: 23.1382 - mse: 23.1382 - mae: 3.6875 - val_loss: 24.2697 - val_mse: 24.2697 - val_mae: 3.6565\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 0s 226us/step - loss: 23.0148 - mse: 23.0148 - mae: 3.6767 - val_loss: 24.1334 - val_mse: 24.1334 - val_mae: 3.6507\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 0s 220us/step - loss: 22.8885 - mse: 22.8885 - mae: 3.6668 - val_loss: 23.9704 - val_mse: 23.9704 - val_mae: 3.6425\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 0s 217us/step - loss: 22.7569 - mse: 22.7569 - mae: 3.6574 - val_loss: 23.8173 - val_mse: 23.8173 - val_mae: 3.6320\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 0s 151us/step - loss: 22.6221 - mse: 22.6221 - mae: 3.6466 - val_loss: 23.6591 - val_mse: 23.6591 - val_mae: 3.6186\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 0s 171us/step - loss: 22.4946 - mse: 22.4946 - mae: 3.6360 - val_loss: 23.5457 - val_mse: 23.5457 - val_mae: 3.6113\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 0s 193us/step - loss: 22.3617 - mse: 22.3617 - mae: 3.6246 - val_loss: 23.4855 - val_mse: 23.4855 - val_mae: 3.6102\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 0s 200us/step - loss: 22.2212 - mse: 22.2212 - mae: 3.6111 - val_loss: 23.4029 - val_mse: 23.4029 - val_mae: 3.6088\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 0s 186us/step - loss: 22.0897 - mse: 22.0897 - mae: 3.6011 - val_loss: 23.2640 - val_mse: 23.2640 - val_mae: 3.5998\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 0s 176us/step - loss: 21.9606 - mse: 21.9606 - mae: 3.5932 - val_loss: 23.1550 - val_mse: 23.1550 - val_mae: 3.5942\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 0s 164us/step - loss: 21.8187 - mse: 21.8188 - mae: 3.5841 - val_loss: 23.0733 - val_mse: 23.0733 - val_mae: 3.5910\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 0s 187us/step - loss: 21.6805 - mse: 21.6805 - mae: 3.5742 - val_loss: 22.9430 - val_mse: 22.9430 - val_mae: 3.5797\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 0s 150us/step - loss: 21.5652 - mse: 21.5652 - mae: 3.5653 - val_loss: 22.8766 - val_mse: 22.8766 - val_mae: 3.5755\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 0s 152us/step - loss: 21.4356 - mse: 21.4356 - mae: 3.5568 - val_loss: 22.8366 - val_mse: 22.8366 - val_mae: 3.5737\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 0s 146us/step - loss: 21.3000 - mse: 21.3000 - mae: 3.5491 - val_loss: 22.8019 - val_mse: 22.8019 - val_mae: 3.5718\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 0s 220us/step - loss: 21.1621 - mse: 21.1621 - mae: 3.5402 - val_loss: 22.6891 - val_mse: 22.6891 - val_mae: 3.5640\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 0s 217us/step - loss: 21.0542 - mse: 21.0542 - mae: 3.5330 - val_loss: 22.5928 - val_mse: 22.5928 - val_mae: 3.5576\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 0s 169us/step - loss: 20.9481 - mse: 20.9481 - mae: 3.5275 - val_loss: 22.5249 - val_mse: 22.5249 - val_mae: 3.5517\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 0s 250us/step - loss: 20.8418 - mse: 20.8418 - mae: 3.5217 - val_loss: 22.4713 - val_mse: 22.4713 - val_mae: 3.5475\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 0s 192us/step - loss: 20.7373 - mse: 20.7373 - mae: 3.5134 - val_loss: 22.3703 - val_mse: 22.3703 - val_mae: 3.5390\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 0s 174us/step - loss: 20.6398 - mse: 20.6398 - mae: 3.5065 - val_loss: 22.2866 - val_mse: 22.2866 - val_mae: 3.5336\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 0s 155us/step - loss: 20.5419 - mse: 20.5419 - mae: 3.5002 - val_loss: 22.2595 - val_mse: 22.2595 - val_mae: 3.5334\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 0s 202us/step - loss: 20.4433 - mse: 20.4433 - mae: 3.4931 - val_loss: 22.2433 - val_mse: 22.2433 - val_mae: 3.5344\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 0s 178us/step - loss: 20.3399 - mse: 20.3399 - mae: 3.4855 - val_loss: 22.1348 - val_mse: 22.1348 - val_mae: 3.5221\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 0s 160us/step - loss: 20.2520 - mse: 20.2520 - mae: 3.4784 - val_loss: 22.1016 - val_mse: 22.1016 - val_mae: 3.5193\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 0s 153us/step - loss: 20.1464 - mse: 20.1464 - mae: 3.4715 - val_loss: 22.0768 - val_mse: 22.0768 - val_mae: 3.5182\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 0s 211us/step - loss: 20.0595 - mse: 20.0595 - mae: 3.4651 - val_loss: 22.0637 - val_mse: 22.0637 - val_mae: 3.5175\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 0s 200us/step - loss: 19.9589 - mse: 19.9589 - mae: 3.4572 - val_loss: 21.9885 - val_mse: 21.9885 - val_mae: 3.5106\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 0s 174us/step - loss: 19.8746 - mse: 19.8746 - mae: 3.4513 - val_loss: 21.9420 - val_mse: 21.9420 - val_mae: 3.5053\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 0s 163us/step - loss: 19.7887 - mse: 19.7887 - mae: 3.4428 - val_loss: 21.9539 - val_mse: 21.9539 - val_mae: 3.5066\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 0s 207us/step - loss: 19.6911 - mse: 19.6911 - mae: 3.4351 - val_loss: 21.9049 - val_mse: 21.9049 - val_mae: 3.5025\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 0s 211us/step - loss: 19.6152 - mse: 19.6152 - mae: 3.4301 - val_loss: 21.8517 - val_mse: 21.8517 - val_mae: 3.4942\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 0s 230us/step - loss: 19.5216 - mse: 19.5216 - mae: 3.4229 - val_loss: 21.8458 - val_mse: 21.8458 - val_mae: 3.4950\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 0s 143us/step - loss: 19.4372 - mse: 19.4372 - mae: 3.4156 - val_loss: 21.8079 - val_mse: 21.8079 - val_mae: 3.4918\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 0s 119us/step - loss: 19.3624 - mse: 19.3624 - mae: 3.4101 - val_loss: 21.7894 - val_mse: 21.7894 - val_mae: 3.4925\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 0s 164us/step - loss: 19.2799 - mse: 19.2799 - mae: 3.4046 - val_loss: 21.7876 - val_mse: 21.7876 - val_mae: 3.4915\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 0s 145us/step - loss: 19.1962 - mse: 19.1962 - mae: 3.3974 - val_loss: 21.7479 - val_mse: 21.7479 - val_mae: 3.4857\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 0s 175us/step - loss: 19.1225 - mse: 19.1225 - mae: 3.3924 - val_loss: 21.7308 - val_mse: 21.7308 - val_mae: 3.4850\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 0s 207us/step - loss: 19.0478 - mse: 19.0478 - mae: 3.3861 - val_loss: 21.7315 - val_mse: 21.7315 - val_mae: 3.4831\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 0s 164us/step - loss: 18.9645 - mse: 18.9645 - mae: 3.3797 - val_loss: 21.6937 - val_mse: 21.6937 - val_mae: 3.4787\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 0s 162us/step - loss: 18.9010 - mse: 18.9010 - mae: 3.3752 - val_loss: 21.6304 - val_mse: 21.6304 - val_mae: 3.4684\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 0s 250us/step - loss: 18.8240 - mse: 18.8240 - mae: 3.3688 - val_loss: 21.6310 - val_mse: 21.6310 - val_mae: 3.4672\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 0s 159us/step - loss: 18.7452 - mse: 18.7452 - mae: 3.3621 - val_loss: 21.6840 - val_mse: 21.6840 - val_mae: 3.4758\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 0s 192us/step - loss: 18.6790 - mse: 18.6790 - mae: 3.3603 - val_loss: 21.6123 - val_mse: 21.6123 - val_mae: 3.4631\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 0s 182us/step - loss: 18.5897 - mse: 18.5897 - mae: 3.3512 - val_loss: 21.6032 - val_mse: 21.6032 - val_mae: 3.4595\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 0s 174us/step - loss: 18.5225 - mse: 18.5225 - mae: 3.3461 - val_loss: 21.5985 - val_mse: 21.5985 - val_mae: 3.4611\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 0s 151us/step - loss: 18.4405 - mse: 18.4405 - mae: 3.3418 - val_loss: 21.5682 - val_mse: 21.5682 - val_mae: 3.4553\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 0s 153us/step - loss: 18.3600 - mse: 18.3600 - mae: 3.3340 - val_loss: 21.5310 - val_mse: 21.5310 - val_mae: 3.4492\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 0s 179us/step - loss: 18.2997 - mse: 18.2997 - mae: 3.3292 - val_loss: 21.5786 - val_mse: 21.5786 - val_mae: 3.4552\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 0s 217us/step - loss: 18.2270 - mse: 18.2270 - mae: 3.3249 - val_loss: 21.5155 - val_mse: 21.5155 - val_mae: 3.4428\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 0s 211us/step - loss: 18.1621 - mse: 18.1621 - mae: 3.3180 - val_loss: 21.5530 - val_mse: 21.5530 - val_mae: 3.4486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "190/190 [==============================] - 0s 167us/step - loss: 18.0869 - mse: 18.0869 - mae: 3.3131 - val_loss: 21.5601 - val_mse: 21.5601 - val_mae: 3.4500\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 0s 209us/step - loss: 18.0238 - mse: 18.0238 - mae: 3.3082 - val_loss: 21.5930 - val_mse: 21.5930 - val_mae: 3.4494\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 0s 278us/step - loss: 17.9607 - mse: 17.9607 - mae: 3.3016 - val_loss: 21.5888 - val_mse: 21.5888 - val_mae: 3.4468\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 0s 188us/step - loss: 17.8910 - mse: 17.8910 - mae: 3.2979 - val_loss: 21.5963 - val_mse: 21.5963 - val_mae: 3.4460\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 0s 199us/step - loss: 17.8292 - mse: 17.8292 - mae: 3.2921 - val_loss: 21.6553 - val_mse: 21.6553 - val_mae: 3.4478\n"
     ]
    }
   ],
   "source": [
    "model=model_dnn(look_back)\n",
    "history=model.fit(trainX,trainY, epochs=100, batch_size=30, verbose=1, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error(RMSE): 4.21; Train Mean Absolute Error(MAE) : 3.28 \n",
      "Test Root Mean Squared Error(RMSE): 4.65; Test Mean Absolute Error(MAE) : 3.45 \n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f ' \n",
    "% (np.sqrt(train_score[1]), train_score[2]))\n",
    "test_score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n",
    "% (np.sqrt(test_score[1]), test_score[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.655325262887136, 21.655324935913086, 3.4477503299713135]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6535284159681645"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(testY,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast1=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/ML_FORECAST_70%.csv\",parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>LSTM_1</th>\n",
       "      <th>ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>15.910</td>\n",
       "      <td>12.966378</td>\n",
       "      <td>12.579720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>10.261</td>\n",
       "      <td>12.850510</td>\n",
       "      <td>12.747951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-22</td>\n",
       "      <td>15.035</td>\n",
       "      <td>13.017899</td>\n",
       "      <td>12.972117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>12.190</td>\n",
       "      <td>12.846584</td>\n",
       "      <td>12.491053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>11.514</td>\n",
       "      <td>12.917412</td>\n",
       "      <td>12.801822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1       date  actual_value     LSTM_1        ANN\n",
       "0           0             0 2013-08-20        15.910  12.966378  12.579720\n",
       "1           1             1 2013-08-21        10.261  12.850510  12.747951\n",
       "2           2             2 2013-08-22        15.035  13.017899  12.972117\n",
       "3           3             3 2013-08-23        12.190  12.846584  12.491053\n",
       "4           4             4 2013-08-24        11.514  12.917412  12.801822"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast1['DNN']=np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>LSTM_1</th>\n",
       "      <th>ANN</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>15.910</td>\n",
       "      <td>12.966378</td>\n",
       "      <td>12.579720</td>\n",
       "      <td>13.722870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>10.261</td>\n",
       "      <td>12.850510</td>\n",
       "      <td>12.747951</td>\n",
       "      <td>9.726567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-22</td>\n",
       "      <td>15.035</td>\n",
       "      <td>13.017899</td>\n",
       "      <td>12.972117</td>\n",
       "      <td>12.697343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>12.190</td>\n",
       "      <td>12.846584</td>\n",
       "      <td>12.491053</td>\n",
       "      <td>12.186090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>11.514</td>\n",
       "      <td>12.917412</td>\n",
       "      <td>12.801822</td>\n",
       "      <td>11.137547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>2013-10-24</td>\n",
       "      <td>13.996</td>\n",
       "      <td>12.674856</td>\n",
       "      <td>12.599476</td>\n",
       "      <td>12.235719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>15.341</td>\n",
       "      <td>12.811443</td>\n",
       "      <td>12.186004</td>\n",
       "      <td>15.911834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>9.206</td>\n",
       "      <td>12.779969</td>\n",
       "      <td>12.580894</td>\n",
       "      <td>8.385585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>12.771</td>\n",
       "      <td>13.015878</td>\n",
       "      <td>13.101615</td>\n",
       "      <td>11.958587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>2013-10-28</td>\n",
       "      <td>11.808</td>\n",
       "      <td>12.906087</td>\n",
       "      <td>12.750529</td>\n",
       "      <td>14.282024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1       date  actual_value     LSTM_1        ANN  \\\n",
       "0            0             0 2013-08-20        15.910  12.966378  12.579720   \n",
       "1            1             1 2013-08-21        10.261  12.850510  12.747951   \n",
       "2            2             2 2013-08-22        15.035  13.017899  12.972117   \n",
       "3            3             3 2013-08-23        12.190  12.846584  12.491053   \n",
       "4            4             4 2013-08-24        11.514  12.917412  12.801822   \n",
       "..         ...           ...        ...           ...        ...        ...   \n",
       "65          65            65 2013-10-24        13.996  12.674856  12.599476   \n",
       "66          66            66 2013-10-25        15.341  12.811443  12.186004   \n",
       "67          67            67 2013-10-26         9.206  12.779969  12.580894   \n",
       "68          68            68 2013-10-27        12.771  13.015878  13.101615   \n",
       "69          69            69 2013-10-28        11.808  12.906087  12.750529   \n",
       "\n",
       "          DNN  \n",
       "0   13.722870  \n",
       "1    9.726567  \n",
       "2   12.697343  \n",
       "3   12.186090  \n",
       "4   11.137547  \n",
       "..        ...  \n",
       "65  12.235719  \n",
       "66  15.911834  \n",
       "67   8.385585  \n",
       "68  11.958587  \n",
       "69  14.282024  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast1.to_csv('ML_FORECAST_60%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.812, 16.496,  6.776, 12.563, 15.451, 16.976,  8.755, 14.82 ,\n",
       "        15.363,  7.108, 14.876, 14.69 , 21.102, 12.869, 11.143, 14.353,\n",
       "         7.188, 23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624,\n",
       "        13.773, 11.822, 15.561, 11.52 , 16.106, 14.261],\n",
       "       [16.496,  6.776, 12.563, 15.451, 16.976,  8.755, 14.82 , 15.363,\n",
       "         7.108, 14.876, 14.69 , 21.102, 12.869, 11.143, 14.353,  7.188,\n",
       "        23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773,\n",
       "        11.822, 15.561, 11.52 , 16.106, 14.261,  9.749],\n",
       "       [ 6.776, 12.563, 15.451, 16.976,  8.755, 14.82 , 15.363,  7.108,\n",
       "        14.876, 14.69 , 21.102, 12.869, 11.143, 14.353,  7.188, 23.635,\n",
       "         9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822,\n",
       "        15.561, 11.52 , 16.106, 14.261,  9.749, 28.771],\n",
       "       [12.563, 15.451, 16.976,  8.755, 14.82 , 15.363,  7.108, 14.876,\n",
       "        14.69 , 21.102, 12.869, 11.143, 14.353,  7.188, 23.635,  9.265,\n",
       "        10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561,\n",
       "        11.52 , 16.106, 14.261,  9.749, 28.771, 13.167],\n",
       "       [15.451, 16.976,  8.755, 14.82 , 15.363,  7.108, 14.876, 14.69 ,\n",
       "        21.102, 12.869, 11.143, 14.353,  7.188, 23.635,  9.265, 10.294,\n",
       "        14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 ,\n",
       "        16.106, 14.261,  9.749, 28.771, 13.167, 18.661],\n",
       "       [16.976,  8.755, 14.82 , 15.363,  7.108, 14.876, 14.69 , 21.102,\n",
       "        12.869, 11.143, 14.353,  7.188, 23.635,  9.265, 10.294, 14.31 ,\n",
       "        20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 , 16.106,\n",
       "        14.261,  9.749, 28.771, 13.167, 18.661, 11.816],\n",
       "       [ 8.755, 14.82 , 15.363,  7.108, 14.876, 14.69 , 21.102, 12.869,\n",
       "        11.143, 14.353,  7.188, 23.635,  9.265, 10.294, 14.31 , 20.102,\n",
       "        20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,\n",
       "         9.749, 28.771, 13.167, 18.661, 11.816, 13.967],\n",
       "       [14.82 , 15.363,  7.108, 14.876, 14.69 , 21.102, 12.869, 11.143,\n",
       "        14.353,  7.188, 23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,\n",
       "         4.624, 13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,  9.749,\n",
       "        28.771, 13.167, 18.661, 11.816, 13.967, 10.304],\n",
       "       [15.363,  7.108, 14.876, 14.69 , 21.102, 12.869, 11.143, 14.353,\n",
       "         7.188, 23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624,\n",
       "        13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,  9.749, 28.771,\n",
       "        13.167, 18.661, 11.816, 13.967, 10.304,  6.076],\n",
       "       [ 7.108, 14.876, 14.69 , 21.102, 12.869, 11.143, 14.353,  7.188,\n",
       "        23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773,\n",
       "        11.822, 15.561, 11.52 , 16.106, 14.261,  9.749, 28.771, 13.167,\n",
       "        18.661, 11.816, 13.967, 10.304,  6.076, 17.39 ],\n",
       "       [14.876, 14.69 , 21.102, 12.869, 11.143, 14.353,  7.188, 23.635,\n",
       "         9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822,\n",
       "        15.561, 11.52 , 16.106, 14.261,  9.749, 28.771, 13.167, 18.661,\n",
       "        11.816, 13.967, 10.304,  6.076, 17.39 , 13.229],\n",
       "       [14.69 , 21.102, 12.869, 11.143, 14.353,  7.188, 23.635,  9.265,\n",
       "        10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561,\n",
       "        11.52 , 16.106, 14.261,  9.749, 28.771, 13.167, 18.661, 11.816,\n",
       "        13.967, 10.304,  6.076, 17.39 , 13.229,  8.961],\n",
       "       [21.102, 12.869, 11.143, 14.353,  7.188, 23.635,  9.265, 10.294,\n",
       "        14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 ,\n",
       "        16.106, 14.261,  9.749, 28.771, 13.167, 18.661, 11.816, 13.967,\n",
       "        10.304,  6.076, 17.39 , 13.229,  8.961, 10.316],\n",
       "       [12.869, 11.143, 14.353,  7.188, 23.635,  9.265, 10.294, 14.31 ,\n",
       "        20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 , 16.106,\n",
       "        14.261,  9.749, 28.771, 13.167, 18.661, 11.816, 13.967, 10.304,\n",
       "         6.076, 17.39 , 13.229,  8.961, 10.316, 22.102],\n",
       "       [11.143, 14.353,  7.188, 23.635,  9.265, 10.294, 14.31 , 20.102,\n",
       "        20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,\n",
       "         9.749, 28.771, 13.167, 18.661, 11.816, 13.967, 10.304,  6.076,\n",
       "        17.39 , 13.229,  8.961, 10.316, 22.102,  3.073],\n",
       "       [14.353,  7.188, 23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,\n",
       "         4.624, 13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,  9.749,\n",
       "        28.771, 13.167, 18.661, 11.816, 13.967, 10.304,  6.076, 17.39 ,\n",
       "        13.229,  8.961, 10.316, 22.102,  3.073,  3.449],\n",
       "       [ 7.188, 23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624,\n",
       "        13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,  9.749, 28.771,\n",
       "        13.167, 18.661, 11.816, 13.967, 10.304,  6.076, 17.39 , 13.229,\n",
       "         8.961, 10.316, 22.102,  3.073,  3.449, 14.79 ],\n",
       "       [23.635,  9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773,\n",
       "        11.822, 15.561, 11.52 , 16.106, 14.261,  9.749, 28.771, 13.167,\n",
       "        18.661, 11.816, 13.967, 10.304,  6.076, 17.39 , 13.229,  8.961,\n",
       "        10.316, 22.102,  3.073,  3.449, 14.79 , 14.808],\n",
       "       [ 9.265, 10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822,\n",
       "        15.561, 11.52 , 16.106, 14.261,  9.749, 28.771, 13.167, 18.661,\n",
       "        11.816, 13.967, 10.304,  6.076, 17.39 , 13.229,  8.961, 10.316,\n",
       "        22.102,  3.073,  3.449, 14.79 , 14.808, 16.453],\n",
       "       [10.294, 14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561,\n",
       "        11.52 , 16.106, 14.261,  9.749, 28.771, 13.167, 18.661, 11.816,\n",
       "        13.967, 10.304,  6.076, 17.39 , 13.229,  8.961, 10.316, 22.102,\n",
       "         3.073,  3.449, 14.79 , 14.808, 16.453, 11.706],\n",
       "       [14.31 , 20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 ,\n",
       "        16.106, 14.261,  9.749, 28.771, 13.167, 18.661, 11.816, 13.967,\n",
       "        10.304,  6.076, 17.39 , 13.229,  8.961, 10.316, 22.102,  3.073,\n",
       "         3.449, 14.79 , 14.808, 16.453, 11.706, 17.414],\n",
       "       [20.102, 20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 , 16.106,\n",
       "        14.261,  9.749, 28.771, 13.167, 18.661, 11.816, 13.967, 10.304,\n",
       "         6.076, 17.39 , 13.229,  8.961, 10.316, 22.102,  3.073,  3.449,\n",
       "        14.79 , 14.808, 16.453, 11.706, 17.414, 13.229],\n",
       "       [20.5  ,  4.624, 13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,\n",
       "         9.749, 28.771, 13.167, 18.661, 11.816, 13.967, 10.304,  6.076,\n",
       "        17.39 , 13.229,  8.961, 10.316, 22.102,  3.073,  3.449, 14.79 ,\n",
       "        14.808, 16.453, 11.706, 17.414, 13.229,  8.698],\n",
       "       [ 4.624, 13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,  9.749,\n",
       "        28.771, 13.167, 18.661, 11.816, 13.967, 10.304,  6.076, 17.39 ,\n",
       "        13.229,  8.961, 10.316, 22.102,  3.073,  3.449, 14.79 , 14.808,\n",
       "        16.453, 11.706, 17.414, 13.229,  8.698, 12.335],\n",
       "       [13.773, 11.822, 15.561, 11.52 , 16.106, 14.261,  9.749, 28.771,\n",
       "        13.167, 18.661, 11.816, 13.967, 10.304,  6.076, 17.39 , 13.229,\n",
       "         8.961, 10.316, 22.102,  3.073,  3.449, 14.79 , 14.808, 16.453,\n",
       "        11.706, 17.414, 13.229,  8.698, 12.335, 12.38 ],\n",
       "       [11.822, 15.561, 11.52 , 16.106, 14.261,  9.749, 28.771, 13.167,\n",
       "        18.661, 11.816, 13.967, 10.304,  6.076, 17.39 , 13.229,  8.961,\n",
       "        10.316, 22.102,  3.073,  3.449, 14.79 , 14.808, 16.453, 11.706,\n",
       "        17.414, 13.229,  8.698, 12.335, 12.38 , 20.155],\n",
       "       [15.561, 11.52 , 16.106, 14.261,  9.749, 28.771, 13.167, 18.661,\n",
       "        11.816, 13.967, 10.304,  6.076, 17.39 , 13.229,  8.961, 10.316,\n",
       "        22.102,  3.073,  3.449, 14.79 , 14.808, 16.453, 11.706, 17.414,\n",
       "        13.229,  8.698, 12.335, 12.38 , 20.155, 13.996],\n",
       "       [11.52 , 16.106, 14.261,  9.749, 28.771, 13.167, 18.661, 11.816,\n",
       "        13.967, 10.304,  6.076, 17.39 , 13.229,  8.961, 10.316, 22.102,\n",
       "         3.073,  3.449, 14.79 , 14.808, 16.453, 11.706, 17.414, 13.229,\n",
       "         8.698, 12.335, 12.38 , 20.155, 13.996, 15.341],\n",
       "       [16.106, 14.261,  9.749, 28.771, 13.167, 18.661, 11.816, 13.967,\n",
       "        10.304,  6.076, 17.39 , 13.229,  8.961, 10.316, 22.102,  3.073,\n",
       "         3.449, 14.79 , 14.808, 16.453, 11.706, 17.414, 13.229,  8.698,\n",
       "        12.335, 12.38 , 20.155, 13.996, 15.341,  9.206],\n",
       "       [14.261,  9.749, 28.771, 13.167, 18.661, 11.816, 13.967, 10.304,\n",
       "         6.076, 17.39 , 13.229,  8.961, 10.316, 22.102,  3.073,  3.449,\n",
       "        14.79 , 14.808, 16.453, 11.706, 17.414, 13.229,  8.698, 12.335,\n",
       "        12.38 , 20.155, 13.996, 15.341,  9.206, 12.771]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = pd.DataFrame(columns=['File_name','RMSE_ERROR_CNN','RMSE_ERROR_LSTM','RMSE_ERROR_CNN+LSTM','RMSE_ERROR_DNN','MSE','MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/CNN+LSTM_forecast_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Train on 91 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 13.1917 - mse: 13.1917 - mae: 3.2152 - val_loss: 7.2414 - val_mse: 7.2414 - val_mae: 2.5033\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 205us/step - loss: 10.8451 - mse: 10.8451 - mae: 2.8368 - val_loss: 5.6850 - val_mse: 5.6850 - val_mae: 2.1833\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 257us/step - loss: 8.8952 - mse: 8.8952 - mae: 2.4724 - val_loss: 4.2346 - val_mse: 4.2346 - val_mae: 1.8538\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 192us/step - loss: 7.2965 - mse: 7.2965 - mae: 2.1663 - val_loss: 3.1078 - val_mse: 3.1078 - val_mae: 1.5628\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 279us/step - loss: 6.0139 - mse: 6.0139 - mae: 1.9297 - val_loss: 2.2450 - val_mse: 2.2450 - val_mae: 1.2776\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 243us/step - loss: 5.0110 - mse: 5.0110 - mae: 1.7662 - val_loss: 1.6180 - val_mse: 1.6180 - val_mae: 1.0265\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 360us/step - loss: 4.3093 - mse: 4.3093 - mae: 1.6559 - val_loss: 1.2277 - val_mse: 1.2277 - val_mae: 0.8888\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 290us/step - loss: 3.8953 - mse: 3.8953 - mae: 1.5989 - val_loss: 1.0300 - val_mse: 1.0300 - val_mae: 0.8329\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 396us/step - loss: 3.6923 - mse: 3.6923 - mae: 1.5759 - val_loss: 0.9733 - val_mse: 0.9733 - val_mae: 0.8178\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 234us/step - loss: 3.6207 - mse: 3.6207 - mae: 1.5661 - val_loss: 0.9941 - val_mse: 0.9941 - val_mae: 0.8054\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 372us/step - loss: 3.6088 - mse: 3.6088 - mae: 1.5599 - val_loss: 1.0379 - val_mse: 1.0379 - val_mae: 0.8294\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 173us/step - loss: 3.5978 - mse: 3.5978 - mae: 1.5508 - val_loss: 1.0711 - val_mse: 1.0711 - val_mae: 0.8429\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 166us/step - loss: 3.5569 - mse: 3.5569 - mae: 1.5378 - val_loss: 1.0817 - val_mse: 1.0817 - val_mae: 0.8474\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 306us/step - loss: 3.4840 - mse: 3.4840 - mae: 1.5192 - val_loss: 1.0712 - val_mse: 1.0712 - val_mae: 0.8421\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 419us/step - loss: 3.3866 - mse: 3.3866 - mae: 1.4964 - val_loss: 1.0424 - val_mse: 1.0424 - val_mae: 0.8278\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 227us/step - loss: 3.2766 - mse: 3.2766 - mae: 1.4733 - val_loss: 1.0036 - val_mse: 1.0036 - val_mae: 0.8096\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 353us/step - loss: 3.1652 - mse: 3.1652 - mae: 1.4494 - val_loss: 0.9644 - val_mse: 0.9644 - val_mae: 0.7964\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 233us/step - loss: 3.0605 - mse: 3.0605 - mae: 1.4266 - val_loss: 0.9382 - val_mse: 0.9382 - val_mae: 0.7932\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 246us/step - loss: 2.9680 - mse: 2.9680 - mae: 1.4054 - val_loss: 0.9204 - val_mse: 0.9204 - val_mae: 0.7913\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 328us/step - loss: 2.8874 - mse: 2.8874 - mae: 1.3858 - val_loss: 0.9130 - val_mse: 0.9130 - val_mae: 0.7902\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 271us/step - loss: 2.8140 - mse: 2.8140 - mae: 1.3673 - val_loss: 0.9127 - val_mse: 0.9127 - val_mae: 0.7895\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 279us/step - loss: 2.7458 - mse: 2.7458 - mae: 1.3494 - val_loss: 0.9164 - val_mse: 0.9164 - val_mae: 0.7906\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 263us/step - loss: 2.6810 - mse: 2.6810 - mae: 1.3321 - val_loss: 0.9249 - val_mse: 0.9249 - val_mae: 0.7948\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 208us/step - loss: 2.6172 - mse: 2.6172 - mae: 1.3156 - val_loss: 0.9349 - val_mse: 0.9349 - val_mae: 0.7985\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 343us/step - loss: 2.5590 - mse: 2.5590 - mae: 1.3019 - val_loss: 0.9501 - val_mse: 0.9501 - val_mae: 0.8049\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 207us/step - loss: 2.5150 - mse: 2.5150 - mae: 1.2907 - val_loss: 0.9695 - val_mse: 0.9695 - val_mae: 0.8128\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 252us/step - loss: 2.4745 - mse: 2.4745 - mae: 1.2798 - val_loss: 0.9920 - val_mse: 0.9920 - val_mae: 0.8219\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 142us/step - loss: 2.4489 - mse: 2.4489 - mae: 1.2723 - val_loss: 1.0223 - val_mse: 1.0223 - val_mae: 0.8313\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 201us/step - loss: 2.4338 - mse: 2.4338 - mae: 1.2676 - val_loss: 1.0528 - val_mse: 1.0528 - val_mae: 0.8395\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 196us/step - loss: 2.4211 - mse: 2.4211 - mae: 1.2647 - val_loss: 1.0805 - val_mse: 1.0805 - val_mae: 0.8464\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 246us/step - loss: 2.4119 - mse: 2.4119 - mae: 1.2622 - val_loss: 1.1034 - val_mse: 1.1034 - val_mae: 0.8537\n",
      "1\n",
      "[1]\n",
      "Train on 96 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 21.0499 - mse: 21.0499 - mae: 4.3226 - val_loss: 15.6111 - val_mse: 15.6111 - val_mae: 3.7545\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 117us/step - loss: 18.4237 - mse: 18.4237 - mae: 4.0193 - val_loss: 13.5300 - val_mse: 13.5300 - val_mae: 3.4692\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 212us/step - loss: 16.0121 - mse: 16.0121 - mae: 3.7187 - val_loss: 11.6401 - val_mse: 11.6401 - val_mae: 3.1879\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 285us/step - loss: 13.9314 - mse: 13.9314 - mae: 3.4349 - val_loss: 9.9678 - val_mse: 9.9678 - val_mae: 2.9145\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 249us/step - loss: 12.1338 - mse: 12.1338 - mae: 3.1682 - val_loss: 8.5480 - val_mse: 8.5480 - val_mae: 2.6592\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 214us/step - loss: 10.6049 - mse: 10.6049 - mae: 2.9236 - val_loss: 7.4390 - val_mse: 7.4390 - val_mae: 2.4417\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 306us/step - loss: 9.3565 - mse: 9.3565 - mae: 2.7121 - val_loss: 6.5777 - val_mse: 6.5777 - val_mae: 2.2585\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 202us/step - loss: 8.3625 - mse: 8.3625 - mae: 2.5347 - val_loss: 5.9911 - val_mse: 5.9911 - val_mae: 2.1221\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 267us/step - loss: 7.5982 - mse: 7.5982 - mae: 2.3933 - val_loss: 5.5680 - val_mse: 5.5680 - val_mae: 2.0115\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 334us/step - loss: 6.9373 - mse: 6.9373 - mae: 2.2660 - val_loss: 5.2162 - val_mse: 5.2162 - val_mae: 1.9109\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 263us/step - loss: 6.3776 - mse: 6.3776 - mae: 2.1446 - val_loss: 4.8791 - val_mse: 4.8791 - val_mae: 1.8041\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 249us/step - loss: 5.8388 - mse: 5.8388 - mae: 2.0164 - val_loss: 4.5007 - val_mse: 4.5007 - val_mae: 1.7037\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 205us/step - loss: 5.3161 - mse: 5.3161 - mae: 1.8806 - val_loss: 4.0733 - val_mse: 4.0733 - val_mae: 1.6097\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 267us/step - loss: 4.8117 - mse: 4.8117 - mae: 1.7477 - val_loss: 3.6653 - val_mse: 3.6653 - val_mae: 1.5063\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 180us/step - loss: 4.3247 - mse: 4.3247 - mae: 1.6130 - val_loss: 3.2863 - val_mse: 3.2863 - val_mae: 1.3909\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 146us/step - loss: 3.8682 - mse: 3.8682 - mae: 1.4842 - val_loss: 2.9412 - val_mse: 2.9412 - val_mae: 1.2833\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 312us/step - loss: 3.4440 - mse: 3.4440 - mae: 1.3767 - val_loss: 2.6523 - val_mse: 2.6523 - val_mae: 1.1854\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 200us/step - loss: 3.0781 - mse: 3.0781 - mae: 1.2970 - val_loss: 2.4190 - val_mse: 2.4190 - val_mae: 1.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 226us/step - loss: 2.7881 - mse: 2.7881 - mae: 1.2310 - val_loss: 2.2619 - val_mse: 2.2619 - val_mae: 1.0534\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 270us/step - loss: 2.5817 - mse: 2.5817 - mae: 1.1900 - val_loss: 2.1655 - val_mse: 2.1655 - val_mae: 1.0088\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 211us/step - loss: 2.4500 - mse: 2.4500 - mae: 1.1815 - val_loss: 2.1162 - val_mse: 2.1162 - val_mae: 1.0059\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 2.3812 - mse: 2.3812 - mae: 1.1909 - val_loss: 2.0995 - val_mse: 2.0995 - val_mae: 1.0237\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 252us/step - loss: 2.3465 - mse: 2.3465 - mae: 1.1983 - val_loss: 2.0932 - val_mse: 2.0932 - val_mae: 1.0479\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 235us/step - loss: 2.3121 - mse: 2.3121 - mae: 1.1972 - val_loss: 2.0808 - val_mse: 2.0808 - val_mae: 1.0536\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 262us/step - loss: 2.2667 - mse: 2.2667 - mae: 1.1876 - val_loss: 2.0546 - val_mse: 2.0546 - val_mae: 1.0466\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 128us/step - loss: 2.2160 - mse: 2.2160 - mae: 1.1744 - val_loss: 2.0193 - val_mse: 2.0193 - val_mae: 1.0328\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 231us/step - loss: 2.1698 - mse: 2.1698 - mae: 1.1598 - val_loss: 1.9840 - val_mse: 1.9840 - val_mae: 1.0220\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 632us/step - loss: 2.1284 - mse: 2.1284 - mae: 1.1468 - val_loss: 1.9557 - val_mse: 1.9557 - val_mae: 1.0118\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 164us/step - loss: 2.0907 - mse: 2.0906 - mae: 1.1352 - val_loss: 1.9328 - val_mse: 1.9328 - val_mae: 1.0027\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 212us/step - loss: 2.0556 - mse: 2.0556 - mae: 1.1241 - val_loss: 1.9183 - val_mse: 1.9183 - val_mae: 0.9981\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 311us/step - loss: 2.0254 - mse: 2.0254 - mae: 1.1142 - val_loss: 1.9077 - val_mse: 1.9077 - val_mae: 0.9970\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 292us/step - loss: 1.9989 - mse: 1.9989 - mae: 1.1059 - val_loss: 1.9031 - val_mse: 1.9031 - val_mae: 0.9993\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 287us/step - loss: 1.9751 - mse: 1.9751 - mae: 1.0991 - val_loss: 1.8987 - val_mse: 1.8987 - val_mae: 1.0026\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 230us/step - loss: 1.9532 - mse: 1.9532 - mae: 1.0936 - val_loss: 1.8939 - val_mse: 1.8939 - val_mae: 1.0055\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 260us/step - loss: 1.9332 - mse: 1.9332 - mae: 1.0888 - val_loss: 1.8890 - val_mse: 1.8890 - val_mae: 1.0079\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 295us/step - loss: 1.9139 - mse: 1.9139 - mae: 1.0838 - val_loss: 1.8797 - val_mse: 1.8797 - val_mae: 1.0081\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 257us/step - loss: 1.8939 - mse: 1.8939 - mae: 1.0781 - val_loss: 1.8677 - val_mse: 1.8677 - val_mae: 1.0075\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 336us/step - loss: 1.8743 - mse: 1.8743 - mae: 1.0721 - val_loss: 1.8605 - val_mse: 1.8605 - val_mae: 1.0089\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 262us/step - loss: 1.8560 - mse: 1.8560 - mae: 1.0663 - val_loss: 1.8565 - val_mse: 1.8565 - val_mae: 1.0113\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 406us/step - loss: 1.8393 - mse: 1.8393 - mae: 1.0610 - val_loss: 1.8522 - val_mse: 1.8522 - val_mae: 1.0136\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 114us/step - loss: 1.8238 - mse: 1.8238 - mae: 1.0560 - val_loss: 1.8466 - val_mse: 1.8466 - val_mae: 1.0153\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 446us/step - loss: 1.8091 - mse: 1.8091 - mae: 1.0517 - val_loss: 1.8410 - val_mse: 1.8410 - val_mae: 1.0168\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 415us/step - loss: 1.7950 - mse: 1.7950 - mae: 1.0474 - val_loss: 1.8335 - val_mse: 1.8335 - val_mae: 1.0176\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 412us/step - loss: 1.7797 - mse: 1.7797 - mae: 1.0426 - val_loss: 1.8248 - val_mse: 1.8248 - val_mae: 1.0182\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 240us/step - loss: 1.7642 - mse: 1.7642 - mae: 1.0375 - val_loss: 1.8178 - val_mse: 1.8178 - val_mae: 1.0194\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 229us/step - loss: 1.7494 - mse: 1.7494 - mae: 1.0330 - val_loss: 1.8116 - val_mse: 1.8116 - val_mae: 1.0207\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 194us/step - loss: 1.7346 - mse: 1.7346 - mae: 1.0286 - val_loss: 1.8076 - val_mse: 1.8076 - val_mae: 1.0224\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 173us/step - loss: 1.7205 - mse: 1.7205 - mae: 1.0248 - val_loss: 1.8048 - val_mse: 1.8048 - val_mae: 1.0244\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 220us/step - loss: 1.7068 - mse: 1.7068 - mae: 1.0211 - val_loss: 1.8032 - val_mse: 1.8032 - val_mae: 1.0269\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 279us/step - loss: 1.6937 - mse: 1.6937 - mae: 1.0176 - val_loss: 1.8016 - val_mse: 1.8016 - val_mae: 1.0285\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 275us/step - loss: 1.6806 - mse: 1.6806 - mae: 1.0141 - val_loss: 1.8015 - val_mse: 1.8015 - val_mae: 1.0304\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 170us/step - loss: 1.6691 - mse: 1.6691 - mae: 1.0112 - val_loss: 1.8003 - val_mse: 1.8003 - val_mae: 1.0319\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 231us/step - loss: 1.6568 - mse: 1.6568 - mae: 1.0079 - val_loss: 1.7981 - val_mse: 1.7981 - val_mae: 1.0329\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 211us/step - loss: 1.6444 - mse: 1.6444 - mae: 1.0044 - val_loss: 1.7959 - val_mse: 1.7959 - val_mae: 1.0333\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 174us/step - loss: 1.6308 - mse: 1.6308 - mae: 1.0003 - val_loss: 1.7943 - val_mse: 1.7943 - val_mae: 1.0333\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 271us/step - loss: 1.6165 - mse: 1.6165 - mae: 0.9957 - val_loss: 1.7921 - val_mse: 1.7921 - val_mae: 1.0320\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 328us/step - loss: 1.6017 - mse: 1.6017 - mae: 0.9911 - val_loss: 1.7909 - val_mse: 1.7909 - val_mae: 1.0307\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 261us/step - loss: 1.5869 - mse: 1.5869 - mae: 0.9862 - val_loss: 1.7920 - val_mse: 1.7920 - val_mae: 1.0304\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.5287 - mse: 1.5287 - mae: 0.975 - 0s 300us/step - loss: 1.5736 - mse: 1.5736 - mae: 0.9819 - val_loss: 1.7933 - val_mse: 1.7933 - val_mae: 1.0305\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 214us/step - loss: 1.5613 - mse: 1.5613 - mae: 0.9782 - val_loss: 1.7951 - val_mse: 1.7951 - val_mae: 1.0316\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 179us/step - loss: 1.5503 - mse: 1.5503 - mae: 0.9751 - val_loss: 1.7990 - val_mse: 1.7990 - val_mae: 1.0341\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 209us/step - loss: 1.5398 - mse: 1.5398 - mae: 0.9723 - val_loss: 1.8033 - val_mse: 1.8033 - val_mae: 1.0357\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 192us/step - loss: 1.5283 - mse: 1.5283 - mae: 0.9685 - val_loss: 1.8064 - val_mse: 1.8064 - val_mae: 1.0349\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 156us/step - loss: 1.5159 - mse: 1.5159 - mae: 0.9635 - val_loss: 1.8070 - val_mse: 1.8070 - val_mae: 1.0334\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 208us/step - loss: 1.5039 - mse: 1.5039 - mae: 0.9592 - val_loss: 1.8072 - val_mse: 1.8072 - val_mae: 1.0321\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 230us/step - loss: 1.4921 - mse: 1.4921 - mae: 0.9547 - val_loss: 1.8101 - val_mse: 1.8101 - val_mae: 1.0322\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 213us/step - loss: 1.4813 - mse: 1.4813 - mae: 0.9506 - val_loss: 1.8161 - val_mse: 1.8161 - val_mae: 1.0354\n",
      "2\n",
      "[2]\n",
      "Train on 70 samples, validate on 11 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 3.6926 - mse: 3.6926 - mae: 1.5754 - val_loss: 3.3558 - val_mse: 3.3558 - val_mae: 1.7528\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 318us/step - loss: 3.3860 - mse: 3.3860 - mae: 1.4616 - val_loss: 2.8663 - val_mse: 2.8663 - val_mae: 1.6071\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 234us/step - loss: 3.0636 - mse: 3.0636 - mae: 1.3371 - val_loss: 2.2887 - val_mse: 2.2887 - val_mae: 1.4133\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 203us/step - loss: 2.7547 - mse: 2.7547 - mae: 1.2217 - val_loss: 1.7143 - val_mse: 1.7143 - val_mae: 1.1758\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 487us/step - loss: 2.4479 - mse: 2.4479 - mae: 1.1236 - val_loss: 1.2030 - val_mse: 1.2030 - val_mae: 0.9328\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 2.1415 - mse: 2.1415 - mae: 1.0331 - val_loss: 0.8286 - val_mse: 0.8286 - val_mae: 0.7528\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 292us/step - loss: 1.8998 - mse: 1.8998 - mae: 0.9817 - val_loss: 0.5885 - val_mse: 0.5885 - val_mae: 0.6404\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 204us/step - loss: 1.7453 - mse: 1.7453 - mae: 0.9861 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.5996\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 240us/step - loss: 1.6730 - mse: 1.6730 - mae: 1.0137 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.6157\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 273us/step - loss: 1.6490 - mse: 1.6490 - mae: 1.0348 - val_loss: 0.4714 - val_mse: 0.4714 - val_mae: 0.6222\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 171us/step - loss: 1.6331 - mse: 1.6331 - mae: 1.0418 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.6205\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 234us/step - loss: 1.6054 - mse: 1.6054 - mae: 1.0337 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.6126\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 244us/step - loss: 1.5677 - mse: 1.5677 - mae: 1.0122 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.6006\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 377us/step - loss: 1.5310 - mse: 1.5310 - mae: 0.9874 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.5871\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 325us/step - loss: 1.5031 - mse: 1.5031 - mae: 0.9626 - val_loss: 0.4298 - val_mse: 0.4298 - val_mae: 0.5740\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 178us/step - loss: 1.4842 - mse: 1.4842 - mae: 0.9399 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.5628\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 267us/step - loss: 1.4697 - mse: 1.4697 - mae: 0.9226 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.5591\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 205us/step - loss: 1.4551 - mse: 1.4551 - mae: 0.9094 - val_loss: 0.4427 - val_mse: 0.4427 - val_mae: 0.5593\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 150us/step - loss: 1.4378 - mse: 1.4378 - mae: 0.8992 - val_loss: 0.4404 - val_mse: 0.4404 - val_mae: 0.5585\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 430us/step - loss: 1.4171 - mse: 1.4171 - mae: 0.8923 - val_loss: 0.4349 - val_mse: 0.4349 - val_mae: 0.5571\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 157us/step - loss: 1.3944 - mse: 1.3944 - mae: 0.8885 - val_loss: 0.4287 - val_mse: 0.4287 - val_mae: 0.5555\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 157us/step - loss: 1.3715 - mse: 1.3715 - mae: 0.8863 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.5539\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 300us/step - loss: 1.3495 - mse: 1.3495 - mae: 0.8844 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.5531\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 160us/step - loss: 1.3297 - mse: 1.3297 - mae: 0.8821 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.5533\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 412us/step - loss: 1.3114 - mse: 1.3114 - mae: 0.8785 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.5547\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 283us/step - loss: 1.2946 - mse: 1.2946 - mae: 0.8730 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.5573\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 366us/step - loss: 1.2790 - mse: 1.2790 - mae: 0.8658 - val_loss: 0.4291 - val_mse: 0.4291 - val_mae: 0.5608\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 247us/step - loss: 1.2642 - mse: 1.2642 - mae: 0.8580 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.5649\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 283us/step - loss: 1.2507 - mse: 1.2507 - mae: 0.8504 - val_loss: 0.4392 - val_mse: 0.4392 - val_mae: 0.5690\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 364us/step - loss: 1.2382 - mse: 1.2382 - mae: 0.8431 - val_loss: 0.4454 - val_mse: 0.4454 - val_mae: 0.5737\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 240us/step - loss: 1.2260 - mse: 1.2260 - mae: 0.8362 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.5795\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 362us/step - loss: 1.2139 - mse: 1.2139 - mae: 0.8310 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.5848\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 249us/step - loss: 1.2008 - mse: 1.2008 - mae: 0.8257 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.5884\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 235us/step - loss: 1.1881 - mse: 1.1881 - mae: 0.8206 - val_loss: 0.4744 - val_mse: 0.4744 - val_mae: 0.5898\n",
      "3\n",
      "[3]\n",
      "Train on 87 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 3.6871 - mse: 3.6871 - mae: 1.2926 - val_loss: 2.2393 - val_mse: 2.2393 - val_mae: 1.1143\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 158us/step - loss: 3.3895 - mse: 3.3895 - mae: 1.2605 - val_loss: 2.0501 - val_mse: 2.0501 - val_mae: 1.1046\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 213us/step - loss: 3.2200 - mse: 3.2200 - mae: 1.2503 - val_loss: 1.9323 - val_mse: 1.9323 - val_mae: 1.0964\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 139us/step - loss: 3.1098 - mse: 3.1098 - mae: 1.2508 - val_loss: 1.8834 - val_mse: 1.8834 - val_mae: 1.0978\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 127us/step - loss: 3.0225 - mse: 3.0225 - mae: 1.2428 - val_loss: 1.8830 - val_mse: 1.8830 - val_mae: 1.1006\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 123us/step - loss: 2.9382 - mse: 2.9382 - mae: 1.2277 - val_loss: 1.9064 - val_mse: 1.9064 - val_mae: 1.1028\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 129us/step - loss: 2.8555 - mse: 2.8555 - mae: 1.2087 - val_loss: 1.9394 - val_mse: 1.9394 - val_mae: 1.1025\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 173us/step - loss: 2.7734 - mse: 2.7734 - mae: 1.1849 - val_loss: 1.9807 - val_mse: 1.9807 - val_mae: 1.0993\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 175us/step - loss: 2.7028 - mse: 2.7028 - mae: 1.1587 - val_loss: 2.0165 - val_mse: 2.0165 - val_mae: 1.0948\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 189us/step - loss: 2.6622 - mse: 2.6622 - mae: 1.1374 - val_loss: 2.0271 - val_mse: 2.0271 - val_mae: 1.0880\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 2.6303 - mse: 2.6303 - mae: 1.1233 - val_loss: 2.0164 - val_mse: 2.0164 - val_mae: 1.0804\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 201us/step - loss: 2.5957 - mse: 2.5957 - mae: 1.1183 - val_loss: 1.9984 - val_mse: 1.9984 - val_mae: 1.0746\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 278us/step - loss: 2.5611 - mse: 2.5611 - mae: 1.1186 - val_loss: 1.9813 - val_mse: 1.9813 - val_mae: 1.0770\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 225us/step - loss: 2.5287 - mse: 2.5287 - mae: 1.1202 - val_loss: 1.9673 - val_mse: 1.9673 - val_mae: 1.0825\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 295us/step - loss: 2.4988 - mse: 2.4988 - mae: 1.1205 - val_loss: 1.9579 - val_mse: 1.9579 - val_mae: 1.0859\n",
      "4\n",
      "[4]\n",
      "Train on 93 samples, validate on 16 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 9.6970 - mse: 9.6970 - mae: 2.8772 - val_loss: 6.3864 - val_mse: 6.3864 - val_mae: 2.4070\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 324us/step - loss: 7.7243 - mse: 7.7243 - mae: 2.5138 - val_loss: 4.8899 - val_mse: 4.8899 - val_mae: 2.0688\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 234us/step - loss: 6.1111 - mse: 6.1111 - mae: 2.1773 - val_loss: 3.6787 - val_mse: 3.6787 - val_mae: 1.7490\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 288us/step - loss: 4.8117 - mse: 4.8117 - mae: 1.8656 - val_loss: 2.7069 - val_mse: 2.7069 - val_mae: 1.4364\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 258us/step - loss: 3.7918 - mse: 3.7918 - mae: 1.5776 - val_loss: 1.9882 - val_mse: 1.9882 - val_mae: 1.1489\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 177us/step - loss: 3.0306 - mse: 3.0306 - mae: 1.3227 - val_loss: 1.4647 - val_mse: 1.4647 - val_mae: 0.9090\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 216us/step - loss: 2.4600 - mse: 2.4600 - mae: 1.1338 - val_loss: 1.1619 - val_mse: 1.1619 - val_mae: 0.7643\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 205us/step - loss: 2.0687 - mse: 2.0687 - mae: 1.0187 - val_loss: 0.9866 - val_mse: 0.9866 - val_mae: 0.7251\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 299us/step - loss: 1.8064 - mse: 1.8064 - mae: 0.9543 - val_loss: 0.8997 - val_mse: 0.8997 - val_mae: 0.7476\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 258us/step - loss: 1.6444 - mse: 1.6444 - mae: 0.9278 - val_loss: 0.8740 - val_mse: 0.8740 - val_mae: 0.7777\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 260us/step - loss: 1.5610 - mse: 1.5610 - mae: 0.9202 - val_loss: 0.8922 - val_mse: 0.8922 - val_mae: 0.8155\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 246us/step - loss: 1.5317 - mse: 1.5317 - mae: 0.9214 - val_loss: 0.9325 - val_mse: 0.9325 - val_mae: 0.8627\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 222us/step - loss: 1.5328 - mse: 1.5328 - mae: 0.9309 - val_loss: 0.9776 - val_mse: 0.9776 - val_mae: 0.8993\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 222us/step - loss: 1.5448 - mse: 1.5448 - mae: 0.9434 - val_loss: 1.0138 - val_mse: 1.0138 - val_mae: 0.9235\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 192us/step - loss: 1.5554 - mse: 1.5554 - mae: 0.9532 - val_loss: 1.0332 - val_mse: 1.0332 - val_mae: 0.9356\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 262us/step - loss: 1.5570 - mse: 1.5570 - mae: 0.9578 - val_loss: 1.0397 - val_mse: 1.0397 - val_mae: 0.9401\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 284us/step - loss: 1.5520 - mse: 1.5520 - mae: 0.9580 - val_loss: 1.0341 - val_mse: 1.0341 - val_mae: 0.9373\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 224us/step - loss: 1.5426 - mse: 1.5426 - mae: 0.9548 - val_loss: 1.0225 - val_mse: 1.0225 - val_mae: 0.9309\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 178us/step - loss: 1.5300 - mse: 1.5300 - mae: 0.9502 - val_loss: 1.0098 - val_mse: 1.0098 - val_mae: 0.9234\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 216us/step - loss: 1.5168 - mse: 1.5168 - mae: 0.9460 - val_loss: 0.9980 - val_mse: 0.9980 - val_mae: 0.9157\n",
      "5\n",
      "[5]\n",
      "Train on 70 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 14.3941 - mse: 14.3941 - mae: 3.3986 - val_loss: 8.8016 - val_mse: 8.8016 - val_mae: 2.6838\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 566us/step - loss: 10.3307 - mse: 10.3307 - mae: 2.8331 - val_loss: 5.9105 - val_mse: 5.9105 - val_mae: 2.0966\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 467us/step - loss: 7.2693 - mse: 7.2693 - mae: 2.3392 - val_loss: 3.8844 - val_mse: 3.8844 - val_mae: 1.6025\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 423us/step - loss: 5.1098 - mse: 5.1098 - mae: 1.9016 - val_loss: 2.5798 - val_mse: 2.5798 - val_mae: 1.3874\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 371us/step - loss: 3.7241 - mse: 3.7241 - mae: 1.5869 - val_loss: 1.7767 - val_mse: 1.7767 - val_mae: 1.1950\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 463us/step - loss: 2.9011 - mse: 2.9011 - mae: 1.3818 - val_loss: 1.3423 - val_mse: 1.3423 - val_mae: 1.0517\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 242us/step - loss: 2.4308 - mse: 2.4308 - mae: 1.2343 - val_loss: 1.1004 - val_mse: 1.1004 - val_mae: 0.9292\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 224us/step - loss: 2.1848 - mse: 2.1848 - mae: 1.1433 - val_loss: 1.0257 - val_mse: 1.0257 - val_mae: 0.8453\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 515us/step - loss: 2.0837 - mse: 2.0837 - mae: 1.0834 - val_loss: 1.0292 - val_mse: 1.0292 - val_mae: 0.8353\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 289us/step - loss: 2.0611 - mse: 2.0611 - mae: 1.0449 - val_loss: 1.0610 - val_mse: 1.0610 - val_mae: 0.8251\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 242us/step - loss: 2.0718 - mse: 2.0718 - mae: 1.0251 - val_loss: 1.0936 - val_mse: 1.0936 - val_mae: 0.8329\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 255us/step - loss: 2.0864 - mse: 2.0864 - mae: 1.0144 - val_loss: 1.1106 - val_mse: 1.1106 - val_mae: 0.8403\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 320us/step - loss: 2.0923 - mse: 2.0923 - mae: 1.0077 - val_loss: 1.1103 - val_mse: 1.1103 - val_mae: 0.8415\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 323us/step - loss: 2.0863 - mse: 2.0863 - mae: 1.0042 - val_loss: 1.0961 - val_mse: 1.0961 - val_mae: 0.8385\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 368us/step - loss: 2.0710 - mse: 2.0710 - mae: 1.0029 - val_loss: 1.0718 - val_mse: 1.0718 - val_mae: 0.8324\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 326us/step - loss: 2.0501 - mse: 2.0501 - mae: 1.0031 - val_loss: 1.0417 - val_mse: 1.0417 - val_mae: 0.8232\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 266us/step - loss: 2.0273 - mse: 2.0273 - mae: 1.0045 - val_loss: 1.0110 - val_mse: 1.0110 - val_mae: 0.8126\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 314us/step - loss: 2.0053 - mse: 2.0053 - mae: 1.0069 - val_loss: 0.9834 - val_mse: 0.9834 - val_mae: 0.8020\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 256us/step - loss: 1.9861 - mse: 1.9861 - mae: 1.0108 - val_loss: 0.9620 - val_mse: 0.9620 - val_mae: 0.7926\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 442us/step - loss: 1.9710 - mse: 1.9710 - mae: 1.0149 - val_loss: 0.9449 - val_mse: 0.9449 - val_mae: 0.7839\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 294us/step - loss: 1.9596 - mse: 1.9596 - mae: 1.0195 - val_loss: 0.9313 - val_mse: 0.9313 - val_mae: 0.7760\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 510us/step - loss: 1.9508 - mse: 1.9508 - mae: 1.0231 - val_loss: 0.9204 - val_mse: 0.9204 - val_mae: 0.7704\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 428us/step - loss: 1.9436 - mse: 1.9436 - mae: 1.0256 - val_loss: 0.9120 - val_mse: 0.9120 - val_mae: 0.7689\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 369us/step - loss: 1.9367 - mse: 1.9367 - mae: 1.0272 - val_loss: 0.9063 - val_mse: 0.9063 - val_mae: 0.7686\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 339us/step - loss: 1.9301 - mse: 1.9301 - mae: 1.0278 - val_loss: 0.9025 - val_mse: 0.9025 - val_mae: 0.7685\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 352us/step - loss: 1.9233 - mse: 1.9233 - mae: 1.0274 - val_loss: 0.8995 - val_mse: 0.8995 - val_mae: 0.7677\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 233us/step - loss: 1.9166 - mse: 1.9166 - mae: 1.0262 - val_loss: 0.8969 - val_mse: 0.8969 - val_mae: 0.7661\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 352us/step - loss: 1.9097 - mse: 1.9097 - mae: 1.0244 - val_loss: 0.8948 - val_mse: 0.8948 - val_mae: 0.7651\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 1.9025 - mse: 1.9025 - mae: 1.0221 - val_loss: 0.8931 - val_mse: 0.8931 - val_mae: 0.7646\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 376us/step - loss: 1.8951 - mse: 1.8951 - mae: 1.0195 - val_loss: 0.8918 - val_mse: 0.8918 - val_mae: 0.7643\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 343us/step - loss: 1.8876 - mse: 1.8876 - mae: 1.0169 - val_loss: 0.8907 - val_mse: 0.8907 - val_mae: 0.7640\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.0506 - mse: 3.0506 - mae: 1.263 - 0s 310us/step - loss: 1.8801 - mse: 1.8801 - mae: 1.0142 - val_loss: 0.8897 - val_mse: 0.8897 - val_mae: 0.7637\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 460us/step - loss: 1.8725 - mse: 1.8725 - mae: 1.0115 - val_loss: 0.8887 - val_mse: 0.8887 - val_mae: 0.7632\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 260us/step - loss: 1.8650 - mse: 1.8650 - mae: 1.0088 - val_loss: 0.8875 - val_mse: 0.8875 - val_mae: 0.7625\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 0s 304us/step - loss: 1.8574 - mse: 1.8574 - mae: 1.0063 - val_loss: 0.8864 - val_mse: 0.8864 - val_mae: 0.7619\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 0s 285us/step - loss: 1.8497 - mse: 1.8497 - mae: 1.0037 - val_loss: 0.8852 - val_mse: 0.8852 - val_mae: 0.7613\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 0s 316us/step - loss: 1.8419 - mse: 1.8419 - mae: 1.0013 - val_loss: 0.8829 - val_mse: 0.8829 - val_mae: 0.7603\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 0s 323us/step - loss: 1.8353 - mse: 1.8353 - mae: 0.9989 - val_loss: 0.8809 - val_mse: 0.8809 - val_mae: 0.7593\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 0s 296us/step - loss: 1.8291 - mse: 1.8291 - mae: 0.9967 - val_loss: 0.8790 - val_mse: 0.8790 - val_mae: 0.7585\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 0s 410us/step - loss: 1.8229 - mse: 1.8229 - mae: 0.9946 - val_loss: 0.8766 - val_mse: 0.8766 - val_mae: 0.7575\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 0s 335us/step - loss: 1.8165 - mse: 1.8165 - mae: 0.9925 - val_loss: 0.8742 - val_mse: 0.8742 - val_mae: 0.7564\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 0s 277us/step - loss: 1.8101 - mse: 1.8101 - mae: 0.9904 - val_loss: 0.8717 - val_mse: 0.8717 - val_mae: 0.7554\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 0s 407us/step - loss: 1.8037 - mse: 1.8037 - mae: 0.9884 - val_loss: 0.8693 - val_mse: 0.8693 - val_mae: 0.7544\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 0s 300us/step - loss: 1.7971 - mse: 1.7971 - mae: 0.9864 - val_loss: 0.8665 - val_mse: 0.8665 - val_mae: 0.7532\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 0s 360us/step - loss: 1.7906 - mse: 1.7906 - mae: 0.9845 - val_loss: 0.8633 - val_mse: 0.8633 - val_mae: 0.7519\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 0s 378us/step - loss: 1.7840 - mse: 1.7840 - mae: 0.9828 - val_loss: 0.8599 - val_mse: 0.8599 - val_mae: 0.7506\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 0s 283us/step - loss: 1.7778 - mse: 1.7778 - mae: 0.9814 - val_loss: 0.8569 - val_mse: 0.8569 - val_mae: 0.7496\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 0s 366us/step - loss: 1.7716 - mse: 1.7716 - mae: 0.9798 - val_loss: 0.8537 - val_mse: 0.8537 - val_mae: 0.7487\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 0s 266us/step - loss: 1.7655 - mse: 1.7655 - mae: 0.9782 - val_loss: 0.8505 - val_mse: 0.8505 - val_mae: 0.7480\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 0s 322us/step - loss: 1.7591 - mse: 1.7591 - mae: 0.9765 - val_loss: 0.8469 - val_mse: 0.8469 - val_mae: 0.7467\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 0s 348us/step - loss: 1.7531 - mse: 1.7531 - mae: 0.9748 - val_loss: 0.8435 - val_mse: 0.8435 - val_mae: 0.7456\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 0s 303us/step - loss: 1.7470 - mse: 1.7470 - mae: 0.9729 - val_loss: 0.8390 - val_mse: 0.8390 - val_mae: 0.7442\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 0s 315us/step - loss: 1.7405 - mse: 1.7405 - mae: 0.9710 - val_loss: 0.8335 - val_mse: 0.8335 - val_mae: 0.7425\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 0s 267us/step - loss: 1.7341 - mse: 1.7341 - mae: 0.9693 - val_loss: 0.8284 - val_mse: 0.8284 - val_mae: 0.7409\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 0s 325us/step - loss: 1.7277 - mse: 1.7277 - mae: 0.9675 - val_loss: 0.8236 - val_mse: 0.8236 - val_mae: 0.7394\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 0s 299us/step - loss: 1.7214 - mse: 1.7214 - mae: 0.9656 - val_loss: 0.8196 - val_mse: 0.8196 - val_mae: 0.7385\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 0s 283us/step - loss: 1.7151 - mse: 1.7151 - mae: 0.9637 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7376\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 0s 250us/step - loss: 1.7090 - mse: 1.7090 - mae: 0.9621 - val_loss: 0.8125 - val_mse: 0.8125 - val_mae: 0.7371\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 0s 224us/step - loss: 1.7026 - mse: 1.7026 - mae: 0.9603 - val_loss: 0.8086 - val_mse: 0.8086 - val_mae: 0.7359\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 0s 267us/step - loss: 1.6968 - mse: 1.6968 - mae: 0.9586 - val_loss: 0.8059 - val_mse: 0.8059 - val_mae: 0.7349\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 0s 283us/step - loss: 1.6907 - mse: 1.6907 - mae: 0.9564 - val_loss: 0.8041 - val_mse: 0.8041 - val_mae: 0.7339\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 0s 269us/step - loss: 1.6845 - mse: 1.6845 - mae: 0.9540 - val_loss: 0.8029 - val_mse: 0.8029 - val_mae: 0.7331\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 0s 404us/step - loss: 1.6782 - mse: 1.6782 - mae: 0.9515 - val_loss: 0.8005 - val_mse: 0.8005 - val_mae: 0.7319\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 0s 370us/step - loss: 1.6715 - mse: 1.6715 - mae: 0.9493 - val_loss: 0.7971 - val_mse: 0.7971 - val_mae: 0.7301\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 0s 273us/step - loss: 1.6649 - mse: 1.6649 - mae: 0.9472 - val_loss: 0.7945 - val_mse: 0.7945 - val_mae: 0.7288\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 0s 316us/step - loss: 1.6582 - mse: 1.6582 - mae: 0.9449 - val_loss: 0.7929 - val_mse: 0.7929 - val_mae: 0.7277\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 0s 497us/step - loss: 1.6513 - mse: 1.6513 - mae: 0.9426 - val_loss: 0.7912 - val_mse: 0.7912 - val_mae: 0.7267\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 0s 327us/step - loss: 1.6433 - mse: 1.6433 - mae: 0.9403 - val_loss: 0.7898 - val_mse: 0.7898 - val_mae: 0.7262\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 0s 268us/step - loss: 1.6355 - mse: 1.6355 - mae: 0.9385 - val_loss: 0.7880 - val_mse: 0.7880 - val_mae: 0.7255\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 0s 267us/step - loss: 1.6275 - mse: 1.6275 - mae: 0.9366 - val_loss: 0.7863 - val_mse: 0.7863 - val_mae: 0.7245\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 0s 254us/step - loss: 1.6194 - mse: 1.6194 - mae: 0.9342 - val_loss: 0.7845 - val_mse: 0.7845 - val_mae: 0.7233\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 0s 362us/step - loss: 1.6114 - mse: 1.6114 - mae: 0.9315 - val_loss: 0.7829 - val_mse: 0.7829 - val_mae: 0.7222\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 0s 356us/step - loss: 1.6035 - mse: 1.6035 - mae: 0.9290 - val_loss: 0.7797 - val_mse: 0.7797 - val_mae: 0.7206\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 0s 307us/step - loss: 1.5953 - mse: 1.5953 - mae: 0.9268 - val_loss: 0.7771 - val_mse: 0.7771 - val_mae: 0.7192\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 0s 409us/step - loss: 1.5874 - mse: 1.5874 - mae: 0.9246 - val_loss: 0.7753 - val_mse: 0.7753 - val_mae: 0.7179\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 0s 278us/step - loss: 1.5796 - mse: 1.5796 - mae: 0.9222 - val_loss: 0.7727 - val_mse: 0.7727 - val_mae: 0.7162\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 0s 325us/step - loss: 1.5719 - mse: 1.5719 - mae: 0.9197 - val_loss: 0.7714 - val_mse: 0.7714 - val_mae: 0.7146\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 0s 348us/step - loss: 1.5640 - mse: 1.5640 - mae: 0.9167 - val_loss: 0.7707 - val_mse: 0.7707 - val_mae: 0.7127\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 298us/step - loss: 1.5565 - mse: 1.5565 - mae: 0.9138 - val_loss: 0.7679 - val_mse: 0.7679 - val_mae: 0.7102\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 0s 294us/step - loss: 1.5490 - mse: 1.5490 - mae: 0.9114 - val_loss: 0.7642 - val_mse: 0.7642 - val_mae: 0.7077\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 0s 399us/step - loss: 1.5417 - mse: 1.5417 - mae: 0.9092 - val_loss: 0.7618 - val_mse: 0.7618 - val_mae: 0.7058\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 0s 296us/step - loss: 1.5346 - mse: 1.5346 - mae: 0.9067 - val_loss: 0.7610 - val_mse: 0.7610 - val_mae: 0.7051\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 0s 330us/step - loss: 1.5277 - mse: 1.5277 - mae: 0.9042 - val_loss: 0.7610 - val_mse: 0.7610 - val_mae: 0.7046\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 0s 497us/step - loss: 1.5209 - mse: 1.5209 - mae: 0.9016 - val_loss: 0.7592 - val_mse: 0.7592 - val_mae: 0.7027\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 0s 332us/step - loss: 1.5138 - mse: 1.5138 - mae: 0.8989 - val_loss: 0.7562 - val_mse: 0.7562 - val_mae: 0.7001\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 0s 351us/step - loss: 1.5067 - mse: 1.5067 - mae: 0.8964 - val_loss: 0.7521 - val_mse: 0.7521 - val_mae: 0.6971\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 0s 294us/step - loss: 1.4997 - mse: 1.4997 - mae: 0.8942 - val_loss: 0.7497 - val_mse: 0.7497 - val_mae: 0.6953\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 0s 312us/step - loss: 1.4930 - mse: 1.4930 - mae: 0.8917 - val_loss: 0.7485 - val_mse: 0.7485 - val_mae: 0.6938\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 0s 246us/step - loss: 1.4866 - mse: 1.4866 - mae: 0.8889 - val_loss: 0.7478 - val_mse: 0.7478 - val_mae: 0.6929\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 0s 396us/step - loss: 1.4803 - mse: 1.4803 - mae: 0.8862 - val_loss: 0.7455 - val_mse: 0.7455 - val_mae: 0.6910\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 0s 282us/step - loss: 1.4742 - mse: 1.4742 - mae: 0.8836 - val_loss: 0.7422 - val_mse: 0.7422 - val_mae: 0.6890\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 0s 286us/step - loss: 1.4679 - mse: 1.4679 - mae: 0.8810 - val_loss: 0.7394 - val_mse: 0.7394 - val_mae: 0.6872\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 0s 247us/step - loss: 1.4615 - mse: 1.4615 - mae: 0.8781 - val_loss: 0.7374 - val_mse: 0.7374 - val_mae: 0.6862\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 0s 477us/step - loss: 1.4549 - mse: 1.4549 - mae: 0.8753 - val_loss: 0.7363 - val_mse: 0.7363 - val_mae: 0.6856\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 0s 280us/step - loss: 1.4482 - mse: 1.4482 - mae: 0.8728 - val_loss: 0.7333 - val_mse: 0.7333 - val_mae: 0.6836\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 0s 425us/step - loss: 1.4414 - mse: 1.4414 - mae: 0.8702 - val_loss: 0.7306 - val_mse: 0.7306 - val_mae: 0.6818\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 0s 319us/step - loss: 1.4348 - mse: 1.4348 - mae: 0.8675 - val_loss: 0.7288 - val_mse: 0.7288 - val_mae: 0.6801\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 0s 294us/step - loss: 1.4284 - mse: 1.4284 - mae: 0.8644 - val_loss: 0.7278 - val_mse: 0.7278 - val_mae: 0.6793\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 0s 385us/step - loss: 1.4219 - mse: 1.4219 - mae: 0.8617 - val_loss: 0.7252 - val_mse: 0.7252 - val_mae: 0.6782\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 0s 259us/step - loss: 1.4156 - mse: 1.4156 - mae: 0.8593 - val_loss: 0.7205 - val_mse: 0.7205 - val_mae: 0.6757\n",
      "6\n",
      "[6]\n",
      "Train on 82 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 7.3839 - mse: 7.3839 - mae: 2.5848 - val_loss: 5.2519 - val_mse: 5.2519 - val_mae: 2.1530\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 200us/step - loss: 6.4582 - mse: 6.4582 - mae: 2.3995 - val_loss: 4.5590 - val_mse: 4.5590 - val_mae: 1.9792\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 223us/step - loss: 5.5655 - mse: 5.5655 - mae: 2.2050 - val_loss: 3.9528 - val_mse: 3.9528 - val_mae: 1.8075\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 311us/step - loss: 4.7256 - mse: 4.7256 - mae: 2.0051 - val_loss: 3.4551 - val_mse: 3.4551 - val_mae: 1.6453\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 402us/step - loss: 3.9548 - mse: 3.9548 - mae: 1.8029 - val_loss: 3.0073 - val_mse: 3.0073 - val_mae: 1.4798\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 386us/step - loss: 3.2563 - mse: 3.2563 - mae: 1.5996 - val_loss: 2.5883 - val_mse: 2.5883 - val_mae: 1.3242\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 218us/step - loss: 2.6439 - mse: 2.6439 - mae: 1.4030 - val_loss: 2.2238 - val_mse: 2.2238 - val_mae: 1.1760\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 192us/step - loss: 2.1127 - mse: 2.1127 - mae: 1.2214 - val_loss: 1.9297 - val_mse: 1.9297 - val_mae: 1.0562\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 257us/step - loss: 1.6638 - mse: 1.6638 - mae: 1.0624 - val_loss: 1.6737 - val_mse: 1.6737 - val_mae: 0.9666\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 306us/step - loss: 1.3074 - mse: 1.3074 - mae: 0.9173 - val_loss: 1.4419 - val_mse: 1.4419 - val_mae: 0.8869\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 262us/step - loss: 1.0394 - mse: 1.0394 - mae: 0.7961 - val_loss: 1.2765 - val_mse: 1.2765 - val_mae: 0.8139\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 324us/step - loss: 0.8417 - mse: 0.8417 - mae: 0.7011 - val_loss: 1.1798 - val_mse: 1.1798 - val_mae: 0.7897\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 271us/step - loss: 0.7282 - mse: 0.7282 - mae: 0.6594 - val_loss: 1.1481 - val_mse: 1.1481 - val_mae: 0.8136\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 441us/step - loss: 0.6787 - mse: 0.6787 - mae: 0.6482 - val_loss: 1.1637 - val_mse: 1.1637 - val_mae: 0.8398\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 219us/step - loss: 0.6714 - mse: 0.6714 - mae: 0.6616 - val_loss: 1.1974 - val_mse: 1.1974 - val_mae: 0.8700\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 275us/step - loss: 0.6824 - mse: 0.6824 - mae: 0.6750 - val_loss: 1.2236 - val_mse: 1.2236 - val_mae: 0.8854\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 305us/step - loss: 0.6908 - mse: 0.6908 - mae: 0.6836 - val_loss: 1.2301 - val_mse: 1.2301 - val_mae: 0.8873\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 233us/step - loss: 0.6877 - mse: 0.6877 - mae: 0.6830 - val_loss: 1.2181 - val_mse: 1.2181 - val_mae: 0.8787\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 185us/step - loss: 0.6739 - mse: 0.6739 - mae: 0.6757 - val_loss: 1.1955 - val_mse: 1.1955 - val_mae: 0.8632\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 300us/step - loss: 0.6554 - mse: 0.6554 - mae: 0.6643 - val_loss: 1.1717 - val_mse: 1.1717 - val_mae: 0.8444\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 218us/step - loss: 0.6388 - mse: 0.6388 - mae: 0.6520 - val_loss: 1.1547 - val_mse: 1.1547 - val_mae: 0.8259\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 203us/step - loss: 0.6278 - mse: 0.6278 - mae: 0.6415 - val_loss: 1.1423 - val_mse: 1.1423 - val_mae: 0.8092\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 411us/step - loss: 0.6217 - mse: 0.6217 - mae: 0.6335 - val_loss: 1.1336 - val_mse: 1.1336 - val_mae: 0.7954\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 262us/step - loss: 0.6176 - mse: 0.6176 - mae: 0.6276 - val_loss: 1.1262 - val_mse: 1.1262 - val_mae: 0.7845\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 219us/step - loss: 0.6141 - mse: 0.6141 - mae: 0.6233 - val_loss: 1.1195 - val_mse: 1.1195 - val_mae: 0.7768\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 278us/step - loss: 0.6104 - mse: 0.6104 - mae: 0.6203 - val_loss: 1.1129 - val_mse: 1.1129 - val_mae: 0.7718\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 225us/step - loss: 0.6060 - mse: 0.6060 - mae: 0.6184 - val_loss: 1.1068 - val_mse: 1.1068 - val_mae: 0.7688\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 341us/step - loss: 0.6012 - mse: 0.6012 - mae: 0.6169 - val_loss: 1.1011 - val_mse: 1.1011 - val_mae: 0.7672\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 360us/step - loss: 0.5958 - mse: 0.5958 - mae: 0.6158 - val_loss: 1.0957 - val_mse: 1.0957 - val_mae: 0.7662\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 368us/step - loss: 0.5906 - mse: 0.5906 - mae: 0.6149 - val_loss: 1.0907 - val_mse: 1.0907 - val_mae: 0.7654\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 368us/step - loss: 0.5860 - mse: 0.5860 - mae: 0.6141 - val_loss: 1.0857 - val_mse: 1.0857 - val_mae: 0.7648\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 209us/step - loss: 0.5818 - mse: 0.5818 - mae: 0.6134 - val_loss: 1.0808 - val_mse: 1.0808 - val_mae: 0.7634\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 279us/step - loss: 0.5780 - mse: 0.5780 - mae: 0.6126 - val_loss: 1.0761 - val_mse: 1.0761 - val_mae: 0.7612\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 215us/step - loss: 0.5745 - mse: 0.5745 - mae: 0.6115 - val_loss: 1.0717 - val_mse: 1.0717 - val_mae: 0.7581\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 215us/step - loss: 0.5711 - mse: 0.5711 - mae: 0.6099 - val_loss: 1.0676 - val_mse: 1.0676 - val_mae: 0.7544\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 284us/step - loss: 0.5677 - mse: 0.5677 - mae: 0.6081 - val_loss: 1.0635 - val_mse: 1.0635 - val_mae: 0.7502\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 251us/step - loss: 0.5644 - mse: 0.5644 - mae: 0.6061 - val_loss: 1.0595 - val_mse: 1.0595 - val_mae: 0.7461\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 299us/step - loss: 0.5610 - mse: 0.5610 - mae: 0.6042 - val_loss: 1.0557 - val_mse: 1.0557 - val_mae: 0.7421\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 270us/step - loss: 0.5577 - mse: 0.5577 - mae: 0.6024 - val_loss: 1.0516 - val_mse: 1.0516 - val_mae: 0.7377\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 341us/step - loss: 0.5541 - mse: 0.5541 - mae: 0.6004 - val_loss: 1.0473 - val_mse: 1.0473 - val_mae: 0.7330\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 297us/step - loss: 0.5505 - mse: 0.5505 - mae: 0.5984 - val_loss: 1.0433 - val_mse: 1.0433 - val_mae: 0.7283\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 254us/step - loss: 0.5470 - mse: 0.5470 - mae: 0.5967 - val_loss: 1.0394 - val_mse: 1.0394 - val_mae: 0.7239\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 313us/step - loss: 0.5434 - mse: 0.5434 - mae: 0.5952 - val_loss: 1.0357 - val_mse: 1.0357 - val_mae: 0.7200\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 230us/step - loss: 0.5397 - mse: 0.5397 - mae: 0.5937 - val_loss: 1.0321 - val_mse: 1.0321 - val_mae: 0.7160\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 328us/step - loss: 0.5361 - mse: 0.5361 - mae: 0.5923 - val_loss: 1.0285 - val_mse: 1.0285 - val_mae: 0.7122\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 238us/step - loss: 0.5328 - mse: 0.5328 - mae: 0.5910 - val_loss: 1.0257 - val_mse: 1.0257 - val_mae: 0.7091\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 209us/step - loss: 0.5296 - mse: 0.5296 - mae: 0.5897 - val_loss: 1.0233 - val_mse: 1.0233 - val_mae: 0.7060\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 386us/step - loss: 0.5264 - mse: 0.5264 - mae: 0.5884 - val_loss: 1.0212 - val_mse: 1.0212 - val_mae: 0.7032\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 205us/step - loss: 0.5232 - mse: 0.5232 - mae: 0.5869 - val_loss: 1.0195 - val_mse: 1.0195 - val_mae: 0.7004\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 236us/step - loss: 0.5198 - mse: 0.5198 - mae: 0.5852 - val_loss: 1.0178 - val_mse: 1.0178 - val_mae: 0.6974\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 213us/step - loss: 0.5165 - mse: 0.5165 - mae: 0.5835 - val_loss: 1.0167 - val_mse: 1.0167 - val_mae: 0.6953\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 189us/step - loss: 0.5132 - mse: 0.5132 - mae: 0.5818 - val_loss: 1.0159 - val_mse: 1.0159 - val_mae: 0.6945\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 304us/step - loss: 0.5102 - mse: 0.5102 - mae: 0.5802 - val_loss: 1.0159 - val_mse: 1.0159 - val_mae: 0.6939\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 270us/step - loss: 0.5074 - mse: 0.5074 - mae: 0.5786 - val_loss: 1.0155 - val_mse: 1.0155 - val_mae: 0.6929\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 258us/step - loss: 0.5047 - mse: 0.5047 - mae: 0.5771 - val_loss: 1.0146 - val_mse: 1.0146 - val_mae: 0.6914\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 354us/step - loss: 0.5021 - mse: 0.5021 - mae: 0.5756 - val_loss: 1.0142 - val_mse: 1.0142 - val_mae: 0.6908\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 233us/step - loss: 0.4994 - mse: 0.4994 - mae: 0.5742 - val_loss: 1.0142 - val_mse: 1.0142 - val_mae: 0.6907\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 249us/step - loss: 0.4968 - mse: 0.4968 - mae: 0.5729 - val_loss: 1.0134 - val_mse: 1.0134 - val_mae: 0.6895\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 400us/step - loss: 0.4942 - mse: 0.4942 - mae: 0.5714 - val_loss: 1.0120 - val_mse: 1.0120 - val_mae: 0.6875\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 307us/step - loss: 0.4916 - mse: 0.4916 - mae: 0.5699 - val_loss: 1.0116 - val_mse: 1.0116 - val_mae: 0.6861\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 242us/step - loss: 0.4891 - mse: 0.4891 - mae: 0.5683 - val_loss: 1.0119 - val_mse: 1.0119 - val_mae: 0.6848\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 293us/step - loss: 0.4868 - mse: 0.4868 - mae: 0.5667 - val_loss: 1.0116 - val_mse: 1.0116 - val_mae: 0.6832\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 419us/step - loss: 0.4843 - mse: 0.4843 - mae: 0.5650 - val_loss: 1.0114 - val_mse: 1.0114 - val_mae: 0.6819\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 257us/step - loss: 0.4818 - mse: 0.4818 - mae: 0.5634 - val_loss: 1.0110 - val_mse: 1.0110 - val_mae: 0.6808\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 230us/step - loss: 0.4794 - mse: 0.4794 - mae: 0.5621 - val_loss: 1.0121 - val_mse: 1.0121 - val_mae: 0.6815\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 224us/step - loss: 0.4772 - mse: 0.4772 - mae: 0.5608 - val_loss: 1.0125 - val_mse: 1.0125 - val_mae: 0.6810\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 278us/step - loss: 0.4749 - mse: 0.4749 - mae: 0.5593 - val_loss: 1.0127 - val_mse: 1.0127 - val_mae: 0.6801\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 642us/step - loss: 0.4726 - mse: 0.4726 - mae: 0.5577 - val_loss: 1.0132 - val_mse: 1.0132 - val_mae: 0.6794\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 494us/step - loss: 0.4705 - mse: 0.4705 - mae: 0.5563 - val_loss: 1.0137 - val_mse: 1.0137 - val_mae: 0.6790\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 310us/step - loss: 0.4683 - mse: 0.4683 - mae: 0.5551 - val_loss: 1.0147 - val_mse: 1.0147 - val_mae: 0.6792\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 349us/step - loss: 0.4661 - mse: 0.4661 - mae: 0.5539 - val_loss: 1.0159 - val_mse: 1.0159 - val_mae: 0.6794\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 271us/step - loss: 0.4639 - mse: 0.4639 - mae: 0.5526 - val_loss: 1.0163 - val_mse: 1.0163 - val_mae: 0.6783\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 219us/step - loss: 0.4618 - mse: 0.4618 - mae: 0.5511 - val_loss: 1.0161 - val_mse: 1.0161 - val_mae: 0.6764\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 175us/step - loss: 0.4598 - mse: 0.4598 - mae: 0.5497 - val_loss: 1.0164 - val_mse: 1.0164 - val_mae: 0.6753\n",
      "7\n",
      "[7]\n",
      "Train on 88 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 12.9061 - mse: 12.9061 - mae: 3.0168 - val_loss: 9.7486 - val_mse: 9.7486 - val_mae: 2.8394\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 207us/step - loss: 11.4607 - mse: 11.4607 - mae: 2.7525 - val_loss: 8.4897 - val_mse: 8.4897 - val_mae: 2.5965\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 203us/step - loss: 10.1422 - mse: 10.1422 - mae: 2.4853 - val_loss: 7.3584 - val_mse: 7.3584 - val_mae: 2.3507\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 271us/step - loss: 8.9756 - mse: 8.9756 - mae: 2.2302 - val_loss: 6.3688 - val_mse: 6.3688 - val_mae: 2.1138\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 206us/step - loss: 7.9887 - mse: 7.9887 - mae: 2.0146 - val_loss: 5.5385 - val_mse: 5.5385 - val_mae: 1.8958\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 225us/step - loss: 7.1831 - mse: 7.1831 - mae: 1.8248 - val_loss: 4.8424 - val_mse: 4.8424 - val_mae: 1.6932\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 276us/step - loss: 6.5396 - mse: 6.5396 - mae: 1.6838 - val_loss: 4.2816 - val_mse: 4.2816 - val_mae: 1.5121\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 209us/step - loss: 6.0169 - mse: 6.0169 - mae: 1.5738 - val_loss: 3.8878 - val_mse: 3.8878 - val_mae: 1.3550\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 247us/step - loss: 5.5729 - mse: 5.5729 - mae: 1.5092 - val_loss: 3.5729 - val_mse: 3.5729 - val_mae: 1.2696\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 256us/step - loss: 5.2384 - mse: 5.2384 - mae: 1.4786 - val_loss: 3.3140 - val_mse: 3.3140 - val_mae: 1.2046\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 267us/step - loss: 4.9946 - mse: 4.9946 - mae: 1.4702 - val_loss: 3.1185 - val_mse: 3.1185 - val_mae: 1.1500\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 239us/step - loss: 4.7980 - mse: 4.7980 - mae: 1.4650 - val_loss: 2.9681 - val_mse: 2.9681 - val_mae: 1.1247\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 232us/step - loss: 4.6372 - mse: 4.6372 - mae: 1.4640 - val_loss: 2.8554 - val_mse: 2.8554 - val_mae: 1.1115\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 360us/step - loss: 4.5046 - mse: 4.5046 - mae: 1.4653 - val_loss: 2.7795 - val_mse: 2.7795 - val_mae: 1.1085\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 291us/step - loss: 4.4003 - mse: 4.4003 - mae: 1.4672 - val_loss: 2.7277 - val_mse: 2.7277 - val_mae: 1.1074\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 234us/step - loss: 4.3252 - mse: 4.3252 - mae: 1.4699 - val_loss: 2.6915 - val_mse: 2.6915 - val_mae: 1.1107\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 225us/step - loss: 4.2591 - mse: 4.2591 - mae: 1.4705 - val_loss: 2.6694 - val_mse: 2.6694 - val_mae: 1.1141\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 296us/step - loss: 4.1960 - mse: 4.1960 - mae: 1.4679 - val_loss: 2.6554 - val_mse: 2.6554 - val_mae: 1.1171\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 238us/step - loss: 4.1351 - mse: 4.1351 - mae: 1.4624 - val_loss: 2.6497 - val_mse: 2.6497 - val_mae: 1.1206\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 225us/step - loss: 4.0767 - mse: 4.0767 - mae: 1.4554 - val_loss: 2.6499 - val_mse: 2.6499 - val_mae: 1.1254\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 260us/step - loss: 4.0220 - mse: 4.0220 - mae: 1.4476 - val_loss: 2.6524 - val_mse: 2.6524 - val_mae: 1.1293\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 221us/step - loss: 3.9689 - mse: 3.9689 - mae: 1.4387 - val_loss: 2.6560 - val_mse: 2.6560 - val_mae: 1.1325\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 288us/step - loss: 3.9178 - mse: 3.9178 - mae: 1.4295 - val_loss: 2.6586 - val_mse: 2.6586 - val_mae: 1.1344\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 349us/step - loss: 3.8688 - mse: 3.8688 - mae: 1.4195 - val_loss: 2.6616 - val_mse: 2.6616 - val_mae: 1.1358\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 226us/step - loss: 3.8226 - mse: 3.8226 - mae: 1.4094 - val_loss: 2.6655 - val_mse: 2.6655 - val_mae: 1.1375\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 237us/step - loss: 3.7797 - mse: 3.7797 - mae: 1.3997 - val_loss: 2.6685 - val_mse: 2.6685 - val_mae: 1.1387\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 253us/step - loss: 3.7391 - mse: 3.7391 - mae: 1.3904 - val_loss: 2.6698 - val_mse: 2.6698 - val_mae: 1.1395\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 312us/step - loss: 3.6998 - mse: 3.6998 - mae: 1.3812 - val_loss: 2.6705 - val_mse: 2.6705 - val_mae: 1.1401\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 244us/step - loss: 3.6615 - mse: 3.6615 - mae: 1.3724 - val_loss: 2.6702 - val_mse: 2.6702 - val_mae: 1.1411\n",
      "8\n",
      "[8]\n",
      "Train on 71 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 12.4229 - mse: 12.4229 - mae: 3.3129 - val_loss: 5.6502 - val_mse: 5.6502 - val_mae: 2.3064\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 363us/step - loss: 10.9041 - mse: 10.9041 - mae: 3.0721 - val_loss: 4.7980 - val_mse: 4.7980 - val_mae: 2.1093\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 663us/step - loss: 9.3993 - mse: 9.3993 - mae: 2.8123 - val_loss: 3.9981 - val_mse: 3.9981 - val_mae: 1.9043\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 301us/step - loss: 8.0374 - mse: 8.0374 - mae: 2.5559 - val_loss: 3.3005 - val_mse: 3.3005 - val_mae: 1.7028\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 438us/step - loss: 6.8339 - mse: 6.8339 - mae: 2.3115 - val_loss: 2.7034 - val_mse: 2.7034 - val_mae: 1.5080\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 189us/step - loss: 5.7793 - mse: 5.7793 - mae: 2.0753 - val_loss: 2.1898 - val_mse: 2.1898 - val_mae: 1.3110\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 465us/step - loss: 4.8828 - mse: 4.8828 - mae: 1.8450 - val_loss: 1.7571 - val_mse: 1.7571 - val_mae: 1.1182\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.6990 - mse: 5.6990 - mae: 1.901 - 0s 320us/step - loss: 4.1514 - mse: 4.1514 - mae: 1.6350 - val_loss: 1.4003 - val_mse: 1.4003 - val_mae: 0.9649\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 486us/step - loss: 3.5693 - mse: 3.5693 - mae: 1.4692 - val_loss: 1.1029 - val_mse: 1.1029 - val_mae: 0.8080\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 300us/step - loss: 3.1265 - mse: 3.1265 - mae: 1.3469 - val_loss: 0.9033 - val_mse: 0.9033 - val_mae: 0.6976\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 492us/step - loss: 2.7960 - mse: 2.7960 - mae: 1.2544 - val_loss: 0.7909 - val_mse: 0.7909 - val_mae: 0.6172\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 364us/step - loss: 2.5591 - mse: 2.5591 - mae: 1.2007 - val_loss: 0.7195 - val_mse: 0.7195 - val_mae: 0.5455\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 337us/step - loss: 2.3831 - mse: 2.3831 - mae: 1.1551 - val_loss: 0.6814 - val_mse: 0.6814 - val_mae: 0.5081\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 234us/step - loss: 2.2639 - mse: 2.2639 - mae: 1.1227 - val_loss: 0.6646 - val_mse: 0.6646 - val_mae: 0.5194\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 345us/step - loss: 2.1730 - mse: 2.1730 - mae: 1.1015 - val_loss: 0.6577 - val_mse: 0.6577 - val_mae: 0.5290\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 266us/step - loss: 2.1002 - mse: 2.1002 - mae: 1.0834 - val_loss: 0.6554 - val_mse: 0.6554 - val_mae: 0.5441\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 211us/step - loss: 2.0335 - mse: 2.0335 - mae: 1.0686 - val_loss: 0.6540 - val_mse: 0.6540 - val_mae: 0.5537\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 330us/step - loss: 1.9730 - mse: 1.9730 - mae: 1.0555 - val_loss: 0.6515 - val_mse: 0.6515 - val_mae: 0.5586\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 457us/step - loss: 1.9205 - mse: 1.9205 - mae: 1.0436 - val_loss: 0.6475 - val_mse: 0.6475 - val_mae: 0.5596\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 276us/step - loss: 1.8729 - mse: 1.8729 - mae: 1.0317 - val_loss: 0.6422 - val_mse: 0.6422 - val_mae: 0.5577\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 350us/step - loss: 1.8274 - mse: 1.8274 - mae: 1.0191 - val_loss: 0.6363 - val_mse: 0.6363 - val_mae: 0.5543\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 380us/step - loss: 1.7847 - mse: 1.7847 - mae: 1.0067 - val_loss: 0.6301 - val_mse: 0.6301 - val_mae: 0.5503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 346us/step - loss: 1.7444 - mse: 1.7444 - mae: 0.9953 - val_loss: 0.6241 - val_mse: 0.6241 - val_mae: 0.5462\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 613us/step - loss: 1.7063 - mse: 1.7063 - mae: 0.9840 - val_loss: 0.6185 - val_mse: 0.6185 - val_mae: 0.5424\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 541us/step - loss: 1.6708 - mse: 1.6708 - mae: 0.9732 - val_loss: 0.6135 - val_mse: 0.6135 - val_mae: 0.5394\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 348us/step - loss: 1.6367 - mse: 1.6367 - mae: 0.9627 - val_loss: 0.6089 - val_mse: 0.6089 - val_mae: 0.5370\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 299us/step - loss: 1.6035 - mse: 1.6035 - mae: 0.9527 - val_loss: 0.6050 - val_mse: 0.6050 - val_mae: 0.5353\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 327us/step - loss: 1.5716 - mse: 1.5716 - mae: 0.9434 - val_loss: 0.6018 - val_mse: 0.6018 - val_mae: 0.5343\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 394us/step - loss: 1.5413 - mse: 1.5413 - mae: 0.9348 - val_loss: 0.5991 - val_mse: 0.5991 - val_mae: 0.5337\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 193us/step - loss: 1.5130 - mse: 1.5130 - mae: 0.9266 - val_loss: 0.5966 - val_mse: 0.5966 - val_mae: 0.5329\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 203us/step - loss: 1.4861 - mse: 1.4861 - mae: 0.9188 - val_loss: 0.5943 - val_mse: 0.5943 - val_mae: 0.5320\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 277us/step - loss: 1.4606 - mse: 1.4606 - mae: 0.9111 - val_loss: 0.5923 - val_mse: 0.5923 - val_mae: 0.5310\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 283us/step - loss: 1.4363 - mse: 1.4363 - mae: 0.9035 - val_loss: 0.5905 - val_mse: 0.5905 - val_mae: 0.5299\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 319us/step - loss: 1.4130 - mse: 1.4130 - mae: 0.8959 - val_loss: 0.5886 - val_mse: 0.5886 - val_mae: 0.5284\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 255us/step - loss: 1.3904 - mse: 1.3904 - mae: 0.8880 - val_loss: 0.5867 - val_mse: 0.5867 - val_mae: 0.5266\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 420us/step - loss: 1.3685 - mse: 1.3685 - mae: 0.8803 - val_loss: 0.5849 - val_mse: 0.5849 - val_mae: 0.5248\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 376us/step - loss: 1.3471 - mse: 1.3471 - mae: 0.8724 - val_loss: 0.5833 - val_mse: 0.5833 - val_mae: 0.5230\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 280us/step - loss: 1.3258 - mse: 1.3258 - mae: 0.8641 - val_loss: 0.5819 - val_mse: 0.5819 - val_mae: 0.5213\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 279us/step - loss: 1.3044 - mse: 1.3044 - mae: 0.8560 - val_loss: 0.5816 - val_mse: 0.5816 - val_mae: 0.5203\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 360us/step - loss: 1.2831 - mse: 1.2831 - mae: 0.8480 - val_loss: 0.5815 - val_mse: 0.5815 - val_mae: 0.5195\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 274us/step - loss: 1.2620 - mse: 1.2620 - mae: 0.8405 - val_loss: 0.5803 - val_mse: 0.5803 - val_mae: 0.5208\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 466us/step - loss: 1.2410 - mse: 1.2410 - mae: 0.8327 - val_loss: 0.5792 - val_mse: 0.5792 - val_mae: 0.5229\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 308us/step - loss: 1.2202 - mse: 1.2202 - mae: 0.8248 - val_loss: 0.5800 - val_mse: 0.5800 - val_mae: 0.5268\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 225us/step - loss: 1.1993 - mse: 1.1993 - mae: 0.8170 - val_loss: 0.5824 - val_mse: 0.5824 - val_mae: 0.5314\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 316us/step - loss: 1.1793 - mse: 1.1793 - mae: 0.8101 - val_loss: 0.5854 - val_mse: 0.5854 - val_mae: 0.5363\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 190us/step - loss: 1.1600 - mse: 1.1600 - mae: 0.8039 - val_loss: 0.5886 - val_mse: 0.5886 - val_mae: 0.5414\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 452us/step - loss: 1.1419 - mse: 1.1419 - mae: 0.7987 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.5462\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 403us/step - loss: 1.1244 - mse: 1.1244 - mae: 0.7936 - val_loss: 0.5951 - val_mse: 0.5951 - val_mae: 0.5505\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 241us/step - loss: 1.1079 - mse: 1.1079 - mae: 0.7885 - val_loss: 0.5977 - val_mse: 0.5977 - val_mae: 0.5541\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 320us/step - loss: 1.0925 - mse: 1.0925 - mae: 0.7835 - val_loss: 0.5999 - val_mse: 0.5999 - val_mae: 0.5569\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 222us/step - loss: 1.0784 - mse: 1.0784 - mae: 0.7786 - val_loss: 0.6014 - val_mse: 0.6014 - val_mae: 0.5590\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 420us/step - loss: 1.0653 - mse: 1.0653 - mae: 0.7743 - val_loss: 0.6027 - val_mse: 0.6027 - val_mae: 0.5608\n",
      "9\n",
      "[9]\n",
      "Train on 72 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 5.2366 - mse: 5.2366 - mae: 1.9967 - val_loss: 3.0923 - val_mse: 3.0923 - val_mae: 1.6440\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 311us/step - loss: 4.6371 - mse: 4.6371 - mae: 1.8520 - val_loss: 2.6643 - val_mse: 2.6643 - val_mae: 1.5126\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 323us/step - loss: 4.1258 - mse: 4.1258 - mae: 1.7210 - val_loss: 2.2958 - val_mse: 2.2958 - val_mae: 1.3886\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 263us/step - loss: 3.6835 - mse: 3.6835 - mae: 1.5992 - val_loss: 1.9950 - val_mse: 1.9950 - val_mae: 1.2745\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 401us/step - loss: 3.3145 - mse: 3.3145 - mae: 1.4874 - val_loss: 1.7348 - val_mse: 1.7348 - val_mae: 1.1639\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 215us/step - loss: 2.9995 - mse: 2.9995 - mae: 1.3819 - val_loss: 1.5247 - val_mse: 1.5247 - val_mae: 1.0610\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 263us/step - loss: 2.7366 - mse: 2.7366 - mae: 1.2907 - val_loss: 1.3696 - val_mse: 1.3696 - val_mae: 0.9707\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 241us/step - loss: 2.5057 - mse: 2.5057 - mae: 1.2043 - val_loss: 1.2406 - val_mse: 1.2406 - val_mae: 0.8873\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 397us/step - loss: 2.2938 - mse: 2.2938 - mae: 1.1198 - val_loss: 1.1240 - val_mse: 1.1240 - val_mae: 0.8051\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 267us/step - loss: 2.1069 - mse: 2.1069 - mae: 1.0408 - val_loss: 1.0215 - val_mse: 1.0215 - val_mae: 0.7363\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 406us/step - loss: 1.9425 - mse: 1.9425 - mae: 0.9627 - val_loss: 0.9323 - val_mse: 0.9323 - val_mae: 0.6924\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 227us/step - loss: 1.7960 - mse: 1.7960 - mae: 0.8945 - val_loss: 0.8579 - val_mse: 0.8579 - val_mae: 0.6498\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 300us/step - loss: 1.6655 - mse: 1.6655 - mae: 0.8485 - val_loss: 0.7999 - val_mse: 0.7999 - val_mae: 0.6124\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 255us/step - loss: 1.5478 - mse: 1.5478 - mae: 0.8170 - val_loss: 0.7427 - val_mse: 0.7427 - val_mae: 0.5721\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 208us/step - loss: 1.4429 - mse: 1.4429 - mae: 0.7995 - val_loss: 0.7028 - val_mse: 0.7028 - val_mae: 0.5483\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 390us/step - loss: 1.3602 - mse: 1.3602 - mae: 0.7959 - val_loss: 0.6779 - val_mse: 0.6779 - val_mae: 0.5609\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 541us/step - loss: 1.2992 - mse: 1.2992 - mae: 0.7990 - val_loss: 0.6675 - val_mse: 0.6675 - val_mae: 0.5954\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 364us/step - loss: 1.2591 - mse: 1.2591 - mae: 0.8049 - val_loss: 0.6681 - val_mse: 0.6681 - val_mae: 0.6355\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 444us/step - loss: 1.2292 - mse: 1.2292 - mae: 0.8086 - val_loss: 0.6705 - val_mse: 0.6705 - val_mae: 0.6677\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 434us/step - loss: 1.2074 - mse: 1.2074 - mae: 0.8113 - val_loss: 0.6697 - val_mse: 0.6697 - val_mae: 0.6899\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 276us/step - loss: 1.1948 - mse: 1.1948 - mae: 0.8165 - val_loss: 0.6683 - val_mse: 0.6683 - val_mae: 0.7036\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 654us/step - loss: 1.1857 - mse: 1.1857 - mae: 0.8217 - val_loss: 0.6641 - val_mse: 0.6641 - val_mae: 0.7095\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 247us/step - loss: 1.1770 - mse: 1.1770 - mae: 0.8237 - val_loss: 0.6552 - val_mse: 0.6552 - val_mae: 0.7083\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 324us/step - loss: 1.1670 - mse: 1.1670 - mae: 0.8217 - val_loss: 0.6420 - val_mse: 0.6420 - val_mae: 0.7012\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 331us/step - loss: 1.1556 - mse: 1.1556 - mae: 0.8164 - val_loss: 0.6261 - val_mse: 0.6261 - val_mae: 0.6899\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 458us/step - loss: 1.1439 - mse: 1.1439 - mae: 0.8087 - val_loss: 0.6094 - val_mse: 0.6094 - val_mae: 0.6762\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 296us/step - loss: 1.1327 - mse: 1.1327 - mae: 0.7995 - val_loss: 0.5941 - val_mse: 0.5941 - val_mae: 0.6622\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 354us/step - loss: 1.1229 - mse: 1.1229 - mae: 0.7906 - val_loss: 0.5799 - val_mse: 0.5799 - val_mae: 0.6487\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 200us/step - loss: 1.1145 - mse: 1.1145 - mae: 0.7828 - val_loss: 0.5666 - val_mse: 0.5666 - val_mae: 0.6363\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 263us/step - loss: 1.1071 - mse: 1.1071 - mae: 0.7770 - val_loss: 0.5552 - val_mse: 0.5552 - val_mae: 0.6265\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 260us/step - loss: 1.1000 - mse: 1.1000 - mae: 0.7720 - val_loss: 0.5454 - val_mse: 0.5454 - val_mae: 0.6192\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 246us/step - loss: 1.0929 - mse: 1.0929 - mae: 0.7679 - val_loss: 0.5368 - val_mse: 0.5368 - val_mae: 0.6140\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 332us/step - loss: 1.0856 - mse: 1.0856 - mae: 0.7645 - val_loss: 0.5288 - val_mse: 0.5288 - val_mae: 0.6100\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 396us/step - loss: 1.0783 - mse: 1.0783 - mae: 0.7617 - val_loss: 0.5215 - val_mse: 0.5215 - val_mae: 0.6070\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 271us/step - loss: 1.0710 - mse: 1.0710 - mae: 0.7591 - val_loss: 0.5146 - val_mse: 0.5146 - val_mae: 0.6045\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 176us/step - loss: 1.0639 - mse: 1.0639 - mae: 0.7568 - val_loss: 0.5074 - val_mse: 0.5074 - val_mae: 0.6018\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 402us/step - loss: 1.0570 - mse: 1.0570 - mae: 0.7546 - val_loss: 0.5002 - val_mse: 0.5002 - val_mae: 0.5988\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 280us/step - loss: 1.0504 - mse: 1.0504 - mae: 0.7522 - val_loss: 0.4931 - val_mse: 0.4931 - val_mae: 0.5953\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 343us/step - loss: 1.0440 - mse: 1.0440 - mae: 0.7497 - val_loss: 0.4860 - val_mse: 0.4860 - val_mae: 0.5913\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 332us/step - loss: 1.0379 - mse: 1.0379 - mae: 0.7471 - val_loss: 0.4788 - val_mse: 0.4788 - val_mae: 0.5869\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 345us/step - loss: 1.0322 - mse: 1.0322 - mae: 0.7444 - val_loss: 0.4734 - val_mse: 0.4734 - val_mae: 0.5838\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 328us/step - loss: 1.0266 - mse: 1.0266 - mae: 0.7418 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.5813\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 458us/step - loss: 1.0215 - mse: 1.0215 - mae: 0.7393 - val_loss: 0.4640 - val_mse: 0.4640 - val_mae: 0.5787\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 230us/step - loss: 1.0163 - mse: 1.0163 - mae: 0.7370 - val_loss: 0.4591 - val_mse: 0.4591 - val_mae: 0.5760\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 490us/step - loss: 1.0111 - mse: 1.0111 - mae: 0.7348 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.5732\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 221us/step - loss: 1.0060 - mse: 1.0060 - mae: 0.7328 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.5703\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 270us/step - loss: 1.0010 - mse: 1.0010 - mae: 0.7305 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.5671\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 246us/step - loss: 0.9959 - mse: 0.9959 - mae: 0.7282 - val_loss: 0.4398 - val_mse: 0.4398 - val_mae: 0.5639\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 238us/step - loss: 0.9914 - mse: 0.9914 - mae: 0.7260 - val_loss: 0.4368 - val_mse: 0.4368 - val_mae: 0.5624\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 405us/step - loss: 0.9865 - mse: 0.9865 - mae: 0.7241 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.5613\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 394us/step - loss: 0.9822 - mse: 0.9822 - mae: 0.7223 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.5599\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 290us/step - loss: 0.9779 - mse: 0.9779 - mae: 0.7204 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.5579\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 478us/step - loss: 0.9736 - mse: 0.9736 - mae: 0.7182 - val_loss: 0.4248 - val_mse: 0.4248 - val_mae: 0.5554\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 202us/step - loss: 0.9695 - mse: 0.9695 - mae: 0.7161 - val_loss: 0.4209 - val_mse: 0.4209 - val_mae: 0.5528\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 481us/step - loss: 0.9652 - mse: 0.9652 - mae: 0.7142 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.5500\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 502us/step - loss: 0.9609 - mse: 0.9609 - mae: 0.7124 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.5472\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 424us/step - loss: 0.9570 - mse: 0.9570 - mae: 0.7105 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.5457\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 334us/step - loss: 0.9530 - mse: 0.9530 - mae: 0.7088 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.5446\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 228us/step - loss: 0.9492 - mse: 0.9492 - mae: 0.7071 - val_loss: 0.4077 - val_mse: 0.4077 - val_mae: 0.5424\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 216us/step - loss: 0.9453 - mse: 0.9453 - mae: 0.7053 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.5400\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 284us/step - loss: 0.9413 - mse: 0.9413 - mae: 0.7035 - val_loss: 0.4031 - val_mse: 0.4031 - val_mae: 0.5377\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 529us/step - loss: 0.9374 - mse: 0.9374 - mae: 0.7015 - val_loss: 0.4016 - val_mse: 0.4016 - val_mae: 0.5358\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 356us/step - loss: 0.9334 - mse: 0.9334 - mae: 0.7000 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.5340\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 344us/step - loss: 0.9295 - mse: 0.9295 - mae: 0.6983 - val_loss: 0.3988 - val_mse: 0.3988 - val_mae: 0.5320\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 316us/step - loss: 0.9261 - mse: 0.9261 - mae: 0.6965 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.5305\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 309us/step - loss: 0.9223 - mse: 0.9223 - mae: 0.6947 - val_loss: 0.3977 - val_mse: 0.3977 - val_mae: 0.5289\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 283us/step - loss: 0.9190 - mse: 0.9190 - mae: 0.6928 - val_loss: 0.3972 - val_mse: 0.3972 - val_mae: 0.5269\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 294us/step - loss: 0.9156 - mse: 0.9156 - mae: 0.6907 - val_loss: 0.3964 - val_mse: 0.3964 - val_mae: 0.5248\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 653us/step - loss: 0.9122 - mse: 0.9122 - mae: 0.6886 - val_loss: 0.3952 - val_mse: 0.3952 - val_mae: 0.5222\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 390us/step - loss: 0.9089 - mse: 0.9089 - mae: 0.6862 - val_loss: 0.3937 - val_mse: 0.3937 - val_mae: 0.5191\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 259us/step - loss: 0.9056 - mse: 0.9056 - mae: 0.6838 - val_loss: 0.3921 - val_mse: 0.3921 - val_mae: 0.5159\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 281us/step - loss: 0.9025 - mse: 0.9025 - mae: 0.6814 - val_loss: 0.3907 - val_mse: 0.3907 - val_mae: 0.5134\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 420us/step - loss: 0.8991 - mse: 0.8991 - mae: 0.6790 - val_loss: 0.3892 - val_mse: 0.3892 - val_mae: 0.5117\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 330us/step - loss: 0.8960 - mse: 0.8960 - mae: 0.6769 - val_loss: 0.3896 - val_mse: 0.3896 - val_mae: 0.5119\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 236us/step - loss: 0.8928 - mse: 0.8928 - mae: 0.6752 - val_loss: 0.3909 - val_mse: 0.3909 - val_mae: 0.5133\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 285us/step - loss: 0.8900 - mse: 0.8900 - mae: 0.6735 - val_loss: 0.3919 - val_mse: 0.3919 - val_mae: 0.5147\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 255us/step - loss: 0.8870 - mse: 0.8870 - mae: 0.6715 - val_loss: 0.3921 - val_mse: 0.3921 - val_mae: 0.5156\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 244us/step - loss: 0.8840 - mse: 0.8840 - mae: 0.6693 - val_loss: 0.3919 - val_mse: 0.3919 - val_mae: 0.5161\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 236us/step - loss: 0.8809 - mse: 0.8809 - mae: 0.6672 - val_loss: 0.3918 - val_mse: 0.3918 - val_mae: 0.5165\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 336us/step - loss: 0.8777 - mse: 0.8777 - mae: 0.6651 - val_loss: 0.3915 - val_mse: 0.3915 - val_mae: 0.5166\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 281us/step - loss: 0.8745 - mse: 0.8745 - mae: 0.6629 - val_loss: 0.3919 - val_mse: 0.3919 - val_mae: 0.5171\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 344us/step - loss: 0.8714 - mse: 0.8714 - mae: 0.6608 - val_loss: 0.3931 - val_mse: 0.3931 - val_mae: 0.5180\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.8681 - mse: 0.8681 - mae: 0.6587 - val_loss: 0.3946 - val_mse: 0.3946 - val_mae: 0.5194\n",
      "10\n",
      "[10]\n",
      "Train on 97 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 9.0469 - mse: 9.0469 - mae: 2.4626 - val_loss: 6.4229 - val_mse: 6.4229 - val_mae: 2.0891\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 178us/step - loss: 8.3411 - mse: 8.3411 - mae: 2.3212 - val_loss: 5.9232 - val_mse: 5.9232 - val_mae: 1.9613\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 173us/step - loss: 7.6718 - mse: 7.6718 - mae: 2.1815 - val_loss: 5.4080 - val_mse: 5.4080 - val_mae: 1.8201\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 607us/step - loss: 7.0004 - mse: 7.0004 - mae: 2.0440 - val_loss: 4.9117 - val_mse: 4.9117 - val_mae: 1.6736\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 145us/step - loss: 6.3515 - mse: 6.3515 - mae: 1.9223 - val_loss: 4.4700 - val_mse: 4.4700 - val_mae: 1.5503\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 274us/step - loss: 5.7338 - mse: 5.7338 - mae: 1.8169 - val_loss: 4.0673 - val_mse: 4.0673 - val_mae: 1.4520\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 208us/step - loss: 5.1699 - mse: 5.1699 - mae: 1.7165 - val_loss: 3.7044 - val_mse: 3.7044 - val_mae: 1.3929\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 274us/step - loss: 4.6677 - mse: 4.6677 - mae: 1.6200 - val_loss: 3.3934 - val_mse: 3.3934 - val_mae: 1.3704\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 217us/step - loss: 4.2397 - mse: 4.2397 - mae: 1.5365 - val_loss: 3.1416 - val_mse: 3.1416 - val_mae: 1.3873\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 221us/step - loss: 3.8898 - mse: 3.8898 - mae: 1.4774 - val_loss: 2.9402 - val_mse: 2.9402 - val_mae: 1.4019\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 167us/step - loss: 3.6131 - mse: 3.6131 - mae: 1.4412 - val_loss: 2.7991 - val_mse: 2.7991 - val_mae: 1.4137\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 201us/step - loss: 3.4175 - mse: 3.4175 - mae: 1.4246 - val_loss: 2.7143 - val_mse: 2.7143 - val_mae: 1.4380\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 264us/step - loss: 3.2975 - mse: 3.2975 - mae: 1.4185 - val_loss: 2.6717 - val_mse: 2.6717 - val_mae: 1.4587\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 494us/step - loss: 3.2353 - mse: 3.2353 - mae: 1.4170 - val_loss: 2.6538 - val_mse: 2.6538 - val_mae: 1.4735\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 554us/step - loss: 3.2075 - mse: 3.2075 - mae: 1.4165 - val_loss: 2.6490 - val_mse: 2.6490 - val_mae: 1.4832\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 238us/step - loss: 3.1929 - mse: 3.1929 - mae: 1.4149 - val_loss: 2.6455 - val_mse: 2.6455 - val_mae: 1.4873\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 237us/step - loss: 3.1782 - mse: 3.1782 - mae: 1.4130 - val_loss: 2.6388 - val_mse: 2.6388 - val_mae: 1.4867\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 652us/step - loss: 3.1584 - mse: 3.1584 - mae: 1.4083 - val_loss: 2.6295 - val_mse: 2.6295 - val_mae: 1.4827\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 166us/step - loss: 3.1353 - mse: 3.1353 - mae: 1.4009 - val_loss: 2.6213 - val_mse: 2.6213 - val_mae: 1.4775\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 385us/step - loss: 3.1139 - mse: 3.1139 - mae: 1.3936 - val_loss: 2.6175 - val_mse: 2.6175 - val_mae: 1.4728\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 211us/step - loss: 3.0919 - mse: 3.0919 - mae: 1.3857 - val_loss: 2.6169 - val_mse: 2.6169 - val_mae: 1.4687\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 557us/step - loss: 3.0736 - mse: 3.0736 - mae: 1.3791 - val_loss: 2.6141 - val_mse: 2.6141 - val_mae: 1.4647\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 290us/step - loss: 3.0560 - mse: 3.0560 - mae: 1.3726 - val_loss: 2.6058 - val_mse: 2.6058 - val_mae: 1.4597\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 696us/step - loss: 3.0380 - mse: 3.0380 - mae: 1.3665 - val_loss: 2.5934 - val_mse: 2.5934 - val_mae: 1.4541\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 206us/step - loss: 3.0213 - mse: 3.0213 - mae: 1.3609 - val_loss: 2.5820 - val_mse: 2.5820 - val_mae: 1.4501\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 257us/step - loss: 3.0066 - mse: 3.0066 - mae: 1.3563 - val_loss: 2.5744 - val_mse: 2.5744 - val_mae: 1.4481\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 216us/step - loss: 2.9921 - mse: 2.9921 - mae: 1.3521 - val_loss: 2.5703 - val_mse: 2.5703 - val_mae: 1.4473\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 298us/step - loss: 2.9775 - mse: 2.9775 - mae: 1.3483 - val_loss: 2.5683 - val_mse: 2.5683 - val_mae: 1.4471\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 242us/step - loss: 2.9629 - mse: 2.9629 - mae: 1.3450 - val_loss: 2.5689 - val_mse: 2.5689 - val_mae: 1.4477\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 360us/step - loss: 2.9488 - mse: 2.9488 - mae: 1.3418 - val_loss: 2.5724 - val_mse: 2.5724 - val_mae: 1.4488\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 236us/step - loss: 2.9351 - mse: 2.9351 - mae: 1.3386 - val_loss: 2.5777 - val_mse: 2.5777 - val_mae: 1.4500\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 257us/step - loss: 2.9217 - mse: 2.9217 - mae: 1.3354 - val_loss: 2.5809 - val_mse: 2.5809 - val_mae: 1.4507\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 206us/step - loss: 2.9084 - mse: 2.9084 - mae: 1.3320 - val_loss: 2.5842 - val_mse: 2.5842 - val_mae: 1.4512\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 760us/step - loss: 2.8948 - mse: 2.8948 - mae: 1.3283 - val_loss: 2.5874 - val_mse: 2.5874 - val_mae: 1.4518\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 206us/step - loss: 2.8811 - mse: 2.8811 - mae: 1.3246 - val_loss: 2.5904 - val_mse: 2.5904 - val_mae: 1.4524\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 329us/step - loss: 2.8665 - mse: 2.8665 - mae: 1.3207 - val_loss: 2.5951 - val_mse: 2.5951 - val_mae: 1.4535\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 175us/step - loss: 2.8521 - mse: 2.8521 - mae: 1.3171 - val_loss: 2.6041 - val_mse: 2.6041 - val_mae: 1.4562\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 236us/step - loss: 2.8376 - mse: 2.8376 - mae: 1.3134 - val_loss: 2.6214 - val_mse: 2.6214 - val_mae: 1.4609\n",
      "11\n",
      "[11]\n",
      "Train on 98 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 20.7081 - mse: 20.7081 - mae: 3.8002 - val_loss: 10.2888 - val_mse: 10.2888 - val_mae: 2.9571\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 17.6449 - mse: 17.6449 - mae: 3.4759 - val_loss: 8.7423 - val_mse: 8.7423 - val_mae: 2.6960\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 14.9376 - mse: 14.9376 - mae: 3.1672 - val_loss: 7.5336 - val_mse: 7.5336 - val_mae: 2.4692\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 12.7195 - mse: 12.7195 - mae: 2.8892 - val_loss: 6.6198 - val_mse: 6.6198 - val_mae: 2.2810\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 10.9170 - mse: 10.9170 - mae: 2.6422 - val_loss: 5.8813 - val_mse: 5.8813 - val_mae: 2.1185\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 9.4944 - mse: 9.4944 - mae: 2.4293 - val_loss: 5.2654 - val_mse: 5.2654 - val_mae: 1.9712\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 8.3692 - mse: 8.3692 - mae: 2.2415 - val_loss: 4.7494 - val_mse: 4.7494 - val_mae: 1.8373\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 7.4792 - mse: 7.4792 - mae: 2.0955 - val_loss: 4.3196 - val_mse: 4.3196 - val_mae: 1.7266\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 6.7858 - mse: 6.7858 - mae: 1.9754 - val_loss: 3.9502 - val_mse: 3.9502 - val_mae: 1.6421\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 6.2297 - mse: 6.2297 - mae: 1.8765 - val_loss: 3.6393 - val_mse: 3.6393 - val_mae: 1.5680\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 5.7706 - mse: 5.7706 - mae: 1.7888 - val_loss: 3.3731 - val_mse: 3.3731 - val_mae: 1.5031\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 5.3916 - mse: 5.3916 - mae: 1.7119 - val_loss: 3.1446 - val_mse: 3.1446 - val_mae: 1.4445\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 315us/step - loss: 5.0764 - mse: 5.0764 - mae: 1.6432 - val_loss: 2.9450 - val_mse: 2.9450 - val_mae: 1.3898\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 265us/step - loss: 4.8032 - mse: 4.8032 - mae: 1.5932 - val_loss: 2.7737 - val_mse: 2.7737 - val_mae: 1.3529\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 4.5651 - mse: 4.5651 - mae: 1.5492 - val_loss: 2.6198 - val_mse: 2.6198 - val_mae: 1.3190\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 4.3546 - mse: 4.3546 - mae: 1.5071 - val_loss: 2.4823 - val_mse: 2.4823 - val_mae: 1.2875\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 183us/step - loss: 4.1692 - mse: 4.1692 - mae: 1.4677 - val_loss: 2.3615 - val_mse: 2.3615 - val_mae: 1.2649\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 4.0043 - mse: 4.0043 - mae: 1.4388 - val_loss: 2.2523 - val_mse: 2.2523 - val_mae: 1.2488\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 3.8513 - mse: 3.8513 - mae: 1.4157 - val_loss: 2.1535 - val_mse: 2.1535 - val_mae: 1.2325\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 193us/step - loss: 3.7100 - mse: 3.7100 - mae: 1.3973 - val_loss: 2.0649 - val_mse: 2.0649 - val_mae: 1.2159\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 3.5796 - mse: 3.5796 - mae: 1.3819 - val_loss: 1.9828 - val_mse: 1.9828 - val_mae: 1.1989\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 3.4594 - mse: 3.4594 - mae: 1.3718 - val_loss: 1.9142 - val_mse: 1.9142 - val_mae: 1.1838\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 3.3438 - mse: 3.3438 - mae: 1.3608 - val_loss: 1.8523 - val_mse: 1.8523 - val_mae: 1.1678\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 193us/step - loss: 3.2380 - mse: 3.2380 - mae: 1.3501 - val_loss: 1.8029 - val_mse: 1.8029 - val_mae: 1.1534\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 203us/step - loss: 3.1431 - mse: 3.1431 - mae: 1.3420 - val_loss: 1.7614 - val_mse: 1.7614 - val_mae: 1.1462\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 3.0557 - mse: 3.0557 - mae: 1.3330 - val_loss: 1.7249 - val_mse: 1.7249 - val_mae: 1.1409\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 2.9726 - mse: 2.9726 - mae: 1.3227 - val_loss: 1.6925 - val_mse: 1.6925 - val_mae: 1.1347\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 2.8965 - mse: 2.8965 - mae: 1.3127 - val_loss: 1.6656 - val_mse: 1.6656 - val_mae: 1.1297\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 193us/step - loss: 2.8249 - mse: 2.8249 - mae: 1.3023 - val_loss: 1.6429 - val_mse: 1.6429 - val_mae: 1.1285\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 2.7584 - mse: 2.7584 - mae: 1.2920 - val_loss: 1.6249 - val_mse: 1.6249 - val_mae: 1.1277\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 173us/step - loss: 2.6977 - mse: 2.6977 - mae: 1.2822 - val_loss: 1.6117 - val_mse: 1.6117 - val_mae: 1.1273\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 153us/step - loss: 2.6418 - mse: 2.6418 - mae: 1.2724 - val_loss: 1.6026 - val_mse: 1.6026 - val_mae: 1.1271\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 173us/step - loss: 2.5898 - mse: 2.5898 - mae: 1.2625 - val_loss: 1.5978 - val_mse: 1.5978 - val_mae: 1.1276\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 173us/step - loss: 2.5418 - mse: 2.5418 - mae: 1.2533 - val_loss: 1.5954 - val_mse: 1.5954 - val_mae: 1.1283\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 356us/step - loss: 2.4997 - mse: 2.4997 - mae: 1.2447 - val_loss: 1.5937 - val_mse: 1.5937 - val_mae: 1.1291\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 489us/step - loss: 2.4613 - mse: 2.4613 - mae: 1.2362 - val_loss: 1.5934 - val_mse: 1.5934 - val_mae: 1.1304\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 411us/step - loss: 2.4266 - mse: 2.4266 - mae: 1.2279 - val_loss: 1.5930 - val_mse: 1.5930 - val_mae: 1.1312\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.3943 - mse: 2.3943 - mae: 1.2196 - val_loss: 1.5934 - val_mse: 1.5934 - val_mae: 1.1322\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 319us/step - loss: 2.3647 - mse: 2.3647 - mae: 1.2118 - val_loss: 1.5932 - val_mse: 1.5932 - val_mae: 1.1329\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.3375 - mse: 2.3375 - mae: 1.2048 - val_loss: 1.5925 - val_mse: 1.5925 - val_mae: 1.1334\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 319us/step - loss: 2.3126 - mse: 2.3126 - mae: 1.1984 - val_loss: 1.5926 - val_mse: 1.5926 - val_mae: 1.1340\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.2907 - mse: 2.2907 - mae: 1.1928 - val_loss: 1.5920 - val_mse: 1.5920 - val_mae: 1.1343\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.2716 - mse: 2.2716 - mae: 1.1881 - val_loss: 1.5907 - val_mse: 1.5907 - val_mae: 1.1344\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.2541 - mse: 2.2541 - mae: 1.1839 - val_loss: 1.5895 - val_mse: 1.5895 - val_mae: 1.1342\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.2376 - mse: 2.2376 - mae: 1.1795 - val_loss: 1.5886 - val_mse: 1.5886 - val_mae: 1.1340\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 159us/step - loss: 2.2227 - mse: 2.2227 - mae: 1.1751 - val_loss: 1.5875 - val_mse: 1.5875 - val_mae: 1.1337\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 240us/step - loss: 2.2091 - mse: 2.2091 - mae: 1.1708 - val_loss: 1.5870 - val_mse: 1.5870 - val_mae: 1.1337\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 163us/step - loss: 2.1962 - mse: 2.1962 - mae: 1.1666 - val_loss: 1.5865 - val_mse: 1.5865 - val_mae: 1.1336\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 2.1840 - mse: 2.1840 - mae: 1.1631 - val_loss: 1.5858 - val_mse: 1.5858 - val_mae: 1.1334\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 173us/step - loss: 2.1726 - mse: 2.1726 - mae: 1.1599 - val_loss: 1.5849 - val_mse: 1.5849 - val_mae: 1.1331\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 183us/step - loss: 2.1620 - mse: 2.1620 - mae: 1.1567 - val_loss: 1.5838 - val_mse: 1.5838 - val_mae: 1.1328\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 2.1520 - mse: 2.1520 - mae: 1.1537 - val_loss: 1.5827 - val_mse: 1.5827 - val_mae: 1.1325\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 193us/step - loss: 2.1427 - mse: 2.1427 - mae: 1.1509 - val_loss: 1.5823 - val_mse: 1.5823 - val_mae: 1.1324\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 2.1334 - mse: 2.1334 - mae: 1.1479 - val_loss: 1.5820 - val_mse: 1.5820 - val_mae: 1.1323\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 193us/step - loss: 2.1248 - mse: 2.1248 - mae: 1.1452 - val_loss: 1.5813 - val_mse: 1.5813 - val_mae: 1.1320\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 2.1166 - mse: 2.1166 - mae: 1.1426 - val_loss: 1.5806 - val_mse: 1.5806 - val_mae: 1.1317\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 2.1087 - mse: 2.1087 - mae: 1.1399 - val_loss: 1.5795 - val_mse: 1.5795 - val_mae: 1.1312\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 265us/step - loss: 2.1012 - mse: 2.1012 - mae: 1.1374 - val_loss: 1.5784 - val_mse: 1.5784 - val_mae: 1.1306\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 2.0940 - mse: 2.0940 - mae: 1.1349 - val_loss: 1.5776 - val_mse: 1.5776 - val_mae: 1.1302\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 193us/step - loss: 2.0869 - mse: 2.0869 - mae: 1.1324 - val_loss: 1.5769 - val_mse: 1.5769 - val_mae: 1.1298\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 2.0802 - mse: 2.0802 - mae: 1.1300 - val_loss: 1.5760 - val_mse: 1.5760 - val_mae: 1.1293\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 2.0737 - mse: 2.0737 - mae: 1.1278 - val_loss: 1.5750 - val_mse: 1.5750 - val_mae: 1.1288\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 2.0678 - mse: 2.0678 - mae: 1.1259 - val_loss: 1.5744 - val_mse: 1.5744 - val_mae: 1.1283\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 2.0620 - mse: 2.0620 - mae: 1.1239 - val_loss: 1.5736 - val_mse: 1.5736 - val_mae: 1.1278\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 2.0516 - mse: 2.0516 - mae: 1.1206 - val_loss: 1.5727 - val_mse: 1.5727 - val_mae: 1.1273\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 2.0406 - mse: 2.0406 - mae: 1.1169 - val_loss: 1.5717 - val_mse: 1.5717 - val_mae: 1.1267\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.5822 - mse: 2.5822 - mae: 1.166 - 0s 254us/step - loss: 2.0294 - mse: 2.0294 - mae: 1.1130 - val_loss: 1.5712 - val_mse: 1.5712 - val_mae: 1.1262\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 2.0199 - mse: 2.0199 - mae: 1.1092 - val_loss: 1.5711 - val_mse: 1.5711 - val_mae: 1.1257\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 2.0117 - mse: 2.0117 - mae: 1.1059 - val_loss: 1.5713 - val_mse: 1.5713 - val_mae: 1.1252\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 2.0023 - mse: 2.0023 - mae: 1.1010 - val_loss: 1.5716 - val_mse: 1.5716 - val_mae: 1.1248\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 183us/step - loss: 1.9937 - mse: 1.9937 - mae: 1.0952 - val_loss: 1.5723 - val_mse: 1.5723 - val_mae: 1.1244\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 316us/step - loss: 1.9893 - mse: 1.9893 - mae: 1.0969 - val_loss: 1.5731 - val_mse: 1.5731 - val_mae: 1.1240\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 183us/step - loss: 1.9852 - mse: 1.9852 - mae: 1.0964 - val_loss: 1.5735 - val_mse: 1.5735 - val_mae: 1.1236\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 192us/step - loss: 1.9794 - mse: 1.9794 - mae: 1.0939 - val_loss: 1.5729 - val_mse: 1.5729 - val_mae: 1.1229\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 1.9733 - mse: 1.9733 - mae: 1.0912 - val_loss: 1.5717 - val_mse: 1.5717 - val_mae: 1.1221\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 1.9668 - mse: 1.9668 - mae: 1.0885 - val_loss: 1.5711 - val_mse: 1.5711 - val_mae: 1.1215\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 1.9608 - mse: 1.9608 - mae: 1.0857 - val_loss: 1.5704 - val_mse: 1.5704 - val_mae: 1.1210\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.4681 - mse: 2.4681 - mae: 1.115 - 0s 285us/step - loss: 1.9553 - mse: 1.9553 - mae: 1.0830 - val_loss: 1.5696 - val_mse: 1.5696 - val_mae: 1.1205\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 1.9500 - mse: 1.9500 - mae: 1.0806 - val_loss: 1.5688 - val_mse: 1.5688 - val_mae: 1.1199\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 1.9448 - mse: 1.9448 - mae: 1.0785 - val_loss: 1.5678 - val_mse: 1.5678 - val_mae: 1.1191\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 336us/step - loss: 1.9392 - mse: 1.9392 - mae: 1.0764 - val_loss: 1.5670 - val_mse: 1.5670 - val_mae: 1.1182\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 265us/step - loss: 1.9333 - mse: 1.9333 - mae: 1.0743 - val_loss: 1.5674 - val_mse: 1.5674 - val_mae: 1.1176\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 1.9275 - mse: 1.9275 - mae: 1.0701 - val_loss: 1.5687 - val_mse: 1.5687 - val_mae: 1.1173\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 438us/step - loss: 1.9229 - mse: 1.9229 - mae: 1.0705 - val_loss: 1.5701 - val_mse: 1.5701 - val_mae: 1.1170\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 387us/step - loss: 1.9177 - mse: 1.9177 - mae: 1.0678 - val_loss: 1.5705 - val_mse: 1.5705 - val_mae: 1.1162\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 1.9126 - mse: 1.9126 - mae: 1.0652 - val_loss: 1.5701 - val_mse: 1.5701 - val_mae: 1.1152\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 1.9077 - mse: 1.9077 - mae: 1.0631 - val_loss: 1.5705 - val_mse: 1.5705 - val_mae: 1.1145\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 275us/step - loss: 1.9030 - mse: 1.9030 - mae: 1.0607 - val_loss: 1.5710 - val_mse: 1.5710 - val_mae: 1.1138\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 275us/step - loss: 1.8986 - mse: 1.8986 - mae: 1.0596 - val_loss: 1.5714 - val_mse: 1.5714 - val_mae: 1.1131\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 1.8949 - mse: 1.8949 - mae: 1.0580 - val_loss: 1.5712 - val_mse: 1.5712 - val_mae: 1.1123\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 1.8903 - mse: 1.8903 - mae: 1.0560 - val_loss: 1.5705 - val_mse: 1.5705 - val_mae: 1.1115\n",
      "12\n",
      "[12]\n",
      "Train on 74 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 4.9789 - mse: 4.9789 - mae: 2.0417 - val_loss: 4.7753 - val_mse: 4.7753 - val_mae: 2.0156\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 229us/step - loss: 4.2922 - mse: 4.2922 - mae: 1.8715 - val_loss: 4.0581 - val_mse: 4.0581 - val_mae: 1.8260\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 229us/step - loss: 3.6599 - mse: 3.6599 - mae: 1.6988 - val_loss: 3.4305 - val_mse: 3.4305 - val_mae: 1.6372\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 3.1080 - mse: 3.1080 - mae: 1.5319 - val_loss: 2.8964 - val_mse: 2.8964 - val_mae: 1.4506\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 270us/step - loss: 2.6212 - mse: 2.6212 - mae: 1.3697 - val_loss: 2.4357 - val_mse: 2.4357 - val_mae: 1.2662\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 351us/step - loss: 2.2030 - mse: 2.2030 - mae: 1.2123 - val_loss: 2.0567 - val_mse: 2.0567 - val_mae: 1.0966\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 1.8436 - mse: 1.8436 - mae: 1.0668 - val_loss: 1.7442 - val_mse: 1.7442 - val_mae: 0.9819\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 1.5461 - mse: 1.5461 - mae: 0.9424 - val_loss: 1.5124 - val_mse: 1.5124 - val_mae: 0.8932\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 1.3091 - mse: 1.3091 - mae: 0.8418 - val_loss: 1.3409 - val_mse: 1.3409 - val_mae: 0.8198\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 431us/step - loss: 1.1322 - mse: 1.1322 - mae: 0.7607 - val_loss: 1.2234 - val_mse: 1.2234 - val_mae: 0.7830\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 377us/step - loss: 1.0067 - mse: 1.0067 - mae: 0.7091 - val_loss: 1.1504 - val_mse: 1.1504 - val_mae: 0.7564\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 270us/step - loss: 0.9237 - mse: 0.9237 - mae: 0.6788 - val_loss: 1.1029 - val_mse: 1.1029 - val_mae: 0.7777\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 296us/step - loss: 0.8722 - mse: 0.8722 - mae: 0.6698 - val_loss: 1.0723 - val_mse: 1.0723 - val_mae: 0.8037\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.8408 - mse: 0.8408 - mae: 0.6698 - val_loss: 1.0585 - val_mse: 1.0585 - val_mae: 0.8243\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 0.8197 - mse: 0.8197 - mae: 0.6719 - val_loss: 1.0534 - val_mse: 1.0534 - val_mae: 0.8381\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 0.8032 - mse: 0.8032 - mae: 0.6730 - val_loss: 1.0516 - val_mse: 1.0516 - val_mae: 0.8462\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 229us/step - loss: 0.7886 - mse: 0.7886 - mae: 0.6727 - val_loss: 1.0504 - val_mse: 1.0504 - val_mae: 0.8496\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 0.7745 - mse: 0.7745 - mae: 0.6705 - val_loss: 1.0497 - val_mse: 1.0497 - val_mae: 0.8498\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 391us/step - loss: 0.7610 - mse: 0.7610 - mae: 0.6666 - val_loss: 1.0478 - val_mse: 1.0478 - val_mae: 0.8473\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 297us/step - loss: 0.7478 - mse: 0.7478 - mae: 0.6609 - val_loss: 1.0456 - val_mse: 1.0456 - val_mae: 0.8437\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 0.7348 - mse: 0.7348 - mae: 0.6542 - val_loss: 1.0428 - val_mse: 1.0428 - val_mae: 0.8393\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.7221 - mse: 0.7221 - mae: 0.6465 - val_loss: 1.0400 - val_mse: 1.0400 - val_mae: 0.8344\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 404us/step - loss: 0.7105 - mse: 0.7105 - mae: 0.6386 - val_loss: 1.0370 - val_mse: 1.0370 - val_mae: 0.8296\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 0.6993 - mse: 0.6993 - mae: 0.6306 - val_loss: 1.0341 - val_mse: 1.0341 - val_mae: 0.8251\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 0.6881 - mse: 0.6881 - mae: 0.6225 - val_loss: 1.0316 - val_mse: 1.0316 - val_mae: 0.8212\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 216us/step - loss: 0.6772 - mse: 0.6772 - mae: 0.6146 - val_loss: 1.0300 - val_mse: 1.0300 - val_mae: 0.8185\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.6663 - mse: 0.6663 - mae: 0.6068 - val_loss: 1.0287 - val_mse: 1.0287 - val_mae: 0.8168\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 297us/step - loss: 0.6552 - mse: 0.6552 - mae: 0.5993 - val_loss: 1.0275 - val_mse: 1.0275 - val_mae: 0.8158\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.6444 - mse: 0.6444 - mae: 0.5922 - val_loss: 1.0266 - val_mse: 1.0266 - val_mae: 0.8154\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.6342 - mse: 0.6342 - mae: 0.5862 - val_loss: 1.0261 - val_mse: 1.0261 - val_mae: 0.8156\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.6234 - mse: 0.6234 - mae: 0.5808 - val_loss: 1.0257 - val_mse: 1.0257 - val_mae: 0.8163\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 0.6122 - mse: 0.6122 - mae: 0.5759 - val_loss: 1.0202 - val_mse: 1.0202 - val_mae: 0.8155\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.5996 - mse: 0.5996 - mae: 0.5706 - val_loss: 1.0119 - val_mse: 1.0119 - val_mae: 0.8139\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.5874 - mse: 0.5874 - mae: 0.5662 - val_loss: 1.0038 - val_mse: 1.0038 - val_mae: 0.8130\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 0s 216us/step - loss: 0.5765 - mse: 0.5765 - mae: 0.5622 - val_loss: 0.9960 - val_mse: 0.9960 - val_mae: 0.8130\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 0s 297us/step - loss: 0.5665 - mse: 0.5665 - mae: 0.5571 - val_loss: 0.9883 - val_mse: 0.9883 - val_mae: 0.8123\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 0.5572 - mse: 0.5572 - mae: 0.5510 - val_loss: 0.9806 - val_mse: 0.9806 - val_mae: 0.8107\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.5482 - mse: 0.5482 - mae: 0.5440 - val_loss: 0.9724 - val_mse: 0.9724 - val_mae: 0.8078\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 0s 350us/step - loss: 0.5401 - mse: 0.5401 - mae: 0.5369 - val_loss: 0.9645 - val_mse: 0.9645 - val_mae: 0.8054\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.5323 - mse: 0.5323 - mae: 0.5305 - val_loss: 0.9565 - val_mse: 0.9565 - val_mae: 0.8037\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - 0s 296us/step - loss: 0.5242 - mse: 0.5242 - mae: 0.5250 - val_loss: 0.9500 - val_mse: 0.9500 - val_mae: 0.8028\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - 0s 229us/step - loss: 0.5165 - mse: 0.5165 - mae: 0.5202 - val_loss: 0.9459 - val_mse: 0.9459 - val_mae: 0.8025\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - 0s 323us/step - loss: 0.5094 - mse: 0.5094 - mae: 0.5153 - val_loss: 0.9406 - val_mse: 0.9406 - val_mae: 0.8003\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - 0s 297us/step - loss: 0.5032 - mse: 0.5032 - mae: 0.5101 - val_loss: 0.9422 - val_mse: 0.9422 - val_mae: 0.7994\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.4977 - mse: 0.4977 - mae: 0.5051 - val_loss: 0.9440 - val_mse: 0.9440 - val_mae: 0.7990\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - 0s 269us/step - loss: 0.4927 - mse: 0.4927 - mae: 0.5007 - val_loss: 0.9460 - val_mse: 0.9460 - val_mae: 0.7992\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.4884 - mse: 0.4884 - mae: 0.4972 - val_loss: 0.9469 - val_mse: 0.9469 - val_mae: 0.7998\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 0.4838 - mse: 0.4838 - mae: 0.4944 - val_loss: 0.9453 - val_mse: 0.9453 - val_mae: 0.8009\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - 0s 216us/step - loss: 0.4791 - mse: 0.4791 - mae: 0.4926 - val_loss: 0.9446 - val_mse: 0.9446 - val_mae: 0.8021\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.4744 - mse: 0.4744 - mae: 0.4911 - val_loss: 0.9451 - val_mse: 0.9451 - val_mae: 0.8031\n",
      "Epoch 51/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.4699 - mse: 0.4699 - mae: 0.4893 - val_loss: 0.9469 - val_mse: 0.9469 - val_mae: 0.8040\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 350us/step - loss: 0.4654 - mse: 0.4654 - mae: 0.4868 - val_loss: 0.9498 - val_mse: 0.9498 - val_mae: 0.8048\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - 0s 270us/step - loss: 0.4608 - mse: 0.4608 - mae: 0.4839 - val_loss: 0.9531 - val_mse: 0.9531 - val_mae: 0.8056\n",
      "13\n",
      "[13]\n",
      "Train on 86 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 7.5035 - mse: 7.5035 - mae: 2.3615 - val_loss: 4.4418 - val_mse: 4.4418 - val_mae: 1.8336\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 6.1136 - mse: 6.1136 - mae: 2.0633 - val_loss: 3.5627 - val_mse: 3.5627 - val_mae: 1.5791\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 4.9738 - mse: 4.9738 - mae: 1.7929 - val_loss: 2.8347 - val_mse: 2.8347 - val_mae: 1.3561\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 174us/step - loss: 4.0813 - mse: 4.0813 - mae: 1.5559 - val_loss: 2.2815 - val_mse: 2.2815 - val_mae: 1.1707\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 3.3859 - mse: 3.3859 - mae: 1.3826 - val_loss: 1.8470 - val_mse: 1.8470 - val_mae: 1.0096\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 244us/step - loss: 2.8715 - mse: 2.8715 - mae: 1.2462 - val_loss: 1.5084 - val_mse: 1.5084 - val_mae: 0.8908\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 2.4944 - mse: 2.4944 - mae: 1.1537 - val_loss: 1.2684 - val_mse: 1.2684 - val_mae: 0.7964\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 348us/step - loss: 2.2449 - mse: 2.2449 - mae: 1.1160 - val_loss: 1.1145 - val_mse: 1.1145 - val_mae: 0.7421\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 2.1035 - mse: 2.1035 - mae: 1.1041 - val_loss: 1.0252 - val_mse: 1.0252 - val_mae: 0.7249\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 197us/step - loss: 2.0365 - mse: 2.0365 - mae: 1.1150 - val_loss: 0.9792 - val_mse: 0.9792 - val_mae: 0.7253\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 186us/step - loss: 2.0214 - mse: 2.0214 - mae: 1.1396 - val_loss: 0.9560 - val_mse: 0.9560 - val_mae: 0.7320\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 359us/step - loss: 2.0260 - mse: 2.0260 - mae: 1.1596 - val_loss: 0.9402 - val_mse: 0.9402 - val_mae: 0.7390\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 2.0264 - mse: 2.0264 - mae: 1.1709 - val_loss: 0.9237 - val_mse: 0.9237 - val_mae: 0.7393\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 220us/step - loss: 2.0147 - mse: 2.0147 - mae: 1.1705 - val_loss: 0.9065 - val_mse: 0.9065 - val_mae: 0.7355\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.9936 - mse: 1.9936 - mae: 1.1612 - val_loss: 0.8899 - val_mse: 0.8899 - val_mae: 0.7285\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 333us/step - loss: 1.9685 - mse: 1.9685 - mae: 1.1479 - val_loss: 0.8759 - val_mse: 0.8759 - val_mae: 0.7197\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 197us/step - loss: 1.9437 - mse: 1.9437 - mae: 1.1320 - val_loss: 0.8647 - val_mse: 0.8647 - val_mae: 0.7123\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.9217 - mse: 1.9217 - mae: 1.1157 - val_loss: 0.8580 - val_mse: 0.8580 - val_mae: 0.7070\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 1.9035 - mse: 1.9035 - mae: 1.1017 - val_loss: 0.8530 - val_mse: 0.8530 - val_mae: 0.7018\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 174us/step - loss: 1.8878 - mse: 1.8878 - mae: 1.0908 - val_loss: 0.8477 - val_mse: 0.8477 - val_mae: 0.6973\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 197us/step - loss: 1.8737 - mse: 1.8737 - mae: 1.0816 - val_loss: 0.8401 - val_mse: 0.8401 - val_mae: 0.6930\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 1.8611 - mse: 1.8611 - mae: 1.0747 - val_loss: 0.8320 - val_mse: 0.8320 - val_mae: 0.6898\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 1.8502 - mse: 1.8502 - mae: 1.0699 - val_loss: 0.8232 - val_mse: 0.8232 - val_mae: 0.6878\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 417us/step - loss: 1.8402 - mse: 1.8402 - mae: 1.0668 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.6861\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 406us/step - loss: 1.8309 - mse: 1.8309 - mae: 1.0648 - val_loss: 0.8067 - val_mse: 0.8067 - val_mae: 0.6846\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 186us/step - loss: 1.8221 - mse: 1.8221 - mae: 1.0633 - val_loss: 0.7965 - val_mse: 0.7965 - val_mae: 0.6828\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.8133 - mse: 1.8133 - mae: 1.0619 - val_loss: 0.7862 - val_mse: 0.7862 - val_mae: 0.6808\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.8044 - mse: 1.8044 - mae: 1.0604 - val_loss: 0.7768 - val_mse: 0.7768 - val_mae: 0.6789\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 186us/step - loss: 1.7959 - mse: 1.7959 - mae: 1.0586 - val_loss: 0.7689 - val_mse: 0.7689 - val_mae: 0.6771\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 1.7876 - mse: 1.7876 - mae: 1.0561 - val_loss: 0.7622 - val_mse: 0.7622 - val_mae: 0.6753\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 174us/step - loss: 1.7798 - mse: 1.7798 - mae: 1.0535 - val_loss: 0.7569 - val_mse: 0.7569 - val_mae: 0.6736\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 360us/step - loss: 1.7723 - mse: 1.7723 - mae: 1.0507 - val_loss: 0.7536 - val_mse: 0.7536 - val_mae: 0.6726\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 1.7657 - mse: 1.7657 - mae: 1.0480 - val_loss: 0.7501 - val_mse: 0.7501 - val_mae: 0.6714\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 186us/step - loss: 1.7591 - mse: 1.7591 - mae: 1.0456 - val_loss: 0.7460 - val_mse: 0.7460 - val_mae: 0.6701\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 186us/step - loss: 1.7520 - mse: 1.7520 - mae: 1.0434 - val_loss: 0.7412 - val_mse: 0.7412 - val_mae: 0.6684\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 244us/step - loss: 1.7446 - mse: 1.7446 - mae: 1.0413 - val_loss: 0.7368 - val_mse: 0.7368 - val_mae: 0.6667\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.7384 - mse: 1.7384 - mae: 1.0395 - val_loss: 0.7327 - val_mse: 0.7327 - val_mae: 0.6649\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 1.7324 - mse: 1.7324 - mae: 1.0371 - val_loss: 0.7297 - val_mse: 0.7297 - val_mae: 0.6633\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 1.7263 - mse: 1.7263 - mae: 1.0345 - val_loss: 0.7276 - val_mse: 0.7276 - val_mae: 0.6618\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.7202 - mse: 1.7202 - mae: 1.0320 - val_loss: 0.7255 - val_mse: 0.7255 - val_mae: 0.6604\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 197us/step - loss: 1.7139 - mse: 1.7139 - mae: 1.0297 - val_loss: 0.7224 - val_mse: 0.7224 - val_mae: 0.6588\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.5931 - mse: 1.5931 - mae: 0.953 - 0s 371us/step - loss: 1.7074 - mse: 1.7074 - mae: 1.0276 - val_loss: 0.7184 - val_mse: 0.7184 - val_mae: 0.6573\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 266us/step - loss: 1.7009 - mse: 1.7009 - mae: 1.0257 - val_loss: 0.7140 - val_mse: 0.7140 - val_mae: 0.6559\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 1.6945 - mse: 1.6945 - mae: 1.0241 - val_loss: 0.7094 - val_mse: 0.7094 - val_mae: 0.6547\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 1.6883 - mse: 1.6883 - mae: 1.0226 - val_loss: 0.7059 - val_mse: 0.7059 - val_mae: 0.6539\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 197us/step - loss: 1.6822 - mse: 1.6822 - mae: 1.0210 - val_loss: 0.7034 - val_mse: 0.7034 - val_mae: 0.6533\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.6763 - mse: 1.6763 - mae: 1.0192 - val_loss: 0.7017 - val_mse: 0.7017 - val_mae: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 220us/step - loss: 1.6704 - mse: 1.6704 - mae: 1.0174 - val_loss: 0.6996 - val_mse: 0.6996 - val_mae: 0.6526\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.6645 - mse: 1.6645 - mae: 1.0157 - val_loss: 0.6969 - val_mse: 0.6969 - val_mae: 0.6519\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 244us/step - loss: 1.6586 - mse: 1.6586 - mae: 1.0141 - val_loss: 0.6947 - val_mse: 0.6947 - val_mae: 0.6512\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.5432 - mse: 1.5432 - mae: 0.936 - 0s 220us/step - loss: 1.6528 - mse: 1.6528 - mae: 1.0123 - val_loss: 0.6930 - val_mse: 0.6930 - val_mae: 0.6505\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 1.6471 - mse: 1.6471 - mae: 1.0103 - val_loss: 0.6916 - val_mse: 0.6916 - val_mae: 0.6506\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 1.6414 - mse: 1.6414 - mae: 1.0082 - val_loss: 0.6903 - val_mse: 0.6903 - val_mae: 0.6507\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.6357 - mse: 1.6357 - mae: 1.0060 - val_loss: 0.6888 - val_mse: 0.6888 - val_mae: 0.6509\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.6301 - mse: 1.6301 - mae: 1.0040 - val_loss: 0.6871 - val_mse: 0.6871 - val_mae: 0.6512\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.6244 - mse: 1.6244 - mae: 1.0020 - val_loss: 0.6851 - val_mse: 0.6851 - val_mae: 0.6516\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.6191 - mse: 1.6191 - mae: 1.0002 - val_loss: 0.6832 - val_mse: 0.6832 - val_mae: 0.6520\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 1.6136 - mse: 1.6136 - mae: 0.9985 - val_loss: 0.6819 - val_mse: 0.6819 - val_mae: 0.6526\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 162us/step - loss: 1.6082 - mse: 1.6082 - mae: 0.9969 - val_loss: 0.6812 - val_mse: 0.6812 - val_mae: 0.6533\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 1.6025 - mse: 1.6025 - mae: 0.9950 - val_loss: 0.6805 - val_mse: 0.6805 - val_mae: 0.6540\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 186us/step - loss: 1.5968 - mse: 1.5968 - mae: 0.9930 - val_loss: 0.6795 - val_mse: 0.6795 - val_mae: 0.6547\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.5908 - mse: 1.5908 - mae: 0.9908 - val_loss: 0.6784 - val_mse: 0.6784 - val_mae: 0.6555\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.5844 - mse: 1.5844 - mae: 0.9885 - val_loss: 0.6771 - val_mse: 0.6771 - val_mae: 0.6563\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.5783 - mse: 1.5783 - mae: 0.9862 - val_loss: 0.6760 - val_mse: 0.6760 - val_mae: 0.6570\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.5720 - mse: 1.5720 - mae: 0.9840 - val_loss: 0.6748 - val_mse: 0.6748 - val_mae: 0.6576\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 197us/step - loss: 1.5658 - mse: 1.5658 - mae: 0.9818 - val_loss: 0.6737 - val_mse: 0.6737 - val_mae: 0.6581\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 1.5596 - mse: 1.5596 - mae: 0.9795 - val_loss: 0.6720 - val_mse: 0.6720 - val_mae: 0.6588\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.5533 - mse: 1.5533 - mae: 0.9775 - val_loss: 0.6694 - val_mse: 0.6694 - val_mae: 0.6597\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 1.5471 - mse: 1.5471 - mae: 0.9759 - val_loss: 0.6666 - val_mse: 0.6666 - val_mae: 0.6605\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 348us/step - loss: 1.5414 - mse: 1.5414 - mae: 0.9747 - val_loss: 0.6642 - val_mse: 0.6642 - val_mae: 0.6608\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 1.5359 - mse: 1.5359 - mae: 0.9730 - val_loss: 0.6630 - val_mse: 0.6630 - val_mae: 0.6607\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 1.5301 - mse: 1.5301 - mae: 0.9708 - val_loss: 0.6625 - val_mse: 0.6625 - val_mae: 0.6603\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.5242 - mse: 1.5242 - mae: 0.9681 - val_loss: 0.6626 - val_mse: 0.6626 - val_mae: 0.6597\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.5184 - mse: 1.5184 - mae: 0.9653 - val_loss: 0.6630 - val_mse: 0.6630 - val_mae: 0.6593\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 1.5124 - mse: 1.5124 - mae: 0.9628 - val_loss: 0.6627 - val_mse: 0.6627 - val_mae: 0.6590\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.5065 - mse: 1.5065 - mae: 0.9603 - val_loss: 0.6621 - val_mse: 0.6621 - val_mae: 0.6587\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 1.5006 - mse: 1.5006 - mae: 0.9580 - val_loss: 0.6614 - val_mse: 0.6614 - val_mae: 0.6585\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.4139 - mse: 1.4139 - mae: 0.879 - 0s 301us/step - loss: 1.4948 - mse: 1.4948 - mae: 0.9561 - val_loss: 0.6609 - val_mse: 0.6609 - val_mae: 0.6584\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.4893 - mse: 1.4893 - mae: 0.9546 - val_loss: 0.6612 - val_mse: 0.6612 - val_mae: 0.6586\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.4840 - mse: 1.4840 - mae: 0.9529 - val_loss: 0.6618 - val_mse: 0.6618 - val_mae: 0.6590\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 244us/step - loss: 1.4783 - mse: 1.4783 - mae: 0.9506 - val_loss: 0.6615 - val_mse: 0.6615 - val_mae: 0.6594\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.4737 - mse: 1.4737 - mae: 0.9486 - val_loss: 0.6606 - val_mse: 0.6606 - val_mae: 0.6592\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 151us/step - loss: 1.4688 - mse: 1.4688 - mae: 0.9468 - val_loss: 0.6607 - val_mse: 0.6607 - val_mae: 0.6588\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 348us/step - loss: 1.4641 - mse: 1.4641 - mae: 0.9451 - val_loss: 0.6610 - val_mse: 0.6610 - val_mae: 0.6586\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.4594 - mse: 1.4594 - mae: 0.9437 - val_loss: 0.6614 - val_mse: 0.6614 - val_mae: 0.6588\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.4543 - mse: 1.4543 - mae: 0.9425 - val_loss: 0.6600 - val_mse: 0.6600 - val_mae: 0.6591\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.4501 - mse: 1.4501 - mae: 0.9416 - val_loss: 0.6592 - val_mse: 0.6592 - val_mae: 0.6589\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 1.4457 - mse: 1.4457 - mae: 0.9404 - val_loss: 0.6595 - val_mse: 0.6595 - val_mae: 0.6585\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.4411 - mse: 1.4411 - mae: 0.9388 - val_loss: 0.6598 - val_mse: 0.6598 - val_mae: 0.6585\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 1.4362 - mse: 1.4362 - mae: 0.9373 - val_loss: 0.6589 - val_mse: 0.6589 - val_mae: 0.6590\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.4317 - mse: 1.4317 - mae: 0.9363 - val_loss: 0.6582 - val_mse: 0.6582 - val_mae: 0.6592\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 244us/step - loss: 1.4274 - mse: 1.4274 - mae: 0.9352 - val_loss: 0.6581 - val_mse: 0.6581 - val_mae: 0.6592\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 220us/step - loss: 1.4231 - mse: 1.4231 - mae: 0.9337 - val_loss: 0.6579 - val_mse: 0.6579 - val_mae: 0.6593\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.4184 - mse: 1.4184 - mae: 0.9322 - val_loss: 0.6572 - val_mse: 0.6572 - val_mae: 0.6594\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.3643 - mse: 1.3643 - mae: 0.866 - 0s 325us/step - loss: 1.4140 - mse: 1.4140 - mae: 0.9309 - val_loss: 0.6572 - val_mse: 0.6572 - val_mae: 0.6595\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.4095 - mse: 1.4095 - mae: 0.9296 - val_loss: 0.6572 - val_mse: 0.6572 - val_mae: 0.6598\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 1.4050 - mse: 1.4050 - mae: 0.9282 - val_loss: 0.6573 - val_mse: 0.6573 - val_mae: 0.6603\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.4009 - mse: 1.4009 - mae: 0.9270 - val_loss: 0.6572 - val_mse: 0.6572 - val_mae: 0.6604\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.3965 - mse: 1.3965 - mae: 0.9257 - val_loss: 0.6572 - val_mse: 0.6572 - val_mae: 0.6605\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 232us/step - loss: 1.3920 - mse: 1.3920 - mae: 0.9241 - val_loss: 0.6566 - val_mse: 0.6566 - val_mae: 0.6609\n",
      "14\n",
      "[14]\n",
      "Train on 76 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 7.5890 - mse: 7.5890 - mae: 2.4557 - val_loss: 8.5586 - val_mse: 8.5586 - val_mae: 2.6283\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 197us/step - loss: 6.4960 - mse: 6.4960 - mae: 2.2285 - val_loss: 7.2819 - val_mse: 7.2819 - val_mae: 2.3892\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 5.5529 - mse: 5.5529 - mae: 2.0128 - val_loss: 6.1589 - val_mse: 6.1589 - val_mae: 2.1608\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 262us/step - loss: 4.7599 - mse: 4.7599 - mae: 1.8084 - val_loss: 5.1067 - val_mse: 5.1067 - val_mae: 1.9115\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 525us/step - loss: 4.1008 - mse: 4.1008 - mae: 1.6172 - val_loss: 4.2459 - val_mse: 4.2459 - val_mae: 1.7071\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 341us/step - loss: 3.5037 - mse: 3.5037 - mae: 1.4352 - val_loss: 3.4622 - val_mse: 3.4622 - val_mae: 1.4983\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 210us/step - loss: 2.9932 - mse: 2.9932 - mae: 1.2782 - val_loss: 2.7948 - val_mse: 2.7948 - val_mae: 1.2957\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 2.5558 - mse: 2.5558 - mae: 1.1385 - val_loss: 2.2708 - val_mse: 2.2708 - val_mae: 1.1714\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 341us/step - loss: 2.2085 - mse: 2.2085 - mae: 1.0261 - val_loss: 1.8850 - val_mse: 1.8850 - val_mae: 1.0868\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 289us/step - loss: 1.9500 - mse: 1.9500 - mae: 0.9439 - val_loss: 1.6347 - val_mse: 1.6347 - val_mae: 1.0114\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 1.7871 - mse: 1.7871 - mae: 0.9016 - val_loss: 1.5049 - val_mse: 1.5049 - val_mae: 0.9514\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 315us/step - loss: 1.6999 - mse: 1.6999 - mae: 0.8917 - val_loss: 1.4575 - val_mse: 1.4575 - val_mae: 0.9581\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 249us/step - loss: 1.6670 - mse: 1.6670 - mae: 0.8996 - val_loss: 1.4591 - val_mse: 1.4591 - val_mae: 0.9892\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 1.6648 - mse: 1.6648 - mae: 0.9218 - val_loss: 1.4800 - val_mse: 1.4800 - val_mae: 1.0239\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 276us/step - loss: 1.6706 - mse: 1.6706 - mae: 0.9389 - val_loss: 1.4968 - val_mse: 1.4968 - val_mae: 1.0424\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 302us/step - loss: 1.6706 - mse: 1.6706 - mae: 0.9459 - val_loss: 1.4977 - val_mse: 1.4977 - val_mae: 1.0464\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 276us/step - loss: 1.6589 - mse: 1.6589 - mae: 0.9431 - val_loss: 1.4821 - val_mse: 1.4821 - val_mae: 1.0388\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 394us/step - loss: 1.6384 - mse: 1.6384 - mae: 0.9329 - val_loss: 1.4570 - val_mse: 1.4570 - val_mae: 1.0232\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 262us/step - loss: 1.6147 - mse: 1.6147 - mae: 0.9190 - val_loss: 1.4306 - val_mse: 1.4306 - val_mae: 1.0030\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 499us/step - loss: 1.5923 - mse: 1.5923 - mae: 0.9032 - val_loss: 1.4090 - val_mse: 1.4090 - val_mae: 0.9822\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 213us/step - loss: 1.5740 - mse: 1.5740 - mae: 0.8892 - val_loss: 1.3943 - val_mse: 1.3943 - val_mae: 0.9661\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 302us/step - loss: 1.5598 - mse: 1.5598 - mae: 0.8777 - val_loss: 1.3852 - val_mse: 1.3852 - val_mae: 0.9570\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 367us/step - loss: 1.5481 - mse: 1.5481 - mae: 0.8680 - val_loss: 1.3799 - val_mse: 1.3799 - val_mae: 0.9508\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 262us/step - loss: 1.5375 - mse: 1.5375 - mae: 0.8613 - val_loss: 1.3765 - val_mse: 1.3765 - val_mae: 0.9472\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 302us/step - loss: 1.5266 - mse: 1.5266 - mae: 0.8563 - val_loss: 1.3736 - val_mse: 1.3736 - val_mae: 0.9461\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 433us/step - loss: 1.5151 - mse: 1.5151 - mae: 0.8523 - val_loss: 1.3710 - val_mse: 1.3710 - val_mae: 0.9471\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 1.5032 - mse: 1.5032 - mae: 0.8488 - val_loss: 1.3689 - val_mse: 1.3689 - val_mae: 0.9496\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 263us/step - loss: 1.4912 - mse: 1.4912 - mae: 0.8469 - val_loss: 1.3674 - val_mse: 1.3674 - val_mae: 0.9534\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 368us/step - loss: 1.4802 - mse: 1.4802 - mae: 0.8459 - val_loss: 1.3665 - val_mse: 1.3665 - val_mae: 0.9571\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.4696 - mse: 1.4696 - mae: 0.8450 - val_loss: 1.3659 - val_mse: 1.3659 - val_mae: 0.9605\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.4583 - mse: 1.4583 - mae: 0.8438 - val_loss: 1.3655 - val_mse: 1.3655 - val_mae: 0.9637\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 0s 276us/step - loss: 1.4477 - mse: 1.4477 - mae: 0.8424 - val_loss: 1.3646 - val_mse: 1.3646 - val_mae: 0.9665\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.4397 - mse: 1.4397 - mae: 0.8410 - val_loss: 1.3632 - val_mse: 1.3632 - val_mae: 0.9688\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.4317 - mse: 1.4317 - mae: 0.8390 - val_loss: 1.3612 - val_mse: 1.3612 - val_mae: 0.9707\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 1.4239 - mse: 1.4239 - mae: 0.8368 - val_loss: 1.3597 - val_mse: 1.3597 - val_mae: 0.9726\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 0s 249us/step - loss: 1.4156 - mse: 1.4156 - mae: 0.8342 - val_loss: 1.3588 - val_mse: 1.3588 - val_mae: 0.9747\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 0s 249us/step - loss: 1.4073 - mse: 1.4073 - mae: 0.8316 - val_loss: 1.3582 - val_mse: 1.3582 - val_mae: 0.9767\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 1.3988 - mse: 1.3988 - mae: 0.8290 - val_loss: 1.3581 - val_mse: 1.3581 - val_mae: 0.9787\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.3905 - mse: 1.3905 - mae: 0.8266 - val_loss: 1.3584 - val_mse: 1.3584 - val_mae: 0.9809\n",
      "Epoch 40/100\n",
      "76/76 [==============================] - 0s 210us/step - loss: 1.3822 - mse: 1.3822 - mae: 0.8243 - val_loss: 1.3588 - val_mse: 1.3588 - val_mae: 0.9834\n",
      "Epoch 41/100\n",
      "76/76 [==============================] - 0s 302us/step - loss: 1.3737 - mse: 1.3737 - mae: 0.8220 - val_loss: 1.3592 - val_mse: 1.3592 - val_mae: 0.9858\n",
      "Epoch 42/100\n",
      "76/76 [==============================] - 0s 315us/step - loss: 1.3653 - mse: 1.3653 - mae: 0.8199 - val_loss: 1.3600 - val_mse: 1.3600 - val_mae: 0.9885\n",
      "Epoch 43/100\n",
      "76/76 [==============================] - 0s 262us/step - loss: 1.3565 - mse: 1.3565 - mae: 0.8178 - val_loss: 1.3615 - val_mse: 1.3615 - val_mae: 0.9915\n",
      "Epoch 44/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.3479 - mse: 1.3479 - mae: 0.8158 - val_loss: 1.3619 - val_mse: 1.3619 - val_mae: 0.9944\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 262us/step - loss: 1.3390 - mse: 1.3390 - mae: 0.8138 - val_loss: 1.3623 - val_mse: 1.3623 - val_mae: 0.9976\n",
      "Epoch 46/100\n",
      "76/76 [==============================] - 0s 223us/step - loss: 1.3302 - mse: 1.3302 - mae: 0.8118 - val_loss: 1.3631 - val_mse: 1.3631 - val_mae: 1.0010\n",
      "Epoch 47/100\n",
      "76/76 [==============================] - 0s 289us/step - loss: 1.3217 - mse: 1.3217 - mae: 0.8096 - val_loss: 1.3640 - val_mse: 1.3640 - val_mae: 1.0042\n",
      "Epoch 48/100\n",
      "76/76 [==============================] - 0s 236us/step - loss: 1.3133 - mse: 1.3133 - mae: 0.8073 - val_loss: 1.3651 - val_mse: 1.3651 - val_mae: 1.0072\n",
      "15\n",
      "[15]\n",
      "Train on 101 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 26.8419 - mse: 26.8419 - mae: 4.8947 - val_loss: 11.3082 - val_mse: 11.3082 - val_mae: 3.2365\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 294us/step - loss: 21.0888 - mse: 21.0888 - mae: 4.2663 - val_loss: 8.3955 - val_mse: 8.3955 - val_mae: 2.7272\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 16.2313 - mse: 16.2313 - mae: 3.6481 - val_loss: 6.2182 - val_mse: 6.2182 - val_mae: 2.2497\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 267us/step - loss: 12.3488 - mse: 12.3488 - mae: 3.0638 - val_loss: 4.6471 - val_mse: 4.6471 - val_mae: 1.8245\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 286us/step - loss: 9.4713 - mse: 9.4713 - mae: 2.5622 - val_loss: 3.6154 - val_mse: 3.6154 - val_mae: 1.4685\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 237us/step - loss: 7.5171 - mse: 7.5171 - mae: 2.1743 - val_loss: 2.9564 - val_mse: 2.9564 - val_mae: 1.2238\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 207us/step - loss: 6.2031 - mse: 6.2031 - mae: 1.9152 - val_loss: 2.5369 - val_mse: 2.5369 - val_mae: 1.1129\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 306us/step - loss: 5.3072 - mse: 5.3072 - mae: 1.7342 - val_loss: 2.2651 - val_mse: 2.2651 - val_mae: 1.0356\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 276us/step - loss: 4.6642 - mse: 4.6642 - mae: 1.6062 - val_loss: 2.0811 - val_mse: 2.0811 - val_mae: 0.9789\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 286us/step - loss: 4.2176 - mse: 4.2176 - mae: 1.5260 - val_loss: 1.9742 - val_mse: 1.9742 - val_mae: 0.9721\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 346us/step - loss: 3.9278 - mse: 3.9278 - mae: 1.4892 - val_loss: 1.9379 - val_mse: 1.9379 - val_mae: 1.0045\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 296us/step - loss: 3.7524 - mse: 3.7524 - mae: 1.4761 - val_loss: 1.9392 - val_mse: 1.9392 - val_mae: 1.0384\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 385us/step - loss: 3.6542 - mse: 3.6542 - mae: 1.4740 - val_loss: 1.9578 - val_mse: 1.9578 - val_mae: 1.0665\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 3.6018 - mse: 3.6018 - mae: 1.4783 - val_loss: 1.9773 - val_mse: 1.9773 - val_mae: 1.0894\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 207us/step - loss: 3.5659 - mse: 3.5659 - mae: 1.4777 - val_loss: 1.9866 - val_mse: 1.9866 - val_mae: 1.1009\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 197us/step - loss: 3.5341 - mse: 3.5341 - mae: 1.4763 - val_loss: 1.9820 - val_mse: 1.9820 - val_mae: 1.1031\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 336us/step - loss: 3.5002 - mse: 3.5002 - mae: 1.4717 - val_loss: 1.9625 - val_mse: 1.9625 - val_mae: 1.0971\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 306us/step - loss: 3.4596 - mse: 3.4596 - mae: 1.4640 - val_loss: 1.9310 - val_mse: 1.9310 - val_mae: 1.0843\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 3.4132 - mse: 3.4132 - mae: 1.4538 - val_loss: 1.8927 - val_mse: 1.8927 - val_mae: 1.0679\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 3.3637 - mse: 3.3637 - mae: 1.4418 - val_loss: 1.8514 - val_mse: 1.8514 - val_mae: 1.0495\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 3.3137 - mse: 3.3137 - mae: 1.4290 - val_loss: 1.8100 - val_mse: 1.8100 - val_mae: 1.0304\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 346us/step - loss: 3.2651 - mse: 3.2651 - mae: 1.4162 - val_loss: 1.7705 - val_mse: 1.7705 - val_mae: 1.0111\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 207us/step - loss: 3.2160 - mse: 3.2160 - mae: 1.4031 - val_loss: 1.7336 - val_mse: 1.7336 - val_mae: 0.9921\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 207us/step - loss: 3.1681 - mse: 3.1681 - mae: 1.3900 - val_loss: 1.6983 - val_mse: 1.6983 - val_mae: 0.9730\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 296us/step - loss: 3.1211 - mse: 3.1211 - mae: 1.3770 - val_loss: 1.6651 - val_mse: 1.6651 - val_mae: 0.9545\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 434us/step - loss: 3.0751 - mse: 3.0751 - mae: 1.3643 - val_loss: 1.6343 - val_mse: 1.6343 - val_mae: 0.9366\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 267us/step - loss: 3.0309 - mse: 3.0309 - mae: 1.3520 - val_loss: 1.6088 - val_mse: 1.6088 - val_mae: 0.9194\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 2.9871 - mse: 2.9871 - mae: 1.3400 - val_loss: 1.5863 - val_mse: 1.5863 - val_mae: 0.9020\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 237us/step - loss: 2.9427 - mse: 2.9427 - mae: 1.3269 - val_loss: 1.5648 - val_mse: 1.5648 - val_mae: 0.8880\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 178us/step - loss: 2.9031 - mse: 2.9031 - mae: 1.3162 - val_loss: 1.5474 - val_mse: 1.5474 - val_mae: 0.8763\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 188us/step - loss: 2.8686 - mse: 2.8686 - mae: 1.3072 - val_loss: 1.5335 - val_mse: 1.5335 - val_mae: 0.8675\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 2.8352 - mse: 2.8352 - mae: 1.2995 - val_loss: 1.5222 - val_mse: 1.5222 - val_mae: 0.8629\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 197us/step - loss: 2.8018 - mse: 2.8018 - mae: 1.2918 - val_loss: 1.5086 - val_mse: 1.5086 - val_mae: 0.8556\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 227us/step - loss: 2.7686 - mse: 2.7686 - mae: 1.2850 - val_loss: 1.4953 - val_mse: 1.4953 - val_mae: 0.8464\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 237us/step - loss: 2.7368 - mse: 2.7368 - mae: 1.2795 - val_loss: 1.4844 - val_mse: 1.4844 - val_mae: 0.8366\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 188us/step - loss: 2.7052 - mse: 2.7052 - mae: 1.2740 - val_loss: 1.4764 - val_mse: 1.4764 - val_mae: 0.8269\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 197us/step - loss: 2.6778 - mse: 2.6778 - mae: 1.2688 - val_loss: 1.4725 - val_mse: 1.4725 - val_mae: 0.8186\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 247us/step - loss: 2.6551 - mse: 2.6551 - mae: 1.2643 - val_loss: 1.4745 - val_mse: 1.4745 - val_mae: 0.8130\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 266us/step - loss: 2.6350 - mse: 2.6350 - mae: 1.2597 - val_loss: 1.4807 - val_mse: 1.4807 - val_mae: 0.8095\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 257us/step - loss: 2.6165 - mse: 2.6165 - mae: 1.2550 - val_loss: 1.4881 - val_mse: 1.4881 - val_mae: 0.8099\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 296us/step - loss: 2.5991 - mse: 2.5991 - mae: 1.2503 - val_loss: 1.4957 - val_mse: 1.4957 - val_mae: 0.8105\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 247us/step - loss: 2.5829 - mse: 2.5829 - mae: 1.2457 - val_loss: 1.5026 - val_mse: 1.5026 - val_mae: 0.8106\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 197us/step - loss: 2.5670 - mse: 2.5670 - mae: 1.2412 - val_loss: 1.5092 - val_mse: 1.5092 - val_mae: 0.8105\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 286us/step - loss: 2.5520 - mse: 2.5520 - mae: 1.2367 - val_loss: 1.5162 - val_mse: 1.5162 - val_mae: 0.8105\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 227us/step - loss: 2.5390 - mse: 2.5390 - mae: 1.2324 - val_loss: 1.5235 - val_mse: 1.5235 - val_mae: 0.8109\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 247us/step - loss: 2.5266 - mse: 2.5266 - mae: 1.2282 - val_loss: 1.5293 - val_mse: 1.5293 - val_mae: 0.8108\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 217us/step - loss: 2.5135 - mse: 2.5135 - mae: 1.2233 - val_loss: 1.5338 - val_mse: 1.5338 - val_mae: 0.8102\n",
      "16\n",
      "[16]\n",
      "Train on 73 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 3.0805 - mse: 3.0805 - mae: 1.3217 - val_loss: 0.9435 - val_mse: 0.9435 - val_mae: 0.6989\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 287us/step - loss: 2.4639 - mse: 2.4639 - mae: 1.1443 - val_loss: 0.8977 - val_mse: 0.8977 - val_mae: 0.7636\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 260us/step - loss: 2.1797 - mse: 2.1797 - mae: 1.0478 - val_loss: 1.0624 - val_mse: 1.0624 - val_mae: 0.8861\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 246us/step - loss: 2.0886 - mse: 2.0886 - mae: 1.0126 - val_loss: 1.2376 - val_mse: 1.2376 - val_mae: 0.9974\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 273us/step - loss: 2.0392 - mse: 2.0392 - mae: 0.9926 - val_loss: 1.3101 - val_mse: 1.3101 - val_mae: 1.0379\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 260us/step - loss: 1.9593 - mse: 1.9593 - mae: 0.9696 - val_loss: 1.2738 - val_mse: 1.2738 - val_mae: 1.0246\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 273us/step - loss: 1.8484 - mse: 1.8484 - mae: 0.9413 - val_loss: 1.1745 - val_mse: 1.1745 - val_mae: 0.9758\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 219us/step - loss: 1.7381 - mse: 1.7381 - mae: 0.9108 - val_loss: 1.0732 - val_mse: 1.0732 - val_mae: 0.9142\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 437us/step - loss: 1.6553 - mse: 1.6553 - mae: 0.8911 - val_loss: 0.9956 - val_mse: 0.9956 - val_mae: 0.8526\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 232us/step - loss: 1.6026 - mse: 1.6026 - mae: 0.8737 - val_loss: 0.9534 - val_mse: 0.9534 - val_mae: 0.8045\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 300us/step - loss: 1.5676 - mse: 1.5676 - mae: 0.8720 - val_loss: 0.9458 - val_mse: 0.9458 - val_mae: 0.7802\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 273us/step - loss: 1.5368 - mse: 1.5368 - mae: 0.8690 - val_loss: 0.9630 - val_mse: 0.9630 - val_mae: 0.7856\n",
      "17\n",
      "[17]\n",
      "Train on 90 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.5882 - mse: 2.5882 - mae: 1.1789 - val_loss: 1.3182 - val_mse: 1.3182 - val_mae: 0.9522\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 475us/step - loss: 2.3529 - mse: 2.3529 - mae: 1.1508 - val_loss: 1.2576 - val_mse: 1.2576 - val_mae: 0.9560\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 252us/step - loss: 2.2322 - mse: 2.2322 - mae: 1.1638 - val_loss: 1.2549 - val_mse: 1.2549 - val_mae: 0.9553\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 377us/step - loss: 2.1868 - mse: 2.1868 - mae: 1.1851 - val_loss: 1.2751 - val_mse: 1.2751 - val_mae: 0.9500\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 388us/step - loss: 2.1657 - mse: 2.1657 - mae: 1.1927 - val_loss: 1.2769 - val_mse: 1.2769 - val_mae: 0.9422\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 252us/step - loss: 2.1323 - mse: 2.1323 - mae: 1.1848 - val_loss: 1.2512 - val_mse: 1.2512 - val_mae: 0.9328\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 399us/step - loss: 2.0879 - mse: 2.0879 - mae: 1.1654 - val_loss: 1.2160 - val_mse: 1.2160 - val_mae: 0.9278\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 2.0439 - mse: 2.0439 - mae: 1.1403 - val_loss: 1.1824 - val_mse: 1.1824 - val_mae: 0.9218\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 211us/step - loss: 2.0099 - mse: 2.0099 - mae: 1.1193 - val_loss: 1.1522 - val_mse: 1.1522 - val_mae: 0.9135\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 266us/step - loss: 1.9801 - mse: 1.9801 - mae: 1.1019 - val_loss: 1.1305 - val_mse: 1.1305 - val_mae: 0.9056\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 366us/step - loss: 1.9555 - mse: 1.9555 - mae: 1.0901 - val_loss: 1.1156 - val_mse: 1.1156 - val_mae: 0.8991\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 233us/step - loss: 1.9287 - mse: 1.9287 - mae: 1.0818 - val_loss: 1.1015 - val_mse: 1.1015 - val_mae: 0.8904\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.8987 - mse: 1.8987 - mae: 1.0754 - val_loss: 1.0923 - val_mse: 1.0923 - val_mae: 0.8814\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 288us/step - loss: 1.8701 - mse: 1.8701 - mae: 1.0733 - val_loss: 1.0858 - val_mse: 1.0858 - val_mae: 0.8730\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 288us/step - loss: 1.8447 - mse: 1.8447 - mae: 1.0694 - val_loss: 1.0787 - val_mse: 1.0787 - val_mae: 0.8682\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.8191 - mse: 1.8191 - mae: 1.0621 - val_loss: 1.0720 - val_mse: 1.0720 - val_mae: 0.8671\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 288us/step - loss: 1.7915 - mse: 1.7915 - mae: 1.0520 - val_loss: 1.0675 - val_mse: 1.0675 - val_mae: 0.8683\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 244us/step - loss: 1.7674 - mse: 1.7674 - mae: 1.0422 - val_loss: 1.0602 - val_mse: 1.0602 - val_mae: 0.8664\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 222us/step - loss: 1.7435 - mse: 1.7435 - mae: 1.0331 - val_loss: 1.0506 - val_mse: 1.0506 - val_mae: 0.8616\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 421us/step - loss: 1.7203 - mse: 1.7203 - mae: 1.0250 - val_loss: 1.0383 - val_mse: 1.0383 - val_mae: 0.8541\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 1.6970 - mse: 1.6970 - mae: 1.0175 - val_loss: 1.0243 - val_mse: 1.0243 - val_mae: 0.8450\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 299us/step - loss: 1.6738 - mse: 1.6738 - mae: 1.0096 - val_loss: 1.0108 - val_mse: 1.0108 - val_mae: 0.8378\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 465us/step - loss: 1.6520 - mse: 1.6520 - mae: 1.0007 - val_loss: 0.9970 - val_mse: 0.9970 - val_mae: 0.8292\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 288us/step - loss: 1.6310 - mse: 1.6310 - mae: 0.9931 - val_loss: 0.9857 - val_mse: 0.9857 - val_mae: 0.8206\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.6112 - mse: 1.6112 - mae: 0.9870 - val_loss: 0.9791 - val_mse: 0.9791 - val_mae: 0.8171\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 244us/step - loss: 1.5888 - mse: 1.5888 - mae: 0.9777 - val_loss: 0.9777 - val_mse: 0.9777 - val_mae: 0.8195\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 432us/step - loss: 1.5684 - mse: 1.5684 - mae: 0.9675 - val_loss: 0.9853 - val_mse: 0.9853 - val_mae: 0.8238\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 222us/step - loss: 1.5488 - mse: 1.5488 - mae: 0.9598 - val_loss: 0.9865 - val_mse: 0.9865 - val_mae: 0.8236\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.5289 - mse: 1.5289 - mae: 0.9548 - val_loss: 0.9850 - val_mse: 0.9850 - val_mae: 0.8223\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 366us/step - loss: 1.5090 - mse: 1.5090 - mae: 0.9504 - val_loss: 0.9807 - val_mse: 0.9807 - val_mae: 0.8197\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 177us/step - loss: 1.4919 - mse: 1.4919 - mae: 0.9453 - val_loss: 0.9760 - val_mse: 0.9760 - val_mae: 0.8168\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.4732 - mse: 1.4732 - mae: 0.9361 - val_loss: 0.9766 - val_mse: 0.9766 - val_mae: 0.8169\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 177us/step - loss: 1.4561 - mse: 1.4561 - mae: 0.9259 - val_loss: 0.9821 - val_mse: 0.9821 - val_mae: 0.8209\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.4409 - mse: 1.4409 - mae: 0.9175 - val_loss: 0.9780 - val_mse: 0.9780 - val_mae: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.4228 - mse: 1.4228 - mae: 0.9127 - val_loss: 0.9771 - val_mse: 0.9771 - val_mae: 0.8215\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.4064 - mse: 1.4064 - mae: 0.9075 - val_loss: 0.9789 - val_mse: 0.9789 - val_mae: 0.8252\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 288us/step - loss: 1.3906 - mse: 1.3906 - mae: 0.9013 - val_loss: 0.9806 - val_mse: 0.9806 - val_mae: 0.8288\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.3773 - mse: 1.3773 - mae: 0.8955 - val_loss: 0.9760 - val_mse: 0.9760 - val_mae: 0.8286\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.3621 - mse: 1.3621 - mae: 0.8907 - val_loss: 0.9713 - val_mse: 0.9713 - val_mae: 0.8285\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.3483 - mse: 1.3483 - mae: 0.8845 - val_loss: 0.9680 - val_mse: 0.9680 - val_mae: 0.8289\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.3360 - mse: 1.3360 - mae: 0.8784 - val_loss: 0.9587 - val_mse: 0.9587 - val_mae: 0.8266\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.3232 - mse: 1.3232 - mae: 0.8741 - val_loss: 0.9517 - val_mse: 0.9517 - val_mae: 0.8260\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.3111 - mse: 1.3111 - mae: 0.8682 - val_loss: 0.9465 - val_mse: 0.9465 - val_mae: 0.8250\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.2996 - mse: 1.2996 - mae: 0.8617 - val_loss: 0.9422 - val_mse: 0.9422 - val_mae: 0.8245\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 1.2880 - mse: 1.2880 - mae: 0.8552 - val_loss: 0.9403 - val_mse: 0.9403 - val_mae: 0.8251\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 199us/step - loss: 1.2783 - mse: 1.2783 - mae: 0.8498 - val_loss: 0.9355 - val_mse: 0.9355 - val_mae: 0.8266\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.2668 - mse: 1.2668 - mae: 0.8474 - val_loss: 0.9283 - val_mse: 0.9283 - val_mae: 0.8280\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 1.2567 - mse: 1.2567 - mae: 0.8446 - val_loss: 0.9206 - val_mse: 0.9206 - val_mae: 0.8270\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.2468 - mse: 1.2468 - mae: 0.8401 - val_loss: 0.9126 - val_mse: 0.9126 - val_mae: 0.8242\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 1.2382 - mse: 1.2382 - mae: 0.8334 - val_loss: 0.9086 - val_mse: 0.9086 - val_mae: 0.8222\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 188us/step - loss: 1.2278 - mse: 1.2278 - mae: 0.8273 - val_loss: 0.9012 - val_mse: 0.9012 - val_mae: 0.8221\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 166us/step - loss: 1.2178 - mse: 1.2178 - mae: 0.8244 - val_loss: 0.8986 - val_mse: 0.8986 - val_mae: 0.8225\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 266us/step - loss: 1.2086 - mse: 1.2086 - mae: 0.8195 - val_loss: 0.9001 - val_mse: 0.9001 - val_mae: 0.8230\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 299us/step - loss: 1.1989 - mse: 1.1989 - mae: 0.8142 - val_loss: 0.9003 - val_mse: 0.9003 - val_mae: 0.8249\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 266us/step - loss: 1.1897 - mse: 1.1897 - mae: 0.8107 - val_loss: 0.9060 - val_mse: 0.9060 - val_mae: 0.8308\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 233us/step - loss: 1.1804 - mse: 1.1804 - mae: 0.8086 - val_loss: 0.9142 - val_mse: 0.9142 - val_mae: 0.8370\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 321us/step - loss: 1.1714 - mse: 1.1714 - mae: 0.8062 - val_loss: 0.9196 - val_mse: 0.9196 - val_mae: 0.8402\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 244us/step - loss: 1.1628 - mse: 1.1628 - mae: 0.8026 - val_loss: 0.9201 - val_mse: 0.9201 - val_mae: 0.8402\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 188us/step - loss: 1.1545 - mse: 1.1545 - mae: 0.7976 - val_loss: 0.9183 - val_mse: 0.9183 - val_mae: 0.8391\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.1464 - mse: 1.1464 - mae: 0.7929 - val_loss: 0.9165 - val_mse: 0.9165 - val_mae: 0.8390\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 277us/step - loss: 1.1388 - mse: 1.1388 - mae: 0.7895 - val_loss: 0.9149 - val_mse: 0.9149 - val_mae: 0.8387\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 1.1309 - mse: 1.1309 - mae: 0.7856 - val_loss: 0.9141 - val_mse: 0.9141 - val_mae: 0.8388\n",
      "18\n",
      "[18]\n",
      "Train on 74 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 7.0872 - mse: 7.0872 - mae: 2.5000 - val_loss: 8.0572 - val_mse: 8.0572 - val_mae: 2.6297\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 6.1050 - mse: 6.1050 - mae: 2.3005 - val_loss: 6.7003 - val_mse: 6.7003 - val_mae: 2.3692\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 323us/step - loss: 5.1945 - mse: 5.1945 - mae: 2.0985 - val_loss: 5.5082 - val_mse: 5.5082 - val_mae: 2.1145\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 270us/step - loss: 4.3944 - mse: 4.3944 - mae: 1.9020 - val_loss: 4.4935 - val_mse: 4.4935 - val_mae: 1.8828\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 296us/step - loss: 3.7006 - mse: 3.7006 - mae: 1.7135 - val_loss: 3.6599 - val_mse: 3.6599 - val_mae: 1.6760\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 270us/step - loss: 3.1036 - mse: 3.1036 - mae: 1.5327 - val_loss: 2.9766 - val_mse: 2.9766 - val_mae: 1.4862\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 458us/step - loss: 2.6202 - mse: 2.6202 - mae: 1.3706 - val_loss: 2.4514 - val_mse: 2.4514 - val_mae: 1.3305\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 2.2312 - mse: 2.2312 - mae: 1.2260 - val_loss: 2.0183 - val_mse: 2.0183 - val_mae: 1.1873\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 337us/step - loss: 1.9373 - mse: 1.9373 - mae: 1.0989 - val_loss: 1.6808 - val_mse: 1.6808 - val_mae: 1.0619\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 1.7156 - mse: 1.7156 - mae: 0.9970 - val_loss: 1.3994 - val_mse: 1.3994 - val_mae: 0.9422\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 1.5534 - mse: 1.5534 - mae: 0.9137 - val_loss: 1.1837 - val_mse: 1.1837 - val_mae: 0.8330\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 229us/step - loss: 1.4214 - mse: 1.4214 - mae: 0.8448 - val_loss: 1.0282 - val_mse: 1.0282 - val_mae: 0.7518\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 296us/step - loss: 1.3143 - mse: 1.3143 - mae: 0.7937 - val_loss: 0.8965 - val_mse: 0.8965 - val_mae: 0.6911\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 1.2227 - mse: 1.2227 - mae: 0.7518 - val_loss: 0.7852 - val_mse: 0.7852 - val_mae: 0.6524\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 1.1416 - mse: 1.1416 - mae: 0.7198 - val_loss: 0.6927 - val_mse: 0.6927 - val_mae: 0.6258\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 418us/step - loss: 1.0702 - mse: 1.0702 - mae: 0.6952 - val_loss: 0.6194 - val_mse: 0.6194 - val_mae: 0.6179\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 202us/step - loss: 1.0083 - mse: 1.0083 - mae: 0.6780 - val_loss: 0.5615 - val_mse: 0.5615 - val_mae: 0.6095\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 566us/step - loss: 0.9561 - mse: 0.9561 - mae: 0.6645 - val_loss: 0.5163 - val_mse: 0.5163 - val_mae: 0.6003\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 377us/step - loss: 0.9138 - mse: 0.9138 - mae: 0.6565 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.5911\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 391us/step - loss: 0.8801 - mse: 0.8801 - mae: 0.6519 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.5821\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 283us/step - loss: 0.8546 - mse: 0.8546 - mae: 0.6532 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.5735\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 229us/step - loss: 0.8366 - mse: 0.8366 - mae: 0.6575 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.5652\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 0.8250 - mse: 0.8250 - mae: 0.6653 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.5578\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 0.8182 - mse: 0.8182 - mae: 0.6733 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5634\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 216us/step - loss: 0.8149 - mse: 0.8149 - mae: 0.6813 - val_loss: 0.4698 - val_mse: 0.4698 - val_mae: 0.5732\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 0.8135 - mse: 0.8135 - mae: 0.6880 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5808\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 243us/step - loss: 0.8130 - mse: 0.8130 - mae: 0.6938 - val_loss: 0.4875 - val_mse: 0.4875 - val_mae: 0.5866\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 337us/step - loss: 0.8126 - mse: 0.8126 - mae: 0.6980 - val_loss: 0.4949 - val_mse: 0.4949 - val_mae: 0.5916\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 350us/step - loss: 0.8118 - mse: 0.8118 - mae: 0.7003 - val_loss: 0.4999 - val_mse: 0.4999 - val_mae: 0.5951\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 0.8104 - mse: 0.8104 - mae: 0.7010 - val_loss: 0.5028 - val_mse: 0.5028 - val_mae: 0.5974\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 256us/step - loss: 0.8086 - mse: 0.8086 - mae: 0.7005 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.5982\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 0.8063 - mse: 0.8063 - mae: 0.6991 - val_loss: 0.5019 - val_mse: 0.5019 - val_mae: 0.5980\n",
      "19\n",
      "[19]\n",
      "Train on 87 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 13.6358 - mse: 13.6358 - mae: 3.5168 - val_loss: 7.7657 - val_mse: 7.7657 - val_mae: 2.7245\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 180us/step - loss: 11.1392 - mse: 11.1392 - mae: 3.1496 - val_loss: 5.9976 - val_mse: 5.9976 - val_mae: 2.3856\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 447us/step - loss: 8.8737 - mse: 8.8737 - mae: 2.7757 - val_loss: 4.5080 - val_mse: 4.5080 - val_mae: 2.0569\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 6.9414 - mse: 6.9414 - mae: 2.4125 - val_loss: 3.3246 - val_mse: 3.3246 - val_mae: 1.7517\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 5.3750 - mse: 5.3750 - mae: 2.0698 - val_loss: 2.4200 - val_mse: 2.4200 - val_mae: 1.4747\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 4.1685 - mse: 4.1685 - mae: 1.7604 - val_loss: 1.7165 - val_mse: 1.7165 - val_mae: 1.2167\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 185us/step - loss: 3.2584 - mse: 3.2584 - mae: 1.4890 - val_loss: 1.2001 - val_mse: 1.2001 - val_mae: 0.9852\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 2.5707 - mse: 2.5707 - mae: 1.2565 - val_loss: 0.8280 - val_mse: 0.8280 - val_mae: 0.7729\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 195us/step - loss: 2.0574 - mse: 2.0574 - mae: 1.0808 - val_loss: 0.5797 - val_mse: 0.5797 - val_mae: 0.6010\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 195us/step - loss: 1.7110 - mse: 1.7110 - mae: 0.9788 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4997\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 1.4801 - mse: 1.4801 - mae: 0.9223 - val_loss: 0.3394 - val_mse: 0.3394 - val_mae: 0.4664\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 1.3275 - mse: 1.3275 - mae: 0.8887 - val_loss: 0.2930 - val_mse: 0.2930 - val_mae: 0.4583\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 1.2301 - mse: 1.2301 - mae: 0.8690 - val_loss: 0.2718 - val_mse: 0.2718 - val_mae: 0.4539\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 1.1762 - mse: 1.1762 - mae: 0.8594 - val_loss: 0.2680 - val_mse: 0.2680 - val_mae: 0.4635\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 1.1479 - mse: 1.1479 - mae: 0.8561 - val_loss: 0.2737 - val_mse: 0.2737 - val_mae: 0.4788\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 1.1328 - mse: 1.1328 - mae: 0.8542 - val_loss: 0.2844 - val_mse: 0.2844 - val_mae: 0.4908\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 183us/step - loss: 1.1258 - mse: 1.1258 - mae: 0.8549 - val_loss: 0.2967 - val_mse: 0.2967 - val_mae: 0.5010\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 344us/step - loss: 1.1236 - mse: 1.1236 - mae: 0.8562 - val_loss: 0.3081 - val_mse: 0.3081 - val_mae: 0.5141\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 1.1239 - mse: 1.1239 - mae: 0.8578 - val_loss: 0.3170 - val_mse: 0.3170 - val_mae: 0.5233\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 0s 264us/step - loss: 1.1241 - mse: 1.1241 - mae: 0.8589 - val_loss: 0.3232 - val_mse: 0.3232 - val_mae: 0.5293\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 1.1239 - mse: 1.1239 - mae: 0.8591 - val_loss: 0.3265 - val_mse: 0.3265 - val_mae: 0.5323\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 0s 200us/step - loss: 1.1226 - mse: 1.1226 - mae: 0.8586 - val_loss: 0.3273 - val_mse: 0.3273 - val_mae: 0.5331\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 1.1204 - mse: 1.1204 - mae: 0.8574 - val_loss: 0.3262 - val_mse: 0.3262 - val_mae: 0.5323\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 1.1174 - mse: 1.1174 - mae: 0.8558 - val_loss: 0.3236 - val_mse: 0.3236 - val_mae: 0.5302\n",
      "20\n",
      "[20]\n",
      "Train on 98 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 3.5679 - mse: 3.5679 - mae: 1.4281 - val_loss: 1.8538 - val_mse: 1.8538 - val_mae: 1.0171\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 272us/step - loss: 2.7013 - mse: 2.7013 - mae: 1.1993 - val_loss: 1.4401 - val_mse: 1.4401 - val_mae: 0.8791\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 214us/step - loss: 2.2026 - mse: 2.2026 - mae: 1.0766 - val_loss: 1.3510 - val_mse: 1.3510 - val_mae: 0.8722\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 236us/step - loss: 2.0174 - mse: 2.0174 - mae: 1.0429 - val_loss: 1.3984 - val_mse: 1.3984 - val_mae: 0.9378\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 285us/step - loss: 1.9700 - mse: 1.9700 - mae: 1.0421 - val_loss: 1.4220 - val_mse: 1.4220 - val_mae: 0.9618\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 1.9311 - mse: 1.9311 - mae: 1.0364 - val_loss: 1.3884 - val_mse: 1.3884 - val_mae: 0.9513\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 1.8798 - mse: 1.8798 - mae: 1.0189 - val_loss: 1.3358 - val_mse: 1.3358 - val_mae: 0.9231\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 1.8456 - mse: 1.8456 - mae: 1.0046 - val_loss: 1.2992 - val_mse: 1.2992 - val_mae: 0.8925\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 529us/step - loss: 1.8392 - mse: 1.8392 - mae: 0.9959 - val_loss: 1.2890 - val_mse: 1.2890 - val_mae: 0.8729\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 347us/step - loss: 1.8366 - mse: 1.8366 - mae: 0.9898 - val_loss: 1.2906 - val_mse: 1.2906 - val_mae: 0.8676\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 356us/step - loss: 1.8257 - mse: 1.8257 - mae: 0.9859 - val_loss: 1.2942 - val_mse: 1.2942 - val_mae: 0.8714\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 224us/step - loss: 1.8046 - mse: 1.8046 - mae: 0.9810 - val_loss: 1.2994 - val_mse: 1.2994 - val_mae: 0.8808\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 265us/step - loss: 1.7784 - mse: 1.7784 - mae: 0.9757 - val_loss: 1.3068 - val_mse: 1.3068 - val_mae: 0.8924\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 458us/step - loss: 1.7523 - mse: 1.7523 - mae: 0.9711 - val_loss: 1.3171 - val_mse: 1.3171 - val_mae: 0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 387us/step - loss: 1.7303 - mse: 1.7303 - mae: 0.9668 - val_loss: 1.3259 - val_mse: 1.3259 - val_mae: 0.9133\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 1.7119 - mse: 1.7119 - mae: 0.9618 - val_loss: 1.3305 - val_mse: 1.3305 - val_mae: 0.9179\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 305us/step - loss: 1.6983 - mse: 1.6983 - mae: 0.9564 - val_loss: 1.3318 - val_mse: 1.3318 - val_mae: 0.9195\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 213us/step - loss: 1.6865 - mse: 1.6865 - mae: 0.9511 - val_loss: 1.3323 - val_mse: 1.3323 - val_mae: 0.9200\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 1.6757 - mse: 1.6757 - mae: 0.9465 - val_loss: 1.3327 - val_mse: 1.3327 - val_mae: 0.9206\n",
      "21\n",
      "[21]\n",
      "Train on 79 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 3.3027 - mse: 3.3027 - mae: 1.4774 - val_loss: 0.8047 - val_mse: 0.8047 - val_mae: 0.6854\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 227us/step - loss: 2.8204 - mse: 2.8204 - mae: 1.3272 - val_loss: 0.6611 - val_mse: 0.6611 - val_mae: 0.5927\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 252us/step - loss: 2.3928 - mse: 2.3928 - mae: 1.1960 - val_loss: 0.5445 - val_mse: 0.5445 - val_mae: 0.5227\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 240us/step - loss: 2.0213 - mse: 2.0213 - mae: 1.0940 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4503\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 240us/step - loss: 1.7161 - mse: 1.7161 - mae: 1.0275 - val_loss: 0.4120 - val_mse: 0.4120 - val_mae: 0.4234\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 354us/step - loss: 1.4864 - mse: 1.4864 - mae: 0.9843 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4097\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 391us/step - loss: 1.3297 - mse: 1.3297 - mae: 0.9543 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4431\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 341us/step - loss: 1.2361 - mse: 1.2361 - mae: 0.9366 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.5235\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 240us/step - loss: 1.1939 - mse: 1.1939 - mae: 0.9255 - val_loss: 0.5423 - val_mse: 0.5423 - val_mae: 0.5987\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 404us/step - loss: 1.1798 - mse: 1.1798 - mae: 0.9242 - val_loss: 0.5816 - val_mse: 0.5816 - val_mae: 0.6458\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 240us/step - loss: 1.1736 - mse: 1.1736 - mae: 0.9222 - val_loss: 0.5945 - val_mse: 0.5945 - val_mae: 0.6642\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 379us/step - loss: 1.1620 - mse: 1.1620 - mae: 0.9164 - val_loss: 0.5824 - val_mse: 0.5824 - val_mae: 0.6587\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 354us/step - loss: 1.1423 - mse: 1.1423 - mae: 0.9081 - val_loss: 0.5490 - val_mse: 0.5490 - val_mae: 0.6342\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 253us/step - loss: 1.1188 - mse: 1.1188 - mae: 0.8983 - val_loss: 0.5069 - val_mse: 0.5069 - val_mae: 0.5991\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 252us/step - loss: 1.0962 - mse: 1.0962 - mae: 0.8881 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.5608\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 316us/step - loss: 1.0758 - mse: 1.0758 - mae: 0.8787 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.5219\n",
      "22\n",
      "[22]\n",
      "Train on 102 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 9.8499 - mse: 9.8499 - mae: 2.8014 - val_loss: 9.6569 - val_mse: 9.6569 - val_mae: 2.8109\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 460us/step - loss: 8.5265 - mse: 8.5265 - mae: 2.5555 - val_loss: 8.4015 - val_mse: 8.4015 - val_mae: 2.5645\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 186us/step - loss: 7.2588 - mse: 7.2588 - mae: 2.2925 - val_loss: 7.0748 - val_mse: 7.0748 - val_mae: 2.2805\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 117us/step - loss: 6.0366 - mse: 6.0366 - mae: 2.0077 - val_loss: 5.7396 - val_mse: 5.7396 - val_mae: 1.9796\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 396us/step - loss: 4.9488 - mse: 4.9488 - mae: 1.7265 - val_loss: 4.6191 - val_mse: 4.6191 - val_mae: 1.7025\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 4.0291 - mse: 4.0291 - mae: 1.4909 - val_loss: 3.7242 - val_mse: 3.7242 - val_mae: 1.5166\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 167us/step - loss: 3.3133 - mse: 3.3133 - mae: 1.3310 - val_loss: 3.0546 - val_mse: 3.0546 - val_mae: 1.3740\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 244us/step - loss: 2.7948 - mse: 2.7948 - mae: 1.2351 - val_loss: 2.5992 - val_mse: 2.5992 - val_mae: 1.2838\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 2.4549 - mse: 2.4549 - mae: 1.1824 - val_loss: 2.3076 - val_mse: 2.3076 - val_mae: 1.2266\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 196us/step - loss: 2.2589 - mse: 2.2589 - mae: 1.1635 - val_loss: 2.1494 - val_mse: 2.1494 - val_mae: 1.2114\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 2.1682 - mse: 2.1682 - mae: 1.1587 - val_loss: 2.0829 - val_mse: 2.0829 - val_mae: 1.2289\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 2.1398 - mse: 2.1398 - mae: 1.1673 - val_loss: 2.0670 - val_mse: 2.0670 - val_mae: 1.2470\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 235us/step - loss: 2.1371 - mse: 2.1371 - mae: 1.1791 - val_loss: 2.0699 - val_mse: 2.0699 - val_mae: 1.2573\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 2.1369 - mse: 2.1369 - mae: 1.1851 - val_loss: 2.0762 - val_mse: 2.0762 - val_mae: 1.2610\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 2.1298 - mse: 2.1298 - mae: 1.1842 - val_loss: 2.0823 - val_mse: 2.0823 - val_mae: 1.2598\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 2.1173 - mse: 2.1173 - mae: 1.1783 - val_loss: 2.0899 - val_mse: 2.0899 - val_mae: 1.2556\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 2.1038 - mse: 2.1038 - mae: 1.1701 - val_loss: 2.1000 - val_mse: 2.1000 - val_mae: 1.2499\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 2.0933 - mse: 2.0933 - mae: 1.1611 - val_loss: 2.1126 - val_mse: 2.1126 - val_mae: 1.2441\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 244us/step - loss: 2.0860 - mse: 2.0860 - mae: 1.1525 - val_loss: 2.1248 - val_mse: 2.1248 - val_mae: 1.2417\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 411us/step - loss: 2.0801 - mse: 2.0801 - mae: 1.1460 - val_loss: 2.1349 - val_mse: 2.1349 - val_mae: 1.2407\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 254us/step - loss: 2.0750 - mse: 2.0750 - mae: 1.1407 - val_loss: 2.1423 - val_mse: 2.1423 - val_mae: 1.2415\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 323us/step - loss: 2.0696 - mse: 2.0696 - mae: 1.1369 - val_loss: 2.1481 - val_mse: 2.1481 - val_mae: 1.2441\n",
      "23\n",
      "[23]\n",
      "Train on 82 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 5.2274 - mse: 5.2274 - mae: 1.8878 - val_loss: 3.0068 - val_mse: 3.0068 - val_mae: 1.4534\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 400us/step - loss: 4.9041 - mse: 4.9041 - mae: 1.7966 - val_loss: 2.8277 - val_mse: 2.8277 - val_mae: 1.3849\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 304us/step - loss: 4.6129 - mse: 4.6129 - mae: 1.7106 - val_loss: 2.6498 - val_mse: 2.6498 - val_mae: 1.3152\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 255us/step - loss: 4.3247 - mse: 4.3247 - mae: 1.6244 - val_loss: 2.4808 - val_mse: 2.4808 - val_mae: 1.2484\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 304us/step - loss: 4.0399 - mse: 4.0399 - mae: 1.5424 - val_loss: 2.3175 - val_mse: 2.3175 - val_mae: 1.1796\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 243us/step - loss: 3.7601 - mse: 3.7601 - mae: 1.4639 - val_loss: 2.1619 - val_mse: 2.1619 - val_mae: 1.1097\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 280us/step - loss: 3.4817 - mse: 3.4817 - mae: 1.3823 - val_loss: 2.0138 - val_mse: 2.0138 - val_mae: 1.0390\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 292us/step - loss: 3.2117 - mse: 3.2117 - mae: 1.3103 - val_loss: 1.8740 - val_mse: 1.8740 - val_mae: 0.9739\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 365us/step - loss: 2.9473 - mse: 2.9473 - mae: 1.2462 - val_loss: 1.7320 - val_mse: 1.7320 - val_mae: 0.9031\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 255us/step - loss: 2.6878 - mse: 2.6878 - mae: 1.1872 - val_loss: 1.5731 - val_mse: 1.5731 - val_mae: 0.8239\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 316us/step - loss: 2.4512 - mse: 2.4512 - mae: 1.1370 - val_loss: 1.4305 - val_mse: 1.4305 - val_mae: 0.8113\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 328us/step - loss: 2.2303 - mse: 2.2303 - mae: 1.1025 - val_loss: 1.3028 - val_mse: 1.3028 - val_mae: 0.8319\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 304us/step - loss: 2.0225 - mse: 2.0225 - mae: 1.0711 - val_loss: 1.2057 - val_mse: 1.2057 - val_mae: 0.8534\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 325us/step - loss: 1.8726 - mse: 1.8726 - mae: 1.0468 - val_loss: 1.1538 - val_mse: 1.1538 - val_mae: 0.8742\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 243us/step - loss: 1.7855 - mse: 1.7855 - mae: 1.0362 - val_loss: 1.1525 - val_mse: 1.1525 - val_mae: 0.8965\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 280us/step - loss: 1.7567 - mse: 1.7567 - mae: 1.0492 - val_loss: 1.1808 - val_mse: 1.1808 - val_mae: 0.9178\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 328us/step - loss: 1.7472 - mse: 1.7472 - mae: 1.0626 - val_loss: 1.2239 - val_mse: 1.2239 - val_mae: 0.9527\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 316us/step - loss: 1.7427 - mse: 1.7427 - mae: 1.0695 - val_loss: 1.2511 - val_mse: 1.2511 - val_mae: 0.9660\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 340us/step - loss: 1.7280 - mse: 1.7280 - mae: 1.0687 - val_loss: 1.2574 - val_mse: 1.2574 - val_mae: 0.9647\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 316us/step - loss: 1.7038 - mse: 1.7038 - mae: 1.0615 - val_loss: 1.2546 - val_mse: 1.2546 - val_mae: 0.9559\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 365us/step - loss: 1.6775 - mse: 1.6775 - mae: 1.0506 - val_loss: 1.2583 - val_mse: 1.2583 - val_mae: 0.9486\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 304us/step - loss: 1.6540 - mse: 1.6540 - mae: 1.0380 - val_loss: 1.2598 - val_mse: 1.2598 - val_mae: 0.9411\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 243us/step - loss: 1.6359 - mse: 1.6359 - mae: 1.0270 - val_loss: 1.2603 - val_mse: 1.2603 - val_mae: 0.9343\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 255us/step - loss: 1.6216 - mse: 1.6216 - mae: 1.0180 - val_loss: 1.2610 - val_mse: 1.2610 - val_mae: 0.9304\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 304us/step - loss: 1.6087 - mse: 1.6087 - mae: 1.0105 - val_loss: 1.2641 - val_mse: 1.2641 - val_mae: 0.9293\n",
      "24\n",
      "[24]\n",
      "Train on 87 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 2.4131 - mse: 2.4131 - mae: 1.1701 - val_loss: 1.8426 - val_mse: 1.8426 - val_mae: 1.1030\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 1.9263 - mse: 1.9263 - mae: 1.0120 - val_loss: 1.3250 - val_mse: 1.3250 - val_mae: 0.8966\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 1.5663 - mse: 1.5663 - mae: 0.8796 - val_loss: 0.9737 - val_mse: 0.9737 - val_mae: 0.7633\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 1.3765 - mse: 1.3765 - mae: 0.8617 - val_loss: 0.8037 - val_mse: 0.8037 - val_mae: 0.6552\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 1.3335 - mse: 1.3335 - mae: 0.8938 - val_loss: 0.7594 - val_mse: 0.7594 - val_mae: 0.6271\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 1.3558 - mse: 1.3558 - mae: 0.9350 - val_loss: 0.7605 - val_mse: 0.7605 - val_mae: 0.6399\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 1.3594 - mse: 1.3594 - mae: 0.9502 - val_loss: 0.7594 - val_mse: 0.7594 - val_mae: 0.6367\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 1.3244 - mse: 1.3244 - mae: 0.9372 - val_loss: 0.7536 - val_mse: 0.7536 - val_mae: 0.6200\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 1.2700 - mse: 1.2700 - mae: 0.9051 - val_loss: 0.7569 - val_mse: 0.7569 - val_mae: 0.6187\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 286us/step - loss: 1.2229 - mse: 1.2229 - mae: 0.8718 - val_loss: 0.7767 - val_mse: 0.7767 - val_mae: 0.6426\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 1.1957 - mse: 1.1957 - mae: 0.8421 - val_loss: 0.8057 - val_mse: 0.8057 - val_mae: 0.6756\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 1.1827 - mse: 1.1827 - mae: 0.8206 - val_loss: 0.8299 - val_mse: 0.8299 - val_mae: 0.6965\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 1.1722 - mse: 1.1722 - mae: 0.8087 - val_loss: 0.8394 - val_mse: 0.8394 - val_mae: 0.7041\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 1.1567 - mse: 1.1567 - mae: 0.8032 - val_loss: 0.8335 - val_mse: 0.8335 - val_mae: 0.7000\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - ETA: 0s - loss: 0.6703 - mse: 0.6703 - mae: 0.591 - 0s 344us/step - loss: 1.1362 - mse: 1.1362 - mae: 0.8025 - val_loss: 0.8180 - val_mse: 0.8180 - val_mae: 0.6878\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 1.1153 - mse: 1.1153 - mae: 0.8048 - val_loss: 0.8014 - val_mse: 0.8014 - val_mae: 0.6724\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 1.0979 - mse: 1.0979 - mae: 0.8100 - val_loss: 0.7883 - val_mse: 0.7883 - val_mae: 0.6578\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 1.0848 - mse: 1.0848 - mae: 0.8133 - val_loss: 0.7818 - val_mse: 0.7818 - val_mae: 0.6515\n",
      "25\n",
      "[25]\n",
      "Train on 81 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 4.7875 - mse: 4.7875 - mae: 2.0458 - val_loss: 5.3344 - val_mse: 5.3344 - val_mae: 2.1594\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 3.8344 - mse: 3.8344 - mae: 1.7971 - val_loss: 4.2053 - val_mse: 4.2053 - val_mae: 1.8859\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 3.0608 - mse: 3.0608 - mae: 1.5642 - val_loss: 3.2831 - val_mse: 3.2831 - val_mae: 1.6260\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 0s 480us/step - loss: 2.4390 - mse: 2.4390 - mae: 1.3466 - val_loss: 2.5392 - val_mse: 2.5392 - val_mae: 1.3889\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 1.9403 - mse: 1.9403 - mae: 1.1449 - val_loss: 1.9597 - val_mse: 1.9597 - val_mae: 1.1928\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 1.5476 - mse: 1.5476 - mae: 0.9621 - val_loss: 1.5141 - val_mse: 1.5141 - val_mae: 1.0442\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 1.2479 - mse: 1.2479 - mae: 0.8155 - val_loss: 1.1834 - val_mse: 1.1834 - val_mae: 0.9102\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 1.0283 - mse: 1.0283 - mae: 0.7083 - val_loss: 0.9496 - val_mse: 0.9496 - val_mae: 0.7875\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 0s 295us/step - loss: 0.8766 - mse: 0.8766 - mae: 0.6514 - val_loss: 0.7904 - val_mse: 0.7904 - val_mae: 0.7044\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 0.7809 - mse: 0.7809 - mae: 0.6384 - val_loss: 0.6922 - val_mse: 0.6922 - val_mae: 0.6582\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.7273 - mse: 0.7273 - mae: 0.6486 - val_loss: 0.6410 - val_mse: 0.6410 - val_mae: 0.6317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.7019 - mse: 0.7019 - mae: 0.6621 - val_loss: 0.6214 - val_mse: 0.6214 - val_mae: 0.6120\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.6929 - mse: 0.6929 - mae: 0.6773 - val_loss: 0.6198 - val_mse: 0.6198 - val_mae: 0.6042\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.6926 - mse: 0.6926 - mae: 0.6895 - val_loss: 0.6256 - val_mse: 0.6256 - val_mae: 0.6050\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 0s 295us/step - loss: 0.6943 - mse: 0.6943 - mae: 0.6985 - val_loss: 0.6306 - val_mse: 0.6306 - val_mae: 0.6060\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.6946 - mse: 0.6946 - mae: 0.7030 - val_loss: 0.6314 - val_mse: 0.6314 - val_mae: 0.6049\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 0s 443us/step - loss: 0.6925 - mse: 0.6925 - mae: 0.7034 - val_loss: 0.6280 - val_mse: 0.6280 - val_mae: 0.6026\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 0s 332us/step - loss: 0.6884 - mse: 0.6884 - mae: 0.7010 - val_loss: 0.6213 - val_mse: 0.6213 - val_mae: 0.5985\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.6827 - mse: 0.6827 - mae: 0.6963 - val_loss: 0.6118 - val_mse: 0.6118 - val_mae: 0.5937\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.6762 - mse: 0.6762 - mae: 0.6901 - val_loss: 0.6013 - val_mse: 0.6013 - val_mae: 0.5920\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.6700 - mse: 0.6700 - mae: 0.6830 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.5903\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - 0s 333us/step - loss: 0.6645 - mse: 0.6645 - mae: 0.6755 - val_loss: 0.5837 - val_mse: 0.5837 - val_mae: 0.5885\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.6599 - mse: 0.6599 - mae: 0.6680 - val_loss: 0.5770 - val_mse: 0.5770 - val_mae: 0.5884\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.6562 - mse: 0.6562 - mae: 0.6611 - val_loss: 0.5721 - val_mse: 0.5721 - val_mae: 0.5896\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.6532 - mse: 0.6532 - mae: 0.6551 - val_loss: 0.5682 - val_mse: 0.5682 - val_mae: 0.5904\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.6502 - mse: 0.6502 - mae: 0.6499 - val_loss: 0.5643 - val_mse: 0.5643 - val_mae: 0.5903\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - 0s 320us/step - loss: 0.6473 - mse: 0.6473 - mae: 0.6456 - val_loss: 0.5601 - val_mse: 0.5601 - val_mae: 0.5894\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.6445 - mse: 0.6445 - mae: 0.6421 - val_loss: 0.5556 - val_mse: 0.5556 - val_mae: 0.5879\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.6414 - mse: 0.6414 - mae: 0.6393 - val_loss: 0.5510 - val_mse: 0.5510 - val_mae: 0.5860\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.6385 - mse: 0.6385 - mae: 0.6373 - val_loss: 0.5464 - val_mse: 0.5464 - val_mae: 0.5838\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.7521 - mse: 0.7521 - mae: 0.670 - 0s 406us/step - loss: 0.6355 - mse: 0.6355 - mae: 0.6357 - val_loss: 0.5424 - val_mse: 0.5424 - val_mae: 0.5820\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - 0s 222us/step - loss: 0.6325 - mse: 0.6325 - mae: 0.6344 - val_loss: 0.5384 - val_mse: 0.5384 - val_mae: 0.5801\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - 0s 406us/step - loss: 0.6293 - mse: 0.6293 - mae: 0.6331 - val_loss: 0.5349 - val_mse: 0.5349 - val_mae: 0.5786\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - 0s 382us/step - loss: 0.6263 - mse: 0.6263 - mae: 0.6321 - val_loss: 0.5317 - val_mse: 0.5317 - val_mae: 0.5781\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.6229 - mse: 0.6229 - mae: 0.6307 - val_loss: 0.5290 - val_mse: 0.5290 - val_mae: 0.5781\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.6196 - mse: 0.6196 - mae: 0.6292 - val_loss: 0.5270 - val_mse: 0.5270 - val_mae: 0.5785\n",
      "Epoch 37/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.6164 - mse: 0.6164 - mae: 0.6275 - val_loss: 0.5248 - val_mse: 0.5248 - val_mae: 0.5788\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - 0s 222us/step - loss: 0.6133 - mse: 0.6133 - mae: 0.6258 - val_loss: 0.5217 - val_mse: 0.5217 - val_mae: 0.5781\n",
      "Epoch 39/100\n",
      "81/81 [==============================] - 0s 320us/step - loss: 0.6103 - mse: 0.6103 - mae: 0.6243 - val_loss: 0.5177 - val_mse: 0.5177 - val_mae: 0.5767\n",
      "Epoch 40/100\n",
      "81/81 [==============================] - 0s 296us/step - loss: 0.6073 - mse: 0.6073 - mae: 0.6225 - val_loss: 0.5134 - val_mse: 0.5134 - val_mae: 0.5751\n",
      "Epoch 41/100\n",
      "81/81 [==============================] - 0s 357us/step - loss: 0.6041 - mse: 0.6041 - mae: 0.6205 - val_loss: 0.5091 - val_mse: 0.5091 - val_mae: 0.5740\n",
      "Epoch 42/100\n",
      "81/81 [==============================] - 0s 332us/step - loss: 0.6008 - mse: 0.6008 - mae: 0.6186 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.5740\n",
      "Epoch 43/100\n",
      "81/81 [==============================] - 0s 296us/step - loss: 0.5980 - mse: 0.5980 - mae: 0.6171 - val_loss: 0.5060 - val_mse: 0.5060 - val_mae: 0.5733\n",
      "Epoch 44/100\n",
      "81/81 [==============================] - 0s 357us/step - loss: 0.5957 - mse: 0.5957 - mae: 0.6158 - val_loss: 0.5041 - val_mse: 0.5041 - val_mae: 0.5727\n",
      "Epoch 45/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5930 - mse: 0.5930 - mae: 0.6144 - val_loss: 0.5026 - val_mse: 0.5026 - val_mae: 0.5724\n",
      "Epoch 46/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.5904 - mse: 0.5904 - mae: 0.6131 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.5719\n",
      "Epoch 47/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5879 - mse: 0.5879 - mae: 0.6120 - val_loss: 0.4996 - val_mse: 0.4996 - val_mae: 0.5711\n",
      "Epoch 48/100\n",
      "81/81 [==============================] - 0s 320us/step - loss: 0.5855 - mse: 0.5855 - mae: 0.6110 - val_loss: 0.4982 - val_mse: 0.4982 - val_mae: 0.5704\n",
      "Epoch 49/100\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.5829 - mse: 0.5829 - mae: 0.6099 - val_loss: 0.4972 - val_mse: 0.4972 - val_mae: 0.5700\n",
      "Epoch 50/100\n",
      "81/81 [==============================] - 0s 296us/step - loss: 0.5802 - mse: 0.5802 - mae: 0.6089 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5699\n",
      "Epoch 51/100\n",
      "81/81 [==============================] - 0s 332us/step - loss: 0.5779 - mse: 0.5779 - mae: 0.6080 - val_loss: 0.4959 - val_mse: 0.4959 - val_mae: 0.5698\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - 0s 452us/step - loss: 0.5753 - mse: 0.5753 - mae: 0.6069 - val_loss: 0.4952 - val_mse: 0.4952 - val_mae: 0.5701\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5725 - mse: 0.5725 - mae: 0.6055 - val_loss: 0.4944 - val_mse: 0.4944 - val_mae: 0.5703\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - 0s 382us/step - loss: 0.5697 - mse: 0.5697 - mae: 0.6040 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5706\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.5668 - mse: 0.5668 - mae: 0.6023 - val_loss: 0.4928 - val_mse: 0.4928 - val_mae: 0.5708\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.5639 - mse: 0.5639 - mae: 0.6004 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.5709\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - 0s 382us/step - loss: 0.5609 - mse: 0.5609 - mae: 0.5986 - val_loss: 0.4902 - val_mse: 0.4902 - val_mae: 0.5708\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 0.5579 - mse: 0.5579 - mae: 0.5970 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.5709\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.5549 - mse: 0.5549 - mae: 0.5954 - val_loss: 0.4885 - val_mse: 0.4885 - val_mae: 0.5711\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.5516 - mse: 0.5516 - mae: 0.5937 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5704\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 246us/step - loss: 0.5483 - mse: 0.5483 - mae: 0.5920 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.5696\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.5452 - mse: 0.5452 - mae: 0.5906 - val_loss: 0.4835 - val_mse: 0.4835 - val_mae: 0.5684\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.5422 - mse: 0.5422 - mae: 0.5895 - val_loss: 0.4818 - val_mse: 0.4818 - val_mae: 0.5672\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - 0s 320us/step - loss: 0.5392 - mse: 0.5392 - mae: 0.5883 - val_loss: 0.4801 - val_mse: 0.4801 - val_mae: 0.5660\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - 0s 443us/step - loss: 0.5363 - mse: 0.5363 - mae: 0.5871 - val_loss: 0.4785 - val_mse: 0.4785 - val_mae: 0.5648\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - 0s 505us/step - loss: 0.5334 - mse: 0.5334 - mae: 0.5858 - val_loss: 0.4770 - val_mse: 0.4770 - val_mae: 0.5635\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - 0s 457us/step - loss: 0.5305 - mse: 0.5305 - mae: 0.5845 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.5626\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.5278 - mse: 0.5278 - mae: 0.5833 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.5615\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - 0s 295us/step - loss: 0.5250 - mse: 0.5250 - mae: 0.5821 - val_loss: 0.4757 - val_mse: 0.4757 - val_mae: 0.5605\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.5223 - mse: 0.5223 - mae: 0.5808 - val_loss: 0.4748 - val_mse: 0.4748 - val_mae: 0.5594\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - 0s 382us/step - loss: 0.5197 - mse: 0.5197 - mae: 0.5795 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5582\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5172 - mse: 0.5172 - mae: 0.5784 - val_loss: 0.4736 - val_mse: 0.4736 - val_mae: 0.5572\n",
      "Epoch 73/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.5147 - mse: 0.5147 - mae: 0.5771 - val_loss: 0.4732 - val_mse: 0.4732 - val_mae: 0.5564\n",
      "Epoch 74/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5120 - mse: 0.5120 - mae: 0.5755 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.5556\n",
      "Epoch 75/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.5093 - mse: 0.5093 - mae: 0.5738 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.5548\n",
      "Epoch 76/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.5068 - mse: 0.5068 - mae: 0.5723 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.5539\n",
      "Epoch 77/100\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5042 - mse: 0.5042 - mae: 0.5706 - val_loss: 0.4711 - val_mse: 0.4711 - val_mae: 0.5530\n",
      "Epoch 78/100\n",
      "81/81 [==============================] - 0s 420us/step - loss: 0.5016 - mse: 0.5016 - mae: 0.5687 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.5521\n",
      "Epoch 79/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.4989 - mse: 0.4989 - mae: 0.5671 - val_loss: 0.4694 - val_mse: 0.4694 - val_mae: 0.5507\n",
      "Epoch 80/100\n",
      "81/81 [==============================] - 0s 320us/step - loss: 0.4965 - mse: 0.4965 - mae: 0.5659 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.5491\n",
      "Epoch 81/100\n",
      "81/81 [==============================] - 0s 296us/step - loss: 0.4941 - mse: 0.4941 - mae: 0.5647 - val_loss: 0.4668 - val_mse: 0.4668 - val_mae: 0.5477\n",
      "Epoch 82/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.4917 - mse: 0.4917 - mae: 0.5634 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.5466\n",
      "Epoch 83/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.4894 - mse: 0.4894 - mae: 0.5624 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.5452\n",
      "Epoch 84/100\n",
      "81/81 [==============================] - 0s 295us/step - loss: 0.4870 - mse: 0.4870 - mae: 0.5613 - val_loss: 0.4665 - val_mse: 0.4665 - val_mae: 0.5444\n",
      "Epoch 85/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.4845 - mse: 0.4845 - mae: 0.5597 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.5441\n",
      "Epoch 86/100\n",
      "81/81 [==============================] - 0s 419us/step - loss: 0.4822 - mse: 0.4822 - mae: 0.5580 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.5439\n",
      "Epoch 87/100\n",
      "81/81 [==============================] - 0s 259us/step - loss: 0.4798 - mse: 0.4798 - mae: 0.5563 - val_loss: 0.4683 - val_mse: 0.4683 - val_mae: 0.5437\n",
      "Epoch 88/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.4774 - mse: 0.4774 - mae: 0.5546 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.5432\n",
      "Epoch 89/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.4749 - mse: 0.4749 - mae: 0.5533 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.5420\n",
      "Epoch 90/100\n",
      "81/81 [==============================] - 0s 295us/step - loss: 0.4727 - mse: 0.4727 - mae: 0.5523 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.5411\n",
      "Epoch 91/100\n",
      "81/81 [==============================] - 0s 406us/step - loss: 0.4702 - mse: 0.4702 - mae: 0.5509 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.5409\n",
      "Epoch 92/100\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.4679 - mse: 0.4679 - mae: 0.5490 - val_loss: 0.4711 - val_mse: 0.4711 - val_mae: 0.5407\n",
      "Epoch 93/100\n",
      "81/81 [==============================] - 0s 234us/step - loss: 0.4658 - mse: 0.4658 - mae: 0.5472 - val_loss: 0.4713 - val_mse: 0.4713 - val_mae: 0.5399\n",
      "26\n",
      "[26]\n",
      "Train on 95 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "95/95 [==============================] - 1s 10ms/step - loss: 3.2872 - mse: 3.2872 - mae: 1.3352 - val_loss: 0.8451 - val_mse: 0.8451 - val_mae: 0.6828\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s 399us/step - loss: 2.9252 - mse: 2.9252 - mae: 1.2762 - val_loss: 0.7749 - val_mse: 0.7749 - val_mae: 0.6990\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s 378us/step - loss: 2.7866 - mse: 2.7866 - mae: 1.2564 - val_loss: 0.7560 - val_mse: 0.7560 - val_mae: 0.7082\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s 252us/step - loss: 2.7262 - mse: 2.7262 - mae: 1.2542 - val_loss: 0.7547 - val_mse: 0.7547 - val_mae: 0.7124\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s 294us/step - loss: 2.6750 - mse: 2.6750 - mae: 1.2456 - val_loss: 0.7551 - val_mse: 0.7551 - val_mae: 0.7126\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s 273us/step - loss: 2.6205 - mse: 2.6205 - mae: 1.2343 - val_loss: 0.7512 - val_mse: 0.7512 - val_mae: 0.7098\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s 347us/step - loss: 2.5665 - mse: 2.5665 - mae: 1.2196 - val_loss: 0.7476 - val_mse: 0.7476 - val_mae: 0.7044\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s 441us/step - loss: 2.5170 - mse: 2.5170 - mae: 1.2048 - val_loss: 0.7474 - val_mse: 0.7474 - val_mae: 0.7003\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s 472us/step - loss: 2.4755 - mse: 2.4755 - mae: 1.1914 - val_loss: 0.7494 - val_mse: 0.7494 - val_mae: 0.6992\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 0s 325us/step - loss: 2.4417 - mse: 2.4417 - mae: 1.1827 - val_loss: 0.7512 - val_mse: 0.7512 - val_mae: 0.6993\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 0s 231us/step - loss: 2.4127 - mse: 2.4127 - mae: 1.1765 - val_loss: 0.7525 - val_mse: 0.7525 - val_mae: 0.6999\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 0s 273us/step - loss: 2.3846 - mse: 2.3846 - mae: 1.1709 - val_loss: 0.7540 - val_mse: 0.7540 - val_mae: 0.7005\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 0s 241us/step - loss: 2.3571 - mse: 2.3571 - mae: 1.1657 - val_loss: 0.7563 - val_mse: 0.7563 - val_mae: 0.7012\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 0s 241us/step - loss: 2.3305 - mse: 2.3305 - mae: 1.1605 - val_loss: 0.7586 - val_mse: 0.7586 - val_mae: 0.7015\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 0s 283us/step - loss: 2.3039 - mse: 2.3039 - mae: 1.1548 - val_loss: 0.7624 - val_mse: 0.7624 - val_mae: 0.7020\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 0s 399us/step - loss: 2.2791 - mse: 2.2791 - mae: 1.1490 - val_loss: 0.7659 - val_mse: 0.7659 - val_mae: 0.7026\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 0s 336us/step - loss: 2.2557 - mse: 2.2557 - mae: 1.1429 - val_loss: 0.7685 - val_mse: 0.7685 - val_mae: 0.7056\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 0s 556us/step - loss: 2.2348 - mse: 2.2348 - mae: 1.1379 - val_loss: 0.7706 - val_mse: 0.7706 - val_mae: 0.7076\n",
      "27\n",
      "[27]\n",
      "Train on 70 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 6.9136 - mse: 6.9136 - mae: 2.2930 - val_loss: 6.3917 - val_mse: 6.3917 - val_mae: 2.3490\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 611us/step - loss: 6.1858 - mse: 6.1858 - mae: 2.1381 - val_loss: 5.6945 - val_mse: 5.6945 - val_mae: 2.1878\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 5.4917 - mse: 5.4917 - mae: 1.9780 - val_loss: 5.0527 - val_mse: 5.0527 - val_mae: 2.0259\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 4.8619 - mse: 4.8619 - mae: 1.8196 - val_loss: 4.4810 - val_mse: 4.4810 - val_mae: 1.8684\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 399us/step - loss: 4.3045 - mse: 4.3045 - mae: 1.6678 - val_loss: 4.0095 - val_mse: 4.0095 - val_mae: 1.7217\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 570us/step - loss: 3.8120 - mse: 3.8120 - mae: 1.5219 - val_loss: 3.5752 - val_mse: 3.5752 - val_mae: 1.5768\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 276us/step - loss: 3.3865 - mse: 3.3865 - mae: 1.3835 - val_loss: 3.1970 - val_mse: 3.1970 - val_mae: 1.4455\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 3.0438 - mse: 3.0438 - mae: 1.2587 - val_loss: 2.8256 - val_mse: 2.8256 - val_mae: 1.3304\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 299us/step - loss: 2.7475 - mse: 2.7475 - mae: 1.1558 - val_loss: 2.4838 - val_mse: 2.4838 - val_mae: 1.2363\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 299us/step - loss: 2.5000 - mse: 2.5000 - mae: 1.0714 - val_loss: 2.1738 - val_mse: 2.1738 - val_mae: 1.1411\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 285us/step - loss: 2.2845 - mse: 2.2845 - mae: 1.0069 - val_loss: 1.9210 - val_mse: 1.9210 - val_mae: 1.0717\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 285us/step - loss: 2.1002 - mse: 2.1002 - mae: 0.9596 - val_loss: 1.6834 - val_mse: 1.6834 - val_mae: 1.0440\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.9508 - mse: 1.9508 - mae: 0.9256 - val_loss: 1.4843 - val_mse: 1.4843 - val_mae: 1.0181\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.8330 - mse: 1.8330 - mae: 0.9009 - val_loss: 1.3219 - val_mse: 1.3219 - val_mae: 0.9914\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 328us/step - loss: 1.7542 - mse: 1.7542 - mae: 0.8830 - val_loss: 1.1902 - val_mse: 1.1902 - val_mae: 0.9605\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 1.7035 - mse: 1.7035 - mae: 0.8764 - val_loss: 1.0935 - val_mse: 1.0935 - val_mae: 0.9331\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 442us/step - loss: 1.6695 - mse: 1.6695 - mae: 0.8783 - val_loss: 1.0226 - val_mse: 1.0226 - val_mae: 0.9093\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 1.6488 - mse: 1.6488 - mae: 0.8799 - val_loss: 0.9843 - val_mse: 0.9843 - val_mae: 0.8952\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 299us/step - loss: 1.6303 - mse: 1.6303 - mae: 0.8842 - val_loss: 0.9574 - val_mse: 0.9574 - val_mae: 0.8825\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 1.6085 - mse: 1.6085 - mae: 0.8849 - val_loss: 0.9349 - val_mse: 0.9349 - val_mae: 0.8706\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 356us/step - loss: 1.5849 - mse: 1.5849 - mae: 0.8825 - val_loss: 0.9147 - val_mse: 0.9147 - val_mae: 0.8597\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 371us/step - loss: 1.5629 - mse: 1.5629 - mae: 0.8764 - val_loss: 0.9011 - val_mse: 0.9011 - val_mae: 0.8522\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 299us/step - loss: 1.5420 - mse: 1.5420 - mae: 0.8688 - val_loss: 0.8960 - val_mse: 0.8960 - val_mae: 0.8496\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 484us/step - loss: 1.5194 - mse: 1.5194 - mae: 0.8618 - val_loss: 0.8979 - val_mse: 0.8979 - val_mae: 0.8517\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.4957 - mse: 1.4957 - mae: 0.8554 - val_loss: 0.9051 - val_mse: 0.9051 - val_mae: 0.8571\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.4723 - mse: 1.4723 - mae: 0.8492 - val_loss: 0.9122 - val_mse: 0.9122 - val_mae: 0.8623\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.4525 - mse: 1.4525 - mae: 0.8428 - val_loss: 0.9153 - val_mse: 0.9153 - val_mae: 0.8648\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.4331 - mse: 1.4331 - mae: 0.8354 - val_loss: 0.9155 - val_mse: 0.9155 - val_mae: 0.8658\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 285us/step - loss: 1.4156 - mse: 1.4156 - mae: 0.8292 - val_loss: 0.9138 - val_mse: 0.9138 - val_mae: 0.8662\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 1.4001 - mse: 1.4001 - mae: 0.8245 - val_loss: 0.9111 - val_mse: 0.9111 - val_mae: 0.8662\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 328us/step - loss: 1.3852 - mse: 1.3852 - mae: 0.8199 - val_loss: 0.9075 - val_mse: 0.9075 - val_mae: 0.8656\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 427us/step - loss: 1.3706 - mse: 1.3706 - mae: 0.8157 - val_loss: 0.9032 - val_mse: 0.9032 - val_mae: 0.8648\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 470us/step - loss: 1.3567 - mse: 1.3567 - mae: 0.8119 - val_loss: 0.8995 - val_mse: 0.8995 - val_mae: 0.8639\n",
      "28\n",
      "[28]\n",
      "Train on 89 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 7.4625 - mse: 7.4625 - mae: 2.4037 - val_loss: 6.1082 - val_mse: 6.1082 - val_mae: 2.1966\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 322us/step - loss: 6.2743 - mse: 6.2743 - mae: 2.1448 - val_loss: 5.1751 - val_mse: 5.1751 - val_mae: 1.9623\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 5.2319 - mse: 5.2319 - mae: 1.9007 - val_loss: 4.3665 - val_mse: 4.3665 - val_mae: 1.7287\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 381us/step - loss: 4.3318 - mse: 4.3318 - mae: 1.6734 - val_loss: 3.6831 - val_mse: 3.6831 - val_mae: 1.5148\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 3.5656 - mse: 3.5656 - mae: 1.4663 - val_loss: 3.0963 - val_mse: 3.0963 - val_mae: 1.3570\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 246us/step - loss: 2.9338 - mse: 2.9338 - mae: 1.2943 - val_loss: 2.5994 - val_mse: 2.5994 - val_mae: 1.2493\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 2.4511 - mse: 2.4511 - mae: 1.1527 - val_loss: 2.2462 - val_mse: 2.2462 - val_mae: 1.1882\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 2.1266 - mse: 2.1266 - mae: 1.0819 - val_loss: 1.9618 - val_mse: 1.9618 - val_mae: 1.1525\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.9517 - mse: 1.9517 - mae: 1.0604 - val_loss: 1.7855 - val_mse: 1.7855 - val_mae: 1.1138\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 1.8928 - mse: 1.8928 - mae: 1.0717 - val_loss: 1.6942 - val_mse: 1.6942 - val_mae: 1.0761\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.8984 - mse: 1.8984 - mae: 1.0881 - val_loss: 1.6524 - val_mse: 1.6524 - val_mae: 1.0514\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.9104 - mse: 1.9104 - mae: 1.1016 - val_loss: 1.6311 - val_mse: 1.6311 - val_mae: 1.0456\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.8994 - mse: 1.8994 - mae: 1.1030 - val_loss: 1.6157 - val_mse: 1.6157 - val_mae: 1.0416\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.8617 - mse: 1.8617 - mae: 1.0903 - val_loss: 1.6073 - val_mse: 1.6073 - val_mae: 1.0397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.8099 - mse: 1.8099 - mae: 1.0699 - val_loss: 1.6086 - val_mse: 1.6086 - val_mae: 1.0393\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.7596 - mse: 1.7596 - mae: 1.0505 - val_loss: 1.6189 - val_mse: 1.6189 - val_mae: 1.0375\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 515us/step - loss: 1.7190 - mse: 1.7190 - mae: 1.0340 - val_loss: 1.6320 - val_mse: 1.6320 - val_mae: 1.0355\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 459us/step - loss: 1.6903 - mse: 1.6903 - mae: 1.0191 - val_loss: 1.6459 - val_mse: 1.6459 - val_mae: 1.0360\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.6692 - mse: 1.6692 - mae: 1.0059 - val_loss: 1.6545 - val_mse: 1.6545 - val_mae: 1.0341\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.6518 - mse: 1.6518 - mae: 0.9948 - val_loss: 1.6544 - val_mse: 1.6544 - val_mae: 1.0297\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 213us/step - loss: 1.6344 - mse: 1.6344 - mae: 0.9861 - val_loss: 1.6419 - val_mse: 1.6419 - val_mae: 1.0224\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.6159 - mse: 1.6159 - mae: 0.9797 - val_loss: 1.6234 - val_mse: 1.6234 - val_mae: 1.0142\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 359us/step - loss: 1.5965 - mse: 1.5965 - mae: 0.9754 - val_loss: 1.6017 - val_mse: 1.6017 - val_mae: 1.0099\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 359us/step - loss: 1.5773 - mse: 1.5773 - mae: 0.9721 - val_loss: 1.5785 - val_mse: 1.5785 - val_mae: 1.0056\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.5594 - mse: 1.5594 - mae: 0.9691 - val_loss: 1.5571 - val_mse: 1.5571 - val_mae: 1.0017\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.5434 - mse: 1.5434 - mae: 0.9658 - val_loss: 1.5385 - val_mse: 1.5385 - val_mae: 0.9983\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 325us/step - loss: 1.5282 - mse: 1.5282 - mae: 0.9618 - val_loss: 1.5218 - val_mse: 1.5218 - val_mae: 0.9948\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.5137 - mse: 1.5137 - mae: 0.9576 - val_loss: 1.5080 - val_mse: 1.5080 - val_mae: 0.9914\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 414us/step - loss: 1.4999 - mse: 1.4999 - mae: 0.9531 - val_loss: 1.4957 - val_mse: 1.4957 - val_mae: 0.9878\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.4866 - mse: 1.4866 - mae: 0.9481 - val_loss: 1.4842 - val_mse: 1.4842 - val_mae: 0.9837\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 1.2482 - mse: 1.2482 - mae: 0.963 - 0s 235us/step - loss: 1.4732 - mse: 1.4732 - mae: 0.9427 - val_loss: 1.4737 - val_mse: 1.4737 - val_mae: 0.9813\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.4601 - mse: 1.4601 - mae: 0.9374 - val_loss: 1.4632 - val_mse: 1.4632 - val_mae: 0.9794\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.4480 - mse: 1.4480 - mae: 0.9322 - val_loss: 1.4529 - val_mse: 1.4529 - val_mae: 0.9771\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.4369 - mse: 1.4369 - mae: 0.9273 - val_loss: 1.4421 - val_mse: 1.4421 - val_mae: 0.9744\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.4265 - mse: 1.4265 - mae: 0.9229 - val_loss: 1.4306 - val_mse: 1.4306 - val_mae: 0.9708\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.4163 - mse: 1.4163 - mae: 0.9190 - val_loss: 1.4196 - val_mse: 1.4196 - val_mae: 0.9673\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.4062 - mse: 1.4062 - mae: 0.9154 - val_loss: 1.4094 - val_mse: 1.4094 - val_mae: 0.9642\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.3958 - mse: 1.3958 - mae: 0.9119 - val_loss: 1.4006 - val_mse: 1.4006 - val_mae: 0.9614\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.3856 - mse: 1.3856 - mae: 0.9089 - val_loss: 1.3914 - val_mse: 1.3914 - val_mae: 0.9583\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.3759 - mse: 1.3759 - mae: 0.9059 - val_loss: 1.3826 - val_mse: 1.3826 - val_mae: 0.9551\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.3664 - mse: 1.3664 - mae: 0.9029 - val_loss: 1.3739 - val_mse: 1.3739 - val_mae: 0.9518\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 415us/step - loss: 1.3572 - mse: 1.3572 - mae: 0.8999 - val_loss: 1.3648 - val_mse: 1.3648 - val_mae: 0.9483\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 325us/step - loss: 1.3481 - mse: 1.3481 - mae: 0.8967 - val_loss: 1.3554 - val_mse: 1.3554 - val_mae: 0.9446\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.3391 - mse: 1.3391 - mae: 0.8940 - val_loss: 1.3459 - val_mse: 1.3459 - val_mae: 0.9408\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.3304 - mse: 1.3304 - mae: 0.8911 - val_loss: 1.3380 - val_mse: 1.3380 - val_mae: 0.9375\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.3211 - mse: 1.3211 - mae: 0.8879 - val_loss: 1.3309 - val_mse: 1.3309 - val_mae: 0.9342\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 213us/step - loss: 1.3114 - mse: 1.3114 - mae: 0.8841 - val_loss: 1.3217 - val_mse: 1.3217 - val_mae: 0.9318\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.3011 - mse: 1.3011 - mae: 0.8799 - val_loss: 1.3134 - val_mse: 1.3134 - val_mae: 0.9318\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 359us/step - loss: 1.2917 - mse: 1.2917 - mae: 0.8761 - val_loss: 1.3055 - val_mse: 1.3055 - val_mae: 0.9320\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.2829 - mse: 1.2829 - mae: 0.8725 - val_loss: 1.2989 - val_mse: 1.2989 - val_mae: 0.9326\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 403us/step - loss: 1.2738 - mse: 1.2738 - mae: 0.8689 - val_loss: 1.2913 - val_mse: 1.2913 - val_mae: 0.9326\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 549us/step - loss: 1.2648 - mse: 1.2648 - mae: 0.8653 - val_loss: 1.2819 - val_mse: 1.2819 - val_mae: 0.9318\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 300us/step - loss: 1.2564 - mse: 1.2564 - mae: 0.8620 - val_loss: 1.2723 - val_mse: 1.2723 - val_mae: 0.9307\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.2490 - mse: 1.2490 - mae: 0.8594 - val_loss: 1.2627 - val_mse: 1.2627 - val_mae: 0.9293\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.2421 - mse: 1.2421 - mae: 0.8572 - val_loss: 1.2543 - val_mse: 1.2543 - val_mae: 0.9278\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.2357 - mse: 1.2357 - mae: 0.8552 - val_loss: 1.2464 - val_mse: 1.2464 - val_mae: 0.9264\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 336us/step - loss: 1.2286 - mse: 1.2286 - mae: 0.8528 - val_loss: 1.2388 - val_mse: 1.2388 - val_mae: 0.9251\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 246us/step - loss: 1.2217 - mse: 1.2217 - mae: 0.8502 - val_loss: 1.2326 - val_mse: 1.2326 - val_mae: 0.9243\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.2145 - mse: 1.2145 - mae: 0.8471 - val_loss: 1.2297 - val_mse: 1.2297 - val_mae: 0.9253\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.2079 - mse: 1.2079 - mae: 0.8442 - val_loss: 1.2272 - val_mse: 1.2272 - val_mae: 0.9260\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 0s 213us/step - loss: 1.2023 - mse: 1.2023 - mae: 0.8420 - val_loss: 1.2240 - val_mse: 1.2240 - val_mae: 0.9257\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.1970 - mse: 1.1970 - mae: 0.8402 - val_loss: 1.2208 - val_mse: 1.2208 - val_mae: 0.9248\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.1915 - mse: 1.1915 - mae: 0.8383 - val_loss: 1.2178 - val_mse: 1.2178 - val_mae: 0.9235\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 404us/step - loss: 1.1862 - mse: 1.1862 - mae: 0.8366 - val_loss: 1.2150 - val_mse: 1.2150 - val_mae: 0.9219\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.1809 - mse: 1.1809 - mae: 0.8348 - val_loss: 1.2126 - val_mse: 1.2126 - val_mae: 0.9199\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.1756 - mse: 1.1756 - mae: 0.8331 - val_loss: 1.2105 - val_mse: 1.2105 - val_mae: 0.9178\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.1704 - mse: 1.1704 - mae: 0.8312 - val_loss: 1.2086 - val_mse: 1.2086 - val_mae: 0.9157\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.1653 - mse: 1.1653 - mae: 0.8292 - val_loss: 1.2073 - val_mse: 1.2073 - val_mae: 0.9142\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.1598 - mse: 1.1598 - mae: 0.8271 - val_loss: 1.2062 - val_mse: 1.2062 - val_mae: 0.9133\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 325us/step - loss: 1.1544 - mse: 1.1544 - mae: 0.8250 - val_loss: 1.2055 - val_mse: 1.2055 - val_mae: 0.9130\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.1492 - mse: 1.1492 - mae: 0.8231 - val_loss: 1.2041 - val_mse: 1.2041 - val_mae: 0.9127\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.1440 - mse: 1.1440 - mae: 0.8216 - val_loss: 1.2016 - val_mse: 1.2016 - val_mae: 0.9120\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 0s 213us/step - loss: 1.1389 - mse: 1.1389 - mae: 0.8203 - val_loss: 1.1990 - val_mse: 1.1990 - val_mae: 0.9112\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.1339 - mse: 1.1339 - mae: 0.8191 - val_loss: 1.1965 - val_mse: 1.1965 - val_mae: 0.9108\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.1297 - mse: 1.1297 - mae: 0.8180 - val_loss: 1.1919 - val_mse: 1.1919 - val_mae: 0.9097\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 1.1252 - mse: 1.1252 - mae: 0.8169 - val_loss: 1.1885 - val_mse: 1.1885 - val_mae: 0.9088\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 1.0502 - mse: 1.0502 - mae: 0.881 - 0s 247us/step - loss: 1.1211 - mse: 1.1211 - mae: 0.8156 - val_loss: 1.1863 - val_mse: 1.1863 - val_mae: 0.9081\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.1167 - mse: 1.1167 - mae: 0.8138 - val_loss: 1.1845 - val_mse: 1.1845 - val_mae: 0.9076\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 1.1120 - mse: 1.1120 - mae: 0.8121 - val_loss: 1.1822 - val_mse: 1.1822 - val_mae: 0.9069\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.1075 - mse: 1.1075 - mae: 0.8106 - val_loss: 1.1793 - val_mse: 1.1793 - val_mae: 0.9056\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.1032 - mse: 1.1032 - mae: 0.8093 - val_loss: 1.1762 - val_mse: 1.1762 - val_mae: 0.9042\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 1.0989 - mse: 1.0989 - mae: 0.8079 - val_loss: 1.1726 - val_mse: 1.1726 - val_mae: 0.9026\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 235us/step - loss: 1.0945 - mse: 1.0945 - mae: 0.8064 - val_loss: 1.1696 - val_mse: 1.1696 - val_mae: 0.9010\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.0902 - mse: 1.0902 - mae: 0.8046 - val_loss: 1.1679 - val_mse: 1.1679 - val_mae: 0.8999\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 0s 304us/step - loss: 1.0859 - mse: 1.0859 - mae: 0.8028 - val_loss: 1.1656 - val_mse: 1.1656 - val_mae: 0.8985\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.0812 - mse: 1.0812 - mae: 0.8011 - val_loss: 1.1629 - val_mse: 1.1629 - val_mae: 0.8969\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 0s 392us/step - loss: 1.0774 - mse: 1.0774 - mae: 0.7994 - val_loss: 1.1603 - val_mse: 1.1603 - val_mae: 0.8954\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.0727 - mse: 1.0727 - mae: 0.7976 - val_loss: 1.1578 - val_mse: 1.1578 - val_mae: 0.8942\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.0685 - mse: 1.0685 - mae: 0.7959 - val_loss: 1.1546 - val_mse: 1.1546 - val_mae: 0.8925\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.0640 - mse: 1.0640 - mae: 0.7944 - val_loss: 1.1509 - val_mse: 1.1509 - val_mae: 0.8902\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.0599 - mse: 1.0599 - mae: 0.7928 - val_loss: 1.1488 - val_mse: 1.1488 - val_mae: 0.8890\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 0s 325us/step - loss: 1.0559 - mse: 1.0559 - mae: 0.7910 - val_loss: 1.1470 - val_mse: 1.1470 - val_mae: 0.8886\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.0513 - mse: 1.0513 - mae: 0.7894 - val_loss: 1.1451 - val_mse: 1.1451 - val_mae: 0.8884\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.0473 - mse: 1.0473 - mae: 0.7881 - val_loss: 1.1429 - val_mse: 1.1429 - val_mae: 0.8877\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 1.0436 - mse: 1.0436 - mae: 0.7868 - val_loss: 1.1387 - val_mse: 1.1387 - val_mae: 0.8856\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.9970 - mse: 0.9970 - mae: 0.864 - 0s 280us/step - loss: 1.0397 - mse: 1.0397 - mae: 0.7855 - val_loss: 1.1360 - val_mse: 1.1360 - val_mae: 0.8839\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.0356 - mse: 1.0356 - mae: 0.7836 - val_loss: 1.1349 - val_mse: 1.1349 - val_mae: 0.8833\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.0313 - mse: 1.0313 - mae: 0.7816 - val_loss: 1.1326 - val_mse: 1.1326 - val_mae: 0.8825\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 1.0275 - mse: 1.0275 - mae: 0.7801 - val_loss: 1.1281 - val_mse: 1.1281 - val_mae: 0.8806\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 0s 258us/step - loss: 1.0235 - mse: 1.0235 - mae: 0.7790 - val_loss: 1.1252 - val_mse: 1.1252 - val_mae: 0.8792\n",
      "29\n",
      "[29]\n",
      "Train on 70 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 14.1940 - mse: 14.1940 - mae: 3.0346 - val_loss: 4.1499 - val_mse: 4.1499 - val_mae: 1.8614\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 356us/step - loss: 11.4495 - mse: 11.4495 - mae: 2.6297 - val_loss: 2.7911 - val_mse: 2.7911 - val_mae: 1.4549\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 428us/step - loss: 9.3884 - mse: 9.3884 - mae: 2.2947 - val_loss: 1.8024 - val_mse: 1.8024 - val_mae: 1.1003\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 7.8654 - mse: 7.8654 - mae: 2.0344 - val_loss: 1.1843 - val_mse: 1.1843 - val_mae: 0.8507\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 314us/step - loss: 6.8478 - mse: 6.8478 - mae: 1.8112 - val_loss: 0.8539 - val_mse: 0.8539 - val_mae: 0.7638\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 456us/step - loss: 6.1945 - mse: 6.1945 - mae: 1.6690 - val_loss: 0.7033 - val_mse: 0.7033 - val_mae: 0.7198\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 328us/step - loss: 5.7623 - mse: 5.7623 - mae: 1.5789 - val_loss: 0.6451 - val_mse: 0.6451 - val_mae: 0.6861\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 655us/step - loss: 5.4917 - mse: 5.4917 - mae: 1.5251 - val_loss: 0.6367 - val_mse: 0.6367 - val_mae: 0.6913\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 869us/step - loss: 5.3232 - mse: 5.3232 - mae: 1.4979 - val_loss: 0.6621 - val_mse: 0.6621 - val_mae: 0.7067\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 370us/step - loss: 5.2156 - mse: 5.2156 - mae: 1.4732 - val_loss: 0.6934 - val_mse: 0.6934 - val_mae: 0.7165\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 271us/step - loss: 5.1317 - mse: 5.1317 - mae: 1.4526 - val_loss: 0.7195 - val_mse: 0.7195 - val_mae: 0.7234\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 313us/step - loss: 5.0470 - mse: 5.0470 - mae: 1.4382 - val_loss: 0.7370 - val_mse: 0.7370 - val_mae: 0.7332\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 4.9568 - mse: 4.9568 - mae: 1.4207 - val_loss: 0.7439 - val_mse: 0.7439 - val_mae: 0.7402\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 4.8618 - mse: 4.8618 - mae: 1.3985 - val_loss: 0.7410 - val_mse: 0.7410 - val_mae: 0.7421\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 399us/step - loss: 4.7646 - mse: 4.7646 - mae: 1.3739 - val_loss: 0.7321 - val_mse: 0.7321 - val_mae: 0.7405\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 456us/step - loss: 4.6716 - mse: 4.6716 - mae: 1.3485 - val_loss: 0.7219 - val_mse: 0.7219 - val_mae: 0.7385\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 356us/step - loss: 4.5859 - mse: 4.5859 - mae: 1.3219 - val_loss: 0.7135 - val_mse: 0.7135 - val_mae: 0.7408\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 427us/step - loss: 4.5065 - mse: 4.5065 - mae: 1.2952 - val_loss: 0.7073 - val_mse: 0.7073 - val_mae: 0.7427\n",
      "30\n",
      "[30]\n",
      "Train on 75 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 3.2700 - mse: 3.2700 - mae: 1.4525 - val_loss: 4.6313 - val_mse: 4.6313 - val_mae: 1.6389\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 407us/step - loss: 2.6323 - mse: 2.6323 - mae: 1.2415 - val_loss: 3.9479 - val_mse: 3.9479 - val_mae: 1.4492\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 2.1384 - mse: 2.1384 - mae: 1.0719 - val_loss: 3.3770 - val_mse: 3.3770 - val_mae: 1.3240\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 1.7896 - mse: 1.7896 - mae: 0.9631 - val_loss: 2.9590 - val_mse: 2.9590 - val_mae: 1.2895\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 452us/step - loss: 1.5752 - mse: 1.5752 - mae: 0.9146 - val_loss: 2.6835 - val_mse: 2.6835 - val_mae: 1.3057\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 1.4670 - mse: 1.4670 - mae: 0.9206 - val_loss: 2.5184 - val_mse: 2.5184 - val_mae: 1.3141\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 691us/step - loss: 1.4276 - mse: 1.4276 - mae: 0.9360 - val_loss: 2.4204 - val_mse: 2.4204 - val_mae: 1.3139\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 388us/step - loss: 1.4186 - mse: 1.4186 - mae: 0.9541 - val_loss: 2.3523 - val_mse: 2.3523 - val_mae: 1.3053\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 1.4107 - mse: 1.4107 - mae: 0.9625 - val_loss: 2.3051 - val_mse: 2.3051 - val_mae: 1.2932\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 1.3891 - mse: 1.3891 - mae: 0.9580 - val_loss: 2.2733 - val_mse: 2.2733 - val_mae: 1.2780\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 1.3557 - mse: 1.3557 - mae: 0.9451 - val_loss: 2.2642 - val_mse: 2.2642 - val_mae: 1.2636\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 372us/step - loss: 1.3200 - mse: 1.3200 - mae: 0.9274 - val_loss: 2.2705 - val_mse: 2.2705 - val_mae: 1.2501\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 1.2905 - mse: 1.2905 - mae: 0.9088 - val_loss: 2.2859 - val_mse: 2.2859 - val_mae: 1.2372\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 399us/step - loss: 1.2680 - mse: 1.2680 - mae: 0.8925 - val_loss: 2.3045 - val_mse: 2.3045 - val_mae: 1.2256\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 1.2520 - mse: 1.2520 - mae: 0.8786 - val_loss: 2.3197 - val_mse: 2.3197 - val_mae: 1.2157\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 1.2396 - mse: 1.2396 - mae: 0.8675 - val_loss: 2.3256 - val_mse: 2.3256 - val_mae: 1.2069\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 1.2275 - mse: 1.2275 - mae: 0.8590 - val_loss: 2.3203 - val_mse: 2.3203 - val_mae: 1.1993\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 532us/step - loss: 1.2153 - mse: 1.2153 - mae: 0.8540 - val_loss: 2.3057 - val_mse: 2.3057 - val_mae: 1.1932\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 372us/step - loss: 1.2027 - mse: 1.2027 - mae: 0.8510 - val_loss: 2.2858 - val_mse: 2.2858 - val_mae: 1.1884\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 1.1902 - mse: 1.1902 - mae: 0.8494 - val_loss: 2.2638 - val_mse: 2.2638 - val_mae: 1.1845\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 372us/step - loss: 1.1781 - mse: 1.1781 - mae: 0.8485 - val_loss: 2.2417 - val_mse: 2.2417 - val_mae: 1.1807\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 1.1670 - mse: 1.1670 - mae: 0.8482 - val_loss: 2.2219 - val_mse: 2.2219 - val_mae: 1.1770\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 439us/step - loss: 1.1573 - mse: 1.1573 - mae: 0.8478 - val_loss: 2.2057 - val_mse: 2.2057 - val_mae: 1.1727\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 1.1483 - mse: 1.1483 - mae: 0.8464 - val_loss: 2.1937 - val_mse: 2.1937 - val_mae: 1.1678\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 465us/step - loss: 1.1396 - mse: 1.1396 - mae: 0.8442 - val_loss: 2.1854 - val_mse: 2.1854 - val_mae: 1.1619\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 1.1309 - mse: 1.1309 - mae: 0.8412 - val_loss: 2.1805 - val_mse: 2.1805 - val_mae: 1.1558\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 1.1224 - mse: 1.1224 - mae: 0.8372 - val_loss: 2.1773 - val_mse: 2.1773 - val_mae: 1.1500\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 1.1151 - mse: 1.1151 - mae: 0.8333 - val_loss: 2.1740 - val_mse: 2.1740 - val_mae: 1.1450\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 1.1079 - mse: 1.1079 - mae: 0.8297 - val_loss: 2.1698 - val_mse: 2.1698 - val_mae: 1.1408\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 1.1008 - mse: 1.1008 - mae: 0.8265 - val_loss: 2.1644 - val_mse: 2.1644 - val_mae: 1.1375\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 1.0937 - mse: 1.0937 - mae: 0.8237 - val_loss: 2.1585 - val_mse: 2.1585 - val_mae: 1.1347\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 226us/step - loss: 1.0870 - mse: 1.0870 - mae: 0.8213 - val_loss: 2.1525 - val_mse: 2.1525 - val_mae: 1.1321\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 1.0803 - mse: 1.0803 - mae: 0.8191 - val_loss: 2.1470 - val_mse: 2.1470 - val_mae: 1.1296\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 1.0737 - mse: 1.0737 - mae: 0.8168 - val_loss: 2.1421 - val_mse: 2.1421 - val_mae: 1.1271\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 1.0671 - mse: 1.0671 - mae: 0.8143 - val_loss: 2.1391 - val_mse: 2.1391 - val_mae: 1.1245\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 1.0607 - mse: 1.0607 - mae: 0.8117 - val_loss: 2.1365 - val_mse: 2.1365 - val_mae: 1.1219\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 1.0545 - mse: 1.0545 - mae: 0.8092 - val_loss: 2.1339 - val_mse: 2.1339 - val_mae: 1.1195\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 1.0486 - mse: 1.0486 - mae: 0.8069 - val_loss: 2.1310 - val_mse: 2.1310 - val_mae: 1.1172\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 399us/step - loss: 1.0429 - mse: 1.0429 - mae: 0.8046 - val_loss: 2.1277 - val_mse: 2.1277 - val_mae: 1.1150\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 1.0373 - mse: 1.0373 - mae: 0.8029 - val_loss: 2.1227 - val_mse: 2.1227 - val_mae: 1.1131\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 1.0318 - mse: 1.0318 - mae: 0.8012 - val_loss: 2.1180 - val_mse: 2.1180 - val_mae: 1.1110\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 292us/step - loss: 1.0264 - mse: 1.0264 - mae: 0.7995 - val_loss: 2.1134 - val_mse: 2.1134 - val_mae: 1.1089\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 328us/step - loss: 1.0210 - mse: 1.0210 - mae: 0.7977 - val_loss: 2.1090 - val_mse: 2.1090 - val_mae: 1.1069\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 1.0157 - mse: 1.0157 - mae: 0.7958 - val_loss: 2.1047 - val_mse: 2.1047 - val_mae: 1.1048\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 465us/step - loss: 1.0104 - mse: 1.0104 - mae: 0.7938 - val_loss: 2.1010 - val_mse: 2.1010 - val_mae: 1.1026\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 439us/step - loss: 1.0053 - mse: 1.0053 - mae: 0.7915 - val_loss: 2.0980 - val_mse: 2.0980 - val_mae: 1.1002\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 1.0002 - mse: 1.0002 - mae: 0.7893 - val_loss: 2.0951 - val_mse: 2.0951 - val_mae: 1.0978\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.9952 - mse: 0.9952 - mae: 0.7873 - val_loss: 2.0917 - val_mse: 2.0917 - val_mae: 1.0956\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.9905 - mse: 0.9905 - mae: 0.7856 - val_loss: 2.0868 - val_mse: 2.0868 - val_mae: 1.0935\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 479us/step - loss: 0.9856 - mse: 0.9856 - mae: 0.7840 - val_loss: 2.0807 - val_mse: 2.0807 - val_mae: 1.0914\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.9810 - mse: 0.9810 - mae: 0.7827 - val_loss: 2.0742 - val_mse: 2.0742 - val_mae: 1.0892\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.9764 - mse: 0.9764 - mae: 0.7814 - val_loss: 2.0697 - val_mse: 2.0697 - val_mae: 1.0863\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 258us/step - loss: 0.9716 - mse: 0.9716 - mae: 0.7795 - val_loss: 2.0675 - val_mse: 2.0675 - val_mae: 1.0831\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 0.9670 - mse: 0.9670 - mae: 0.7774 - val_loss: 2.0628 - val_mse: 2.0628 - val_mae: 1.0810\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.9624 - mse: 0.9624 - mae: 0.7761 - val_loss: 2.0556 - val_mse: 2.0556 - val_mae: 1.0794\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 0.9578 - mse: 0.9578 - mae: 0.7751 - val_loss: 2.0482 - val_mse: 2.0482 - val_mae: 1.0769\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.9532 - mse: 0.9532 - mae: 0.7734 - val_loss: 2.0407 - val_mse: 2.0407 - val_mae: 1.0733\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 399us/step - loss: 0.9487 - mse: 0.9487 - mae: 0.7712 - val_loss: 2.0340 - val_mse: 2.0340 - val_mae: 1.0697\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 307us/step - loss: 0.9443 - mse: 0.9443 - mae: 0.7693 - val_loss: 2.0227 - val_mse: 2.0227 - val_mae: 1.0673\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.9398 - mse: 0.9398 - mae: 0.7681 - val_loss: 2.0145 - val_mse: 2.0145 - val_mae: 1.0651\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 452us/step - loss: 0.9354 - mse: 0.9354 - mae: 0.7667 - val_loss: 2.0112 - val_mse: 2.0112 - val_mae: 1.0627\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.9312 - mse: 0.9312 - mae: 0.7651 - val_loss: 2.0082 - val_mse: 2.0082 - val_mae: 1.0604\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 519us/step - loss: 0.9273 - mse: 0.9273 - mae: 0.7633 - val_loss: 2.0112 - val_mse: 2.0112 - val_mae: 1.0574\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 252us/step - loss: 0.9237 - mse: 0.9237 - mae: 0.7610 - val_loss: 2.0106 - val_mse: 2.0106 - val_mae: 1.0554\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 0.9198 - mse: 0.9198 - mae: 0.7595 - val_loss: 2.0058 - val_mse: 2.0058 - val_mae: 1.0545\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 399us/step - loss: 0.9160 - mse: 0.9160 - mae: 0.7585 - val_loss: 2.0012 - val_mse: 2.0012 - val_mae: 1.0524\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.9123 - mse: 0.9123 - mae: 0.7566 - val_loss: 2.0025 - val_mse: 2.0025 - val_mae: 1.0487\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.9085 - mse: 0.9085 - mae: 0.7540 - val_loss: 1.9990 - val_mse: 1.9990 - val_mae: 1.0463\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 439us/step - loss: 0.9051 - mse: 0.9051 - mae: 0.7525 - val_loss: 1.9939 - val_mse: 1.9939 - val_mae: 1.0446\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 479us/step - loss: 0.9014 - mse: 0.9014 - mae: 0.7508 - val_loss: 1.9932 - val_mse: 1.9932 - val_mae: 1.0421\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 479us/step - loss: 0.8981 - mse: 0.8981 - mae: 0.7492 - val_loss: 1.9866 - val_mse: 1.9866 - val_mae: 1.0407\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.8944 - mse: 0.8944 - mae: 0.7481 - val_loss: 1.9824 - val_mse: 1.9824 - val_mae: 1.0388\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.8912 - mse: 0.8912 - mae: 0.7467 - val_loss: 1.9802 - val_mse: 1.9802 - val_mae: 1.0357\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.8880 - mse: 0.8880 - mae: 0.7449 - val_loss: 1.9781 - val_mse: 1.9781 - val_mae: 1.0327\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.8846 - mse: 0.8846 - mae: 0.7437 - val_loss: 1.9728 - val_mse: 1.9728 - val_mae: 1.0313\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 492us/step - loss: 0.8812 - mse: 0.8812 - mae: 0.7422 - val_loss: 1.9751 - val_mse: 1.9751 - val_mae: 1.0284\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 598us/step - loss: 0.8783 - mse: 0.8783 - mae: 0.7405 - val_loss: 1.9682 - val_mse: 1.9682 - val_mae: 1.0272\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.8748 - mse: 0.8748 - mae: 0.7398 - val_loss: 1.9593 - val_mse: 1.9593 - val_mae: 1.0259\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.8719 - mse: 0.8719 - mae: 0.7387 - val_loss: 1.9593 - val_mse: 1.9593 - val_mae: 1.0253\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.8684 - mse: 0.8684 - mae: 0.7361 - val_loss: 1.9641 - val_mse: 1.9641 - val_mae: 1.0255\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.8658 - mse: 0.8658 - mae: 0.7340 - val_loss: 1.9563 - val_mse: 1.9563 - val_mae: 1.0245\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.8621 - mse: 0.8621 - mae: 0.7332 - val_loss: 1.9497 - val_mse: 1.9497 - val_mae: 1.0239\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.8588 - mse: 0.8588 - mae: 0.7321 - val_loss: 1.9505 - val_mse: 1.9505 - val_mae: 1.0239\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 333us/step - loss: 0.8556 - mse: 0.8556 - mae: 0.7302 - val_loss: 1.9510 - val_mse: 1.9510 - val_mae: 1.0236\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.8524 - mse: 0.8524 - mae: 0.7290 - val_loss: 1.9453 - val_mse: 1.9453 - val_mae: 1.0228\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 545us/step - loss: 0.8493 - mse: 0.8493 - mae: 0.7282 - val_loss: 1.9459 - val_mse: 1.9459 - val_mae: 1.0227\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.8457 - mse: 0.8457 - mae: 0.7260 - val_loss: 1.9555 - val_mse: 1.9555 - val_mae: 1.0242\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.8428 - mse: 0.8428 - mae: 0.7240 - val_loss: 1.9515 - val_mse: 1.9515 - val_mae: 1.0239\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.8388 - mse: 0.8388 - mae: 0.7232 - val_loss: 1.9396 - val_mse: 1.9396 - val_mae: 1.0219\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.8356 - mse: 0.8356 - mae: 0.7225 - val_loss: 1.9378 - val_mse: 1.9378 - val_mae: 1.0211\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.8319 - mse: 0.8319 - mae: 0.7201 - val_loss: 1.9430 - val_mse: 1.9430 - val_mae: 1.0216\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 426us/step - loss: 0.8280 - mse: 0.8280 - mae: 0.7175 - val_loss: 1.9422 - val_mse: 1.9422 - val_mae: 1.0215\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.8240 - mse: 0.8240 - mae: 0.7162 - val_loss: 1.9395 - val_mse: 1.9395 - val_mae: 1.0223\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.8205 - mse: 0.8205 - mae: 0.7154 - val_loss: 1.9369 - val_mse: 1.9369 - val_mae: 1.0217\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.8174 - mse: 0.8174 - mae: 0.7138 - val_loss: 1.9364 - val_mse: 1.9364 - val_mae: 1.0201\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 492us/step - loss: 0.8148 - mse: 0.8148 - mae: 0.7115 - val_loss: 1.9339 - val_mse: 1.9339 - val_mae: 1.0187\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 465us/step - loss: 0.8117 - mse: 0.8117 - mae: 0.7102 - val_loss: 1.9234 - val_mse: 1.9234 - val_mae: 1.0175\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.8092 - mse: 0.8092 - mae: 0.7099 - val_loss: 1.9168 - val_mse: 1.9168 - val_mae: 1.0157\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.8065 - mse: 0.8065 - mae: 0.7082 - val_loss: 1.9219 - val_mse: 1.9219 - val_mae: 1.0154\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 279us/step - loss: 0.8035 - mse: 0.8035 - mae: 0.7052 - val_loss: 1.9271 - val_mse: 1.9271 - val_mae: 1.0146\n",
      "31\n",
      "[31]\n",
      "Train on 91 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 22.0388 - mse: 22.0388 - mae: 3.8903 - val_loss: 7.4285 - val_mse: 7.4285 - val_mae: 2.4277\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 317us/step - loss: 17.1837 - mse: 17.1837 - mae: 3.2901 - val_loss: 5.3589 - val_mse: 5.3589 - val_mae: 2.0015\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 13.5406 - mse: 13.5406 - mae: 2.8281 - val_loss: 3.9260 - val_mse: 3.9260 - val_mae: 1.6627\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 274us/step - loss: 10.9621 - mse: 10.9621 - mae: 2.5560 - val_loss: 2.9985 - val_mse: 2.9985 - val_mae: 1.4262\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 9.2051 - mse: 9.2051 - mae: 2.3497 - val_loss: 2.4756 - val_mse: 2.4756 - val_mae: 1.2596\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 312us/step - loss: 8.1633 - mse: 8.1633 - mae: 2.2129 - val_loss: 2.2118 - val_mse: 2.2118 - val_mae: 1.1840\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 7.5893 - mse: 7.5893 - mae: 2.1319 - val_loss: 2.0762 - val_mse: 2.0762 - val_mae: 1.1437\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 274us/step - loss: 7.2102 - mse: 7.2102 - mae: 2.0887 - val_loss: 1.9845 - val_mse: 1.9845 - val_mae: 1.1117\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 384us/step - loss: 6.9344 - mse: 6.9344 - mae: 2.0518 - val_loss: 1.9137 - val_mse: 1.9137 - val_mae: 1.0853\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 241us/step - loss: 6.7241 - mse: 6.7241 - mae: 2.0154 - val_loss: 1.8576 - val_mse: 1.8576 - val_mae: 1.0642\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 318us/step - loss: 6.5582 - mse: 6.5582 - mae: 1.9798 - val_loss: 1.8141 - val_mse: 1.8141 - val_mae: 1.0467\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 351us/step - loss: 6.4147 - mse: 6.4147 - mae: 1.9454 - val_loss: 1.7797 - val_mse: 1.7797 - val_mae: 1.0336\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 6.2788 - mse: 6.2788 - mae: 1.9187 - val_loss: 1.7520 - val_mse: 1.7520 - val_mae: 1.0220\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 471us/step - loss: 6.1424 - mse: 6.1424 - mae: 1.8949 - val_loss: 1.7286 - val_mse: 1.7286 - val_mae: 1.0132\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 241us/step - loss: 6.0071 - mse: 6.0071 - mae: 1.8726 - val_loss: 1.7041 - val_mse: 1.7041 - val_mae: 1.0053\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 373us/step - loss: 5.8681 - mse: 5.8681 - mae: 1.8509 - val_loss: 1.6712 - val_mse: 1.6712 - val_mae: 0.9964\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 406us/step - loss: 5.7363 - mse: 5.7363 - mae: 1.8320 - val_loss: 1.6353 - val_mse: 1.6353 - val_mae: 0.9869\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 285us/step - loss: 5.6149 - mse: 5.6149 - mae: 1.8160 - val_loss: 1.6005 - val_mse: 1.6005 - val_mae: 0.9785\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 274us/step - loss: 5.4968 - mse: 5.4968 - mae: 1.8031 - val_loss: 1.5647 - val_mse: 1.5647 - val_mae: 0.9673\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 5.3853 - mse: 5.3853 - mae: 1.7902 - val_loss: 1.5235 - val_mse: 1.5235 - val_mae: 0.9536\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 373us/step - loss: 5.2738 - mse: 5.2738 - mae: 1.7762 - val_loss: 1.4788 - val_mse: 1.4788 - val_mae: 0.9389\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 307us/step - loss: 5.1611 - mse: 5.1611 - mae: 1.7613 - val_loss: 1.4481 - val_mse: 1.4481 - val_mae: 0.9328\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 318us/step - loss: 5.0500 - mse: 5.0500 - mae: 1.7463 - val_loss: 1.4270 - val_mse: 1.4270 - val_mae: 0.9283\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 287us/step - loss: 4.9451 - mse: 4.9451 - mae: 1.7300 - val_loss: 1.4097 - val_mse: 1.4097 - val_mae: 0.9240\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 274us/step - loss: 4.8456 - mse: 4.8456 - mae: 1.7123 - val_loss: 1.3932 - val_mse: 1.3932 - val_mae: 0.9195\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 329us/step - loss: 4.7526 - mse: 4.7526 - mae: 1.6935 - val_loss: 1.3795 - val_mse: 1.3795 - val_mae: 0.9194\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 362us/step - loss: 4.6711 - mse: 4.6711 - mae: 1.6765 - val_loss: 1.3694 - val_mse: 1.3694 - val_mae: 0.9196\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 263us/step - loss: 4.5936 - mse: 4.5936 - mae: 1.6614 - val_loss: 1.3603 - val_mse: 1.3603 - val_mae: 0.9181\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 307us/step - loss: 4.5127 - mse: 4.5127 - mae: 1.6441 - val_loss: 1.3493 - val_mse: 1.3493 - val_mae: 0.9165\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 373us/step - loss: 4.4378 - mse: 4.4378 - mae: 1.6284 - val_loss: 1.3254 - val_mse: 1.3254 - val_mae: 0.9129\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 318us/step - loss: 4.3674 - mse: 4.3674 - mae: 1.6142 - val_loss: 1.3043 - val_mse: 1.3043 - val_mae: 0.9107\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 4.3020 - mse: 4.3020 - mae: 1.6024 - val_loss: 1.2869 - val_mse: 1.2869 - val_mae: 0.9095\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - ETA: 0s - loss: 4.6450 - mse: 4.6450 - mae: 1.684 - 0s 581us/step - loss: 4.2412 - mse: 4.2412 - mae: 1.5932 - val_loss: 1.2718 - val_mse: 1.2718 - val_mae: 0.9087\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 275us/step - loss: 4.1861 - mse: 4.1861 - mae: 1.5838 - val_loss: 1.2599 - val_mse: 1.2599 - val_mae: 0.9086\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 373us/step - loss: 4.1375 - mse: 4.1375 - mae: 1.5746 - val_loss: 1.2510 - val_mse: 1.2510 - val_mae: 0.9090\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 449us/step - loss: 4.0919 - mse: 4.0919 - mae: 1.5653 - val_loss: 1.2449 - val_mse: 1.2449 - val_mae: 0.9098\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 331us/step - loss: 4.0481 - mse: 4.0481 - mae: 1.5564 - val_loss: 1.2411 - val_mse: 1.2411 - val_mae: 0.9108\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 384us/step - loss: 4.0053 - mse: 4.0053 - mae: 1.5470 - val_loss: 1.2345 - val_mse: 1.2345 - val_mae: 0.9097\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 438us/step - loss: 3.9614 - mse: 3.9614 - mae: 1.5366 - val_loss: 1.2272 - val_mse: 1.2272 - val_mae: 0.9091\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 3.9195 - mse: 3.9195 - mae: 1.5272 - val_loss: 1.2224 - val_mse: 1.2224 - val_mae: 0.9085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 318us/step - loss: 3.8758 - mse: 3.8758 - mae: 1.5179 - val_loss: 1.2187 - val_mse: 1.2187 - val_mae: 0.9083\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 3.8320 - mse: 3.8320 - mae: 1.5082 - val_loss: 1.2142 - val_mse: 1.2142 - val_mae: 0.9089\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 263us/step - loss: 3.7888 - mse: 3.7888 - mae: 1.4987 - val_loss: 1.2094 - val_mse: 1.2094 - val_mae: 0.9101\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 362us/step - loss: 3.7492 - mse: 3.7492 - mae: 1.4902 - val_loss: 1.2054 - val_mse: 1.2054 - val_mae: 0.9110\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 362us/step - loss: 3.7112 - mse: 3.7112 - mae: 1.4824 - val_loss: 1.2037 - val_mse: 1.2037 - val_mae: 0.9122\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 362us/step - loss: 3.6712 - mse: 3.6712 - mae: 1.4739 - val_loss: 1.2034 - val_mse: 1.2034 - val_mae: 0.9142\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 384us/step - loss: 3.6310 - mse: 3.6310 - mae: 1.4645 - val_loss: 1.2062 - val_mse: 1.2062 - val_mae: 0.9166\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 384us/step - loss: 3.5924 - mse: 3.5924 - mae: 1.4549 - val_loss: 1.2150 - val_mse: 1.2150 - val_mae: 0.9215\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 383us/step - loss: 3.5573 - mse: 3.5573 - mae: 1.4469 - val_loss: 1.2285 - val_mse: 1.2285 - val_mae: 0.9270\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 406us/step - loss: 3.5204 - mse: 3.5204 - mae: 1.4397 - val_loss: 1.2396 - val_mse: 1.2396 - val_mae: 0.9345\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 285us/step - loss: 3.4894 - mse: 3.4894 - mae: 1.4328 - val_loss: 1.2483 - val_mse: 1.2483 - val_mae: 0.9412\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 329us/step - loss: 3.4609 - mse: 3.4609 - mae: 1.4255 - val_loss: 1.2540 - val_mse: 1.2540 - val_mae: 0.9468\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 351us/step - loss: 3.4353 - mse: 3.4353 - mae: 1.4192 - val_loss: 1.2583 - val_mse: 1.2583 - val_mae: 0.9517\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 3.4117 - mse: 3.4117 - mae: 1.4142 - val_loss: 1.2629 - val_mse: 1.2629 - val_mae: 0.9568\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 416us/step - loss: 3.3874 - mse: 3.3874 - mae: 1.4101 - val_loss: 1.2696 - val_mse: 1.2696 - val_mae: 0.9626\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 379us/step - loss: 3.3666 - mse: 3.3666 - mae: 1.4058 - val_loss: 1.2731 - val_mse: 1.2731 - val_mae: 0.9659\n",
      "32\n",
      "[32]\n",
      "Train on 93 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 2.2799 - mse: 2.2799 - mae: 1.0871 - val_loss: 2.7059 - val_mse: 2.7059 - val_mae: 1.3513\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 1.9250 - mse: 1.9250 - mae: 1.0270 - val_loss: 2.2084 - val_mse: 2.2084 - val_mae: 1.2458\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 268us/step - loss: 1.7758 - mse: 1.7758 - mae: 1.0182 - val_loss: 2.0065 - val_mse: 2.0065 - val_mae: 1.1845\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 461us/step - loss: 1.7443 - mse: 1.7443 - mae: 1.0407 - val_loss: 1.9133 - val_mse: 1.9133 - val_mae: 1.1464\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 440us/step - loss: 1.7236 - mse: 1.7236 - mae: 1.0512 - val_loss: 1.8586 - val_mse: 1.8586 - val_mae: 1.1314\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 1.6881 - mse: 1.6881 - mae: 1.0412 - val_loss: 1.8373 - val_mse: 1.8373 - val_mae: 1.1292\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 1.6608 - mse: 1.6608 - mae: 1.0256 - val_loss: 1.8646 - val_mse: 1.8646 - val_mae: 1.1413\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.6483 - mse: 1.6483 - mae: 1.0151 - val_loss: 1.8811 - val_mse: 1.8811 - val_mae: 1.1453\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 268us/step - loss: 1.6426 - mse: 1.6426 - mae: 1.0089 - val_loss: 1.8756 - val_mse: 1.8756 - val_mae: 1.1429\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 1.6340 - mse: 1.6340 - mae: 1.0060 - val_loss: 1.8523 - val_mse: 1.8523 - val_mae: 1.1343\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.6214 - mse: 1.6214 - mae: 1.0076 - val_loss: 1.8176 - val_mse: 1.8176 - val_mae: 1.1249\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 1.6055 - mse: 1.6055 - mae: 1.0113 - val_loss: 1.7810 - val_mse: 1.7810 - val_mae: 1.1145\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 268us/step - loss: 1.5940 - mse: 1.5940 - mae: 1.0148 - val_loss: 1.7587 - val_mse: 1.7587 - val_mae: 1.1084\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 236us/step - loss: 1.5851 - mse: 1.5851 - mae: 1.0150 - val_loss: 1.7506 - val_mse: 1.7506 - val_mae: 1.1061\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 1.5773 - mse: 1.5773 - mae: 1.0119 - val_loss: 1.7497 - val_mse: 1.7497 - val_mae: 1.1056\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 407us/step - loss: 1.5694 - mse: 1.5694 - mae: 1.0068 - val_loss: 1.7501 - val_mse: 1.7501 - val_mae: 1.1058\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.5612 - mse: 1.5612 - mae: 1.0019 - val_loss: 1.7476 - val_mse: 1.7476 - val_mae: 1.1060\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 1.5528 - mse: 1.5528 - mae: 0.9984 - val_loss: 1.7429 - val_mse: 1.7429 - val_mae: 1.1058\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.5447 - mse: 1.5447 - mae: 0.9957 - val_loss: 1.7370 - val_mse: 1.7370 - val_mae: 1.1046\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 429us/step - loss: 1.5359 - mse: 1.5359 - mae: 0.9934 - val_loss: 1.7310 - val_mse: 1.7310 - val_mae: 1.1031\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.5276 - mse: 1.5276 - mae: 0.9913 - val_loss: 1.7276 - val_mse: 1.7276 - val_mae: 1.1033\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.5196 - mse: 1.5196 - mae: 0.9889 - val_loss: 1.7233 - val_mse: 1.7233 - val_mae: 1.1025\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 515us/step - loss: 1.5113 - mse: 1.5113 - mae: 0.9861 - val_loss: 1.7196 - val_mse: 1.7196 - val_mae: 1.1019\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 429us/step - loss: 1.5037 - mse: 1.5037 - mae: 0.9834 - val_loss: 1.7184 - val_mse: 1.7184 - val_mae: 1.1020\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 247us/step - loss: 1.4961 - mse: 1.4961 - mae: 0.9804 - val_loss: 1.7144 - val_mse: 1.7144 - val_mae: 1.1001\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.4884 - mse: 1.4884 - mae: 0.9778 - val_loss: 1.7112 - val_mse: 1.7112 - val_mae: 1.0987\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.4817 - mse: 1.4817 - mae: 0.9752 - val_loss: 1.7073 - val_mse: 1.7073 - val_mae: 1.0974\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.4740 - mse: 1.4740 - mae: 0.9725 - val_loss: 1.7028 - val_mse: 1.7028 - val_mae: 1.0951\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 1.4672 - mse: 1.4672 - mae: 0.9701 - val_loss: 1.6958 - val_mse: 1.6958 - val_mae: 1.0919\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 386us/step - loss: 1.4602 - mse: 1.4602 - mae: 0.9682 - val_loss: 1.6905 - val_mse: 1.6905 - val_mae: 1.0889\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 1.4534 - mse: 1.4534 - mae: 0.9656 - val_loss: 1.6921 - val_mse: 1.6921 - val_mae: 1.0901\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.4475 - mse: 1.4475 - mae: 0.9624 - val_loss: 1.6917 - val_mse: 1.6917 - val_mae: 1.0909\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.3705 - mse: 1.3705 - mae: 0.919 - 0s 268us/step - loss: 1.4400 - mse: 1.4400 - mae: 0.9596 - val_loss: 1.6844 - val_mse: 1.6844 - val_mae: 1.0860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 1.4329 - mse: 1.4329 - mae: 0.9575 - val_loss: 1.6811 - val_mse: 1.6811 - val_mae: 1.0850\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 1.4266 - mse: 1.4266 - mae: 0.9554 - val_loss: 1.6790 - val_mse: 1.6790 - val_mae: 1.0845\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 386us/step - loss: 1.4198 - mse: 1.4198 - mae: 0.9529 - val_loss: 1.6784 - val_mse: 1.6784 - val_mae: 1.0833\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 1.4142 - mse: 1.4142 - mae: 0.9505 - val_loss: 1.6720 - val_mse: 1.6720 - val_mae: 1.0796\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 1.4072 - mse: 1.4072 - mae: 0.9489 - val_loss: 1.6647 - val_mse: 1.6647 - val_mae: 1.0773\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.4027 - mse: 1.4027 - mae: 0.9482 - val_loss: 1.6678 - val_mse: 1.6678 - val_mae: 1.0792\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 1.3965 - mse: 1.3965 - mae: 0.9452 - val_loss: 1.6659 - val_mse: 1.6659 - val_mae: 1.0767\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.3904 - mse: 1.3904 - mae: 0.9432 - val_loss: 1.6618 - val_mse: 1.6618 - val_mae: 1.0744\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 333us/step - loss: 1.3846 - mse: 1.3846 - mae: 0.9416 - val_loss: 1.6662 - val_mse: 1.6662 - val_mae: 1.0770\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 386us/step - loss: 1.3803 - mse: 1.3803 - mae: 0.9392 - val_loss: 1.6654 - val_mse: 1.6654 - val_mae: 1.0772\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.3740 - mse: 1.3740 - mae: 0.9372 - val_loss: 1.6612 - val_mse: 1.6612 - val_mae: 1.0744\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 1.3690 - mse: 1.3690 - mae: 0.9360 - val_loss: 1.6561 - val_mse: 1.6561 - val_mae: 1.0716\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.3633 - mse: 1.3633 - mae: 0.9347 - val_loss: 1.6605 - val_mse: 1.6605 - val_mae: 1.0743\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 329us/step - loss: 1.3588 - mse: 1.3588 - mae: 0.9326 - val_loss: 1.6615 - val_mse: 1.6615 - val_mae: 1.0743\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 1.3529 - mse: 1.3529 - mae: 0.9310 - val_loss: 1.6537 - val_mse: 1.6537 - val_mae: 1.0700\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 1.3464 - mse: 1.3464 - mae: 0.9300 - val_loss: 1.6527 - val_mse: 1.6527 - val_mae: 1.0689\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 397us/step - loss: 1.3425 - mse: 1.3425 - mae: 0.9282 - val_loss: 1.6598 - val_mse: 1.6598 - val_mae: 1.0724\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.3362 - mse: 1.3362 - mae: 0.9253 - val_loss: 1.6490 - val_mse: 1.6490 - val_mae: 1.0658\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 397us/step - loss: 1.3290 - mse: 1.3290 - mae: 0.9242 - val_loss: 1.6504 - val_mse: 1.6504 - val_mae: 1.0660\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 386us/step - loss: 1.3253 - mse: 1.3253 - mae: 0.9224 - val_loss: 1.6593 - val_mse: 1.6593 - val_mae: 1.0713\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 1.3195 - mse: 1.3195 - mae: 0.9193 - val_loss: 1.6518 - val_mse: 1.6518 - val_mae: 1.0677\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 1.3119 - mse: 1.3119 - mae: 0.9175 - val_loss: 1.6473 - val_mse: 1.6473 - val_mae: 1.0641\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 1.3066 - mse: 1.3066 - mae: 0.9160 - val_loss: 1.6546 - val_mse: 1.6546 - val_mae: 1.0672\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 1.3009 - mse: 1.3009 - mae: 0.9128 - val_loss: 1.6527 - val_mse: 1.6527 - val_mae: 1.0652\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 1.2950 - mse: 1.2950 - mae: 0.9103 - val_loss: 1.6558 - val_mse: 1.6558 - val_mae: 1.0660\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 386us/step - loss: 1.2907 - mse: 1.2907 - mae: 0.9081 - val_loss: 1.6571 - val_mse: 1.6571 - val_mae: 1.0669\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.2846 - mse: 1.2846 - mae: 0.9056 - val_loss: 1.6504 - val_mse: 1.6504 - val_mae: 1.0630\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.2789 - mse: 1.2789 - mae: 0.9043 - val_loss: 1.6525 - val_mse: 1.6525 - val_mae: 1.0641\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.2754 - mse: 1.2754 - mae: 0.9032 - val_loss: 1.6576 - val_mse: 1.6576 - val_mae: 1.0673\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.2693 - mse: 1.2693 - mae: 0.9007 - val_loss: 1.6513 - val_mse: 1.6513 - val_mae: 1.0635\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.2638 - mse: 1.2638 - mae: 0.8990 - val_loss: 1.6543 - val_mse: 1.6543 - val_mae: 1.0642\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.2595 - mse: 1.2595 - mae: 0.8969 - val_loss: 1.6581 - val_mse: 1.6581 - val_mae: 1.0661\n",
      "33\n",
      "[33]\n",
      "Train on 99 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 8.9623 - mse: 8.9623 - mae: 2.7404 - val_loss: 4.6888 - val_mse: 4.6888 - val_mae: 2.0326\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 302us/step - loss: 7.4067 - mse: 7.4067 - mae: 2.4737 - val_loss: 4.1302 - val_mse: 4.1302 - val_mae: 1.8928\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 262us/step - loss: 6.3542 - mse: 6.3542 - mae: 2.2786 - val_loss: 3.7542 - val_mse: 3.7542 - val_mae: 1.7918\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 252us/step - loss: 5.6798 - mse: 5.6798 - mae: 2.1547 - val_loss: 3.5051 - val_mse: 3.5051 - val_mae: 1.7275\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 328us/step - loss: 5.2533 - mse: 5.2533 - mae: 2.0716 - val_loss: 3.3066 - val_mse: 3.3066 - val_mae: 1.6776\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 292us/step - loss: 4.9871 - mse: 4.9871 - mae: 2.0145 - val_loss: 3.1361 - val_mse: 3.1361 - val_mae: 1.6319\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 262us/step - loss: 4.7673 - mse: 4.7673 - mae: 1.9627 - val_loss: 2.9899 - val_mse: 2.9899 - val_mae: 1.5876\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 282us/step - loss: 4.5463 - mse: 4.5463 - mae: 1.9045 - val_loss: 2.8186 - val_mse: 2.8186 - val_mae: 1.5348\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 353us/step - loss: 4.2831 - mse: 4.2831 - mae: 1.8288 - val_loss: 2.5875 - val_mse: 2.5875 - val_mae: 1.4564\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 343us/step - loss: 3.9532 - mse: 3.9532 - mae: 1.7293 - val_loss: 2.3088 - val_mse: 2.3088 - val_mae: 1.3514\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 272us/step - loss: 3.5473 - mse: 3.5473 - mae: 1.5978 - val_loss: 2.0049 - val_mse: 2.0049 - val_mae: 1.2257\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 282us/step - loss: 3.0392 - mse: 3.0392 - mae: 1.4274 - val_loss: 1.6554 - val_mse: 1.6554 - val_mae: 1.0641\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 352us/step - loss: 2.4795 - mse: 2.4795 - mae: 1.2263 - val_loss: 1.3100 - val_mse: 1.3100 - val_mae: 0.8710\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 353us/step - loss: 1.9692 - mse: 1.9692 - mae: 1.0616 - val_loss: 1.0167 - val_mse: 1.0167 - val_mae: 0.7333\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 383us/step - loss: 1.5938 - mse: 1.5938 - mae: 0.9505 - val_loss: 0.8009 - val_mse: 0.8009 - val_mae: 0.6936\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 282us/step - loss: 1.3781 - mse: 1.3781 - mae: 0.9062 - val_loss: 0.6795 - val_mse: 0.6795 - val_mae: 0.6901\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 282us/step - loss: 1.2885 - mse: 1.2885 - mae: 0.8818 - val_loss: 0.6232 - val_mse: 0.6232 - val_mae: 0.6907\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 242us/step - loss: 1.2696 - mse: 1.2696 - mae: 0.8776 - val_loss: 0.6029 - val_mse: 0.6029 - val_mae: 0.6902\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 433us/step - loss: 1.2687 - mse: 1.2687 - mae: 0.8768 - val_loss: 0.5957 - val_mse: 0.5957 - val_mae: 0.6886\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 343us/step - loss: 1.2577 - mse: 1.2577 - mae: 0.8761 - val_loss: 0.5922 - val_mse: 0.5922 - val_mae: 0.6865\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 353us/step - loss: 1.2329 - mse: 1.2329 - mae: 0.8694 - val_loss: 0.5906 - val_mse: 0.5906 - val_mae: 0.6841\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 1.2021 - mse: 1.2021 - mae: 0.8596 - val_loss: 0.5915 - val_mse: 0.5915 - val_mae: 0.6817\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 302us/step - loss: 1.1735 - mse: 1.1735 - mae: 0.8492 - val_loss: 0.5945 - val_mse: 0.5945 - val_mae: 0.6793\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 403us/step - loss: 1.1507 - mse: 1.1507 - mae: 0.8408 - val_loss: 0.5978 - val_mse: 0.5978 - val_mae: 0.6770\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 564us/step - loss: 1.1337 - mse: 1.1337 - mae: 0.8333 - val_loss: 0.6001 - val_mse: 0.6001 - val_mae: 0.6747\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 93us/step - loss: 1.1200 - mse: 1.1200 - mae: 0.8268 - val_loss: 0.6005 - val_mse: 0.6005 - val_mae: 0.6728\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 484us/step - loss: 1.1079 - mse: 1.1079 - mae: 0.8217 - val_loss: 0.5992 - val_mse: 0.5992 - val_mae: 0.6714\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 363us/step - loss: 1.0962 - mse: 1.0962 - mae: 0.8177 - val_loss: 0.5963 - val_mse: 0.5963 - val_mae: 0.6704\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 1.0842 - mse: 1.0842 - mae: 0.8142 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.6694\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 292us/step - loss: 1.0726 - mse: 1.0726 - mae: 0.8112 - val_loss: 0.5867 - val_mse: 0.5867 - val_mae: 0.6680\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 352us/step - loss: 1.0620 - mse: 1.0620 - mae: 0.8090 - val_loss: 0.5814 - val_mse: 0.5814 - val_mae: 0.6664\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 433us/step - loss: 1.0522 - mse: 1.0522 - mae: 0.8069 - val_loss: 0.5768 - val_mse: 0.5768 - val_mae: 0.6648\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 488us/step - loss: 1.0434 - mse: 1.0434 - mae: 0.8049 - val_loss: 0.5727 - val_mse: 0.5727 - val_mae: 0.6629\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 320us/step - loss: 1.0353 - mse: 1.0353 - mae: 0.8029 - val_loss: 0.5695 - val_mse: 0.5695 - val_mae: 0.6611\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 292us/step - loss: 1.0280 - mse: 1.0280 - mae: 0.8006 - val_loss: 0.5670 - val_mse: 0.5670 - val_mae: 0.6594\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 373us/step - loss: 1.0211 - mse: 1.0211 - mae: 0.7981 - val_loss: 0.5652 - val_mse: 0.5652 - val_mae: 0.6580\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 383us/step - loss: 1.0147 - mse: 1.0147 - mae: 0.7956 - val_loss: 0.5639 - val_mse: 0.5639 - val_mae: 0.6567\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 1.0085 - mse: 1.0085 - mae: 0.7929 - val_loss: 0.5629 - val_mse: 0.5629 - val_mae: 0.6556\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 1.0027 - mse: 1.0027 - mae: 0.7903 - val_loss: 0.5620 - val_mse: 0.5620 - val_mae: 0.6546\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 413us/step - loss: 0.9974 - mse: 0.9974 - mae: 0.7878 - val_loss: 0.5613 - val_mse: 0.5613 - val_mae: 0.6537\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 232us/step - loss: 0.9926 - mse: 0.9926 - mae: 0.7855 - val_loss: 0.5605 - val_mse: 0.5605 - val_mae: 0.6529\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 292us/step - loss: 0.9881 - mse: 0.9881 - mae: 0.7836 - val_loss: 0.5597 - val_mse: 0.5597 - val_mae: 0.6522\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 343us/step - loss: 0.9839 - mse: 0.9839 - mae: 0.7821 - val_loss: 0.5588 - val_mse: 0.5588 - val_mae: 0.6515\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 0.9799 - mse: 0.9799 - mae: 0.7808 - val_loss: 0.5581 - val_mse: 0.5581 - val_mae: 0.6510\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 260us/step - loss: 0.9760 - mse: 0.9760 - mae: 0.7795 - val_loss: 0.5573 - val_mse: 0.5573 - val_mae: 0.6505\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 343us/step - loss: 0.9721 - mse: 0.9721 - mae: 0.7781 - val_loss: 0.5564 - val_mse: 0.5564 - val_mae: 0.6500\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 272us/step - loss: 0.9684 - mse: 0.9684 - mae: 0.7768 - val_loss: 0.5558 - val_mse: 0.5558 - val_mae: 0.6496\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 312us/step - loss: 0.9649 - mse: 0.9649 - mae: 0.7755 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.6494\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 272us/step - loss: 0.9616 - mse: 0.9616 - mae: 0.7743 - val_loss: 0.5553 - val_mse: 0.5553 - val_mae: 0.6492\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 343us/step - loss: 0.9584 - mse: 0.9584 - mae: 0.7732 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.6491\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 312us/step - loss: 0.9554 - mse: 0.9554 - mae: 0.7721 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.6491\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 262us/step - loss: 0.9527 - mse: 0.9527 - mae: 0.7710 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.6491\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 272us/step - loss: 0.9501 - mse: 0.9501 - mae: 0.7700 - val_loss: 0.5556 - val_mse: 0.5556 - val_mae: 0.6491\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 272us/step - loss: 0.9476 - mse: 0.9476 - mae: 0.7689 - val_loss: 0.5557 - val_mse: 0.5557 - val_mae: 0.6493\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 292us/step - loss: 0.9453 - mse: 0.9453 - mae: 0.7679 - val_loss: 0.5559 - val_mse: 0.5559 - val_mae: 0.6495\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 272us/step - loss: 0.9431 - mse: 0.9431 - mae: 0.7669 - val_loss: 0.5560 - val_mse: 0.5560 - val_mae: 0.6496\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 312us/step - loss: 0.9409 - mse: 0.9409 - mae: 0.7659 - val_loss: 0.5561 - val_mse: 0.5561 - val_mae: 0.6496\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 312us/step - loss: 0.9388 - mse: 0.9388 - mae: 0.7650 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.6497\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.6511 - mse: 0.6511 - mae: 0.652 - 0s 272us/step - loss: 0.9369 - mse: 0.9369 - mae: 0.7641 - val_loss: 0.5566 - val_mse: 0.5566 - val_mae: 0.6499\n",
      "34\n",
      "[34]\n",
      "Train on 98 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 20.0228 - mse: 20.0228 - mae: 4.2251 - val_loss: 16.9266 - val_mse: 16.9266 - val_mae: 3.9375\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 275us/step - loss: 16.2850 - mse: 16.2850 - mae: 3.7610 - val_loss: 13.7160 - val_mse: 13.7160 - val_mae: 3.5040\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 438us/step - loss: 13.0664 - mse: 13.0664 - mae: 3.3165 - val_loss: 11.0267 - val_mse: 11.0267 - val_mae: 3.1065\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 326us/step - loss: 10.5761 - mse: 10.5761 - mae: 2.9233 - val_loss: 8.6001 - val_mse: 8.6001 - val_mae: 2.6946\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 356us/step - loss: 8.6193 - mse: 8.6193 - mae: 2.5602 - val_loss: 6.5582 - val_mse: 6.5582 - val_mae: 2.2808\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 234us/step - loss: 6.9030 - mse: 6.9030 - mae: 2.1966 - val_loss: 4.8252 - val_mse: 4.8252 - val_mae: 1.8924\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 275us/step - loss: 5.3478 - mse: 5.3478 - mae: 1.8375 - val_loss: 3.3664 - val_mse: 3.3664 - val_mae: 1.5577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 417us/step - loss: 4.0922 - mse: 4.0922 - mae: 1.5636 - val_loss: 2.3899 - val_mse: 2.3899 - val_mae: 1.3147\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 509us/step - loss: 3.2081 - mse: 3.2081 - mae: 1.4077 - val_loss: 1.8426 - val_mse: 1.8426 - val_mae: 1.1706\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 417us/step - loss: 2.6994 - mse: 2.6994 - mae: 1.3186 - val_loss: 1.6548 - val_mse: 1.6548 - val_mae: 1.1263\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 333us/step - loss: 2.5034 - mse: 2.5034 - mae: 1.2991 - val_loss: 1.6820 - val_mse: 1.6820 - val_mae: 1.0981\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 2.4893 - mse: 2.4893 - mae: 1.3019 - val_loss: 1.7773 - val_mse: 1.7773 - val_mae: 1.0937\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 285us/step - loss: 2.5238 - mse: 2.5238 - mae: 1.3091 - val_loss: 1.8341 - val_mse: 1.8341 - val_mae: 1.0998\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 315us/step - loss: 2.5292 - mse: 2.5292 - mae: 1.3093 - val_loss: 1.8199 - val_mse: 1.8199 - val_mae: 1.0974\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 2.4866 - mse: 2.4866 - mae: 1.2986 - val_loss: 1.7557 - val_mse: 1.7557 - val_mae: 1.0899\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 315us/step - loss: 2.4165 - mse: 2.4165 - mae: 1.2834 - val_loss: 1.6761 - val_mse: 1.6761 - val_mae: 1.0793\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 285us/step - loss: 2.3458 - mse: 2.3458 - mae: 1.2681 - val_loss: 1.6101 - val_mse: 1.6101 - val_mae: 1.0708\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 305us/step - loss: 2.2890 - mse: 2.2890 - mae: 1.2560 - val_loss: 1.5638 - val_mse: 1.5638 - val_mae: 1.0683\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 2.2488 - mse: 2.2488 - mae: 1.2456 - val_loss: 1.5342 - val_mse: 1.5342 - val_mae: 1.0682\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 315us/step - loss: 2.2202 - mse: 2.2202 - mae: 1.2369 - val_loss: 1.5185 - val_mse: 1.5185 - val_mae: 1.0686\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 305us/step - loss: 2.1959 - mse: 2.1959 - mae: 1.2291 - val_loss: 1.5097 - val_mse: 1.5097 - val_mae: 1.0675\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 336us/step - loss: 2.1725 - mse: 2.1725 - mae: 1.2220 - val_loss: 1.5056 - val_mse: 1.5056 - val_mae: 1.0654\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 336us/step - loss: 2.1504 - mse: 2.1504 - mae: 1.2157 - val_loss: 1.5045 - val_mse: 1.5045 - val_mae: 1.0623\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 2.1294 - mse: 2.1294 - mae: 1.2099 - val_loss: 1.5060 - val_mse: 1.5060 - val_mae: 1.0597\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 366us/step - loss: 2.1101 - mse: 2.1101 - mae: 1.2048 - val_loss: 1.5086 - val_mse: 1.5086 - val_mae: 1.0585\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 2.0923 - mse: 2.0923 - mae: 1.1999 - val_loss: 1.5115 - val_mse: 1.5115 - val_mae: 1.0568\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 265us/step - loss: 2.0753 - mse: 2.0753 - mae: 1.1949 - val_loss: 1.5149 - val_mse: 1.5149 - val_mae: 1.0555\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 285us/step - loss: 2.0586 - mse: 2.0586 - mae: 1.1896 - val_loss: 1.5185 - val_mse: 1.5185 - val_mae: 1.0546\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 519us/step - loss: 2.0422 - mse: 2.0422 - mae: 1.1843 - val_loss: 1.5196 - val_mse: 1.5196 - val_mae: 1.0541\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 295us/step - loss: 2.0261 - mse: 2.0261 - mae: 1.1787 - val_loss: 1.5192 - val_mse: 1.5192 - val_mae: 1.0537\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 265us/step - loss: 2.0113 - mse: 2.0113 - mae: 1.1733 - val_loss: 1.5178 - val_mse: 1.5178 - val_mae: 1.0529\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 244us/step - loss: 1.9979 - mse: 1.9979 - mae: 1.1683 - val_loss: 1.5151 - val_mse: 1.5151 - val_mae: 1.0517\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 539us/step - loss: 1.9848 - mse: 1.9848 - mae: 1.1634 - val_loss: 1.5128 - val_mse: 1.5128 - val_mae: 1.0507\n",
      "35\n",
      "[35]\n",
      "Train on 87 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.4582 - mse: 1.4582 - mae: 0.8883 - val_loss: 2.2722 - val_mse: 2.2722 - val_mae: 1.0655\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 513us/step - loss: 1.2461 - mse: 1.2461 - mae: 0.8399 - val_loss: 2.0666 - val_mse: 2.0666 - val_mae: 1.0606\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 504us/step - loss: 1.1313 - mse: 1.1313 - mae: 0.8307 - val_loss: 1.9536 - val_mse: 1.9536 - val_mae: 1.0671\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 768us/step - loss: 1.0904 - mse: 1.0904 - mae: 0.8436 - val_loss: 1.8959 - val_mse: 1.8959 - val_mae: 1.0681\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 477us/step - loss: 1.0829 - mse: 1.0829 - mae: 0.8520 - val_loss: 1.8579 - val_mse: 1.8579 - val_mae: 1.0625\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 1.0730 - mse: 1.0730 - mae: 0.8524 - val_loss: 1.8190 - val_mse: 1.8190 - val_mae: 1.0514\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 493us/step - loss: 1.0512 - mse: 1.0512 - mae: 0.8449 - val_loss: 1.7789 - val_mse: 1.7789 - val_mae: 1.0370\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 330us/step - loss: 1.0237 - mse: 1.0237 - mae: 0.8321 - val_loss: 1.7432 - val_mse: 1.7432 - val_mae: 1.0211\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 0.9994 - mse: 0.9994 - mae: 0.8171 - val_loss: 1.7156 - val_mse: 1.7156 - val_mae: 1.0054\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.9823 - mse: 0.9823 - mae: 0.8021 - val_loss: 1.6950 - val_mse: 1.6950 - val_mae: 0.9910\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.9709 - mse: 0.9709 - mae: 0.7889 - val_loss: 1.6760 - val_mse: 1.6760 - val_mae: 0.9788\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 264us/step - loss: 0.9619 - mse: 0.9619 - mae: 0.7782 - val_loss: 1.6546 - val_mse: 1.6546 - val_mae: 0.9690\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 0.9524 - mse: 0.9524 - mae: 0.7707 - val_loss: 1.6288 - val_mse: 1.6288 - val_mae: 0.9612\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 0.9423 - mse: 0.9423 - mae: 0.7665 - val_loss: 1.5986 - val_mse: 1.5986 - val_mae: 0.9549\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.9316 - mse: 0.9316 - mae: 0.7642 - val_loss: 1.5681 - val_mse: 1.5681 - val_mae: 0.9496\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 344us/step - loss: 0.9218 - mse: 0.9218 - mae: 0.7629 - val_loss: 1.5397 - val_mse: 1.5397 - val_mae: 0.9447\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 424us/step - loss: 0.9131 - mse: 0.9131 - mae: 0.7621 - val_loss: 1.5145 - val_mse: 1.5145 - val_mae: 0.9397\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.9052 - mse: 0.9052 - mae: 0.7610 - val_loss: 1.4919 - val_mse: 1.4919 - val_mae: 0.9343\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.8977 - mse: 0.8977 - mae: 0.7593 - val_loss: 1.4727 - val_mse: 1.4727 - val_mae: 0.9287\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 0.8900 - mse: 0.8900 - mae: 0.7559 - val_loss: 1.4565 - val_mse: 1.4565 - val_mae: 0.9235\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 0s 459us/step - loss: 0.8825 - mse: 0.8825 - mae: 0.7514 - val_loss: 1.4415 - val_mse: 1.4415 - val_mae: 0.9184\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.8751 - mse: 0.8751 - mae: 0.7469 - val_loss: 1.4253 - val_mse: 1.4253 - val_mae: 0.9134\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.8675 - mse: 0.8675 - mae: 0.7428 - val_loss: 1.4075 - val_mse: 1.4075 - val_mae: 0.9084\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.8603 - mse: 0.8603 - mae: 0.7395 - val_loss: 1.3913 - val_mse: 1.3913 - val_mae: 0.9038\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 0s 401us/step - loss: 0.8534 - mse: 0.8534 - mae: 0.7364 - val_loss: 1.3770 - val_mse: 1.3770 - val_mae: 0.8997\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.8466 - mse: 0.8466 - mae: 0.7336 - val_loss: 1.3638 - val_mse: 1.3638 - val_mae: 0.8959\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 0s 447us/step - loss: 0.8401 - mse: 0.8401 - mae: 0.7310 - val_loss: 1.3509 - val_mse: 1.3509 - val_mae: 0.8919\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 0s 427us/step - loss: 0.8334 - mse: 0.8334 - mae: 0.7286 - val_loss: 1.3376 - val_mse: 1.3376 - val_mae: 0.8879\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 0s 355us/step - loss: 0.8277 - mse: 0.8277 - mae: 0.7266 - val_loss: 1.3260 - val_mse: 1.3260 - val_mae: 0.8840\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 0s 390us/step - loss: 0.8219 - mse: 0.8219 - mae: 0.7240 - val_loss: 1.3158 - val_mse: 1.3158 - val_mae: 0.8802\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 0s 264us/step - loss: 0.8160 - mse: 0.8160 - mae: 0.7208 - val_loss: 1.3043 - val_mse: 1.3043 - val_mae: 0.8764\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 0s 378us/step - loss: 0.8107 - mse: 0.8107 - mae: 0.7182 - val_loss: 1.2942 - val_mse: 1.2942 - val_mae: 0.8729\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 0s 263us/step - loss: 0.8055 - mse: 0.8055 - mae: 0.7157 - val_loss: 1.2848 - val_mse: 1.2848 - val_mae: 0.8694\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 0.8003 - mse: 0.8003 - mae: 0.7135 - val_loss: 1.2743 - val_mse: 1.2743 - val_mae: 0.8660\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 0s 286us/step - loss: 0.7953 - mse: 0.7953 - mae: 0.7118 - val_loss: 1.2638 - val_mse: 1.2638 - val_mae: 0.8624\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.7903 - mse: 0.7903 - mae: 0.7099 - val_loss: 1.2530 - val_mse: 1.2530 - val_mae: 0.8584\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.7854 - mse: 0.7854 - mae: 0.7082 - val_loss: 1.2424 - val_mse: 1.2424 - val_mae: 0.8545\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.7806 - mse: 0.7806 - mae: 0.7065 - val_loss: 1.2324 - val_mse: 1.2324 - val_mae: 0.8511\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 0.7759 - mse: 0.7759 - mae: 0.7046 - val_loss: 1.2235 - val_mse: 1.2235 - val_mae: 0.8478\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 0s 481us/step - loss: 0.7712 - mse: 0.7712 - mae: 0.7023 - val_loss: 1.2152 - val_mse: 1.2152 - val_mae: 0.8446\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.7666 - mse: 0.7666 - mae: 0.6999 - val_loss: 1.2070 - val_mse: 1.2070 - val_mae: 0.8410\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 0s 424us/step - loss: 0.7618 - mse: 0.7618 - mae: 0.6978 - val_loss: 1.1988 - val_mse: 1.1988 - val_mae: 0.8374\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.7575 - mse: 0.7575 - mae: 0.6959 - val_loss: 1.1909 - val_mse: 1.1909 - val_mae: 0.8339\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 0s 355us/step - loss: 0.7531 - mse: 0.7531 - mae: 0.6938 - val_loss: 1.1828 - val_mse: 1.1828 - val_mae: 0.8302\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 0s 378us/step - loss: 0.7487 - mse: 0.7487 - mae: 0.6915 - val_loss: 1.1754 - val_mse: 1.1754 - val_mae: 0.8269\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 0s 436us/step - loss: 0.7440 - mse: 0.7440 - mae: 0.6892 - val_loss: 1.1679 - val_mse: 1.1679 - val_mae: 0.8237\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.7399 - mse: 0.7399 - mae: 0.6875 - val_loss: 1.1606 - val_mse: 1.1606 - val_mae: 0.8203\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 0s 218us/step - loss: 0.7356 - mse: 0.7356 - mae: 0.6855 - val_loss: 1.1539 - val_mse: 1.1539 - val_mae: 0.8174\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.7314 - mse: 0.7314 - mae: 0.6837 - val_loss: 1.1469 - val_mse: 1.1469 - val_mae: 0.8144\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 0s 527us/step - loss: 0.7272 - mse: 0.7272 - mae: 0.6819 - val_loss: 1.1411 - val_mse: 1.1411 - val_mae: 0.8117\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 0s 413us/step - loss: 0.7230 - mse: 0.7230 - mae: 0.6798 - val_loss: 1.1353 - val_mse: 1.1353 - val_mae: 0.8087\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 0.7190 - mse: 0.7190 - mae: 0.6776 - val_loss: 1.1297 - val_mse: 1.1297 - val_mae: 0.8059\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.7147 - mse: 0.7147 - mae: 0.6752 - val_loss: 1.1244 - val_mse: 1.1244 - val_mae: 0.8035\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 0.7107 - mse: 0.7107 - mae: 0.6732 - val_loss: 1.1199 - val_mse: 1.1199 - val_mae: 0.8014\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 0s 344us/step - loss: 0.7067 - mse: 0.7067 - mae: 0.6709 - val_loss: 1.1147 - val_mse: 1.1147 - val_mae: 0.7990\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.7024 - mse: 0.7024 - mae: 0.6686 - val_loss: 1.1088 - val_mse: 1.1088 - val_mae: 0.7963\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.6982 - mse: 0.6982 - mae: 0.6668 - val_loss: 1.1027 - val_mse: 1.1027 - val_mae: 0.7935\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 0.6941 - mse: 0.6941 - mae: 0.6652 - val_loss: 1.0975 - val_mse: 1.0975 - val_mae: 0.7908\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6905 - mse: 0.6905 - mae: 0.6634 - val_loss: 1.0938 - val_mse: 1.0938 - val_mae: 0.7885\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6872 - mse: 0.6872 - mae: 0.6614 - val_loss: 1.0909 - val_mse: 1.0909 - val_mae: 0.7859\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 0s 264us/step - loss: 0.6838 - mse: 0.6838 - mae: 0.6595 - val_loss: 1.0866 - val_mse: 1.0866 - val_mae: 0.7824\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.6803 - mse: 0.6803 - mae: 0.6584 - val_loss: 1.0820 - val_mse: 1.0820 - val_mae: 0.7789\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6770 - mse: 0.6770 - mae: 0.6571 - val_loss: 1.0786 - val_mse: 1.0786 - val_mae: 0.7758\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 0.6735 - mse: 0.6735 - mae: 0.6550 - val_loss: 1.0770 - val_mse: 1.0770 - val_mae: 0.7732\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6699 - mse: 0.6699 - mae: 0.6525 - val_loss: 1.0753 - val_mse: 1.0753 - val_mae: 0.7709\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.6664 - mse: 0.6664 - mae: 0.6503 - val_loss: 1.0733 - val_mse: 1.0733 - val_mae: 0.7692\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6632 - mse: 0.6632 - mae: 0.6482 - val_loss: 1.0721 - val_mse: 1.0721 - val_mae: 0.7676\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 0.6596 - mse: 0.6596 - mae: 0.6462 - val_loss: 1.0698 - val_mse: 1.0698 - val_mae: 0.7650\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 0s 252us/step - loss: 0.6562 - mse: 0.6562 - mae: 0.6448 - val_loss: 1.0675 - val_mse: 1.0675 - val_mae: 0.7628\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.6527 - mse: 0.6527 - mae: 0.6435 - val_loss: 1.0655 - val_mse: 1.0655 - val_mae: 0.7602\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 0s 344us/step - loss: 0.6495 - mse: 0.6495 - mae: 0.6418 - val_loss: 1.0652 - val_mse: 1.0652 - val_mae: 0.7584\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.6460 - mse: 0.6460 - mae: 0.6396 - val_loss: 1.0658 - val_mse: 1.0658 - val_mae: 0.7573\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 332us/step - loss: 0.6427 - mse: 0.6427 - mae: 0.6375 - val_loss: 1.0658 - val_mse: 1.0658 - val_mae: 0.7558\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 0.6391 - mse: 0.6391 - mae: 0.6351 - val_loss: 1.0647 - val_mse: 1.0647 - val_mae: 0.7530\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 0s 355us/step - loss: 0.6358 - mse: 0.6358 - mae: 0.6326 - val_loss: 1.0606 - val_mse: 1.0606 - val_mae: 0.7498\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 0s 378us/step - loss: 0.6325 - mse: 0.6325 - mae: 0.6317 - val_loss: 1.0579 - val_mse: 1.0579 - val_mae: 0.7471\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.6293 - mse: 0.6293 - mae: 0.6301 - val_loss: 1.0569 - val_mse: 1.0569 - val_mae: 0.7451\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6258 - mse: 0.6258 - mae: 0.6276 - val_loss: 1.0570 - val_mse: 1.0570 - val_mae: 0.7433\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 0s 321us/step - loss: 0.6222 - mse: 0.6222 - mae: 0.6250 - val_loss: 1.0548 - val_mse: 1.0548 - val_mae: 0.7422\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6190 - mse: 0.6190 - mae: 0.6232 - val_loss: 1.0539 - val_mse: 1.0539 - val_mae: 0.7417\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6157 - mse: 0.6157 - mae: 0.6211 - val_loss: 1.0541 - val_mse: 1.0541 - val_mae: 0.7413\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.6124 - mse: 0.6124 - mae: 0.6184 - val_loss: 1.0536 - val_mse: 1.0536 - val_mae: 0.7404\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 0s 390us/step - loss: 0.6089 - mse: 0.6089 - mae: 0.6164 - val_loss: 1.0504 - val_mse: 1.0504 - val_mae: 0.7392\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 0.6056 - mse: 0.6056 - mae: 0.6158 - val_loss: 1.0486 - val_mse: 1.0486 - val_mae: 0.7382\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.6023 - mse: 0.6023 - mae: 0.6141 - val_loss: 1.0490 - val_mse: 1.0490 - val_mae: 0.7375\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 0s 355us/step - loss: 0.5989 - mse: 0.5989 - mae: 0.6112 - val_loss: 1.0498 - val_mse: 1.0498 - val_mae: 0.7370\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.5955 - mse: 0.5955 - mae: 0.6086 - val_loss: 1.0484 - val_mse: 1.0484 - val_mae: 0.7362\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 0.5919 - mse: 0.5919 - mae: 0.6072 - val_loss: 1.0454 - val_mse: 1.0454 - val_mae: 0.7347\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 0.5887 - mse: 0.5887 - mae: 0.6059 - val_loss: 1.0462 - val_mse: 1.0462 - val_mae: 0.7338\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 0.5852 - mse: 0.5852 - mae: 0.6030 - val_loss: 1.0483 - val_mse: 1.0483 - val_mae: 0.7336\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 0s 264us/step - loss: 0.5819 - mse: 0.5819 - mae: 0.6001 - val_loss: 1.0463 - val_mse: 1.0463 - val_mae: 0.7321\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 0s 424us/step - loss: 0.5784 - mse: 0.5784 - mae: 0.5990 - val_loss: 1.0426 - val_mse: 1.0426 - val_mae: 0.7302\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.5752 - mse: 0.5752 - mae: 0.5979 - val_loss: 1.0438 - val_mse: 1.0438 - val_mae: 0.7296\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 0s 287us/step - loss: 0.5718 - mse: 0.5718 - mae: 0.5951 - val_loss: 1.0470 - val_mse: 1.0470 - val_mae: 0.7299\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.5682 - mse: 0.5682 - mae: 0.5928 - val_loss: 1.0468 - val_mse: 1.0468 - val_mae: 0.7296\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.5654 - mse: 0.5654 - mae: 0.5920 - val_loss: 1.0458 - val_mse: 1.0458 - val_mae: 0.7280\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 0s 241us/step - loss: 0.5617 - mse: 0.5617 - mae: 0.5894 - val_loss: 1.0465 - val_mse: 1.0465 - val_mae: 0.7272\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 0.5585 - mse: 0.5585 - mae: 0.5863 - val_loss: 1.0486 - val_mse: 1.0486 - val_mae: 0.7278\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 0s 275us/step - loss: 0.5552 - mse: 0.5552 - mae: 0.5837 - val_loss: 1.0521 - val_mse: 1.0521 - val_mae: 0.7291\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 0s 447us/step - loss: 0.5519 - mse: 0.5519 - mae: 0.5813 - val_loss: 1.0539 - val_mse: 1.0539 - val_mae: 0.7294\n",
      "36\n",
      "[36]\n",
      "Train on 102 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 9.0862 - mse: 9.0862 - mae: 2.6557 - val_loss: 9.4821 - val_mse: 9.4821 - val_mae: 2.5060\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 299us/step - loss: 7.5150 - mse: 7.5150 - mae: 2.3474 - val_loss: 8.1554 - val_mse: 8.1554 - val_mae: 2.2072\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 6.1994 - mse: 6.1994 - mae: 2.0587 - val_loss: 7.0393 - val_mse: 7.0393 - val_mae: 1.9918\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 5.1126 - mse: 5.1126 - mae: 1.8041 - val_loss: 6.1210 - val_mse: 6.1210 - val_mae: 1.8278\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 4.2245 - mse: 4.2245 - mae: 1.5814 - val_loss: 5.3843 - val_mse: 5.3843 - val_mae: 1.7395\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 3.5235 - mse: 3.5235 - mae: 1.3984 - val_loss: 4.8083 - val_mse: 4.8083 - val_mae: 1.6667\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 2.9950 - mse: 2.9950 - mae: 1.2755 - val_loss: 4.4141 - val_mse: 4.4141 - val_mae: 1.6206\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 2.6154 - mse: 2.6154 - mae: 1.1919 - val_loss: 4.1566 - val_mse: 4.1566 - val_mae: 1.6103\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 2.3633 - mse: 2.3633 - mae: 1.1524 - val_loss: 3.9843 - val_mse: 3.9843 - val_mae: 1.6142\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 2.2179 - mse: 2.2179 - mae: 1.1432 - val_loss: 3.8884 - val_mse: 3.8884 - val_mae: 1.6161\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 2.1436 - mse: 2.1436 - mae: 1.1428 - val_loss: 3.8187 - val_mse: 3.8187 - val_mae: 1.6103\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 381us/step - loss: 2.1148 - mse: 2.1148 - mae: 1.1504 - val_loss: 3.7763 - val_mse: 3.7763 - val_mae: 1.6126\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 352us/step - loss: 2.1097 - mse: 2.1097 - mae: 1.1612 - val_loss: 3.7487 - val_mse: 3.7487 - val_mae: 1.6112\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 2.1145 - mse: 2.1145 - mae: 1.1697 - val_loss: 3.7262 - val_mse: 3.7262 - val_mae: 1.6119\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 2.1118 - mse: 2.1118 - mae: 1.1711 - val_loss: 3.7006 - val_mse: 3.7006 - val_mae: 1.6078\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 244us/step - loss: 2.1018 - mse: 2.1018 - mae: 1.1667 - val_loss: 3.6739 - val_mse: 3.6739 - val_mae: 1.6001\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 254us/step - loss: 2.0895 - mse: 2.0895 - mae: 1.1597 - val_loss: 3.6523 - val_mse: 3.6523 - val_mae: 1.5923\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 323us/step - loss: 2.0771 - mse: 2.0771 - mae: 1.1522 - val_loss: 3.6319 - val_mse: 3.6319 - val_mae: 1.5863\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 450us/step - loss: 2.0674 - mse: 2.0674 - mae: 1.1454 - val_loss: 3.6135 - val_mse: 3.6135 - val_mae: 1.5801\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 332us/step - loss: 2.0592 - mse: 2.0592 - mae: 1.1394 - val_loss: 3.5939 - val_mse: 3.5939 - val_mae: 1.5733\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 2.0525 - mse: 2.0525 - mae: 1.1347 - val_loss: 3.5744 - val_mse: 3.5744 - val_mae: 1.5670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 2.0468 - mse: 2.0468 - mae: 1.1311 - val_loss: 3.5588 - val_mse: 3.5588 - val_mae: 1.5622\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 381us/step - loss: 2.0418 - mse: 2.0418 - mae: 1.1283 - val_loss: 3.5471 - val_mse: 3.5471 - val_mae: 1.5590\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 2.0367 - mse: 2.0367 - mae: 1.1262 - val_loss: 3.5391 - val_mse: 3.5391 - val_mae: 1.5570\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 352us/step - loss: 2.0318 - mse: 2.0318 - mae: 1.1246 - val_loss: 3.5342 - val_mse: 3.5342 - val_mae: 1.5560\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 450us/step - loss: 2.0267 - mse: 2.0267 - mae: 1.1235 - val_loss: 3.5266 - val_mse: 3.5266 - val_mae: 1.5544\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 332us/step - loss: 2.0216 - mse: 2.0216 - mae: 1.1231 - val_loss: 3.5208 - val_mse: 3.5208 - val_mae: 1.5531\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 2.0167 - mse: 2.0167 - mae: 1.1229 - val_loss: 3.5197 - val_mse: 3.5197 - val_mae: 1.5528\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 323us/step - loss: 2.0117 - mse: 2.0117 - mae: 1.1227 - val_loss: 3.5231 - val_mse: 3.5231 - val_mae: 1.5537\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 430us/step - loss: 2.0064 - mse: 2.0064 - mae: 1.1221 - val_loss: 3.5266 - val_mse: 3.5266 - val_mae: 1.5545\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 332us/step - loss: 2.0012 - mse: 2.0012 - mae: 1.1216 - val_loss: 3.5287 - val_mse: 3.5287 - val_mae: 1.5546\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 410us/step - loss: 1.9959 - mse: 1.9959 - mae: 1.1209 - val_loss: 3.5303 - val_mse: 3.5303 - val_mae: 1.5546\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 1.9908 - mse: 1.9908 - mae: 1.1199 - val_loss: 3.5321 - val_mse: 3.5321 - val_mae: 1.5545\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 235us/step - loss: 1.9860 - mse: 1.9860 - mae: 1.1186 - val_loss: 3.5312 - val_mse: 3.5312 - val_mae: 1.5537\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.9815 - mse: 1.9815 - mae: 1.1173 - val_loss: 3.5279 - val_mse: 3.5279 - val_mae: 1.5525\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 393us/step - loss: 1.9768 - mse: 1.9768 - mae: 1.1160 - val_loss: 3.5236 - val_mse: 3.5236 - val_mae: 1.5511\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 381us/step - loss: 1.9722 - mse: 1.9722 - mae: 1.1147 - val_loss: 3.5183 - val_mse: 3.5183 - val_mae: 1.5497\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.9679 - mse: 1.9679 - mae: 1.1135 - val_loss: 3.5169 - val_mse: 3.5169 - val_mae: 1.5496\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.9634 - mse: 1.9634 - mae: 1.1119 - val_loss: 3.5154 - val_mse: 3.5154 - val_mae: 1.5492\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.9589 - mse: 1.9589 - mae: 1.1105 - val_loss: 3.5115 - val_mse: 3.5115 - val_mae: 1.5482\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.9545 - mse: 1.9545 - mae: 1.1092 - val_loss: 3.5088 - val_mse: 3.5088 - val_mae: 1.5477\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.9498 - mse: 1.9498 - mae: 1.1077 - val_loss: 3.5052 - val_mse: 3.5052 - val_mae: 1.5471\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 1.9457 - mse: 1.9457 - mae: 1.1067 - val_loss: 3.5023 - val_mse: 3.5023 - val_mae: 1.5468\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.9412 - mse: 1.9412 - mae: 1.1055 - val_loss: 3.5002 - val_mse: 3.5002 - val_mae: 1.5468\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.9364 - mse: 1.9364 - mae: 1.1042 - val_loss: 3.4976 - val_mse: 3.4976 - val_mae: 1.5467\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.9316 - mse: 1.9316 - mae: 1.1032 - val_loss: 3.4945 - val_mse: 3.4945 - val_mae: 1.5465\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.9267 - mse: 1.9267 - mae: 1.1021 - val_loss: 3.4931 - val_mse: 3.4931 - val_mae: 1.5467\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 1.9205 - mse: 1.9205 - mae: 1.1000 - val_loss: 3.4990 - val_mse: 3.4990 - val_mae: 1.5489\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 1.9133 - mse: 1.9133 - mae: 1.0972 - val_loss: 3.5024 - val_mse: 3.5024 - val_mae: 1.5507\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.9075 - mse: 1.9075 - mae: 1.0955 - val_loss: 3.5026 - val_mse: 3.5026 - val_mae: 1.5518\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.9028 - mse: 1.9028 - mae: 1.0944 - val_loss: 3.5090 - val_mse: 3.5090 - val_mae: 1.5539\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.8991 - mse: 1.8991 - mae: 1.0937 - val_loss: 3.5058 - val_mse: 3.5058 - val_mae: 1.5539\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 352us/step - loss: 1.8953 - mse: 1.8953 - mae: 1.0938 - val_loss: 3.4931 - val_mse: 3.4931 - val_mae: 1.5517\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 340us/step - loss: 1.8916 - mse: 1.8916 - mae: 1.0940 - val_loss: 3.4863 - val_mse: 3.4863 - val_mae: 1.5506\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.8874 - mse: 1.8874 - mae: 1.0930 - val_loss: 3.4866 - val_mse: 3.4866 - val_mae: 1.5512\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.8831 - mse: 1.8831 - mae: 1.0916 - val_loss: 3.4842 - val_mse: 3.4842 - val_mae: 1.5507\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.8789 - mse: 1.8789 - mae: 1.0903 - val_loss: 3.4780 - val_mse: 3.4780 - val_mae: 1.5490\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.8752 - mse: 1.8752 - mae: 1.0893 - val_loss: 3.4757 - val_mse: 3.4757 - val_mae: 1.5482\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.8705 - mse: 1.8705 - mae: 1.0878 - val_loss: 3.4706 - val_mse: 3.4706 - val_mae: 1.5468\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.8656 - mse: 1.8656 - mae: 1.0867 - val_loss: 3.4653 - val_mse: 3.4653 - val_mae: 1.5454\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 1.8608 - mse: 1.8608 - mae: 1.0858 - val_loss: 3.4649 - val_mse: 3.4649 - val_mae: 1.5453\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.8553 - mse: 1.8553 - mae: 1.0841 - val_loss: 3.4616 - val_mse: 3.4616 - val_mae: 1.5444\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 596us/step - loss: 1.8499 - mse: 1.8499 - mae: 1.0825 - val_loss: 3.4548 - val_mse: 3.4548 - val_mae: 1.5423\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 418us/step - loss: 1.8446 - mse: 1.8446 - mae: 1.0813 - val_loss: 3.4438 - val_mse: 3.4438 - val_mae: 1.5391\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 265us/step - loss: 1.8399 - mse: 1.8399 - mae: 1.0803 - val_loss: 3.4366 - val_mse: 3.4366 - val_mae: 1.5370\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 323us/step - loss: 1.8344 - mse: 1.8344 - mae: 1.0784 - val_loss: 3.4329 - val_mse: 3.4329 - val_mae: 1.5361\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 450us/step - loss: 1.8293 - mse: 1.8293 - mae: 1.0769 - val_loss: 3.4257 - val_mse: 3.4257 - val_mae: 1.5339\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 254us/step - loss: 1.8244 - mse: 1.8244 - mae: 1.0759 - val_loss: 3.4143 - val_mse: 3.4143 - val_mae: 1.5306\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 528us/step - loss: 1.8198 - mse: 1.8198 - mae: 1.0750 - val_loss: 3.4080 - val_mse: 3.4080 - val_mae: 1.5286\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.8145 - mse: 1.8145 - mae: 1.0733 - val_loss: 3.4024 - val_mse: 3.4024 - val_mae: 1.5267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.8094 - mse: 1.8094 - mae: 1.0717 - val_loss: 3.3936 - val_mse: 3.3936 - val_mae: 1.5240\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 332us/step - loss: 1.8044 - mse: 1.8044 - mae: 1.0704 - val_loss: 3.3827 - val_mse: 3.3827 - val_mae: 1.5208\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 1.7996 - mse: 1.7996 - mae: 1.0691 - val_loss: 3.3769 - val_mse: 3.3769 - val_mae: 1.5189\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.7943 - mse: 1.7943 - mae: 1.0670 - val_loss: 3.3705 - val_mse: 3.3705 - val_mae: 1.5170\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.7893 - mse: 1.7893 - mae: 1.0650 - val_loss: 3.3620 - val_mse: 3.3620 - val_mae: 1.5144\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 1.7844 - mse: 1.7844 - mae: 1.0635 - val_loss: 3.3548 - val_mse: 3.3548 - val_mae: 1.5123\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 381us/step - loss: 1.7800 - mse: 1.7800 - mae: 1.0624 - val_loss: 3.3536 - val_mse: 3.3536 - val_mae: 1.5123\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.7748 - mse: 1.7748 - mae: 1.0610 - val_loss: 3.3514 - val_mse: 3.3514 - val_mae: 1.5121\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.7700 - mse: 1.7700 - mae: 1.0603 - val_loss: 3.3447 - val_mse: 3.3447 - val_mae: 1.5111\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 1.7654 - mse: 1.7654 - mae: 1.0597 - val_loss: 3.3408 - val_mse: 3.3408 - val_mae: 1.5107\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.7607 - mse: 1.7607 - mae: 1.0583 - val_loss: 3.3446 - val_mse: 3.3446 - val_mae: 1.5116\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 411us/step - loss: 1.7554 - mse: 1.7554 - mae: 1.0555 - val_loss: 3.3447 - val_mse: 3.3447 - val_mae: 1.5117\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 1.7506 - mse: 1.7506 - mae: 1.0536 - val_loss: 3.3388 - val_mse: 3.3388 - val_mae: 1.5109\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 362us/step - loss: 1.7454 - mse: 1.7454 - mae: 1.0519 - val_loss: 3.3330 - val_mse: 3.3330 - val_mae: 1.5099\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 244us/step - loss: 1.7405 - mse: 1.7405 - mae: 1.0501 - val_loss: 3.3341 - val_mse: 3.3341 - val_mae: 1.5099\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 1.7347 - mse: 1.7347 - mae: 1.0474 - val_loss: 3.3340 - val_mse: 3.3340 - val_mae: 1.5097\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 1.7296 - mse: 1.7296 - mae: 1.0454 - val_loss: 3.3315 - val_mse: 3.3315 - val_mae: 1.5101\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 1.7244 - mse: 1.7244 - mae: 1.0439 - val_loss: 3.3272 - val_mse: 3.3272 - val_mae: 1.5100\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.7192 - mse: 1.7192 - mae: 1.0425 - val_loss: 3.3261 - val_mse: 3.3261 - val_mae: 1.5100\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - ETA: 0s - loss: 1.2163 - mse: 1.2163 - mae: 0.904 - 0s 313us/step - loss: 1.7139 - mse: 1.7139 - mae: 1.0408 - val_loss: 3.3252 - val_mse: 3.3252 - val_mae: 1.5099\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.7090 - mse: 1.7090 - mae: 1.0394 - val_loss: 3.3231 - val_mse: 3.3231 - val_mae: 1.5099\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.7035 - mse: 1.7035 - mae: 1.0374 - val_loss: 3.3222 - val_mse: 3.3222 - val_mae: 1.5100\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 274us/step - loss: 1.6983 - mse: 1.6983 - mae: 1.0353 - val_loss: 3.3227 - val_mse: 3.3227 - val_mae: 1.5100\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 528us/step - loss: 1.6928 - mse: 1.6928 - mae: 1.0334 - val_loss: 3.3249 - val_mse: 3.3249 - val_mae: 1.5100\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 353us/step - loss: 1.6879 - mse: 1.6879 - mae: 1.0318 - val_loss: 3.3232 - val_mse: 3.3232 - val_mae: 1.5102\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 1.6826 - mse: 1.6826 - mae: 1.0301 - val_loss: 3.3200 - val_mse: 3.3200 - val_mae: 1.5101\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 1.6775 - mse: 1.6775 - mae: 1.0284 - val_loss: 3.3233 - val_mse: 3.3233 - val_mae: 1.5113\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 1.6721 - mse: 1.6721 - mae: 1.0262 - val_loss: 3.3226 - val_mse: 3.3226 - val_mae: 1.5116\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 254us/step - loss: 1.6666 - mse: 1.6666 - mae: 1.0248 - val_loss: 3.3199 - val_mse: 3.3199 - val_mae: 1.5114\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 352us/step - loss: 1.6613 - mse: 1.6613 - mae: 1.0240 - val_loss: 3.3146 - val_mse: 3.3146 - val_mae: 1.5109\n",
      "37\n",
      "[37]\n",
      "Train on 74 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 15.1191 - mse: 15.1191 - mae: 3.7399 - val_loss: 7.8934 - val_mse: 7.8934 - val_mae: 2.7823\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 211us/step - loss: 12.9332 - mse: 12.9332 - mae: 3.4445 - val_loss: 6.7176 - val_mse: 6.7176 - val_mae: 2.5613\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 472us/step - loss: 11.0776 - mse: 11.0776 - mae: 3.1705 - val_loss: 5.8079 - val_mse: 5.8079 - val_mae: 2.3764\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 302us/step - loss: 9.5717 - mse: 9.5717 - mae: 2.9267 - val_loss: 5.0115 - val_mse: 5.0115 - val_mae: 2.2002\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 323us/step - loss: 8.3170 - mse: 8.3170 - mae: 2.7084 - val_loss: 4.2909 - val_mse: 4.2909 - val_mae: 2.0285\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 701us/step - loss: 7.2468 - mse: 7.2468 - mae: 2.5069 - val_loss: 3.6574 - val_mse: 3.6574 - val_mae: 1.8653\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 593us/step - loss: 6.3026 - mse: 6.3026 - mae: 2.3127 - val_loss: 3.1256 - val_mse: 3.1256 - val_mae: 1.7159\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 431us/step - loss: 5.4736 - mse: 5.4736 - mae: 2.1267 - val_loss: 2.6594 - val_mse: 2.6594 - val_mae: 1.5732\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 285us/step - loss: 4.7451 - mse: 4.7451 - mae: 1.9469 - val_loss: 2.2467 - val_mse: 2.2467 - val_mae: 1.4347\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 728us/step - loss: 4.0974 - mse: 4.0974 - mae: 1.7711 - val_loss: 1.8779 - val_mse: 1.8779 - val_mae: 1.2976\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 377us/step - loss: 3.5302 - mse: 3.5302 - mae: 1.6009 - val_loss: 1.5483 - val_mse: 1.5483 - val_mae: 1.1606\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 3.0386 - mse: 3.0386 - mae: 1.4388 - val_loss: 1.2686 - val_mse: 1.2686 - val_mae: 1.0297\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 2.6224 - mse: 2.6224 - mae: 1.2956 - val_loss: 1.0339 - val_mse: 1.0339 - val_mae: 0.9052\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 499us/step - loss: 2.2795 - mse: 2.2795 - mae: 1.1716 - val_loss: 0.8372 - val_mse: 0.8372 - val_mae: 0.7861\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 606us/step - loss: 1.9996 - mse: 1.9996 - mae: 1.0665 - val_loss: 0.6836 - val_mse: 0.6836 - val_mae: 0.6815\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 391us/step - loss: 1.7757 - mse: 1.7757 - mae: 0.9752 - val_loss: 0.5643 - val_mse: 0.5643 - val_mae: 0.5865\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 512us/step - loss: 1.6035 - mse: 1.6035 - mae: 0.9025 - val_loss: 0.4760 - val_mse: 0.4760 - val_mae: 0.5043\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 431us/step - loss: 1.4750 - mse: 1.4750 - mae: 0.8510 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4353\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 472us/step - loss: 1.3758 - mse: 1.3758 - mae: 0.8120 - val_loss: 0.3534 - val_mse: 0.3534 - val_mae: 0.3816\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 391us/step - loss: 1.3005 - mse: 1.3005 - mae: 0.7836 - val_loss: 0.3140 - val_mse: 0.3140 - val_mae: 0.3450\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 1.2441 - mse: 1.2441 - mae: 0.7659 - val_loss: 0.2857 - val_mse: 0.2857 - val_mae: 0.3452\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 1.2017 - mse: 1.2017 - mae: 0.7532 - val_loss: 0.2659 - val_mse: 0.2659 - val_mae: 0.3488\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 445us/step - loss: 1.1703 - mse: 1.1703 - mae: 0.7436 - val_loss: 0.2524 - val_mse: 0.2524 - val_mae: 0.3546\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 418us/step - loss: 1.1464 - mse: 1.1464 - mae: 0.7369 - val_loss: 0.2430 - val_mse: 0.2430 - val_mae: 0.3622\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 674us/step - loss: 1.1279 - mse: 1.1279 - mae: 0.7326 - val_loss: 0.2372 - val_mse: 0.2372 - val_mae: 0.3710\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 334us/step - loss: 1.1131 - mse: 1.1131 - mae: 0.7298 - val_loss: 0.2339 - val_mse: 0.2339 - val_mae: 0.3779\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 1.1004 - mse: 1.1004 - mae: 0.7289 - val_loss: 0.2324 - val_mse: 0.2324 - val_mae: 0.3827\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 337us/step - loss: 1.0916 - mse: 1.0916 - mae: 0.7295 - val_loss: 0.2317 - val_mse: 0.2317 - val_mae: 0.3869\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 297us/step - loss: 1.0840 - mse: 1.0840 - mae: 0.7309 - val_loss: 0.2313 - val_mse: 0.2313 - val_mae: 0.3901\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 337us/step - loss: 1.0775 - mse: 1.0775 - mae: 0.7326 - val_loss: 0.2319 - val_mse: 0.2319 - val_mae: 0.3943\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 323us/step - loss: 1.0714 - mse: 1.0714 - mae: 0.7338 - val_loss: 0.2332 - val_mse: 0.2332 - val_mae: 0.3990\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 310us/step - loss: 1.0651 - mse: 1.0651 - mae: 0.7344 - val_loss: 0.2351 - val_mse: 0.2351 - val_mae: 0.4039\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 0s 418us/step - loss: 1.0586 - mse: 1.0586 - mae: 0.7344 - val_loss: 0.2370 - val_mse: 0.2370 - val_mae: 0.4084\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 0s 539us/step - loss: 1.0519 - mse: 1.0519 - mae: 0.7341 - val_loss: 0.2390 - val_mse: 0.2390 - val_mae: 0.4124\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 0s 418us/step - loss: 1.0453 - mse: 1.0453 - mae: 0.7338 - val_loss: 0.2411 - val_mse: 0.2411 - val_mae: 0.4161\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 1.0401 - mse: 1.0401 - mae: 0.7330 - val_loss: 0.2421 - val_mse: 0.2421 - val_mae: 0.4172\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 0s 606us/step - loss: 1.0345 - mse: 1.0345 - mae: 0.7312 - val_loss: 0.2419 - val_mse: 0.2419 - val_mae: 0.4151\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 0s 458us/step - loss: 1.0282 - mse: 1.0282 - mae: 0.7285 - val_loss: 0.2415 - val_mse: 0.2415 - val_mae: 0.4121\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 1.0226 - mse: 1.0226 - mae: 0.7264 - val_loss: 0.2413 - val_mse: 0.2413 - val_mae: 0.4103\n",
      "38\n",
      "[38]\n",
      "Train on 86 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 4.3915 - mse: 4.3915 - mae: 1.8027 - val_loss: 4.9615 - val_mse: 4.9615 - val_mae: 1.9640\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 3.6477 - mse: 3.6477 - mae: 1.5884 - val_loss: 4.0796 - val_mse: 4.0796 - val_mae: 1.7749\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 360us/step - loss: 3.0126 - mse: 3.0126 - mae: 1.3870 - val_loss: 3.2989 - val_mse: 3.2989 - val_mae: 1.5887\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 711us/step - loss: 2.4887 - mse: 2.4887 - mae: 1.2288 - val_loss: 2.6675 - val_mse: 2.6675 - val_mae: 1.4313\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 314us/step - loss: 2.0682 - mse: 2.0682 - mae: 1.1031 - val_loss: 2.1860 - val_mse: 2.1860 - val_mae: 1.2946\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 464us/step - loss: 1.7585 - mse: 1.7585 - mae: 0.9950 - val_loss: 1.8300 - val_mse: 1.8300 - val_mae: 1.1614\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 487us/step - loss: 1.5581 - mse: 1.5581 - mae: 0.9346 - val_loss: 1.5984 - val_mse: 1.5984 - val_mae: 1.0850\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 1.4542 - mse: 1.4542 - mae: 0.9307 - val_loss: 1.4776 - val_mse: 1.4776 - val_mae: 1.0572\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 244us/step - loss: 1.4149 - mse: 1.4149 - mae: 0.9342 - val_loss: 1.4256 - val_mse: 1.4256 - val_mae: 1.0363\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.4069 - mse: 1.4069 - mae: 0.9422 - val_loss: 1.4109 - val_mse: 1.4109 - val_mae: 1.0240\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 464us/step - loss: 1.4006 - mse: 1.4006 - mae: 0.9447 - val_loss: 1.4061 - val_mse: 1.4061 - val_mae: 1.0190\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.3823 - mse: 1.3823 - mae: 0.9405 - val_loss: 1.3961 - val_mse: 1.3961 - val_mae: 1.0186\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 1.3516 - mse: 1.3516 - mae: 0.9304 - val_loss: 1.3865 - val_mse: 1.3865 - val_mae: 1.0223\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 522us/step - loss: 1.3158 - mse: 1.3158 - mae: 0.9168 - val_loss: 1.3767 - val_mse: 1.3767 - val_mae: 1.0262\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.2825 - mse: 1.2825 - mae: 0.9015 - val_loss: 1.3717 - val_mse: 1.3717 - val_mae: 1.0298\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 638us/step - loss: 1.2550 - mse: 1.2550 - mae: 0.8862 - val_loss: 1.3670 - val_mse: 1.3670 - val_mae: 1.0321\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 1.2338 - mse: 1.2338 - mae: 0.8742 - val_loss: 1.3609 - val_mse: 1.3609 - val_mae: 1.0328\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 1.2167 - mse: 1.2167 - mae: 0.8658 - val_loss: 1.3531 - val_mse: 1.3531 - val_mae: 1.0317\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.2004 - mse: 1.2004 - mae: 0.8587 - val_loss: 1.3414 - val_mse: 1.3414 - val_mae: 1.0286\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.1834 - mse: 1.1834 - mae: 0.8524 - val_loss: 1.3255 - val_mse: 1.3255 - val_mae: 1.0238\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 360us/step - loss: 1.1654 - mse: 1.1654 - mae: 0.8465 - val_loss: 1.3052 - val_mse: 1.3052 - val_mae: 1.0172\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 1.1476 - mse: 1.1476 - mae: 0.8416 - val_loss: 1.2836 - val_mse: 1.2836 - val_mae: 1.0099\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.1301 - mse: 1.1301 - mae: 0.8373 - val_loss: 1.2623 - val_mse: 1.2623 - val_mae: 1.0023\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 1.1129 - mse: 1.1129 - mae: 0.8329 - val_loss: 1.2423 - val_mse: 1.2423 - val_mae: 0.9947\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 359us/step - loss: 1.0968 - mse: 1.0968 - mae: 0.8287 - val_loss: 1.2249 - val_mse: 1.2249 - val_mae: 0.9889\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 348us/step - loss: 1.0821 - mse: 1.0821 - mae: 0.8244 - val_loss: 1.2095 - val_mse: 1.2095 - val_mae: 0.9837\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 487us/step - loss: 1.0685 - mse: 1.0685 - mae: 0.8201 - val_loss: 1.1957 - val_mse: 1.1957 - val_mae: 0.9792\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 1.0555 - mse: 1.0555 - mae: 0.8158 - val_loss: 1.1833 - val_mse: 1.1833 - val_mae: 0.9753\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 406us/step - loss: 1.0418 - mse: 1.0418 - mae: 0.8110 - val_loss: 1.1732 - val_mse: 1.1732 - val_mae: 0.9724\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 1.0282 - mse: 1.0282 - mae: 0.8058 - val_loss: 1.1642 - val_mse: 1.1642 - val_mae: 0.9699\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.0152 - mse: 1.0152 - mae: 0.8010 - val_loss: 1.1546 - val_mse: 1.1546 - val_mae: 0.9675\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 1.0026 - mse: 1.0026 - mae: 0.7963 - val_loss: 1.1442 - val_mse: 1.1442 - val_mae: 0.9645\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.9901 - mse: 0.9901 - mae: 0.7915 - val_loss: 1.1328 - val_mse: 1.1328 - val_mae: 0.9610\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.9779 - mse: 0.9779 - mae: 0.7866 - val_loss: 1.1213 - val_mse: 1.1213 - val_mae: 0.9574\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 568us/step - loss: 0.9661 - mse: 0.9661 - mae: 0.7823 - val_loss: 1.1089 - val_mse: 1.1089 - val_mae: 0.9532\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 0.9542 - mse: 0.9542 - mae: 0.7780 - val_loss: 1.0961 - val_mse: 1.0961 - val_mae: 0.9486\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.9425 - mse: 0.9425 - mae: 0.7740 - val_loss: 1.0835 - val_mse: 1.0835 - val_mae: 0.9437\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.9322 - mse: 0.9322 - mae: 0.7703 - val_loss: 1.0720 - val_mse: 1.0720 - val_mae: 0.9392\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 441us/step - loss: 0.9226 - mse: 0.9226 - mae: 0.7670 - val_loss: 1.0627 - val_mse: 1.0627 - val_mae: 0.9355\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.9133 - mse: 0.9133 - mae: 0.7641 - val_loss: 1.0549 - val_mse: 1.0549 - val_mae: 0.9323\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.9042 - mse: 0.9042 - mae: 0.7615 - val_loss: 1.0484 - val_mse: 1.0484 - val_mae: 0.9298\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.8957 - mse: 0.8957 - mae: 0.7588 - val_loss: 1.0435 - val_mse: 1.0435 - val_mae: 0.9280\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.8876 - mse: 0.8876 - mae: 0.7559 - val_loss: 1.0391 - val_mse: 1.0391 - val_mae: 0.9264\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 406us/step - loss: 0.8801 - mse: 0.8801 - mae: 0.7532 - val_loss: 1.0346 - val_mse: 1.0346 - val_mae: 0.9247\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.8729 - mse: 0.8729 - mae: 0.7505 - val_loss: 1.0305 - val_mse: 1.0305 - val_mae: 0.9233\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 719us/step - loss: 0.8660 - mse: 0.8660 - mae: 0.7478 - val_loss: 1.0265 - val_mse: 1.0265 - val_mae: 0.9218\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 429us/step - loss: 0.8595 - mse: 0.8595 - mae: 0.7451 - val_loss: 1.0221 - val_mse: 1.0221 - val_mae: 0.9201\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 406us/step - loss: 0.8533 - mse: 0.8533 - mae: 0.7428 - val_loss: 1.0173 - val_mse: 1.0173 - val_mae: 0.9180\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.8473 - mse: 0.8473 - mae: 0.7407 - val_loss: 1.0123 - val_mse: 1.0123 - val_mae: 0.9157\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 464us/step - loss: 0.8417 - mse: 0.8417 - mae: 0.7389 - val_loss: 1.0081 - val_mse: 1.0081 - val_mae: 0.9137\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.8364 - mse: 0.8364 - mae: 0.7372 - val_loss: 1.0051 - val_mse: 1.0051 - val_mae: 0.9124\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.8313 - mse: 0.8313 - mae: 0.7354 - val_loss: 1.0025 - val_mse: 1.0025 - val_mae: 0.9115\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.8264 - mse: 0.8264 - mae: 0.7334 - val_loss: 0.9997 - val_mse: 0.9997 - val_mae: 0.9102\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.8214 - mse: 0.8214 - mae: 0.7315 - val_loss: 0.9961 - val_mse: 0.9961 - val_mae: 0.9085\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.8166 - mse: 0.8166 - mae: 0.7296 - val_loss: 0.9923 - val_mse: 0.9923 - val_mae: 0.9067\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.8120 - mse: 0.8120 - mae: 0.7274 - val_loss: 0.9887 - val_mse: 0.9887 - val_mae: 0.9051\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.8073 - mse: 0.8073 - mae: 0.7252 - val_loss: 0.9862 - val_mse: 0.9862 - val_mae: 0.9041\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 0.8030 - mse: 0.8030 - mae: 0.7232 - val_loss: 0.9839 - val_mse: 0.9839 - val_mae: 0.9032\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.7986 - mse: 0.7986 - mae: 0.7214 - val_loss: 0.9806 - val_mse: 0.9806 - val_mae: 0.9016\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.7943 - mse: 0.7943 - mae: 0.7195 - val_loss: 0.9777 - val_mse: 0.9777 - val_mae: 0.9002\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.7901 - mse: 0.7901 - mae: 0.7174 - val_loss: 0.9767 - val_mse: 0.9767 - val_mae: 0.8998\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 475us/step - loss: 0.7858 - mse: 0.7858 - mae: 0.7152 - val_loss: 0.9769 - val_mse: 0.9769 - val_mae: 0.9003\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 0.7815 - mse: 0.7815 - mae: 0.7130 - val_loss: 0.9772 - val_mse: 0.9772 - val_mae: 0.9008\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 418us/step - loss: 0.7776 - mse: 0.7776 - mae: 0.7110 - val_loss: 0.9764 - val_mse: 0.9764 - val_mae: 0.9006\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.7735 - mse: 0.7735 - mae: 0.7089 - val_loss: 0.9745 - val_mse: 0.9745 - val_mae: 0.8999\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 568us/step - loss: 0.7695 - mse: 0.7695 - mae: 0.7068 - val_loss: 0.9723 - val_mse: 0.9723 - val_mae: 0.8991\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.7658 - mse: 0.7658 - mae: 0.7048 - val_loss: 0.9718 - val_mse: 0.9718 - val_mae: 0.8991\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 626us/step - loss: 0.7621 - mse: 0.7621 - mae: 0.7027 - val_loss: 0.9726 - val_mse: 0.9726 - val_mae: 0.8998\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 258us/step - loss: 0.7585 - mse: 0.7585 - mae: 0.7005 - val_loss: 0.9708 - val_mse: 0.9708 - val_mae: 0.8994\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.7553 - mse: 0.7553 - mae: 0.6981 - val_loss: 0.9711 - val_mse: 0.9711 - val_mae: 0.9000\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.7519 - mse: 0.7519 - mae: 0.6959 - val_loss: 0.9725 - val_mse: 0.9725 - val_mae: 0.9010\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 383us/step - loss: 0.7485 - mse: 0.7485 - mae: 0.6940 - val_loss: 0.9741 - val_mse: 0.9741 - val_mae: 0.9019\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 394us/step - loss: 0.7454 - mse: 0.7454 - mae: 0.6923 - val_loss: 0.9743 - val_mse: 0.9743 - val_mae: 0.9022\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.7424 - mse: 0.7424 - mae: 0.6904 - val_loss: 0.9746 - val_mse: 0.9746 - val_mae: 0.9024\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 475us/step - loss: 0.7392 - mse: 0.7392 - mae: 0.6885 - val_loss: 0.9759 - val_mse: 0.9759 - val_mae: 0.9031\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 406us/step - loss: 0.7359 - mse: 0.7359 - mae: 0.6867 - val_loss: 0.9773 - val_mse: 0.9773 - val_mae: 0.9037\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.7327 - mse: 0.7327 - mae: 0.6849 - val_loss: 0.9781 - val_mse: 0.9781 - val_mae: 0.9039\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 0.7296 - mse: 0.7296 - mae: 0.6832 - val_loss: 0.9779 - val_mse: 0.9779 - val_mae: 0.9035\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 452us/step - loss: 0.7265 - mse: 0.7265 - mae: 0.6815 - val_loss: 0.9756 - val_mse: 0.9756 - val_mae: 0.9023\n",
      "39\n",
      "[39]\n",
      "Train on 96 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 7.3306 - mse: 7.3306 - mae: 2.3783 - val_loss: 4.6545 - val_mse: 4.6545 - val_mae: 2.0024\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 449us/step - loss: 6.0890 - mse: 6.0890 - mae: 2.1003 - val_loss: 3.7498 - val_mse: 3.7498 - val_mae: 1.7548\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 280us/step - loss: 5.0947 - mse: 5.0947 - mae: 1.8495 - val_loss: 3.0625 - val_mse: 3.0625 - val_mae: 1.5295\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 301us/step - loss: 4.2703 - mse: 4.2703 - mae: 1.6282 - val_loss: 2.4957 - val_mse: 2.4957 - val_mae: 1.3172\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 395us/step - loss: 3.6391 - mse: 3.6391 - mae: 1.4415 - val_loss: 2.0853 - val_mse: 2.0853 - val_mae: 1.1405\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 291us/step - loss: 3.1523 - mse: 3.1523 - mae: 1.2899 - val_loss: 1.7538 - val_mse: 1.7538 - val_mae: 0.9977\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 2.7526 - mse: 2.7526 - mae: 1.1564 - val_loss: 1.4670 - val_mse: 1.4670 - val_mae: 0.9078\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 343us/step - loss: 2.4265 - mse: 2.4265 - mae: 1.0525 - val_loss: 1.2404 - val_mse: 1.2404 - val_mae: 0.8647\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 364us/step - loss: 2.1671 - mse: 2.1671 - mae: 0.9910 - val_loss: 1.0658 - val_mse: 1.0658 - val_mae: 0.8400\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 343us/step - loss: 1.9734 - mse: 1.9734 - mae: 0.9636 - val_loss: 0.9440 - val_mse: 0.9440 - val_mae: 0.8326\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 280us/step - loss: 1.8469 - mse: 1.8469 - mae: 0.9636 - val_loss: 0.8729 - val_mse: 0.8729 - val_mae: 0.8260\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 280us/step - loss: 1.7754 - mse: 1.7754 - mae: 0.9718 - val_loss: 0.8404 - val_mse: 0.8404 - val_mae: 0.8199\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 291us/step - loss: 1.7457 - mse: 1.7457 - mae: 0.9809 - val_loss: 0.8339 - val_mse: 0.8339 - val_mae: 0.8155\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 332us/step - loss: 1.7409 - mse: 1.7409 - mae: 0.9942 - val_loss: 0.8394 - val_mse: 0.8394 - val_mae: 0.8126\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 1.7449 - mse: 1.7449 - mae: 1.0058 - val_loss: 0.8467 - val_mse: 0.8467 - val_mae: 0.8132\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 1.7468 - mse: 1.7468 - mae: 1.0124 - val_loss: 0.8504 - val_mse: 0.8504 - val_mae: 0.8141\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 343us/step - loss: 1.7424 - mse: 1.7424 - mae: 1.0133 - val_loss: 0.8498 - val_mse: 0.8498 - val_mae: 0.8139\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 1.7334 - mse: 1.7334 - mae: 1.0102 - val_loss: 0.8454 - val_mse: 0.8454 - val_mae: 0.8126\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 488us/step - loss: 1.7218 - mse: 1.7218 - mae: 1.0048 - val_loss: 0.8389 - val_mse: 0.8389 - val_mae: 0.8112\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 332us/step - loss: 1.7091 - mse: 1.7091 - mae: 0.9982 - val_loss: 0.8321 - val_mse: 0.8321 - val_mae: 0.8110\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 291us/step - loss: 1.6969 - mse: 1.6969 - mae: 0.9915 - val_loss: 0.8259 - val_mse: 0.8259 - val_mae: 0.8108\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 1.6860 - mse: 1.6860 - mae: 0.9852 - val_loss: 0.8209 - val_mse: 0.8209 - val_mae: 0.8104\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 1.6767 - mse: 1.6767 - mae: 0.9798 - val_loss: 0.8179 - val_mse: 0.8179 - val_mae: 0.8105\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 291us/step - loss: 1.6680 - mse: 1.6680 - mae: 0.9755 - val_loss: 0.8161 - val_mse: 0.8161 - val_mae: 0.8106\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 353us/step - loss: 1.6603 - mse: 1.6603 - mae: 0.9719 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.8105\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 301us/step - loss: 1.6528 - mse: 1.6528 - mae: 0.9693 - val_loss: 0.8135 - val_mse: 0.8135 - val_mae: 0.8100\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 447us/step - loss: 1.6461 - mse: 1.6461 - mae: 0.9676 - val_loss: 0.8129 - val_mse: 0.8129 - val_mae: 0.8095\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 457us/step - loss: 1.6397 - mse: 1.6397 - mae: 0.9663 - val_loss: 0.8129 - val_mse: 0.8129 - val_mae: 0.8093\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 343us/step - loss: 1.6336 - mse: 1.6336 - mae: 0.9653 - val_loss: 0.8131 - val_mse: 0.8131 - val_mae: 0.8091\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 301us/step - loss: 1.6277 - mse: 1.6277 - mae: 0.9646 - val_loss: 0.8134 - val_mse: 0.8134 - val_mae: 0.8089\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 1.6219 - mse: 1.6219 - mae: 0.9638 - val_loss: 0.8136 - val_mse: 0.8136 - val_mae: 0.8087\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 364us/step - loss: 1.6158 - mse: 1.6158 - mae: 0.9629 - val_loss: 0.8135 - val_mse: 0.8135 - val_mae: 0.8082\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 395us/step - loss: 1.6096 - mse: 1.6096 - mae: 0.9620 - val_loss: 0.8136 - val_mse: 0.8136 - val_mae: 0.8079\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 356us/step - loss: 1.6033 - mse: 1.6033 - mae: 0.9605 - val_loss: 0.8140 - val_mse: 0.8140 - val_mae: 0.8080\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 312us/step - loss: 1.5976 - mse: 1.5976 - mae: 0.9589 - val_loss: 0.8144 - val_mse: 0.8144 - val_mae: 0.8080\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 343us/step - loss: 1.5920 - mse: 1.5920 - mae: 0.9571 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.8079\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 312us/step - loss: 1.5863 - mse: 1.5863 - mae: 0.9555 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.8079\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 332us/step - loss: 1.5805 - mse: 1.5805 - mae: 0.9537 - val_loss: 0.8153 - val_mse: 0.8153 - val_mae: 0.8081\n",
      "40\n",
      "[40]\n",
      "Train on 78 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 3.7937 - mse: 3.7937 - mae: 1.4779 - val_loss: 1.4913 - val_mse: 1.4913 - val_mae: 1.0481\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 281us/step - loss: 3.2802 - mse: 3.2802 - mae: 1.3289 - val_loss: 1.1693 - val_mse: 1.1693 - val_mae: 0.8762\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 422us/step - loss: 2.8307 - mse: 2.8307 - mae: 1.1862 - val_loss: 0.9038 - val_mse: 0.9038 - val_mae: 0.7025\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 409us/step - loss: 2.4903 - mse: 2.4903 - mae: 1.0895 - val_loss: 0.7074 - val_mse: 0.7074 - val_mae: 0.5573\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 307us/step - loss: 2.2565 - mse: 2.2565 - mae: 1.0353 - val_loss: 0.5716 - val_mse: 0.5716 - val_mae: 0.4740\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 550us/step - loss: 2.1118 - mse: 2.1118 - mae: 1.0336 - val_loss: 0.4884 - val_mse: 0.4884 - val_mae: 0.4210\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 396us/step - loss: 2.0276 - mse: 2.0276 - mae: 1.0454 - val_loss: 0.4435 - val_mse: 0.4435 - val_mae: 0.4303\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 422us/step - loss: 1.9846 - mse: 1.9846 - mae: 1.0558 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4408\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 345us/step - loss: 1.9544 - mse: 1.9544 - mae: 1.0590 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 294us/step - loss: 1.9200 - mse: 1.9200 - mae: 1.0565 - val_loss: 0.4094 - val_mse: 0.4094 - val_mae: 0.4542\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 243us/step - loss: 1.8796 - mse: 1.8796 - mae: 1.0471 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4536\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 401us/step - loss: 1.8360 - mse: 1.8360 - mae: 1.0338 - val_loss: 0.4084 - val_mse: 0.4084 - val_mae: 0.4493\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 401us/step - loss: 1.7933 - mse: 1.7933 - mae: 1.0184 - val_loss: 0.4118 - val_mse: 0.4118 - val_mae: 0.4426\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 200us/step - loss: 1.7556 - mse: 1.7556 - mae: 1.0030 - val_loss: 0.4175 - val_mse: 0.4175 - val_mae: 0.4361\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 200us/step - loss: 1.7250 - mse: 1.7250 - mae: 0.9887 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4326\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 468us/step - loss: 1.7020 - mse: 1.7020 - mae: 0.9761 - val_loss: 0.4301 - val_mse: 0.4301 - val_mae: 0.4314\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 384us/step - loss: 1.6823 - mse: 1.6823 - mae: 0.9653 - val_loss: 0.4346 - val_mse: 0.4346 - val_mae: 0.4315\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 307us/step - loss: 1.6641 - mse: 1.6641 - mae: 0.9566 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4329\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 333us/step - loss: 1.6463 - mse: 1.6463 - mae: 0.9500 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4356\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 250us/step - loss: 1.6281 - mse: 1.6281 - mae: 0.9450 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.4391\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 524us/step - loss: 1.6098 - mse: 1.6098 - mae: 0.9411 - val_loss: 0.4336 - val_mse: 0.4336 - val_mae: 0.4431\n",
      "41\n",
      "[41]\n",
      "Train on 93 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 9.9164 - mse: 9.9164 - mae: 2.9543 - val_loss: 4.1610 - val_mse: 4.1610 - val_mae: 1.9210\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 268us/step - loss: 8.3406 - mse: 8.3406 - mae: 2.6752 - val_loss: 3.3919 - val_mse: 3.3919 - val_mae: 1.7001\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 6.8520 - mse: 6.8520 - mae: 2.3841 - val_loss: 2.6745 - val_mse: 2.6745 - val_mae: 1.4697\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 5.4690 - mse: 5.4690 - mae: 2.0819 - val_loss: 2.0192 - val_mse: 2.0192 - val_mae: 1.2220\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 4.7284 - mse: 4.7284 - mae: 1.853 - 0s 418us/step - loss: 4.1964 - mse: 4.1964 - mae: 1.7586 - val_loss: 1.4611 - val_mse: 1.4611 - val_mae: 0.9536\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 461us/step - loss: 3.0695 - mse: 3.0695 - mae: 1.4276 - val_loss: 1.0292 - val_mse: 1.0292 - val_mae: 0.7454\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 2.1914 - mse: 2.1914 - mae: 1.1488 - val_loss: 0.7582 - val_mse: 0.7582 - val_mae: 0.6618\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.6314 - mse: 1.6314 - mae: 0.9755 - val_loss: 0.6446 - val_mse: 0.6446 - val_mae: 0.6572\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 281us/step - loss: 1.3639 - mse: 1.3639 - mae: 0.9134 - val_loss: 0.6492 - val_mse: 0.6492 - val_mae: 0.7011\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 1.3015 - mse: 1.3015 - mae: 0.9169 - val_loss: 0.6877 - val_mse: 0.6877 - val_mae: 0.7365\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 1.3051 - mse: 1.3051 - mae: 0.9313 - val_loss: 0.6971 - val_mse: 0.6971 - val_mae: 0.7443\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 1.2865 - mse: 1.2865 - mae: 0.9268 - val_loss: 0.6706 - val_mse: 0.6706 - val_mae: 0.7313\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 440us/step - loss: 1.2410 - mse: 1.2411 - mae: 0.9073 - val_loss: 0.6325 - val_mse: 0.6325 - val_mae: 0.7063\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 1.1996 - mse: 1.1996 - mae: 0.8845 - val_loss: 0.6045 - val_mse: 0.6045 - val_mae: 0.6788\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 1.1796 - mse: 1.1796 - mae: 0.8685 - val_loss: 0.5915 - val_mse: 0.5915 - val_mae: 0.6575\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 1.1768 - mse: 1.1768 - mae: 0.8564 - val_loss: 0.5870 - val_mse: 0.5870 - val_mae: 0.6486\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 633us/step - loss: 1.1745 - mse: 1.1745 - mae: 0.8515 - val_loss: 0.5842 - val_mse: 0.5842 - val_mae: 0.6441\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 305us/step - loss: 1.1624 - mse: 1.1624 - mae: 0.8457 - val_loss: 0.5799 - val_mse: 0.5799 - val_mae: 0.6428\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 515us/step - loss: 1.1398 - mse: 1.1398 - mae: 0.8394 - val_loss: 0.5760 - val_mse: 0.5760 - val_mae: 0.6445\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 1.1119 - mse: 1.1119 - mae: 0.8339 - val_loss: 0.5730 - val_mse: 0.5730 - val_mae: 0.6477\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 1.0845 - mse: 1.0845 - mae: 0.8286 - val_loss: 0.5709 - val_mse: 0.5709 - val_mae: 0.6506\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 1.0607 - mse: 1.0607 - mae: 0.8235 - val_loss: 0.5687 - val_mse: 0.5687 - val_mae: 0.6522\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 1.0411 - mse: 1.0411 - mae: 0.8188 - val_loss: 0.5665 - val_mse: 0.5665 - val_mae: 0.6526\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 293us/step - loss: 1.0248 - mse: 1.0248 - mae: 0.8141 - val_loss: 0.5644 - val_mse: 0.5644 - val_mae: 0.6520\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 1.0109 - mse: 1.0109 - mae: 0.8094 - val_loss: 0.5614 - val_mse: 0.5614 - val_mae: 0.6503\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.9985 - mse: 0.9985 - mae: 0.8043 - val_loss: 0.5579 - val_mse: 0.5579 - val_mae: 0.6480\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 0.9864 - mse: 0.9864 - mae: 0.7992 - val_loss: 0.5546 - val_mse: 0.5546 - val_mae: 0.6459\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 0.9744 - mse: 0.9744 - mae: 0.7943 - val_loss: 0.5515 - val_mse: 0.5515 - val_mae: 0.6441\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.9621 - mse: 0.9621 - mae: 0.7897 - val_loss: 0.5483 - val_mse: 0.5483 - val_mae: 0.6424\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.9498 - mse: 0.9498 - mae: 0.7853 - val_loss: 0.5451 - val_mse: 0.5451 - val_mae: 0.6410\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 0.9379 - mse: 0.9379 - mae: 0.7812 - val_loss: 0.5421 - val_mse: 0.5421 - val_mae: 0.6396\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 0.9268 - mse: 0.9268 - mae: 0.7775 - val_loss: 0.5394 - val_mse: 0.5394 - val_mae: 0.6382\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.9164 - mse: 0.9164 - mae: 0.7739 - val_loss: 0.5369 - val_mse: 0.5369 - val_mae: 0.6367\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 0.9067 - mse: 0.9067 - mae: 0.7703 - val_loss: 0.5348 - val_mse: 0.5348 - val_mae: 0.6354\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 0.8973 - mse: 0.8973 - mae: 0.7664 - val_loss: 0.5330 - val_mse: 0.5330 - val_mae: 0.6344\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 333us/step - loss: 0.8883 - mse: 0.8883 - mae: 0.7627 - val_loss: 0.5315 - val_mse: 0.5315 - val_mae: 0.6336\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 0.8796 - mse: 0.8796 - mae: 0.7590 - val_loss: 0.5302 - val_mse: 0.5302 - val_mae: 0.6329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 0.8713 - mse: 0.8713 - mae: 0.7554 - val_loss: 0.5290 - val_mse: 0.5290 - val_mae: 0.6322\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 0.8633 - mse: 0.8633 - mae: 0.7519 - val_loss: 0.5279 - val_mse: 0.5279 - val_mae: 0.6317\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 251us/step - loss: 0.8557 - mse: 0.8557 - mae: 0.7484 - val_loss: 0.5268 - val_mse: 0.5268 - val_mae: 0.6312\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 0.8485 - mse: 0.8485 - mae: 0.7450 - val_loss: 0.5258 - val_mse: 0.5258 - val_mae: 0.6306\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 429us/step - loss: 0.8418 - mse: 0.8418 - mae: 0.7417 - val_loss: 0.5248 - val_mse: 0.5248 - val_mae: 0.6298\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.8351 - mse: 0.8351 - mae: 0.7384 - val_loss: 0.5234 - val_mse: 0.5234 - val_mae: 0.6288\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.8283 - mse: 0.8283 - mae: 0.7352 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.6278\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 525us/step - loss: 0.8214 - mse: 0.8214 - mae: 0.7320 - val_loss: 0.5206 - val_mse: 0.5206 - val_mae: 0.6266\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 0.8149 - mse: 0.8149 - mae: 0.7288 - val_loss: 0.5196 - val_mse: 0.5196 - val_mae: 0.6255\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 536us/step - loss: 0.8090 - mse: 0.8090 - mae: 0.7262 - val_loss: 0.5184 - val_mse: 0.5184 - val_mae: 0.6239\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.8036 - mse: 0.8036 - mae: 0.7236 - val_loss: 0.5175 - val_mse: 0.5175 - val_mae: 0.6226\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 0.7986 - mse: 0.7986 - mae: 0.7212 - val_loss: 0.5163 - val_mse: 0.5163 - val_mae: 0.6211\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.7935 - mse: 0.7935 - mae: 0.7188 - val_loss: 0.5151 - val_mse: 0.5151 - val_mae: 0.6194\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.7885 - mse: 0.7885 - mae: 0.7164 - val_loss: 0.5139 - val_mse: 0.5139 - val_mae: 0.6178\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.7838 - mse: 0.7838 - mae: 0.7140 - val_loss: 0.5127 - val_mse: 0.5127 - val_mae: 0.6164\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 0.7789 - mse: 0.7789 - mae: 0.7116 - val_loss: 0.5117 - val_mse: 0.5117 - val_mae: 0.6152\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.7741 - mse: 0.7741 - mae: 0.7092 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.6141\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 0.7696 - mse: 0.7696 - mae: 0.7070 - val_loss: 0.5102 - val_mse: 0.5102 - val_mae: 0.6128\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 0.7649 - mse: 0.7649 - mae: 0.7048 - val_loss: 0.5091 - val_mse: 0.5091 - val_mae: 0.6115\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.7597 - mse: 0.7597 - mae: 0.7023 - val_loss: 0.5080 - val_mse: 0.5080 - val_mae: 0.6103\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.7542 - mse: 0.7542 - mae: 0.6994 - val_loss: 0.5068 - val_mse: 0.5068 - val_mae: 0.6091\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 525us/step - loss: 0.7489 - mse: 0.7489 - mae: 0.6966 - val_loss: 0.5057 - val_mse: 0.5057 - val_mae: 0.6078\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.7438 - mse: 0.7438 - mae: 0.6938 - val_loss: 0.5050 - val_mse: 0.5050 - val_mae: 0.6069\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7149 - mse: 0.7149 - mae: 0.713 - 0s 431us/step - loss: 0.7384 - mse: 0.7384 - mae: 0.6908 - val_loss: 0.5042 - val_mse: 0.5042 - val_mae: 0.6060\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 0s 343us/step - loss: 0.7335 - mse: 0.7335 - mae: 0.6880 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.6052\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 397us/step - loss: 0.7291 - mse: 0.7291 - mae: 0.6856 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.6048\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 0s 279us/step - loss: 0.7246 - mse: 0.7246 - mae: 0.6835 - val_loss: 0.5030 - val_mse: 0.5030 - val_mae: 0.6043\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.7204 - mse: 0.7204 - mae: 0.6816 - val_loss: 0.5031 - val_mse: 0.5031 - val_mae: 0.6039\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.7165 - mse: 0.7165 - mae: 0.6799 - val_loss: 0.5034 - val_mse: 0.5034 - val_mae: 0.6036\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.7127 - mse: 0.7127 - mae: 0.6783 - val_loss: 0.5041 - val_mse: 0.5041 - val_mae: 0.6034\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.7090 - mse: 0.7090 - mae: 0.6767 - val_loss: 0.5051 - val_mse: 0.5051 - val_mae: 0.6033\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 0s 300us/step - loss: 0.7055 - mse: 0.7055 - mae: 0.6751 - val_loss: 0.5057 - val_mse: 0.5057 - val_mae: 0.6031\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.7022 - mse: 0.7022 - mae: 0.6734 - val_loss: 0.5048 - val_mse: 0.5048 - val_mae: 0.6018\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 0.6989 - mse: 0.6989 - mae: 0.6717 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.6005\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 0s 373us/step - loss: 0.6954 - mse: 0.6954 - mae: 0.6700 - val_loss: 0.5035 - val_mse: 0.5035 - val_mae: 0.5999\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.6915 - mse: 0.6915 - mae: 0.6681 - val_loss: 0.5038 - val_mse: 0.5038 - val_mae: 0.5996\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 0.6879 - mse: 0.6879 - mae: 0.6663 - val_loss: 0.5035 - val_mse: 0.5035 - val_mae: 0.5991\n",
      "42\n",
      "[42]\n",
      "Train on 97 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 7.4909 - mse: 7.4909 - mae: 2.3565 - val_loss: 3.8923 - val_mse: 3.8923 - val_mae: 1.6977\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 442us/step - loss: 5.9215 - mse: 5.9215 - mae: 2.0002 - val_loss: 2.8314 - val_mse: 2.8314 - val_mae: 1.4432\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 288us/step - loss: 4.6557 - mse: 4.6557 - mae: 1.6571 - val_loss: 2.0361 - val_mse: 2.0361 - val_mae: 1.2064\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 308us/step - loss: 3.7001 - mse: 3.7001 - mae: 1.4117 - val_loss: 1.4972 - val_mse: 1.4972 - val_mae: 0.9865\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 555us/step - loss: 3.0516 - mse: 3.0516 - mae: 1.2340 - val_loss: 1.1713 - val_mse: 1.1713 - val_mae: 0.8548\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 298us/step - loss: 2.6576 - mse: 2.6576 - mae: 1.1568 - val_loss: 1.0232 - val_mse: 1.0232 - val_mae: 0.7932\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 298us/step - loss: 2.4456 - mse: 2.4456 - mae: 1.1360 - val_loss: 0.9751 - val_mse: 0.9751 - val_mae: 0.7698\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 380us/step - loss: 2.3304 - mse: 2.3304 - mae: 1.1366 - val_loss: 0.9725 - val_mse: 0.9725 - val_mae: 0.7730\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 278us/step - loss: 2.2528 - mse: 2.2528 - mae: 1.1303 - val_loss: 0.9786 - val_mse: 0.9786 - val_mae: 0.7847\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 339us/step - loss: 2.1865 - mse: 2.1865 - mae: 1.1163 - val_loss: 0.9834 - val_mse: 0.9834 - val_mae: 0.7997\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 308us/step - loss: 2.1217 - mse: 2.1217 - mae: 1.0979 - val_loss: 0.9714 - val_mse: 0.9714 - val_mae: 0.8048\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 278us/step - loss: 2.0641 - mse: 2.0641 - mae: 1.0756 - val_loss: 0.9629 - val_mse: 0.9629 - val_mae: 0.8065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 298us/step - loss: 2.0245 - mse: 2.0245 - mae: 1.0578 - val_loss: 0.9605 - val_mse: 0.9605 - val_mae: 0.8060\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 339us/step - loss: 1.9931 - mse: 1.9931 - mae: 1.0414 - val_loss: 0.9619 - val_mse: 0.9619 - val_mae: 0.8045\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 308us/step - loss: 1.9658 - mse: 1.9658 - mae: 1.0266 - val_loss: 0.9641 - val_mse: 0.9641 - val_mae: 0.8026\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 350us/step - loss: 1.9430 - mse: 1.9430 - mae: 1.0139 - val_loss: 0.9673 - val_mse: 0.9673 - val_mae: 0.8010\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 585us/step - loss: 1.9217 - mse: 1.9217 - mae: 1.0031 - val_loss: 0.9713 - val_mse: 0.9713 - val_mae: 0.8037\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 1.4922 - mse: 1.4922 - mae: 0.900 - 0s 429us/step - loss: 1.9000 - mse: 1.9000 - mae: 0.9940 - val_loss: 0.9758 - val_mse: 0.9758 - val_mae: 0.8073\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 391us/step - loss: 1.8790 - mse: 1.8790 - mae: 0.9860 - val_loss: 0.9807 - val_mse: 0.9807 - val_mae: 0.8112\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 391us/step - loss: 1.8588 - mse: 1.8588 - mae: 0.9790 - val_loss: 0.9855 - val_mse: 0.9855 - val_mae: 0.8150\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 258us/step - loss: 1.8395 - mse: 1.8395 - mae: 0.9723 - val_loss: 0.9914 - val_mse: 0.9914 - val_mae: 0.8187\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 308us/step - loss: 1.8215 - mse: 1.8215 - mae: 0.9659 - val_loss: 0.9980 - val_mse: 0.9980 - val_mae: 0.8222\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 370us/step - loss: 1.8052 - mse: 1.8052 - mae: 0.9593 - val_loss: 1.0046 - val_mse: 1.0046 - val_mae: 0.8248\n",
      "43\n",
      "[43]\n",
      "Train on 71 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 1s 18ms/step - loss: 1.8304 - mse: 1.8304 - mae: 1.0205 - val_loss: 1.1625 - val_mse: 1.1625 - val_mae: 0.8131\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 496us/step - loss: 1.6512 - mse: 1.6512 - mae: 0.9474 - val_loss: 0.9790 - val_mse: 0.9790 - val_mae: 0.7698\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 393us/step - loss: 1.4825 - mse: 1.4825 - mae: 0.8843 - val_loss: 0.8616 - val_mse: 0.8616 - val_mae: 0.7515\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 407us/step - loss: 1.3328 - mse: 1.3328 - mae: 0.8354 - val_loss: 0.7994 - val_mse: 0.7994 - val_mae: 0.7657\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 393us/step - loss: 1.2135 - mse: 1.2135 - mae: 0.8159 - val_loss: 0.7957 - val_mse: 0.7957 - val_mae: 0.7851\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 365us/step - loss: 1.1328 - mse: 1.1328 - mae: 0.8122 - val_loss: 0.8399 - val_mse: 0.8399 - val_mae: 0.8021\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 435us/step - loss: 1.0883 - mse: 1.0883 - mae: 0.8215 - val_loss: 0.9181 - val_mse: 0.9181 - val_mae: 0.8179\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 520us/step - loss: 1.0767 - mse: 1.0767 - mae: 0.8440 - val_loss: 1.0088 - val_mse: 1.0088 - val_mae: 0.8405\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 393us/step - loss: 1.0843 - mse: 1.0843 - mae: 0.8630 - val_loss: 1.0859 - val_mse: 1.0859 - val_mae: 0.8763\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 393us/step - loss: 1.0946 - mse: 1.0946 - mae: 0.8743 - val_loss: 1.1306 - val_mse: 1.1306 - val_mae: 0.8974\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 590us/step - loss: 1.0957 - mse: 1.0957 - mae: 0.8780 - val_loss: 1.1404 - val_mse: 1.1404 - val_mae: 0.9023\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 342us/step - loss: 1.0852 - mse: 1.0852 - mae: 0.8740 - val_loss: 1.1238 - val_mse: 1.1238 - val_mae: 0.8951\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 351us/step - loss: 1.0667 - mse: 1.0667 - mae: 0.8644 - val_loss: 1.0928 - val_mse: 1.0928 - val_mae: 0.8808\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 365us/step - loss: 1.0457 - mse: 1.0457 - mae: 0.8518 - val_loss: 1.0589 - val_mse: 1.0589 - val_mae: 0.8655\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 478us/step - loss: 1.0261 - mse: 1.0261 - mae: 0.8391 - val_loss: 1.0288 - val_mse: 1.0288 - val_mae: 0.8644\n",
      "44\n",
      "[44]\n",
      "Train on 73 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 11.6319 - mse: 11.6319 - mae: 2.6906 - val_loss: 1.6802 - val_mse: 1.6802 - val_mae: 1.0622\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 314us/step - loss: 9.4754 - mse: 9.4754 - mae: 2.3756 - val_loss: 1.5805 - val_mse: 1.5805 - val_mae: 0.9883\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 342us/step - loss: 7.7420 - mse: 7.7420 - mae: 2.0832 - val_loss: 1.5737 - val_mse: 1.5737 - val_mae: 0.9133\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 410us/step - loss: 6.4590 - mse: 6.4590 - mae: 1.8233 - val_loss: 1.6433 - val_mse: 1.6433 - val_mae: 0.8578\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 369us/step - loss: 5.5796 - mse: 5.5796 - mae: 1.6294 - val_loss: 1.7655 - val_mse: 1.7655 - val_mae: 0.8220\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 383us/step - loss: 5.0239 - mse: 5.0239 - mae: 1.4974 - val_loss: 1.9125 - val_mse: 1.9125 - val_mae: 0.8129\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 342us/step - loss: 4.7157 - mse: 4.7157 - mae: 1.4037 - val_loss: 2.0386 - val_mse: 2.0386 - val_mae: 0.8400\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 342us/step - loss: 4.5590 - mse: 4.5590 - mae: 1.3457 - val_loss: 2.1439 - val_mse: 2.1439 - val_mae: 0.8828\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 342us/step - loss: 4.4859 - mse: 4.4859 - mae: 1.3122 - val_loss: 2.2124 - val_mse: 2.2124 - val_mae: 0.9092\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 587us/step - loss: 4.4442 - mse: 4.4442 - mae: 1.2924 - val_loss: 2.2362 - val_mse: 2.2362 - val_mae: 0.9212\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 610us/step - loss: 4.3960 - mse: 4.3960 - mae: 1.2782 - val_loss: 2.2217 - val_mse: 2.2217 - val_mae: 0.9156\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 396us/step - loss: 4.3338 - mse: 4.3338 - mae: 1.2641 - val_loss: 2.1798 - val_mse: 2.1798 - val_mae: 0.8959\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 587us/step - loss: 4.2631 - mse: 4.2631 - mae: 1.2512 - val_loss: 2.1219 - val_mse: 2.1219 - val_mae: 0.8665\n",
      "45\n",
      "[45]\n",
      "Train on 102 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 12.6265 - mse: 12.6265 - mae: 3.2182 - val_loss: 7.5807 - val_mse: 7.5807 - val_mae: 2.5858\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 213us/step - loss: 10.3185 - mse: 10.3185 - mae: 2.8438 - val_loss: 6.1461 - val_mse: 6.1461 - val_mae: 2.2985\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 244us/step - loss: 8.6619 - mse: 8.6619 - mae: 2.5488 - val_loss: 5.1385 - val_mse: 5.1385 - val_mae: 2.0804\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 334us/step - loss: 7.5432 - mse: 7.5432 - mae: 2.3247 - val_loss: 4.4436 - val_mse: 4.4436 - val_mae: 1.9199\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 400us/step - loss: 6.7316 - mse: 6.7316 - mae: 2.1455 - val_loss: 3.9259 - val_mse: 3.9259 - val_mae: 1.7854\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 264us/step - loss: 6.0854 - mse: 6.0854 - mae: 1.9916 - val_loss: 3.4968 - val_mse: 3.4968 - val_mae: 1.6706\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 549us/step - loss: 5.5343 - mse: 5.5343 - mae: 1.8531 - val_loss: 3.0930 - val_mse: 3.0930 - val_mae: 1.5526\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 275us/step - loss: 5.0322 - mse: 5.0322 - mae: 1.7198 - val_loss: 2.6933 - val_mse: 2.6933 - val_mae: 1.4210\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 551us/step - loss: 4.5551 - mse: 4.5551 - mae: 1.5904 - val_loss: 2.3127 - val_mse: 2.3127 - val_mae: 1.2799\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 321us/step - loss: 4.1108 - mse: 4.1108 - mae: 1.4770 - val_loss: 1.9789 - val_mse: 1.9789 - val_mae: 1.1387\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 3.7049 - mse: 3.7049 - mae: 1.3921 - val_loss: 1.6652 - val_mse: 1.6652 - val_mae: 0.9947\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 384us/step - loss: 3.3442 - mse: 3.3442 - mae: 1.3212 - val_loss: 1.3895 - val_mse: 1.3895 - val_mae: 0.8899\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 396us/step - loss: 3.0384 - mse: 3.0384 - mae: 1.2652 - val_loss: 1.1623 - val_mse: 1.1623 - val_mae: 0.8121\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 470us/step - loss: 2.7917 - mse: 2.7917 - mae: 1.2294 - val_loss: 0.9835 - val_mse: 0.9835 - val_mae: 0.7541\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 348us/step - loss: 2.6076 - mse: 2.6076 - mae: 1.2137 - val_loss: 0.8528 - val_mse: 0.8528 - val_mae: 0.7036\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 315us/step - loss: 2.4811 - mse: 2.4811 - mae: 1.2093 - val_loss: 0.7668 - val_mse: 0.7668 - val_mae: 0.6719\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 570us/step - loss: 2.4029 - mse: 2.4029 - mae: 1.2111 - val_loss: 0.7165 - val_mse: 0.7165 - val_mae: 0.6605\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 707us/step - loss: 2.3600 - mse: 2.3600 - mae: 1.2150 - val_loss: 0.6901 - val_mse: 0.6901 - val_mae: 0.6514\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 394us/step - loss: 2.3388 - mse: 2.3388 - mae: 1.2203 - val_loss: 0.6786 - val_mse: 0.6786 - val_mae: 0.6464\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 577us/step - loss: 2.3269 - mse: 2.3269 - mae: 1.2244 - val_loss: 0.6754 - val_mse: 0.6754 - val_mae: 0.6557\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 342us/step - loss: 2.3182 - mse: 2.3182 - mae: 1.2265 - val_loss: 0.6747 - val_mse: 0.6747 - val_mae: 0.6615\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 267us/step - loss: 2.3084 - mse: 2.3084 - mae: 1.2262 - val_loss: 0.6742 - val_mse: 0.6742 - val_mae: 0.6639\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 275us/step - loss: 2.2968 - mse: 2.2968 - mae: 1.2235 - val_loss: 0.6726 - val_mse: 0.6726 - val_mae: 0.6637\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 296us/step - loss: 2.2830 - mse: 2.2830 - mae: 1.2190 - val_loss: 0.6707 - val_mse: 0.6707 - val_mae: 0.6621\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 521us/step - loss: 2.2679 - mse: 2.2679 - mae: 1.2130 - val_loss: 0.6691 - val_mse: 0.6691 - val_mae: 0.6598\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 563us/step - loss: 2.2520 - mse: 2.2520 - mae: 1.2063 - val_loss: 0.6681 - val_mse: 0.6681 - val_mae: 0.6574\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 307us/step - loss: 2.2366 - mse: 2.2366 - mae: 1.2000 - val_loss: 0.6663 - val_mse: 0.6663 - val_mae: 0.6555\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 275us/step - loss: 2.2225 - mse: 2.2225 - mae: 1.1943 - val_loss: 0.6646 - val_mse: 0.6646 - val_mae: 0.6539\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 286us/step - loss: 2.2090 - mse: 2.2090 - mae: 1.1889 - val_loss: 0.6631 - val_mse: 0.6631 - val_mae: 0.6533\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 353us/step - loss: 2.1965 - mse: 2.1965 - mae: 1.1842 - val_loss: 0.6613 - val_mse: 0.6613 - val_mae: 0.6536\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 235us/step - loss: 2.1849 - mse: 2.1849 - mae: 1.1804 - val_loss: 0.6590 - val_mse: 0.6590 - val_mae: 0.6538\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 266us/step - loss: 2.1739 - mse: 2.1739 - mae: 1.1769 - val_loss: 0.6566 - val_mse: 0.6566 - val_mae: 0.6539\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 2.1626 - mse: 2.1626 - mae: 1.1737 - val_loss: 0.6544 - val_mse: 0.6544 - val_mae: 0.6543\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 333us/step - loss: 2.1513 - mse: 2.1513 - mae: 1.1706 - val_loss: 0.6523 - val_mse: 0.6523 - val_mae: 0.6548\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 315us/step - loss: 2.1403 - mse: 2.1403 - mae: 1.1675 - val_loss: 0.6502 - val_mse: 0.6502 - val_mae: 0.6553\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 257us/step - loss: 2.1292 - mse: 2.1292 - mae: 1.1644 - val_loss: 0.6482 - val_mse: 0.6482 - val_mae: 0.6557\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 353us/step - loss: 2.1183 - mse: 2.1183 - mae: 1.1617 - val_loss: 0.6469 - val_mse: 0.6469 - val_mae: 0.6564\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 447us/step - loss: 2.1077 - mse: 2.1077 - mae: 1.1591 - val_loss: 0.6456 - val_mse: 0.6456 - val_mae: 0.6570\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 246us/step - loss: 2.0971 - mse: 2.0971 - mae: 1.1564 - val_loss: 0.6449 - val_mse: 0.6449 - val_mae: 0.6579\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 383us/step - loss: 2.0865 - mse: 2.0865 - mae: 1.1537 - val_loss: 0.6448 - val_mse: 0.6448 - val_mae: 0.6588\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 474us/step - loss: 2.0759 - mse: 2.0759 - mae: 1.1508 - val_loss: 0.6452 - val_mse: 0.6452 - val_mae: 0.6600\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 323us/step - loss: 2.0651 - mse: 2.0651 - mae: 1.1478 - val_loss: 0.6457 - val_mse: 0.6457 - val_mae: 0.6610\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 466us/step - loss: 2.0540 - mse: 2.0540 - mae: 1.1449 - val_loss: 0.6455 - val_mse: 0.6455 - val_mae: 0.6615\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 351us/step - loss: 2.0423 - mse: 2.0423 - mae: 1.1416 - val_loss: 0.6459 - val_mse: 0.6459 - val_mae: 0.6622\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 431us/step - loss: 2.0315 - mse: 2.0315 - mae: 1.1388 - val_loss: 0.6468 - val_mse: 0.6468 - val_mae: 0.6628\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 514us/step - loss: 2.0210 - mse: 2.0210 - mae: 1.1361 - val_loss: 0.6483 - val_mse: 0.6483 - val_mae: 0.6644\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 2.0109 - mse: 2.0109 - mae: 1.1337 - val_loss: 0.6494 - val_mse: 0.6494 - val_mae: 0.6659\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 411us/step - loss: 2.0012 - mse: 2.0012 - mae: 1.1315 - val_loss: 0.6515 - val_mse: 0.6515 - val_mae: 0.6681\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 383us/step - loss: 1.9913 - mse: 1.9913 - mae: 1.1287 - val_loss: 0.6520 - val_mse: 0.6520 - val_mae: 0.6687\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 324us/step - loss: 1.9814 - mse: 1.9814 - mae: 1.1254 - val_loss: 0.6525 - val_mse: 0.6525 - val_mae: 0.6693\n",
      "46\n",
      "[46]\n",
      "Train on 91 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 14.0798 - mse: 14.0798 - mae: 3.4326 - val_loss: 8.8258 - val_mse: 8.8258 - val_mae: 2.6304\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 304us/step - loss: 10.6301 - mse: 10.6301 - mae: 2.8990 - val_loss: 6.7008 - val_mse: 6.7008 - val_mae: 2.1831\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 337us/step - loss: 8.0088 - mse: 8.0088 - mae: 2.4253 - val_loss: 4.9887 - val_mse: 4.9887 - val_mae: 1.8116\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 429us/step - loss: 5.9727 - mse: 5.9727 - mae: 2.0070 - val_loss: 3.6907 - val_mse: 3.6907 - val_mae: 1.5075\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 4.4546 - mse: 4.4546 - mae: 1.6575 - val_loss: 2.7741 - val_mse: 2.7741 - val_mae: 1.2522\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 307us/step - loss: 3.4546 - mse: 3.4546 - mae: 1.4268 - val_loss: 2.1849 - val_mse: 2.1849 - val_mae: 1.1305\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 683us/step - loss: 2.8564 - mse: 2.8564 - mae: 1.2826 - val_loss: 1.8508 - val_mse: 1.8508 - val_mae: 1.0587\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 703us/step - loss: 2.5415 - mse: 2.5415 - mae: 1.2102 - val_loss: 1.7021 - val_mse: 1.7021 - val_mae: 1.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 370us/step - loss: 2.4193 - mse: 2.4193 - mae: 1.1751 - val_loss: 1.6474 - val_mse: 1.6474 - val_mae: 1.0947\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 627us/step - loss: 2.3983 - mse: 2.3983 - mae: 1.1764 - val_loss: 1.6450 - val_mse: 1.6450 - val_mae: 1.1175\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 321us/step - loss: 2.4076 - mse: 2.4076 - mae: 1.1901 - val_loss: 1.6442 - val_mse: 1.6442 - val_mae: 1.1348\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 286us/step - loss: 2.4089 - mse: 2.4089 - mae: 1.2009 - val_loss: 1.6315 - val_mse: 1.6315 - val_mae: 1.1384\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 277us/step - loss: 2.3871 - mse: 2.3871 - mae: 1.2006 - val_loss: 1.6080 - val_mse: 1.6080 - val_mae: 1.1319\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 207us/step - loss: 2.3433 - mse: 2.3433 - mae: 1.1909 - val_loss: 1.5802 - val_mse: 1.5802 - val_mae: 1.1183\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 396us/step - loss: 2.2883 - mse: 2.2883 - mae: 1.1757 - val_loss: 1.5488 - val_mse: 1.5488 - val_mae: 1.1001\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 515us/step - loss: 2.2306 - mse: 2.2306 - mae: 1.1576 - val_loss: 1.5186 - val_mse: 1.5186 - val_mae: 1.0804\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 215us/step - loss: 2.1764 - mse: 2.1764 - mae: 1.1393 - val_loss: 1.4907 - val_mse: 1.4907 - val_mae: 1.0608\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 275us/step - loss: 2.1284 - mse: 2.1284 - mae: 1.1222 - val_loss: 1.4658 - val_mse: 1.4658 - val_mae: 1.0428\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 302us/step - loss: 2.0881 - mse: 2.0881 - mae: 1.1070 - val_loss: 1.4457 - val_mse: 1.4457 - val_mae: 1.0296\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 257us/step - loss: 2.0546 - mse: 2.0546 - mae: 1.0943 - val_loss: 1.4293 - val_mse: 1.4293 - val_mae: 1.0229\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 405us/step - loss: 2.0260 - mse: 2.0260 - mae: 1.0845 - val_loss: 1.4151 - val_mse: 1.4151 - val_mae: 1.0180\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 747us/step - loss: 2.0004 - mse: 2.0004 - mae: 1.0766 - val_loss: 1.4037 - val_mse: 1.4037 - val_mae: 1.0145\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 215us/step - loss: 1.9760 - mse: 1.9760 - mae: 1.0695 - val_loss: 1.3931 - val_mse: 1.3931 - val_mae: 1.0122\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 362us/step - loss: 1.9532 - mse: 1.9532 - mae: 1.0636 - val_loss: 1.3833 - val_mse: 1.3833 - val_mae: 1.0104\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 504us/step - loss: 1.9325 - mse: 1.9325 - mae: 1.0585 - val_loss: 1.3744 - val_mse: 1.3744 - val_mae: 1.0091\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 387us/step - loss: 1.9123 - mse: 1.9123 - mae: 1.0535 - val_loss: 1.3655 - val_mse: 1.3655 - val_mae: 1.0075\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - ETA: 0s - loss: 2.3742 - mse: 2.3742 - mae: 1.129 - 0s 172us/step - loss: 1.8927 - mse: 1.8927 - mae: 1.0484 - val_loss: 1.3565 - val_mse: 1.3565 - val_mae: 1.0056\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 355us/step - loss: 1.8737 - mse: 1.8737 - mae: 1.0433 - val_loss: 1.3483 - val_mse: 1.3483 - val_mae: 1.0039\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 604us/step - loss: 1.8558 - mse: 1.8558 - mae: 1.0380 - val_loss: 1.3417 - val_mse: 1.3417 - val_mae: 1.0024\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 591us/step - loss: 1.8398 - mse: 1.8398 - mae: 1.0331 - val_loss: 1.3359 - val_mse: 1.3359 - val_mae: 1.0011\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 714us/step - loss: 1.8255 - mse: 1.8255 - mae: 1.0285 - val_loss: 1.3316 - val_mse: 1.3316 - val_mae: 1.0003\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 585us/step - loss: 1.8122 - mse: 1.8122 - mae: 1.0242 - val_loss: 1.3276 - val_mse: 1.3276 - val_mae: 0.9993\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 412us/step - loss: 1.7989 - mse: 1.7989 - mae: 1.0199 - val_loss: 1.3236 - val_mse: 1.3236 - val_mae: 0.9982\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 562us/step - loss: 1.7860 - mse: 1.7860 - mae: 1.0156 - val_loss: 1.3199 - val_mse: 1.3199 - val_mae: 0.9971\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 362us/step - loss: 1.7734 - mse: 1.7734 - mae: 1.0116 - val_loss: 1.3163 - val_mse: 1.3163 - val_mae: 0.9959\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 278us/step - loss: 1.7604 - mse: 1.7604 - mae: 1.0074 - val_loss: 1.3113 - val_mse: 1.3113 - val_mae: 0.9942\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 429us/step - loss: 1.7470 - mse: 1.7470 - mae: 1.0035 - val_loss: 1.3063 - val_mse: 1.3063 - val_mae: 0.9923\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 344us/step - loss: 1.7340 - mse: 1.7340 - mae: 0.9996 - val_loss: 1.3015 - val_mse: 1.3015 - val_mae: 0.9904\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - ETA: 0s - loss: 2.1119 - mse: 2.1119 - mae: 1.059 - 0s 330us/step - loss: 1.7217 - mse: 1.7217 - mae: 0.9959 - val_loss: 1.2971 - val_mse: 1.2971 - val_mae: 0.9889\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 438us/step - loss: 1.7098 - mse: 1.7098 - mae: 0.9923 - val_loss: 1.2928 - val_mse: 1.2928 - val_mae: 0.9873\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 491us/step - loss: 1.6978 - mse: 1.6978 - mae: 0.9889 - val_loss: 1.2883 - val_mse: 1.2883 - val_mae: 0.9855\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 387us/step - loss: 1.6859 - mse: 1.6859 - mae: 0.9863 - val_loss: 1.2836 - val_mse: 1.2836 - val_mae: 0.9838\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 462us/step - loss: 1.6742 - mse: 1.6742 - mae: 0.9838 - val_loss: 1.2792 - val_mse: 1.2792 - val_mae: 0.9821\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 939us/step - loss: 1.6630 - mse: 1.6630 - mae: 0.9813 - val_loss: 1.2745 - val_mse: 1.2745 - val_mae: 0.9805\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 545us/step - loss: 1.6519 - mse: 1.6519 - mae: 0.9789 - val_loss: 1.2704 - val_mse: 1.2704 - val_mae: 0.9793\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 437us/step - loss: 1.6409 - mse: 1.6409 - mae: 0.9765 - val_loss: 1.2666 - val_mse: 1.2666 - val_mae: 0.9781\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 354us/step - loss: 1.6302 - mse: 1.6302 - mae: 0.9741 - val_loss: 1.2630 - val_mse: 1.2630 - val_mae: 0.9769\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 470us/step - loss: 1.6198 - mse: 1.6198 - mae: 0.9716 - val_loss: 1.2589 - val_mse: 1.2589 - val_mae: 0.9756\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 389us/step - loss: 1.6091 - mse: 1.6091 - mae: 0.9689 - val_loss: 1.2544 - val_mse: 1.2544 - val_mae: 0.9740\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 374us/step - loss: 1.5991 - mse: 1.5991 - mae: 0.9664 - val_loss: 1.2508 - val_mse: 1.2508 - val_mae: 0.9728\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 479us/step - loss: 1.5894 - mse: 1.5894 - mae: 0.9640 - val_loss: 1.2476 - val_mse: 1.2476 - val_mae: 0.9717\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 626us/step - loss: 1.5798 - mse: 1.5798 - mae: 0.9616 - val_loss: 1.2446 - val_mse: 1.2446 - val_mae: 0.9707\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - ETA: 0s - loss: 1.8598 - mse: 1.8598 - mae: 1.014 - 0s 392us/step - loss: 1.5705 - mse: 1.5705 - mae: 0.9591 - val_loss: 1.2406 - val_mse: 1.2406 - val_mae: 0.9691\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 386us/step - loss: 1.5611 - mse: 1.5611 - mae: 0.9569 - val_loss: 1.2366 - val_mse: 1.2366 - val_mae: 0.9676\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 341us/step - loss: 1.5516 - mse: 1.5516 - mae: 0.9546 - val_loss: 1.2322 - val_mse: 1.2322 - val_mae: 0.9657\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 342us/step - loss: 1.5426 - mse: 1.5426 - mae: 0.9523 - val_loss: 1.2286 - val_mse: 1.2286 - val_mae: 0.9642\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 576us/step - loss: 1.5342 - mse: 1.5342 - mae: 0.9503 - val_loss: 1.2258 - val_mse: 1.2258 - val_mae: 0.9631\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 440us/step - loss: 1.5259 - mse: 1.5259 - mae: 0.9482 - val_loss: 1.2228 - val_mse: 1.2228 - val_mae: 0.9619\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 429us/step - loss: 1.5173 - mse: 1.5173 - mae: 0.9460 - val_loss: 1.2190 - val_mse: 1.2190 - val_mae: 0.9602\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 319us/step - loss: 1.5085 - mse: 1.5085 - mae: 0.9436 - val_loss: 1.2146 - val_mse: 1.2146 - val_mae: 0.9582\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 319us/step - loss: 1.4998 - mse: 1.4998 - mae: 0.9411 - val_loss: 1.2107 - val_mse: 1.2107 - val_mae: 0.9564\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 487us/step - loss: 1.4910 - mse: 1.4910 - mae: 0.9386 - val_loss: 1.2075 - val_mse: 1.2075 - val_mae: 0.9549\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 416us/step - loss: 1.4821 - mse: 1.4821 - mae: 0.9358 - val_loss: 1.2042 - val_mse: 1.2042 - val_mae: 0.9533\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 535us/step - loss: 1.4734 - mse: 1.4734 - mae: 0.9330 - val_loss: 1.2009 - val_mse: 1.2009 - val_mae: 0.9516\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 250us/step - loss: 1.4653 - mse: 1.4653 - mae: 0.9303 - val_loss: 1.1979 - val_mse: 1.1979 - val_mae: 0.9504\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 237us/step - loss: 1.4575 - mse: 1.4575 - mae: 0.9280 - val_loss: 1.1953 - val_mse: 1.1953 - val_mae: 0.9494\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 602us/step - loss: 1.4500 - mse: 1.4500 - mae: 0.9258 - val_loss: 1.1924 - val_mse: 1.1924 - val_mae: 0.9481\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 385us/step - loss: 1.4427 - mse: 1.4427 - mae: 0.9234 - val_loss: 1.1894 - val_mse: 1.1894 - val_mae: 0.9465\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 346us/step - loss: 1.4355 - mse: 1.4355 - mae: 0.9210 - val_loss: 1.1865 - val_mse: 1.1865 - val_mae: 0.9448\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 341us/step - loss: 1.4285 - mse: 1.4285 - mae: 0.9185 - val_loss: 1.1839 - val_mse: 1.1839 - val_mae: 0.9431\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 395us/step - loss: 1.4224 - mse: 1.4224 - mae: 0.9162 - val_loss: 1.1824 - val_mse: 1.1824 - val_mae: 0.9422\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 395us/step - loss: 1.4158 - mse: 1.4158 - mae: 0.9137 - val_loss: 1.1815 - val_mse: 1.1815 - val_mae: 0.9417\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 510us/step - loss: 1.4094 - mse: 1.4094 - mae: 0.9112 - val_loss: 1.1801 - val_mse: 1.1801 - val_mae: 0.9406\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 1.4031 - mse: 1.4031 - mae: 0.9088 - val_loss: 1.1779 - val_mse: 1.1779 - val_mae: 0.9389\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 451us/step - loss: 1.3966 - mse: 1.3966 - mae: 0.9063 - val_loss: 1.1753 - val_mse: 1.1753 - val_mae: 0.9370\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 160us/step - loss: 1.3903 - mse: 1.3903 - mae: 0.9040 - val_loss: 1.1720 - val_mse: 1.1720 - val_mae: 0.9348\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 636us/step - loss: 1.3839 - mse: 1.3839 - mae: 0.9018 - val_loss: 1.1683 - val_mse: 1.1683 - val_mae: 0.9326\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 406us/step - loss: 1.3775 - mse: 1.3775 - mae: 0.8996 - val_loss: 1.1641 - val_mse: 1.1641 - val_mae: 0.9302\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 329us/step - loss: 1.3715 - mse: 1.3715 - mae: 0.8975 - val_loss: 1.1609 - val_mse: 1.1609 - val_mae: 0.9281\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 397us/step - loss: 1.3645 - mse: 1.3645 - mae: 0.8947 - val_loss: 1.1582 - val_mse: 1.1582 - val_mae: 0.9259\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 650us/step - loss: 1.3582 - mse: 1.3582 - mae: 0.8918 - val_loss: 1.1558 - val_mse: 1.1558 - val_mae: 0.9236\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 321us/step - loss: 1.3523 - mse: 1.3523 - mae: 0.8890 - val_loss: 1.1530 - val_mse: 1.1530 - val_mae: 0.9214\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 399us/step - loss: 1.3464 - mse: 1.3464 - mae: 0.8868 - val_loss: 1.1509 - val_mse: 1.1509 - val_mae: 0.9198\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 450us/step - loss: 1.3406 - mse: 1.3406 - mae: 0.8847 - val_loss: 1.1493 - val_mse: 1.1493 - val_mae: 0.9183\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 393us/step - loss: 1.3348 - mse: 1.3348 - mae: 0.8824 - val_loss: 1.1472 - val_mse: 1.1472 - val_mae: 0.9164\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 296us/step - loss: 1.3301 - mse: 1.3301 - mae: 0.8807 - val_loss: 1.1445 - val_mse: 1.1445 - val_mae: 0.9147\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 360us/step - loss: 1.3247 - mse: 1.3247 - mae: 0.8791 - val_loss: 1.1418 - val_mse: 1.1418 - val_mae: 0.9128\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 338us/step - loss: 1.3194 - mse: 1.3194 - mae: 0.8774 - val_loss: 1.1400 - val_mse: 1.1400 - val_mae: 0.9113\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 429us/step - loss: 1.3145 - mse: 1.3145 - mae: 0.8758 - val_loss: 1.1387 - val_mse: 1.1387 - val_mae: 0.9097\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 309us/step - loss: 1.3099 - mse: 1.3099 - mae: 0.8737 - val_loss: 1.1369 - val_mse: 1.1369 - val_mae: 0.9079\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 482us/step - loss: 1.3050 - mse: 1.3050 - mae: 0.8714 - val_loss: 1.1348 - val_mse: 1.1348 - val_mae: 0.9060\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 397us/step - loss: 1.3001 - mse: 1.3001 - mae: 0.8690 - val_loss: 1.1334 - val_mse: 1.1334 - val_mae: 0.9044\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 449us/step - loss: 1.2954 - mse: 1.2954 - mae: 0.8672 - val_loss: 1.1326 - val_mse: 1.1326 - val_mae: 0.9028\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 395us/step - loss: 1.2911 - mse: 1.2911 - mae: 0.8655 - val_loss: 1.1316 - val_mse: 1.1316 - val_mae: 0.9011\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 1.2865 - mse: 1.2865 - mae: 0.8638 - val_loss: 1.1304 - val_mse: 1.1304 - val_mae: 0.8993\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 351us/step - loss: 1.2817 - mse: 1.2817 - mae: 0.8617 - val_loss: 1.1302 - val_mse: 1.1302 - val_mae: 0.8981\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 309us/step - loss: 1.2776 - mse: 1.2776 - mae: 0.8603 - val_loss: 1.1300 - val_mse: 1.1300 - val_mae: 0.8972\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 693us/step - loss: 1.2734 - mse: 1.2734 - mae: 0.8590 - val_loss: 1.1287 - val_mse: 1.1287 - val_mae: 0.8958\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 408us/step - loss: 1.2692 - mse: 1.2692 - mae: 0.8578 - val_loss: 1.1277 - val_mse: 1.1277 - val_mae: 0.8946\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 612us/step - loss: 1.2658 - mse: 1.2658 - mae: 0.8569 - val_loss: 1.1272 - val_mse: 1.1272 - val_mae: 0.8939\n",
      "47\n",
      "[47]\n",
      "Train on 77 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 14ms/step - loss: 6.2455 - mse: 6.2455 - mae: 2.1383 - val_loss: 3.8600 - val_mse: 3.8600 - val_mae: 1.6034\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 321us/step - loss: 4.9226 - mse: 4.9226 - mae: 1.8327 - val_loss: 3.0957 - val_mse: 3.0957 - val_mae: 1.4315\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 492us/step - loss: 3.7604 - mse: 3.7604 - mae: 1.5169 - val_loss: 2.4104 - val_mse: 2.4104 - val_mae: 1.2917\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 271us/step - loss: 2.8084 - mse: 2.8084 - mae: 1.2058 - val_loss: 1.9041 - val_mse: 1.9041 - val_mae: 1.1987\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 485us/step - loss: 2.1486 - mse: 2.1486 - mae: 1.0108 - val_loss: 1.5597 - val_mse: 1.5597 - val_mae: 1.1001\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 624us/step - loss: 1.7982 - mse: 1.7982 - mae: 0.9621 - val_loss: 1.4135 - val_mse: 1.4135 - val_mae: 1.0263\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 340us/step - loss: 1.7003 - mse: 1.7003 - mae: 0.9836 - val_loss: 1.4011 - val_mse: 1.4011 - val_mae: 0.9950\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 390us/step - loss: 1.7481 - mse: 1.7481 - mae: 1.0396 - val_loss: 1.4348 - val_mse: 1.4348 - val_mae: 0.9905\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 457us/step - loss: 1.8157 - mse: 1.8157 - mae: 1.0789 - val_loss: 1.4503 - val_mse: 1.4503 - val_mae: 0.9902\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 286us/step - loss: 1.8226 - mse: 1.8226 - mae: 1.0829 - val_loss: 1.4321 - val_mse: 1.4321 - val_mae: 0.9930\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 481us/step - loss: 1.7668 - mse: 1.7668 - mae: 1.0592 - val_loss: 1.3997 - val_mse: 1.3997 - val_mae: 0.9979\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 496us/step - loss: 1.6877 - mse: 1.6877 - mae: 1.0186 - val_loss: 1.3773 - val_mse: 1.3773 - val_mae: 1.0035\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 364us/step - loss: 1.6252 - mse: 1.6252 - mae: 0.9751 - val_loss: 1.3748 - val_mse: 1.3748 - val_mae: 1.0089\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 768us/step - loss: 1.5967 - mse: 1.5967 - mae: 0.9430 - val_loss: 1.3868 - val_mse: 1.3868 - val_mae: 1.0228\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 324us/step - loss: 1.5893 - mse: 1.5893 - mae: 0.9275 - val_loss: 1.4014 - val_mse: 1.4014 - val_mae: 1.0330\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 678us/step - loss: 1.5888 - mse: 1.5888 - mae: 0.9183 - val_loss: 1.4079 - val_mse: 1.4079 - val_mae: 1.0385\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 666us/step - loss: 1.5832 - mse: 1.5832 - mae: 0.9119 - val_loss: 1.4028 - val_mse: 1.4028 - val_mae: 1.0384\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 545us/step - loss: 1.5688 - mse: 1.5688 - mae: 0.9078 - val_loss: 1.3885 - val_mse: 1.3885 - val_mae: 1.0313\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 987us/step - loss: 1.5479 - mse: 1.5479 - mae: 0.9052 - val_loss: 1.3707 - val_mse: 1.3707 - val_mae: 1.0199\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 387us/step - loss: 1.5267 - mse: 1.5267 - mae: 0.9042 - val_loss: 1.3550 - val_mse: 1.3550 - val_mae: 1.0091\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 180us/step - loss: 1.5094 - mse: 1.5094 - mae: 0.9052 - val_loss: 1.3432 - val_mse: 1.3432 - val_mae: 1.0055\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 320us/step - loss: 1.4958 - mse: 1.4958 - mae: 0.9068 - val_loss: 1.3354 - val_mse: 1.3354 - val_mae: 1.0035\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 425us/step - loss: 1.4840 - mse: 1.4840 - mae: 0.9081 - val_loss: 1.3308 - val_mse: 1.3308 - val_mae: 1.0022\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 830us/step - loss: 1.4725 - mse: 1.4725 - mae: 0.9064 - val_loss: 1.3291 - val_mse: 1.3291 - val_mae: 1.0017\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 355us/step - loss: 1.4609 - mse: 1.4609 - mae: 0.9019 - val_loss: 1.3289 - val_mse: 1.3289 - val_mae: 1.0052\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 323us/step - loss: 1.4495 - mse: 1.4495 - mae: 0.8951 - val_loss: 1.3321 - val_mse: 1.3321 - val_mae: 1.0111\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 750us/step - loss: 1.4391 - mse: 1.4391 - mae: 0.8875 - val_loss: 1.3353 - val_mse: 1.3353 - val_mae: 1.0168\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 343us/step - loss: 1.4296 - mse: 1.4296 - mae: 0.8801 - val_loss: 1.3378 - val_mse: 1.3378 - val_mae: 1.0217\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 348us/step - loss: 1.4206 - mse: 1.4206 - mae: 0.8739 - val_loss: 1.3395 - val_mse: 1.3395 - val_mae: 1.0256\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 429us/step - loss: 1.4118 - mse: 1.4118 - mae: 0.8694 - val_loss: 1.3407 - val_mse: 1.3407 - val_mae: 1.0288\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.0539 - mse: 2.0539 - mae: 1.021 - 0s 533us/step - loss: 1.4029 - mse: 1.4029 - mae: 0.8663 - val_loss: 1.3419 - val_mse: 1.3419 - val_mae: 1.0316\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 352us/step - loss: 1.3939 - mse: 1.3939 - mae: 0.8641 - val_loss: 1.3432 - val_mse: 1.3432 - val_mae: 1.0341\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 384us/step - loss: 1.3850 - mse: 1.3850 - mae: 0.8623 - val_loss: 1.3451 - val_mse: 1.3451 - val_mae: 1.0368\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 313us/step - loss: 1.3764 - mse: 1.3764 - mae: 0.8603 - val_loss: 1.3477 - val_mse: 1.3477 - val_mae: 1.0399\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 299us/step - loss: 1.3685 - mse: 1.3685 - mae: 0.8581 - val_loss: 1.3485 - val_mse: 1.3485 - val_mae: 1.0420\n",
      "48\n",
      "[48]\n",
      "Train on 89 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 9.7353 - mse: 9.7353 - mae: 2.7841 - val_loss: 5.9358 - val_mse: 5.9358 - val_mae: 2.1600\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 348us/step - loss: 8.3841 - mse: 8.3841 - mae: 2.5312 - val_loss: 4.9190 - val_mse: 4.9190 - val_mae: 1.9057\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 7.1720 - mse: 7.1720 - mae: 2.2797 - val_loss: 4.0214 - val_mse: 4.0214 - val_mae: 1.6543\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 296us/step - loss: 6.0661 - mse: 6.0661 - mae: 2.0409 - val_loss: 3.3278 - val_mse: 3.3278 - val_mae: 1.4510\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 259us/step - loss: 5.0671 - mse: 5.0671 - mae: 1.8108 - val_loss: 2.7874 - val_mse: 2.7874 - val_mae: 1.2631\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 392us/step - loss: 4.1722 - mse: 4.1722 - mae: 1.6197 - val_loss: 2.3407 - val_mse: 2.3407 - val_mae: 1.1037\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 295us/step - loss: 3.4182 - mse: 3.4182 - mae: 1.4644 - val_loss: 1.9479 - val_mse: 1.9479 - val_mae: 0.9690\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 2.8115 - mse: 2.8115 - mae: 1.3307 - val_loss: 1.6883 - val_mse: 1.6883 - val_mae: 0.9184\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 292us/step - loss: 2.4185 - mse: 2.4185 - mae: 1.2443 - val_loss: 1.5650 - val_mse: 1.5650 - val_mae: 0.9606\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 517us/step - loss: 2.2590 - mse: 2.2590 - mae: 1.2111 - val_loss: 1.5353 - val_mse: 1.5353 - val_mae: 1.0264\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 381us/step - loss: 2.2393 - mse: 2.2393 - mae: 1.2088 - val_loss: 1.5566 - val_mse: 1.5566 - val_mae: 1.0726\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 373us/step - loss: 2.2786 - mse: 2.2786 - mae: 1.2299 - val_loss: 1.5851 - val_mse: 1.5851 - val_mae: 1.0990\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 429us/step - loss: 2.3010 - mse: 2.3010 - mae: 1.2441 - val_loss: 1.5861 - val_mse: 1.5861 - val_mae: 1.1044\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 448us/step - loss: 2.2782 - mse: 2.2782 - mae: 1.2400 - val_loss: 1.5598 - val_mse: 1.5598 - val_mae: 1.0936\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 339us/step - loss: 2.2257 - mse: 2.2257 - mae: 1.2216 - val_loss: 1.5248 - val_mse: 1.5248 - val_mae: 1.0740\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 293us/step - loss: 2.1657 - mse: 2.1657 - mae: 1.1969 - val_loss: 1.4970 - val_mse: 1.4970 - val_mae: 1.0507\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 2.1191 - mse: 2.1191 - mae: 1.1758 - val_loss: 1.4819 - val_mse: 1.4819 - val_mae: 1.0283\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 2.0914 - mse: 2.0914 - mae: 1.1615 - val_loss: 1.4765 - val_mse: 1.4765 - val_mae: 1.0088\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 336us/step - loss: 2.0745 - mse: 2.0745 - mae: 1.1542 - val_loss: 1.4757 - val_mse: 1.4757 - val_mae: 0.9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 407us/step - loss: 2.0632 - mse: 2.0632 - mae: 1.1509 - val_loss: 1.4737 - val_mse: 1.4737 - val_mae: 0.9866\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 370us/step - loss: 2.0499 - mse: 2.0499 - mae: 1.1474 - val_loss: 1.4672 - val_mse: 1.4672 - val_mae: 0.9856\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 418us/step - loss: 2.0330 - mse: 2.0330 - mae: 1.1429 - val_loss: 1.4578 - val_mse: 1.4578 - val_mae: 0.9868\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 417us/step - loss: 2.0163 - mse: 2.0163 - mae: 1.1383 - val_loss: 1.4473 - val_mse: 1.4473 - val_mae: 0.9904\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 429us/step - loss: 1.9994 - mse: 1.9994 - mae: 1.1338 - val_loss: 1.4392 - val_mse: 1.4392 - val_mae: 0.9961\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 381us/step - loss: 1.9834 - mse: 1.9834 - mae: 1.1291 - val_loss: 1.4335 - val_mse: 1.4335 - val_mae: 1.0023\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 395us/step - loss: 1.9698 - mse: 1.9698 - mae: 1.1258 - val_loss: 1.4287 - val_mse: 1.4287 - val_mae: 1.0073\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 347us/step - loss: 1.9584 - mse: 1.9584 - mae: 1.1233 - val_loss: 1.4267 - val_mse: 1.4267 - val_mae: 1.0119\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 472us/step - loss: 1.9480 - mse: 1.9480 - mae: 1.1212 - val_loss: 1.4248 - val_mse: 1.4248 - val_mae: 1.0148\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.9373 - mse: 1.9373 - mae: 1.1190 - val_loss: 1.4220 - val_mse: 1.4220 - val_mae: 1.0157\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 275us/step - loss: 1.9261 - mse: 1.9261 - mae: 1.1165 - val_loss: 1.4186 - val_mse: 1.4186 - val_mae: 1.0152\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 295us/step - loss: 1.9157 - mse: 1.9157 - mae: 1.1138 - val_loss: 1.4150 - val_mse: 1.4150 - val_mae: 1.0141\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 646us/step - loss: 1.9063 - mse: 1.9063 - mae: 1.1113 - val_loss: 1.4112 - val_mse: 1.4112 - val_mae: 1.0130\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 271us/step - loss: 1.8975 - mse: 1.8975 - mae: 1.1087 - val_loss: 1.4078 - val_mse: 1.4078 - val_mae: 1.0128\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 1.4254 - mse: 1.4254 - mae: 0.926 - 0s 453us/step - loss: 1.8885 - mse: 1.8885 - mae: 1.1059 - val_loss: 1.4063 - val_mse: 1.4063 - val_mae: 1.0140\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 439us/step - loss: 1.8793 - mse: 1.8793 - mae: 1.1033 - val_loss: 1.4065 - val_mse: 1.4065 - val_mae: 1.0162\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 396us/step - loss: 1.8703 - mse: 1.8703 - mae: 1.1008 - val_loss: 1.4078 - val_mse: 1.4078 - val_mae: 1.0188\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 325us/step - loss: 1.8615 - mse: 1.8615 - mae: 1.0984 - val_loss: 1.4087 - val_mse: 1.4087 - val_mae: 1.0207\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 385us/step - loss: 1.8528 - mse: 1.8528 - mae: 1.0960 - val_loss: 1.4089 - val_mse: 1.4089 - val_mae: 1.0220\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 398us/step - loss: 1.8439 - mse: 1.8439 - mae: 1.0937 - val_loss: 1.4088 - val_mse: 1.4088 - val_mae: 1.0233\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 485us/step - loss: 1.8350 - mse: 1.8350 - mae: 1.0915 - val_loss: 1.4096 - val_mse: 1.4096 - val_mae: 1.0246\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 383us/step - loss: 1.8261 - mse: 1.8261 - mae: 1.0893 - val_loss: 1.4115 - val_mse: 1.4115 - val_mae: 1.0262\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 372us/step - loss: 1.8172 - mse: 1.8172 - mae: 1.0873 - val_loss: 1.4138 - val_mse: 1.4138 - val_mae: 1.0282\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 323us/step - loss: 1.8086 - mse: 1.8086 - mae: 1.0853 - val_loss: 1.4173 - val_mse: 1.4173 - val_mae: 1.0307\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 368us/step - loss: 1.7992 - mse: 1.7992 - mae: 1.0832 - val_loss: 1.4226 - val_mse: 1.4226 - val_mae: 1.0340\n",
      "49\n",
      "[49]\n",
      "Train on 89 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 19.4320 - mse: 19.4320 - mae: 3.6307 - val_loss: 5.1615 - val_mse: 5.1615 - val_mae: 2.1099\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 492us/step - loss: 17.7890 - mse: 17.7890 - mae: 3.4480 - val_loss: 4.7792 - val_mse: 4.7792 - val_mae: 2.0161\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 315us/step - loss: 16.4057 - mse: 16.4057 - mae: 3.2836 - val_loss: 4.4782 - val_mse: 4.4782 - val_mae: 1.9384\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 564us/step - loss: 15.3167 - mse: 15.3167 - mae: 3.1450 - val_loss: 4.2005 - val_mse: 4.2005 - val_mae: 1.8660\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 259us/step - loss: 14.2556 - mse: 14.2556 - mae: 3.0039 - val_loss: 3.9357 - val_mse: 3.9357 - val_mae: 1.7953\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 327us/step - loss: 13.2503 - mse: 13.2503 - mae: 2.8618 - val_loss: 3.6828 - val_mse: 3.6828 - val_mae: 1.7255\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 362us/step - loss: 12.2690 - mse: 12.2690 - mae: 2.7140 - val_loss: 3.4208 - val_mse: 3.4208 - val_mae: 1.6483\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 11.3157 - mse: 11.3157 - mae: 2.5604 - val_loss: 3.1364 - val_mse: 3.1364 - val_mae: 1.5605\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 282us/step - loss: 10.3800 - mse: 10.3800 - mae: 2.3988 - val_loss: 2.8666 - val_mse: 2.8666 - val_mae: 1.4730\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 336us/step - loss: 9.4328 - mse: 9.4328 - mae: 2.2284 - val_loss: 2.6131 - val_mse: 2.6131 - val_mae: 1.3852\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 341us/step - loss: 8.5307 - mse: 8.5307 - mae: 2.0608 - val_loss: 2.3759 - val_mse: 2.3759 - val_mae: 1.2965\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 7.6712 - mse: 7.6712 - mae: 1.9147 - val_loss: 2.1569 - val_mse: 2.1569 - val_mae: 1.2080\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 247us/step - loss: 6.8999 - mse: 6.8999 - mae: 1.7814 - val_loss: 1.9618 - val_mse: 1.9618 - val_mae: 1.1219\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 437us/step - loss: 6.2275 - mse: 6.2275 - mae: 1.6650 - val_loss: 1.7800 - val_mse: 1.7800 - val_mae: 1.0424\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 304us/step - loss: 5.6424 - mse: 5.6424 - mae: 1.5640 - val_loss: 1.6095 - val_mse: 1.6095 - val_mae: 0.9689\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 265us/step - loss: 5.1585 - mse: 5.1585 - mae: 1.4790 - val_loss: 1.4561 - val_mse: 1.4561 - val_mae: 0.8988\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 9.8105 - mse: 9.8105 - mae: 2.252 - 0s 373us/step - loss: 4.7781 - mse: 4.7781 - mae: 1.4294 - val_loss: 1.3229 - val_mse: 1.3229 - val_mae: 0.8260\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 396us/step - loss: 4.4771 - mse: 4.4771 - mae: 1.4034 - val_loss: 1.2071 - val_mse: 1.2071 - val_mae: 0.7698\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 359us/step - loss: 4.2634 - mse: 4.2634 - mae: 1.4035 - val_loss: 1.1183 - val_mse: 1.1183 - val_mae: 0.7430\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 620us/step - loss: 4.1186 - mse: 4.1186 - mae: 1.4059 - val_loss: 1.0571 - val_mse: 1.0571 - val_mae: 0.7298\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 426us/step - loss: 4.0097 - mse: 4.0097 - mae: 1.4079 - val_loss: 1.0150 - val_mse: 1.0150 - val_mae: 0.7197\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 7.8197 - mse: 7.8197 - mae: 2.142 - 0s 371us/step - loss: 3.9240 - mse: 3.9240 - mae: 1.4118 - val_loss: 0.9867 - val_mse: 0.9867 - val_mae: 0.7161\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 3.8481 - mse: 3.8481 - mae: 1.4119 - val_loss: 0.9676 - val_mse: 0.9676 - val_mae: 0.7151\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 519us/step - loss: 3.7751 - mse: 3.7751 - mae: 1.4088 - val_loss: 0.9549 - val_mse: 0.9549 - val_mae: 0.7139\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 227us/step - loss: 3.7013 - mse: 3.7013 - mae: 1.4009 - val_loss: 0.9466 - val_mse: 0.9466 - val_mae: 0.7124\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 378us/step - loss: 3.6292 - mse: 3.6292 - mae: 1.3916 - val_loss: 0.9416 - val_mse: 0.9416 - val_mae: 0.7119\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 246us/step - loss: 3.5683 - mse: 3.5683 - mae: 1.3827 - val_loss: 0.9383 - val_mse: 0.9383 - val_mae: 0.7139\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 540us/step - loss: 3.5165 - mse: 3.5165 - mae: 1.3747 - val_loss: 0.9317 - val_mse: 0.9317 - val_mae: 0.7123\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 439us/step - loss: 3.4651 - mse: 3.4651 - mae: 1.3636 - val_loss: 0.9238 - val_mse: 0.9238 - val_mae: 0.7089\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 3.4162 - mse: 3.4162 - mae: 1.3516 - val_loss: 0.9170 - val_mse: 0.9170 - val_mae: 0.7056\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 405us/step - loss: 3.3713 - mse: 3.3713 - mae: 1.3400 - val_loss: 0.9111 - val_mse: 0.9111 - val_mae: 0.7043\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 3.3323 - mse: 3.3323 - mae: 1.3300 - val_loss: 0.9037 - val_mse: 0.9037 - val_mae: 0.7021\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 517us/step - loss: 3.2965 - mse: 3.2965 - mae: 1.3211 - val_loss: 0.8964 - val_mse: 0.8964 - val_mae: 0.7005\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 382us/step - loss: 3.2631 - mse: 3.2631 - mae: 1.3128 - val_loss: 0.8903 - val_mse: 0.8903 - val_mae: 0.6999\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 485us/step - loss: 3.2316 - mse: 3.2316 - mae: 1.3053 - val_loss: 0.8849 - val_mse: 0.8849 - val_mae: 0.6994\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 361us/step - loss: 3.2018 - mse: 3.2018 - mae: 1.2986 - val_loss: 0.8801 - val_mse: 0.8801 - val_mae: 0.6990\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 361us/step - loss: 3.1734 - mse: 3.1734 - mae: 1.2927 - val_loss: 0.8755 - val_mse: 0.8755 - val_mae: 0.6989\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 319us/step - loss: 3.1464 - mse: 3.1464 - mae: 1.2877 - val_loss: 0.8717 - val_mse: 0.8717 - val_mae: 0.6990\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 362us/step - loss: 3.1209 - mse: 3.1209 - mae: 1.2838 - val_loss: 0.8689 - val_mse: 0.8689 - val_mae: 0.6995\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 511us/step - loss: 3.0968 - mse: 3.0968 - mae: 1.2808 - val_loss: 0.8672 - val_mse: 0.8672 - val_mae: 0.7005\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 279us/step - loss: 3.0722 - mse: 3.0722 - mae: 1.2782 - val_loss: 0.8662 - val_mse: 0.8662 - val_mae: 0.7016\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 3.0476 - mse: 3.0476 - mae: 1.2756 - val_loss: 0.8658 - val_mse: 0.8658 - val_mae: 0.7028\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 361us/step - loss: 3.0239 - mse: 3.0239 - mae: 1.2732 - val_loss: 0.8663 - val_mse: 0.8663 - val_mae: 0.7041\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 297us/step - loss: 3.0018 - mse: 3.0018 - mae: 1.2710 - val_loss: 0.8673 - val_mse: 0.8673 - val_mae: 0.7055\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 316us/step - loss: 2.9800 - mse: 2.9800 - mae: 1.2682 - val_loss: 0.8686 - val_mse: 0.8686 - val_mae: 0.7069\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 304us/step - loss: 2.9590 - mse: 2.9590 - mae: 1.2650 - val_loss: 0.8702 - val_mse: 0.8702 - val_mae: 0.7082\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 574us/step - loss: 2.9382 - mse: 2.9382 - mae: 1.2610 - val_loss: 0.8718 - val_mse: 0.8718 - val_mae: 0.7093\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 290us/step - loss: 2.9169 - mse: 2.9169 - mae: 1.2562 - val_loss: 0.8737 - val_mse: 0.8737 - val_mae: 0.7105\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 315us/step - loss: 2.8959 - mse: 2.8959 - mae: 1.2513 - val_loss: 0.8758 - val_mse: 0.8758 - val_mae: 0.7118\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 461us/step - loss: 2.8762 - mse: 2.8762 - mae: 1.2465 - val_loss: 0.8777 - val_mse: 0.8777 - val_mae: 0.7129\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 461us/step - loss: 2.8567 - mse: 2.8567 - mae: 1.2418 - val_loss: 0.8794 - val_mse: 0.8794 - val_mae: 0.7139\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 457us/step - loss: 2.8391 - mse: 2.8391 - mae: 1.2373 - val_loss: 0.8819 - val_mse: 0.8819 - val_mae: 0.7152\n",
      "50\n",
      "[50]\n",
      "Train on 91 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 1s 12ms/step - loss: 4.3045 - mse: 4.3045 - mae: 1.5953 - val_loss: 2.7148 - val_mse: 2.7148 - val_mae: 1.4413\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 321us/step - loss: 3.8229 - mse: 3.8229 - mae: 1.4545 - val_loss: 2.3422 - val_mse: 2.3422 - val_mae: 1.3354\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 275us/step - loss: 3.3790 - mse: 3.3790 - mae: 1.3405 - val_loss: 2.0205 - val_mse: 2.0205 - val_mae: 1.2275\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 526us/step - loss: 2.9758 - mse: 2.9758 - mae: 1.2486 - val_loss: 1.7537 - val_mse: 1.7537 - val_mae: 1.1139\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - ETA: 0s - loss: 2.9399 - mse: 2.9399 - mae: 1.192 - 0s 342us/step - loss: 2.6349 - mse: 2.6349 - mae: 1.1908 - val_loss: 1.5148 - val_mse: 1.5148 - val_mae: 0.9852\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 377us/step - loss: 2.3615 - mse: 2.3615 - mae: 1.1517 - val_loss: 1.3301 - val_mse: 1.3301 - val_mae: 0.8625\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 307us/step - loss: 2.1593 - mse: 2.1593 - mae: 1.1156 - val_loss: 1.2181 - val_mse: 1.2181 - val_mae: 0.7874\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 361us/step - loss: 2.0270 - mse: 2.0270 - mae: 1.1001 - val_loss: 1.1874 - val_mse: 1.1874 - val_mae: 0.7920\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 484us/step - loss: 1.9626 - mse: 1.9626 - mae: 1.1042 - val_loss: 1.2233 - val_mse: 1.2233 - val_mae: 0.8177\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 307us/step - loss: 1.9606 - mse: 1.9606 - mae: 1.1139 - val_loss: 1.2874 - val_mse: 1.2874 - val_mae: 0.8541\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 318us/step - loss: 1.9937 - mse: 1.9937 - mae: 1.1260 - val_loss: 1.3451 - val_mse: 1.3451 - val_mae: 0.8812\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 416us/step - loss: 2.0273 - mse: 2.0273 - mae: 1.1356 - val_loss: 1.3716 - val_mse: 1.3716 - val_mae: 0.8919\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 542us/step - loss: 2.0408 - mse: 2.0408 - mae: 1.1397 - val_loss: 1.3633 - val_mse: 1.3633 - val_mae: 0.8901\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 470us/step - loss: 2.0315 - mse: 2.0315 - mae: 1.1366 - val_loss: 1.3286 - val_mse: 1.3286 - val_mae: 0.8791\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 635us/step - loss: 2.0080 - mse: 2.0080 - mae: 1.1290 - val_loss: 1.2800 - val_mse: 1.2800 - val_mae: 0.8627\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 340us/step - loss: 1.9783 - mse: 1.9783 - mae: 1.1184 - val_loss: 1.2303 - val_mse: 1.2303 - val_mae: 0.8455\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 487us/step - loss: 1.9494 - mse: 1.9494 - mae: 1.1078 - val_loss: 1.1835 - val_mse: 1.1835 - val_mae: 0.8270\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 429us/step - loss: 1.9258 - mse: 1.9258 - mae: 1.0970 - val_loss: 1.1458 - val_mse: 1.1458 - val_mae: 0.8104\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 268us/step - loss: 1.9066 - mse: 1.9066 - mae: 1.0865 - val_loss: 1.1207 - val_mse: 1.1207 - val_mae: 0.7979\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 571us/step - loss: 1.8915 - mse: 1.8915 - mae: 1.0772 - val_loss: 1.1040 - val_mse: 1.1040 - val_mae: 0.7881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 584us/step - loss: 1.8801 - mse: 1.8801 - mae: 1.0710 - val_loss: 1.0909 - val_mse: 1.0909 - val_mae: 0.7793\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 423us/step - loss: 1.8703 - mse: 1.8703 - mae: 1.0665 - val_loss: 1.0830 - val_mse: 1.0830 - val_mae: 0.7732\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 195us/step - loss: 1.8649 - mse: 1.8649 - mae: 1.0639 - val_loss: 1.0831 - val_mse: 1.0831 - val_mae: 0.7746\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 373us/step - loss: 1.8628 - mse: 1.8628 - mae: 1.0625 - val_loss: 1.0872 - val_mse: 1.0872 - val_mae: 0.7826\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 521us/step - loss: 1.8625 - mse: 1.8625 - mae: 1.0620 - val_loss: 1.0918 - val_mse: 1.0918 - val_mae: 0.7907\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 547us/step - loss: 1.8628 - mse: 1.8628 - mae: 1.0617 - val_loss: 1.0945 - val_mse: 1.0945 - val_mae: 0.7965\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 697us/step - loss: 1.8620 - mse: 1.8620 - mae: 1.0610 - val_loss: 1.0927 - val_mse: 1.0927 - val_mae: 0.7989\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 314us/step - loss: 1.8590 - mse: 1.8590 - mae: 1.0595 - val_loss: 1.0871 - val_mse: 1.0871 - val_mae: 0.7981\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 643us/step - loss: 1.8537 - mse: 1.8537 - mae: 1.0571 - val_loss: 1.0802 - val_mse: 1.0802 - val_mae: 0.7956\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 660us/step - loss: 1.8477 - mse: 1.8477 - mae: 1.0543 - val_loss: 1.0719 - val_mse: 1.0719 - val_mae: 0.7922\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 343us/step - loss: 1.8411 - mse: 1.8411 - mae: 1.0514 - val_loss: 1.0630 - val_mse: 1.0630 - val_mae: 0.7884\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 403us/step - loss: 1.8354 - mse: 1.8354 - mae: 1.0487 - val_loss: 1.0555 - val_mse: 1.0555 - val_mae: 0.7854\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 393us/step - loss: 1.8299 - mse: 1.8299 - mae: 1.0461 - val_loss: 1.0499 - val_mse: 1.0499 - val_mae: 0.7835\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 402us/step - loss: 1.8247 - mse: 1.8247 - mae: 1.0438 - val_loss: 1.0454 - val_mse: 1.0454 - val_mae: 0.7825\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 406us/step - loss: 1.8203 - mse: 1.8203 - mae: 1.0418 - val_loss: 1.0394 - val_mse: 1.0394 - val_mae: 0.7808\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 406us/step - loss: 1.8152 - mse: 1.8152 - mae: 1.0395 - val_loss: 1.0321 - val_mse: 1.0321 - val_mae: 0.7781\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 421us/step - loss: 1.8096 - mse: 1.8096 - mae: 1.0368 - val_loss: 1.0269 - val_mse: 1.0269 - val_mae: 0.7769\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - ETA: 0s - loss: 1.8897 - mse: 1.8897 - mae: 0.937 - 0s 344us/step - loss: 1.8050 - mse: 1.8050 - mae: 1.0347 - val_loss: 1.0228 - val_mse: 1.0228 - val_mae: 0.7768\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 386us/step - loss: 1.8008 - mse: 1.8008 - mae: 1.0328 - val_loss: 1.0182 - val_mse: 1.0182 - val_mae: 0.7762\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 344us/step - loss: 1.7966 - mse: 1.7966 - mae: 1.0308 - val_loss: 1.0125 - val_mse: 1.0125 - val_mae: 0.7743\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 520us/step - loss: 1.7916 - mse: 1.7916 - mae: 1.0284 - val_loss: 1.0080 - val_mse: 1.0080 - val_mae: 0.7733\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 427us/step - loss: 1.7873 - mse: 1.7873 - mae: 1.0263 - val_loss: 1.0037 - val_mse: 1.0037 - val_mae: 0.7726\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 528us/step - loss: 1.7832 - mse: 1.7832 - mae: 1.0243 - val_loss: 0.9993 - val_mse: 0.9993 - val_mae: 0.7715\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 585us/step - loss: 1.7787 - mse: 1.7787 - mae: 1.0220 - val_loss: 0.9929 - val_mse: 0.9929 - val_mae: 0.7685\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 287us/step - loss: 1.7738 - mse: 1.7738 - mae: 1.0198 - val_loss: 0.9884 - val_mse: 0.9884 - val_mae: 0.7669\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 307us/step - loss: 1.7692 - mse: 1.7692 - mae: 1.0178 - val_loss: 0.9855 - val_mse: 0.9855 - val_mae: 0.7663\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 329us/step - loss: 1.7651 - mse: 1.7651 - mae: 1.0161 - val_loss: 0.9814 - val_mse: 0.9814 - val_mae: 0.7659\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 477us/step - loss: 1.7613 - mse: 1.7613 - mae: 1.0144 - val_loss: 0.9772 - val_mse: 0.9772 - val_mae: 0.7654\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 329us/step - loss: 1.7565 - mse: 1.7565 - mae: 1.0122 - val_loss: 0.9729 - val_mse: 0.9729 - val_mae: 0.7643\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 271us/step - loss: 1.7518 - mse: 1.7518 - mae: 1.0100 - val_loss: 0.9693 - val_mse: 0.9693 - val_mae: 0.7638\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 408us/step - loss: 1.7474 - mse: 1.7474 - mae: 1.0083 - val_loss: 0.9645 - val_mse: 0.9645 - val_mae: 0.7631\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 379us/step - loss: 1.7430 - mse: 1.7430 - mae: 1.0065 - val_loss: 0.9595 - val_mse: 0.9595 - val_mae: 0.7620\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 349us/step - loss: 1.7384 - mse: 1.7384 - mae: 1.0046 - val_loss: 0.9573 - val_mse: 0.9573 - val_mae: 0.7623\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 431us/step - loss: 1.7350 - mse: 1.7350 - mae: 1.0035 - val_loss: 0.9548 - val_mse: 0.9548 - val_mae: 0.7626\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 263us/step - loss: 1.7309 - mse: 1.7309 - mae: 1.0024 - val_loss: 0.9504 - val_mse: 0.9504 - val_mae: 0.7619\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 504us/step - loss: 1.7269 - mse: 1.7269 - mae: 1.0010 - val_loss: 0.9485 - val_mse: 0.9485 - val_mae: 0.7627\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 325us/step - loss: 1.7227 - mse: 1.7227 - mae: 0.9998 - val_loss: 0.9471 - val_mse: 0.9471 - val_mae: 0.7636\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 201us/step - loss: 1.7191 - mse: 1.7191 - mae: 0.9982 - val_loss: 0.9426 - val_mse: 0.9426 - val_mae: 0.7626\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 363us/step - loss: 1.7145 - mse: 1.7145 - mae: 0.9963 - val_loss: 0.9391 - val_mse: 0.9391 - val_mae: 0.7618\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 540us/step - loss: 1.7102 - mse: 1.7102 - mae: 0.9945 - val_loss: 0.9386 - val_mse: 0.9386 - val_mae: 0.7627\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 384us/step - loss: 1.7063 - mse: 1.7063 - mae: 0.9935 - val_loss: 0.9377 - val_mse: 0.9377 - val_mae: 0.7634\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 962us/step - loss: 1.7024 - mse: 1.7024 - mae: 0.9923 - val_loss: 0.9352 - val_mse: 0.9352 - val_mae: 0.7631\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 550us/step - loss: 1.6981 - mse: 1.6981 - mae: 0.9907 - val_loss: 0.9321 - val_mse: 0.9321 - val_mae: 0.7628\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.6939 - mse: 1.6939 - mae: 0.9889 - val_loss: 0.9315 - val_mse: 0.9315 - val_mae: 0.7639\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 654us/step - loss: 1.6904 - mse: 1.6904 - mae: 0.9878 - val_loss: 0.9306 - val_mse: 0.9306 - val_mae: 0.7649\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 189us/step - loss: 1.6860 - mse: 1.6860 - mae: 0.9861 - val_loss: 0.9266 - val_mse: 0.9266 - val_mae: 0.7639\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 533us/step - loss: 1.6819 - mse: 1.6819 - mae: 0.9843 - val_loss: 0.9241 - val_mse: 0.9241 - val_mae: 0.7635\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 513us/step - loss: 1.6768 - mse: 1.6768 - mae: 0.9827 - val_loss: 0.9239 - val_mse: 0.9239 - val_mae: 0.7642\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 559us/step - loss: 1.6724 - mse: 1.6724 - mae: 0.9814 - val_loss: 0.9220 - val_mse: 0.9220 - val_mae: 0.7643\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 594us/step - loss: 1.6678 - mse: 1.6678 - mae: 0.9795 - val_loss: 0.9197 - val_mse: 0.9197 - val_mae: 0.7646\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 629us/step - loss: 1.6636 - mse: 1.6636 - mae: 0.9780 - val_loss: 0.9186 - val_mse: 0.9186 - val_mae: 0.7648\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 808us/step - loss: 1.6592 - mse: 1.6592 - mae: 0.9767 - val_loss: 0.9175 - val_mse: 0.9175 - val_mae: 0.7653\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 757us/step - loss: 1.6548 - mse: 1.6548 - mae: 0.9752 - val_loss: 0.9132 - val_mse: 0.9132 - val_mae: 0.7642\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 955us/step - loss: 1.6509 - mse: 1.6509 - mae: 0.9732 - val_loss: 0.9104 - val_mse: 0.9104 - val_mae: 0.7636\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 227us/step - loss: 1.6453 - mse: 1.6453 - mae: 0.9715 - val_loss: 0.9102 - val_mse: 0.9102 - val_mae: 0.7643\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 418us/step - loss: 1.6413 - mse: 1.6413 - mae: 0.9705 - val_loss: 0.9093 - val_mse: 0.9093 - val_mae: 0.7654\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 281us/step - loss: 1.6368 - mse: 1.6368 - mae: 0.9689 - val_loss: 0.9070 - val_mse: 0.9070 - val_mae: 0.7650\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 167us/step - loss: 1.6319 - mse: 1.6319 - mae: 0.9669 - val_loss: 0.9048 - val_mse: 0.9048 - val_mae: 0.7636\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 164us/step - loss: 1.6269 - mse: 1.6269 - mae: 0.9650 - val_loss: 0.9035 - val_mse: 0.9035 - val_mae: 0.7628\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 537us/step - loss: 1.6225 - mse: 1.6225 - mae: 0.9635 - val_loss: 0.9026 - val_mse: 0.9026 - val_mae: 0.7637\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 365us/step - loss: 1.6185 - mse: 1.6185 - mae: 0.9621 - val_loss: 0.9023 - val_mse: 0.9023 - val_mae: 0.7654\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 451us/step - loss: 1.6138 - mse: 1.6138 - mae: 0.9614 - val_loss: 0.9000 - val_mse: 0.9000 - val_mae: 0.7653\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 204us/step - loss: 1.6093 - mse: 1.6093 - mae: 0.9598 - val_loss: 0.8976 - val_mse: 0.8976 - val_mae: 0.7650\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 479us/step - loss: 1.6051 - mse: 1.6051 - mae: 0.9583 - val_loss: 0.8970 - val_mse: 0.8970 - val_mae: 0.7658\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 805us/step - loss: 1.5992 - mse: 1.5992 - mae: 0.9567 - val_loss: 0.8953 - val_mse: 0.8953 - val_mae: 0.7651\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 366us/step - loss: 1.5945 - mse: 1.5945 - mae: 0.9547 - val_loss: 0.8951 - val_mse: 0.8951 - val_mae: 0.7653\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 471us/step - loss: 1.5901 - mse: 1.5901 - mae: 0.9531 - val_loss: 0.8954 - val_mse: 0.8954 - val_mae: 0.7669\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 343us/step - loss: 1.5850 - mse: 1.5850 - mae: 0.9516 - val_loss: 0.8932 - val_mse: 0.8932 - val_mae: 0.7668\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 386us/step - loss: 1.5807 - mse: 1.5807 - mae: 0.9495 - val_loss: 0.8931 - val_mse: 0.8931 - val_mae: 0.7674\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 442us/step - loss: 1.5748 - mse: 1.5748 - mae: 0.9479 - val_loss: 0.8953 - val_mse: 0.8953 - val_mae: 0.7692\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.5703 - mse: 1.5703 - mae: 0.9465 - val_loss: 0.8963 - val_mse: 0.8963 - val_mae: 0.7708\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 274us/step - loss: 1.5658 - mse: 1.5658 - mae: 0.9450 - val_loss: 0.8976 - val_mse: 0.8976 - val_mae: 0.7729\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 418us/step - loss: 1.5611 - mse: 1.5611 - mae: 0.9438 - val_loss: 0.8982 - val_mse: 0.8982 - val_mae: 0.7739\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 342us/step - loss: 1.5560 - mse: 1.5560 - mae: 0.9414 - val_loss: 0.8982 - val_mse: 0.8982 - val_mae: 0.7735\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 384us/step - loss: 1.5508 - mse: 1.5508 - mae: 0.9387 - val_loss: 0.8983 - val_mse: 0.8983 - val_mae: 0.7735\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 297us/step - loss: 1.5458 - mse: 1.5458 - mae: 0.9362 - val_loss: 0.9000 - val_mse: 0.9000 - val_mae: 0.7755\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 464us/step - loss: 1.5403 - mse: 1.5403 - mae: 0.9347 - val_loss: 0.9019 - val_mse: 0.9019 - val_mae: 0.7777\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 238us/step - loss: 1.5345 - mse: 1.5345 - mae: 0.9325 - val_loss: 0.9013 - val_mse: 0.9013 - val_mae: 0.7771\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 389us/step - loss: 1.5301 - mse: 1.5301 - mae: 0.9303 - val_loss: 0.9017 - val_mse: 0.9017 - val_mae: 0.7769\n",
      "51\n",
      "[51]\n",
      "Train on 106 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 12ms/step - loss: 19.1044 - mse: 19.1044 - mae: 4.0426 - val_loss: 7.4931 - val_mse: 7.4931 - val_mae: 2.5611\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 209us/step - loss: 14.2654 - mse: 14.2654 - mae: 3.4061 - val_loss: 5.3604 - val_mse: 5.3604 - val_mae: 2.1196\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 405us/step - loss: 10.5016 - mse: 10.5016 - mae: 2.8096 - val_loss: 3.7790 - val_mse: 3.7790 - val_mae: 1.7139\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 491us/step - loss: 7.6486 - mse: 7.6486 - mae: 2.2820 - val_loss: 2.6101 - val_mse: 2.6101 - val_mae: 1.3334\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 426us/step - loss: 5.6243 - mse: 5.6243 - mae: 1.8530 - val_loss: 1.8022 - val_mse: 1.8022 - val_mae: 1.0452\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 587us/step - loss: 4.2572 - mse: 4.2572 - mae: 1.5506 - val_loss: 1.2866 - val_mse: 1.2866 - val_mae: 0.8311\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 713us/step - loss: 3.3977 - mse: 3.3977 - mae: 1.3516 - val_loss: 1.0066 - val_mse: 1.0066 - val_mae: 0.7138\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - ETA: 0s - loss: 3.8419 - mse: 3.8419 - mae: 1.436 - 0s 458us/step - loss: 2.9269 - mse: 2.9269 - mae: 1.2735 - val_loss: 0.8958 - val_mse: 0.8958 - val_mae: 0.6815\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 389us/step - loss: 2.7238 - mse: 2.7238 - mae: 1.2617 - val_loss: 0.8875 - val_mse: 0.8875 - val_mae: 0.7217\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 284us/step - loss: 2.6768 - mse: 2.6768 - mae: 1.2767 - val_loss: 0.9186 - val_mse: 0.9186 - val_mae: 0.7524\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 464us/step - loss: 2.6828 - mse: 2.6828 - mae: 1.2925 - val_loss: 0.9480 - val_mse: 0.9480 - val_mae: 0.7807\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 160us/step - loss: 2.6792 - mse: 2.6792 - mae: 1.3015 - val_loss: 0.9584 - val_mse: 0.9584 - val_mae: 0.7894\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 346us/step - loss: 2.6474 - mse: 2.6474 - mae: 1.2972 - val_loss: 0.9514 - val_mse: 0.9514 - val_mae: 0.7836\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 339us/step - loss: 2.5938 - mse: 2.5938 - mae: 1.2809 - val_loss: 0.9369 - val_mse: 0.9369 - val_mae: 0.7691\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 431us/step - loss: 2.5363 - mse: 2.5363 - mae: 1.2596 - val_loss: 0.9235 - val_mse: 0.9235 - val_mae: 0.7567\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 430us/step - loss: 2.4870 - mse: 2.4870 - mae: 1.2385 - val_loss: 0.9163 - val_mse: 0.9163 - val_mae: 0.7500\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 367us/step - loss: 2.4480 - mse: 2.4480 - mae: 1.2199 - val_loss: 0.9144 - val_mse: 0.9144 - val_mae: 0.7450\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 303us/step - loss: 2.4170 - mse: 2.4170 - mae: 1.2045 - val_loss: 0.9170 - val_mse: 0.9170 - val_mae: 0.7426\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 274us/step - loss: 2.3899 - mse: 2.3899 - mae: 1.1919 - val_loss: 0.9208 - val_mse: 0.9208 - val_mae: 0.7420\n",
      "52\n",
      "[52]\n",
      "Train on 98 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 14.3156 - mse: 14.3156 - mae: 3.4372 - val_loss: 14.7766 - val_mse: 14.7766 - val_mae: 3.4413\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 356us/step - loss: 12.0833 - mse: 12.0833 - mae: 3.1023 - val_loss: 12.6731 - val_mse: 12.6731 - val_mae: 3.1137\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 493us/step - loss: 10.0907 - mse: 10.0907 - mae: 2.7681 - val_loss: 10.7460 - val_mse: 10.7460 - val_mae: 2.7823\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 556us/step - loss: 8.2600 - mse: 8.2600 - mae: 2.4237 - val_loss: 8.9867 - val_mse: 8.9867 - val_mae: 2.4451\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 359us/step - loss: 6.6947 - mse: 6.6947 - mae: 2.0954 - val_loss: 7.4333 - val_mse: 7.4333 - val_mae: 2.1070\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 328us/step - loss: 5.4240 - mse: 5.4240 - mae: 1.8139 - val_loss: 6.1086 - val_mse: 6.1086 - val_mae: 1.8990\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 254us/step - loss: 4.3994 - mse: 4.3994 - mae: 1.5824 - val_loss: 5.0498 - val_mse: 5.0498 - val_mae: 1.7549\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 392us/step - loss: 3.6265 - mse: 3.6265 - mae: 1.3937 - val_loss: 4.2509 - val_mse: 4.2509 - val_mae: 1.6371\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 378us/step - loss: 3.1008 - mse: 3.1008 - mae: 1.2913 - val_loss: 3.6970 - val_mse: 3.6970 - val_mae: 1.5553\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 266us/step - loss: 2.7853 - mse: 2.7853 - mae: 1.2513 - val_loss: 3.3519 - val_mse: 3.3519 - val_mae: 1.5057\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 313us/step - loss: 2.6254 - mse: 2.6254 - mae: 1.2564 - val_loss: 3.1567 - val_mse: 3.1567 - val_mae: 1.4734\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 319us/step - loss: 2.5654 - mse: 2.5654 - mae: 1.2671 - val_loss: 3.0634 - val_mse: 3.0634 - val_mae: 1.4600\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 645us/step - loss: 2.5561 - mse: 2.5561 - mae: 1.2843 - val_loss: 3.0270 - val_mse: 3.0270 - val_mae: 1.4508\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 336us/step - loss: 2.5520 - mse: 2.5520 - mae: 1.2959 - val_loss: 3.0161 - val_mse: 3.0161 - val_mae: 1.4455\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 356us/step - loss: 2.5327 - mse: 2.5327 - mae: 1.2969 - val_loss: 3.0154 - val_mse: 3.0154 - val_mae: 1.4434\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 307us/step - loss: 2.4963 - mse: 2.4963 - mae: 1.2865 - val_loss: 3.0229 - val_mse: 3.0229 - val_mae: 1.4440\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 327us/step - loss: 2.4519 - mse: 2.4519 - mae: 1.2688 - val_loss: 3.0361 - val_mse: 3.0361 - val_mae: 1.4455\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 489us/step - loss: 2.4076 - mse: 2.4076 - mae: 1.2484 - val_loss: 3.0531 - val_mse: 3.0531 - val_mae: 1.4468\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 296us/step - loss: 2.3676 - mse: 2.3676 - mae: 1.2288 - val_loss: 3.0706 - val_mse: 3.0706 - val_mae: 1.4474\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 873us/step - loss: 2.3333 - mse: 2.3333 - mae: 1.2122 - val_loss: 3.0858 - val_mse: 3.0858 - val_mae: 1.4475\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 287us/step - loss: 2.3037 - mse: 2.3037 - mae: 1.1998 - val_loss: 3.0962 - val_mse: 3.0962 - val_mae: 1.4469\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 317us/step - loss: 2.2752 - mse: 2.2752 - mae: 1.1905 - val_loss: 3.1030 - val_mse: 3.1030 - val_mae: 1.4463\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 390us/step - loss: 2.2470 - mse: 2.2470 - mae: 1.1835 - val_loss: 3.1060 - val_mse: 3.1060 - val_mae: 1.4453\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 447us/step - loss: 2.2193 - mse: 2.2193 - mae: 1.1785 - val_loss: 3.1066 - val_mse: 3.1066 - val_mae: 1.4437\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 449us/step - loss: 2.1926 - mse: 2.1926 - mae: 1.1744 - val_loss: 3.1064 - val_mse: 3.1064 - val_mae: 1.4417\n",
      "53\n",
      "[53]\n",
      "Train on 101 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.9029 - mse: 7.9029 - mae: 2.5151 - val_loss: 4.6343 - val_mse: 4.6343 - val_mae: 1.9215\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 582us/step - loss: 6.6609 - mse: 6.6609 - mae: 2.2625 - val_loss: 3.8536 - val_mse: 3.8536 - val_mae: 1.7046\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 224us/step - loss: 5.6178 - mse: 5.6178 - mae: 2.0238 - val_loss: 3.2042 - val_mse: 3.2042 - val_mae: 1.4988\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 331us/step - loss: 4.7527 - mse: 4.7527 - mae: 1.8009 - val_loss: 2.6793 - val_mse: 2.6793 - val_mae: 1.3070\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 329us/step - loss: 4.0440 - mse: 4.0440 - mae: 1.5970 - val_loss: 2.2343 - val_mse: 2.2343 - val_mae: 1.1217\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 425us/step - loss: 3.4301 - mse: 3.4301 - mae: 1.4134 - val_loss: 1.8539 - val_mse: 1.8539 - val_mae: 0.9682\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 406us/step - loss: 2.9075 - mse: 2.9075 - mae: 1.2680 - val_loss: 1.5501 - val_mse: 1.5501 - val_mae: 0.8660\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 660us/step - loss: 2.4499 - mse: 2.4499 - mae: 1.1545 - val_loss: 1.3193 - val_mse: 1.3193 - val_mae: 0.7893\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 313us/step - loss: 2.0610 - mse: 2.0610 - mae: 1.0548 - val_loss: 1.1411 - val_mse: 1.1411 - val_mae: 0.7653\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 325us/step - loss: 1.7826 - mse: 1.7826 - mae: 0.9898 - val_loss: 1.0822 - val_mse: 1.0822 - val_mae: 0.8009\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 407us/step - loss: 1.6352 - mse: 1.6352 - mae: 0.9742 - val_loss: 1.1034 - val_mse: 1.1034 - val_mae: 0.8757\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 288us/step - loss: 1.5831 - mse: 1.5831 - mae: 0.9787 - val_loss: 1.1581 - val_mse: 1.1581 - val_mae: 0.9337\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 329us/step - loss: 1.5807 - mse: 1.5807 - mae: 0.9836 - val_loss: 1.1979 - val_mse: 1.1979 - val_mae: 0.9633\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 535us/step - loss: 1.5798 - mse: 1.5798 - mae: 0.9864 - val_loss: 1.2005 - val_mse: 1.2005 - val_mae: 0.9669\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 601us/step - loss: 1.5632 - mse: 1.5632 - mae: 0.9814 - val_loss: 1.1730 - val_mse: 1.1730 - val_mae: 0.9514\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 370us/step - loss: 1.5376 - mse: 1.5376 - mae: 0.9700 - val_loss: 1.1363 - val_mse: 1.1363 - val_mae: 0.9269\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 581us/step - loss: 1.5146 - mse: 1.5146 - mae: 0.9576 - val_loss: 1.1047 - val_mse: 1.1047 - val_mae: 0.9016\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 288us/step - loss: 1.4995 - mse: 1.4995 - mae: 0.9471 - val_loss: 1.0839 - val_mse: 1.0839 - val_mae: 0.8810\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 287us/step - loss: 1.4906 - mse: 1.4906 - mae: 0.9384 - val_loss: 1.0729 - val_mse: 1.0729 - val_mae: 0.8673\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 356us/step - loss: 1.4838 - mse: 1.4838 - mae: 0.9318 - val_loss: 1.0695 - val_mse: 1.0695 - val_mae: 0.8613\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 337us/step - loss: 1.4760 - mse: 1.4760 - mae: 0.9277 - val_loss: 1.0728 - val_mse: 1.0728 - val_mae: 0.8631\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 436us/step - loss: 1.4666 - mse: 1.4666 - mae: 0.9259 - val_loss: 1.0795 - val_mse: 1.0795 - val_mae: 0.8686\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 504us/step - loss: 1.4572 - mse: 1.4572 - mae: 0.9251 - val_loss: 1.0888 - val_mse: 1.0888 - val_mae: 0.8761\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 401us/step - loss: 1.4485 - mse: 1.4485 - mae: 0.9245 - val_loss: 1.0980 - val_mse: 1.0980 - val_mae: 0.8824\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 326us/step - loss: 1.4409 - mse: 1.4409 - mae: 0.9232 - val_loss: 1.1037 - val_mse: 1.1037 - val_mae: 0.8849\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 286us/step - loss: 1.4344 - mse: 1.4344 - mae: 0.9211 - val_loss: 1.1061 - val_mse: 1.1061 - val_mae: 0.8844\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 362us/step - loss: 1.4287 - mse: 1.4287 - mae: 0.9188 - val_loss: 1.1065 - val_mse: 1.1065 - val_mae: 0.8831\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 453us/step - loss: 1.4237 - mse: 1.4237 - mae: 0.9166 - val_loss: 1.1065 - val_mse: 1.1065 - val_mae: 0.8821\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 419us/step - loss: 1.4185 - mse: 1.4185 - mae: 0.9144 - val_loss: 1.1088 - val_mse: 1.1088 - val_mae: 0.8834\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 297us/step - loss: 1.4135 - mse: 1.4135 - mae: 0.9127 - val_loss: 1.1097 - val_mse: 1.1097 - val_mae: 0.8842\n",
      "54\n",
      "[54]\n",
      "Train on 74 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 17.1011 - mse: 17.1011 - mae: 3.7172 - val_loss: 5.6955 - val_mse: 5.6955 - val_mae: 2.2698\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 655us/step - loss: 15.4103 - mse: 15.4103 - mae: 3.4913 - val_loss: 4.9630 - val_mse: 4.9630 - val_mae: 2.1095\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 365us/step - loss: 13.9617 - mse: 13.9617 - mae: 3.2814 - val_loss: 4.3401 - val_mse: 4.3401 - val_mae: 1.9596\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 567us/step - loss: 12.7100 - mse: 12.7100 - mae: 3.0914 - val_loss: 3.7983 - val_mse: 3.7983 - val_mae: 1.8172\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 364us/step - loss: 11.6337 - mse: 11.6337 - mae: 2.9207 - val_loss: 3.3663 - val_mse: 3.3663 - val_mae: 1.6916\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 393us/step - loss: 10.7318 - mse: 10.7318 - mae: 2.7690 - val_loss: 3.0179 - val_mse: 3.0179 - val_mae: 1.5858\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 487us/step - loss: 9.9740 - mse: 9.9740 - mae: 2.6350 - val_loss: 2.7305 - val_mse: 2.7305 - val_mae: 1.4971\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 460us/step - loss: 9.3382 - mse: 9.3382 - mae: 2.5206 - val_loss: 2.4832 - val_mse: 2.4832 - val_mae: 1.4209\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 610us/step - loss: 8.7895 - mse: 8.7895 - mae: 2.4183 - val_loss: 2.2698 - val_mse: 2.2698 - val_mae: 1.3556\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 619us/step - loss: 8.3044 - mse: 8.3044 - mae: 2.3268 - val_loss: 2.0785 - val_mse: 2.0785 - val_mae: 1.2967\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 515us/step - loss: 7.8785 - mse: 7.8785 - mae: 2.2439 - val_loss: 1.9066 - val_mse: 1.9066 - val_mae: 1.2433\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 531us/step - loss: 7.4923 - mse: 7.4923 - mae: 2.1655 - val_loss: 1.7470 - val_mse: 1.7470 - val_mae: 1.1911\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 391us/step - loss: 7.1433 - mse: 7.1433 - mae: 2.0919 - val_loss: 1.6049 - val_mse: 1.6049 - val_mae: 1.1434\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 413us/step - loss: 6.8217 - mse: 6.8217 - mae: 2.0212 - val_loss: 1.4732 - val_mse: 1.4732 - val_mae: 1.0963\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 542us/step - loss: 6.5278 - mse: 6.5278 - mae: 1.9533 - val_loss: 1.3471 - val_mse: 1.3471 - val_mae: 1.0473\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 382us/step - loss: 6.2499 - mse: 6.2499 - mae: 1.8859 - val_loss: 1.2337 - val_mse: 1.2337 - val_mae: 1.0027\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 393us/step - loss: 5.9935 - mse: 5.9935 - mae: 1.8187 - val_loss: 1.1270 - val_mse: 1.1270 - val_mae: 0.9586\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 541us/step - loss: 5.7505 - mse: 5.7505 - mae: 1.7522 - val_loss: 1.0288 - val_mse: 1.0288 - val_mae: 0.9134\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 311us/step - loss: 5.5321 - mse: 5.5321 - mae: 1.6886 - val_loss: 0.9392 - val_mse: 0.9392 - val_mae: 0.8661\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 724us/step - loss: 5.3264 - mse: 5.3264 - mae: 1.6280 - val_loss: 0.8480 - val_mse: 0.8480 - val_mae: 0.8142\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 277us/step - loss: 5.1111 - mse: 5.1111 - mae: 1.5657 - val_loss: 0.7573 - val_mse: 0.7573 - val_mae: 0.7583\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 433us/step - loss: 4.8973 - mse: 4.8973 - mae: 1.5036 - val_loss: 0.6686 - val_mse: 0.6686 - val_mae: 0.6983\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 445us/step - loss: 4.6850 - mse: 4.6850 - mae: 1.4434 - val_loss: 0.5810 - val_mse: 0.5810 - val_mae: 0.6332\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 808us/step - loss: 4.4733 - mse: 4.4733 - mae: 1.3886 - val_loss: 0.4994 - val_mse: 0.4994 - val_mae: 0.5734\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 434us/step - loss: 4.2702 - mse: 4.2702 - mae: 1.3414 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.5164\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 297us/step - loss: 4.0781 - mse: 4.0781 - mae: 1.3006 - val_loss: 0.3560 - val_mse: 0.3560 - val_mae: 0.4575\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 404us/step - loss: 3.9003 - mse: 3.9003 - mae: 1.2677 - val_loss: 0.2989 - val_mse: 0.2989 - val_mae: 0.4057\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 712us/step - loss: 3.7422 - mse: 3.7422 - mae: 1.2477 - val_loss: 0.2536 - val_mse: 0.2536 - val_mae: 0.3762\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 376us/step - loss: 3.6083 - mse: 3.6083 - mae: 1.2381 - val_loss: 0.2203 - val_mse: 0.2203 - val_mae: 0.3672\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 371us/step - loss: 3.4978 - mse: 3.4978 - mae: 1.2374 - val_loss: 0.1982 - val_mse: 0.1982 - val_mae: 0.3597\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 433us/step - loss: 3.4076 - mse: 3.4076 - mae: 1.2385 - val_loss: 0.1858 - val_mse: 0.1858 - val_mae: 0.3524\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 488us/step - loss: 3.3350 - mse: 3.3350 - mae: 1.2419 - val_loss: 0.1811 - val_mse: 0.1811 - val_mae: 0.3452\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 0s 337us/step - loss: 3.2806 - mse: 3.2806 - mae: 1.2471 - val_loss: 0.1818 - val_mse: 0.1818 - val_mae: 0.3446\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 0s 345us/step - loss: 3.2412 - mse: 3.2412 - mae: 1.2523 - val_loss: 0.1863 - val_mse: 0.1863 - val_mae: 0.3527\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 0s 712us/step - loss: 3.2120 - mse: 3.2120 - mae: 1.2560 - val_loss: 0.1925 - val_mse: 0.1925 - val_mae: 0.3663\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 0s 292us/step - loss: 3.1901 - mse: 3.1901 - mae: 1.2596 - val_loss: 0.1989 - val_mse: 0.1989 - val_mae: 0.3788\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 0s 357us/step - loss: 3.1725 - mse: 3.1725 - mae: 1.2619 - val_loss: 0.2041 - val_mse: 0.2041 - val_mae: 0.3877\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 0s 261us/step - loss: 3.1567 - mse: 3.1567 - mae: 1.2621 - val_loss: 0.2075 - val_mse: 0.2075 - val_mae: 0.3935\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 0s 422us/step - loss: 3.1414 - mse: 3.1414 - mae: 1.2606 - val_loss: 0.2092 - val_mse: 0.2092 - val_mae: 0.3967\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - 0s 327us/step - loss: 3.1262 - mse: 3.1262 - mae: 1.2577 - val_loss: 0.2092 - val_mse: 0.2092 - val_mae: 0.3980\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - 0s 559us/step - loss: 3.1109 - mse: 3.1109 - mae: 1.2545 - val_loss: 0.2079 - val_mse: 0.2079 - val_mae: 0.3977\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 627us/step - loss: 3.0958 - mse: 3.0958 - mae: 1.2506 - val_loss: 0.2058 - val_mse: 0.2058 - val_mae: 0.3964\n",
      "55\n",
      "[55]\n",
      "Train on 79 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 7.8059 - mse: 7.8059 - mae: 2.4853 - val_loss: 7.7358 - val_mse: 7.7358 - val_mae: 2.6753\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 530us/step - loss: 7.0639 - mse: 7.0639 - mae: 2.3473 - val_loss: 7.0027 - val_mse: 7.0027 - val_mae: 2.5422\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 300us/step - loss: 6.4357 - mse: 6.4357 - mae: 2.2308 - val_loss: 6.4596 - val_mse: 6.4596 - val_mae: 2.4410\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 341us/step - loss: 5.9309 - mse: 5.9309 - mae: 2.1365 - val_loss: 6.0324 - val_mse: 6.0324 - val_mae: 2.3624\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 366us/step - loss: 5.5681 - mse: 5.5681 - mae: 2.0648 - val_loss: 5.7608 - val_mse: 5.7608 - val_mae: 2.3136\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 562us/step - loss: 5.3012 - mse: 5.3012 - mae: 2.0127 - val_loss: 5.5893 - val_mse: 5.5893 - val_mae: 2.2821\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 317us/step - loss: 5.1281 - mse: 5.1281 - mae: 1.9755 - val_loss: 5.5013 - val_mse: 5.5013 - val_mae: 2.2663\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 414us/step - loss: 5.0001 - mse: 5.0001 - mae: 1.9455 - val_loss: 5.4100 - val_mse: 5.4100 - val_mae: 2.2485\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 4.8880 - mse: 4.8880 - mae: 1.9176 - val_loss: 5.3483 - val_mse: 5.3483 - val_mae: 2.2347\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 432us/step - loss: 4.7787 - mse: 4.7787 - mae: 1.8887 - val_loss: 5.2516 - val_mse: 5.2516 - val_mae: 2.2140\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 292us/step - loss: 4.6456 - mse: 4.6456 - mae: 1.8518 - val_loss: 5.1018 - val_mse: 5.1018 - val_mae: 2.1817\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 545us/step - loss: 4.4729 - mse: 4.4729 - mae: 1.8035 - val_loss: 4.8901 - val_mse: 4.8901 - val_mae: 2.1332\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 458us/step - loss: 4.2592 - mse: 4.2592 - mae: 1.7429 - val_loss: 4.5841 - val_mse: 4.5841 - val_mae: 2.0603\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 330us/step - loss: 3.9902 - mse: 3.9902 - mae: 1.6651 - val_loss: 4.2340 - val_mse: 4.2340 - val_mae: 1.9739\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 341us/step - loss: 3.6688 - mse: 3.6688 - mae: 1.5692 - val_loss: 3.8542 - val_mse: 3.8542 - val_mae: 1.8753\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 444us/step - loss: 3.3222 - mse: 3.3222 - mae: 1.4587 - val_loss: 3.4418 - val_mse: 3.4418 - val_mae: 1.7618\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 548us/step - loss: 2.9775 - mse: 2.9775 - mae: 1.3419 - val_loss: 3.0328 - val_mse: 3.0328 - val_mae: 1.6412\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 319us/step - loss: 2.6495 - mse: 2.6495 - mae: 1.2271 - val_loss: 2.6368 - val_mse: 2.6368 - val_mae: 1.5148\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 331us/step - loss: 2.3366 - mse: 2.3366 - mae: 1.1175 - val_loss: 2.2495 - val_mse: 2.2495 - val_mae: 1.3781\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 461us/step - loss: 2.0515 - mse: 2.0515 - mae: 1.0326 - val_loss: 1.8384 - val_mse: 1.8384 - val_mae: 1.2207\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 379us/step - loss: 1.8088 - mse: 1.8088 - mae: 0.9668 - val_loss: 1.4639 - val_mse: 1.4639 - val_mae: 1.0706\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 0s 198us/step - loss: 1.5912 - mse: 1.5912 - mae: 0.9104 - val_loss: 1.0919 - val_mse: 1.0919 - val_mae: 0.8964\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 0s 371us/step - loss: 1.4197 - mse: 1.4197 - mae: 0.8761 - val_loss: 0.7756 - val_mse: 0.7756 - val_mae: 0.7549\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 0s 306us/step - loss: 1.3403 - mse: 1.3403 - mae: 0.8766 - val_loss: 0.5724 - val_mse: 0.5724 - val_mae: 0.6476\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 0s 391us/step - loss: 1.3396 - mse: 1.3396 - mae: 0.8968 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.5821\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 0s 342us/step - loss: 1.3679 - mse: 1.3679 - mae: 0.9181 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.5553\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 0s 492us/step - loss: 1.3687 - mse: 1.3687 - mae: 0.9233 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.5702\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 0s 380us/step - loss: 1.3340 - mse: 1.3340 - mae: 0.9088 - val_loss: 0.4914 - val_mse: 0.4914 - val_mae: 0.6010\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 0s 278us/step - loss: 1.2906 - mse: 1.2906 - mae: 0.8861 - val_loss: 0.5474 - val_mse: 0.5474 - val_mae: 0.6314\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 0s 343us/step - loss: 1.2551 - mse: 1.2551 - mae: 0.8640 - val_loss: 0.6020 - val_mse: 0.6020 - val_mae: 0.6534\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 0s 377us/step - loss: 1.2328 - mse: 1.2328 - mae: 0.8508 - val_loss: 0.6459 - val_mse: 0.6459 - val_mae: 0.6687\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 0s 557us/step - loss: 1.2182 - mse: 1.2182 - mae: 0.8435 - val_loss: 0.6689 - val_mse: 0.6689 - val_mae: 0.6841\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 0s 480us/step - loss: 1.2059 - mse: 1.2059 - mae: 0.8390 - val_loss: 0.6705 - val_mse: 0.6705 - val_mae: 0.6857\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 0s 381us/step - loss: 1.1930 - mse: 1.1930 - mae: 0.8353 - val_loss: 0.6532 - val_mse: 0.6532 - val_mae: 0.6756\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 0s 316us/step - loss: 1.1797 - mse: 1.1797 - mae: 0.8319 - val_loss: 0.6257 - val_mse: 0.6257 - val_mae: 0.6595\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 0s 418us/step - loss: 1.1673 - mse: 1.1673 - mae: 0.8288 - val_loss: 0.5941 - val_mse: 0.5941 - val_mae: 0.6437\n",
      "56\n",
      "[56]\n",
      "Train on 78 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 10.1386 - mse: 10.1386 - mae: 3.0435 - val_loss: 8.0120 - val_mse: 8.0120 - val_mae: 2.7560\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 363us/step - loss: 8.8759 - mse: 8.8759 - mae: 2.8281 - val_loss: 6.8707 - val_mse: 6.8707 - val_mae: 2.5422\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 462us/step - loss: 7.7344 - mse: 7.7344 - mae: 2.6177 - val_loss: 5.8428 - val_mse: 5.8428 - val_mae: 2.3324\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 644us/step - loss: 6.7111 - mse: 6.7111 - mae: 2.4126 - val_loss: 4.9334 - val_mse: 4.9334 - val_mae: 2.1297\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 575us/step - loss: 5.8036 - mse: 5.8036 - mae: 2.2142 - val_loss: 4.1890 - val_mse: 4.1890 - val_mae: 1.9431\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 385us/step - loss: 5.0213 - mse: 5.0213 - mae: 2.0266 - val_loss: 3.5041 - val_mse: 3.5041 - val_mae: 1.7603\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 372us/step - loss: 4.3436 - mse: 4.3436 - mae: 1.8452 - val_loss: 2.9656 - val_mse: 2.9656 - val_mae: 1.5977\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 366us/step - loss: 3.7981 - mse: 3.7981 - mae: 1.6818 - val_loss: 2.4951 - val_mse: 2.4951 - val_mae: 1.4319\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 342us/step - loss: 3.3147 - mse: 3.3147 - mae: 1.5282 - val_loss: 2.0466 - val_mse: 2.0466 - val_mae: 1.2470\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 296us/step - loss: 2.8521 - mse: 2.8521 - mae: 1.3792 - val_loss: 1.6472 - val_mse: 1.6472 - val_mae: 1.0510\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 384us/step - loss: 2.4172 - mse: 2.4172 - mae: 1.2294 - val_loss: 1.3160 - val_mse: 1.3160 - val_mae: 0.8676\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 572us/step - loss: 2.0341 - mse: 2.0341 - mae: 1.0928 - val_loss: 1.0936 - val_mse: 1.0936 - val_mae: 0.7245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 371us/step - loss: 1.7215 - mse: 1.7215 - mae: 0.9885 - val_loss: 0.9807 - val_mse: 0.9807 - val_mae: 0.7329\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 501us/step - loss: 1.5035 - mse: 1.5035 - mae: 0.9416 - val_loss: 0.9380 - val_mse: 0.9380 - val_mae: 0.7894\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 489us/step - loss: 1.3822 - mse: 1.3822 - mae: 0.9299 - val_loss: 0.9728 - val_mse: 0.9728 - val_mae: 0.8332\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 512us/step - loss: 1.3340 - mse: 1.3340 - mae: 0.9302 - val_loss: 1.0391 - val_mse: 1.0391 - val_mae: 0.8743\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 360us/step - loss: 1.3283 - mse: 1.3283 - mae: 0.9381 - val_loss: 1.0777 - val_mse: 1.0777 - val_mae: 0.8929\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 334us/step - loss: 1.3242 - mse: 1.3242 - mae: 0.9389 - val_loss: 1.0810 - val_mse: 1.0810 - val_mae: 0.8905\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 425us/step - loss: 1.3012 - mse: 1.3012 - mae: 0.9290 - val_loss: 1.0526 - val_mse: 1.0526 - val_mae: 0.8748\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 331us/step - loss: 1.2554 - mse: 1.2554 - mae: 0.9070 - val_loss: 1.0063 - val_mse: 1.0063 - val_mae: 0.8496\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 526us/step - loss: 1.2062 - mse: 1.2062 - mae: 0.8803 - val_loss: 0.9645 - val_mse: 0.9645 - val_mae: 0.8195\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 386us/step - loss: 1.1667 - mse: 1.1667 - mae: 0.8550 - val_loss: 0.9348 - val_mse: 0.9348 - val_mae: 0.7885\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 384us/step - loss: 1.1368 - mse: 1.1368 - mae: 0.8321 - val_loss: 0.9173 - val_mse: 0.9173 - val_mae: 0.7633\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 590us/step - loss: 1.1141 - mse: 1.1141 - mae: 0.8141 - val_loss: 0.9027 - val_mse: 0.9027 - val_mae: 0.7413\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 406us/step - loss: 1.0907 - mse: 1.0907 - mae: 0.7981 - val_loss: 0.8938 - val_mse: 0.8938 - val_mae: 0.7373\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 423us/step - loss: 1.0659 - mse: 1.0659 - mae: 0.7864 - val_loss: 0.8877 - val_mse: 0.8877 - val_mae: 0.7385\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 566us/step - loss: 1.0393 - mse: 1.0393 - mae: 0.7770 - val_loss: 0.8844 - val_mse: 0.8844 - val_mae: 0.7441\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 0s 450us/step - loss: 1.0129 - mse: 1.0129 - mae: 0.7682 - val_loss: 0.8852 - val_mse: 0.8852 - val_mae: 0.7570\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 0s 323us/step - loss: 0.9892 - mse: 0.9892 - mae: 0.7613 - val_loss: 0.8880 - val_mse: 0.8880 - val_mae: 0.7692\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 0s 482us/step - loss: 0.9687 - mse: 0.9687 - mae: 0.7557 - val_loss: 0.8912 - val_mse: 0.8912 - val_mae: 0.7799\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 0s 462us/step - loss: 0.9501 - mse: 0.9501 - mae: 0.7505 - val_loss: 0.8931 - val_mse: 0.8931 - val_mae: 0.7884\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 0s 412us/step - loss: 0.9324 - mse: 0.9324 - mae: 0.7445 - val_loss: 0.8933 - val_mse: 0.8933 - val_mae: 0.7948\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 0s 407us/step - loss: 0.9158 - mse: 0.9158 - mae: 0.7379 - val_loss: 0.8926 - val_mse: 0.8926 - val_mae: 0.7997\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 0s 332us/step - loss: 0.9002 - mse: 0.9002 - mae: 0.7315 - val_loss: 0.8919 - val_mse: 0.8919 - val_mae: 0.8038\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 0s 435us/step - loss: 0.8855 - mse: 0.8855 - mae: 0.7251 - val_loss: 0.8915 - val_mse: 0.8915 - val_mae: 0.8076\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 0s 480us/step - loss: 0.8722 - mse: 0.8722 - mae: 0.7194 - val_loss: 0.8917 - val_mse: 0.8917 - val_mae: 0.8115\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 0s 486us/step - loss: 0.8598 - mse: 0.8598 - mae: 0.7142 - val_loss: 0.8927 - val_mse: 0.8927 - val_mae: 0.8156\n",
      "57\n",
      "[57]\n",
      "Train on 84 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 4.6693 - mse: 4.6693 - mae: 1.7400 - val_loss: 6.1243 - val_mse: 6.1243 - val_mae: 2.1654\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 600us/step - loss: 4.4089 - mse: 4.4089 - mae: 1.6665 - val_loss: 5.7233 - val_mse: 5.7233 - val_mae: 2.0814\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 311us/step - loss: 4.1127 - mse: 4.1127 - mae: 1.5821 - val_loss: 5.2370 - val_mse: 5.2370 - val_mae: 1.9820\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 358us/step - loss: 3.8038 - mse: 3.8038 - mae: 1.4825 - val_loss: 4.7217 - val_mse: 4.7217 - val_mae: 1.8638\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 356us/step - loss: 3.4660 - mse: 3.4660 - mae: 1.3754 - val_loss: 4.1980 - val_mse: 4.1980 - val_mae: 1.7303\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 309us/step - loss: 3.1204 - mse: 3.1204 - mae: 1.2817 - val_loss: 3.6482 - val_mse: 3.6482 - val_mae: 1.5751\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 408us/step - loss: 2.7969 - mse: 2.7969 - mae: 1.1833 - val_loss: 3.1320 - val_mse: 3.1320 - val_mae: 1.4524\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 323us/step - loss: 2.5116 - mse: 2.5116 - mae: 1.1062 - val_loss: 2.6946 - val_mse: 2.6946 - val_mae: 1.3471\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 321us/step - loss: 2.2673 - mse: 2.2673 - mae: 1.0488 - val_loss: 2.3430 - val_mse: 2.3430 - val_mae: 1.2405\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 261us/step - loss: 2.0829 - mse: 2.0829 - mae: 1.0104 - val_loss: 2.0828 - val_mse: 2.0828 - val_mae: 1.1445\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 336us/step - loss: 1.9623 - mse: 1.9623 - mae: 0.9927 - val_loss: 1.9183 - val_mse: 1.9183 - val_mae: 1.1028\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 322us/step - loss: 1.8993 - mse: 1.8993 - mae: 0.9879 - val_loss: 1.8320 - val_mse: 1.8320 - val_mae: 1.0868\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 251us/step - loss: 1.8782 - mse: 1.8782 - mae: 0.9994 - val_loss: 1.7956 - val_mse: 1.7956 - val_mae: 1.1029\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.8751 - mse: 1.8751 - mae: 1.0086 - val_loss: 1.7840 - val_mse: 1.7840 - val_mae: 1.1167\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 419us/step - loss: 1.8707 - mse: 1.8707 - mae: 1.0129 - val_loss: 1.7783 - val_mse: 1.7783 - val_mae: 1.1224\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 453us/step - loss: 1.8560 - mse: 1.8560 - mae: 1.0103 - val_loss: 1.7705 - val_mse: 1.7705 - val_mae: 1.1210\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 273us/step - loss: 1.8309 - mse: 1.8309 - mae: 1.0013 - val_loss: 1.7610 - val_mse: 1.7610 - val_mae: 1.1142\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.8011 - mse: 1.8011 - mae: 0.9883 - val_loss: 1.7551 - val_mse: 1.7551 - val_mae: 1.1050\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 512us/step - loss: 1.7708 - mse: 1.7708 - mae: 0.9732 - val_loss: 1.7551 - val_mse: 1.7551 - val_mae: 1.0982\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.7446 - mse: 1.7446 - mae: 0.9591 - val_loss: 1.7592 - val_mse: 1.7592 - val_mae: 1.0973\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 427us/step - loss: 1.7225 - mse: 1.7225 - mae: 0.9459 - val_loss: 1.7653 - val_mse: 1.7653 - val_mae: 1.0977\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 302us/step - loss: 1.7033 - mse: 1.7033 - mae: 0.9338 - val_loss: 1.7709 - val_mse: 1.7709 - val_mae: 1.1028\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.6858 - mse: 1.6858 - mae: 0.9233 - val_loss: 1.7753 - val_mse: 1.7753 - val_mae: 1.1077\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 451us/step - loss: 1.6692 - mse: 1.6692 - mae: 0.9146 - val_loss: 1.7832 - val_mse: 1.7832 - val_mae: 1.1149\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 508us/step - loss: 1.6529 - mse: 1.6529 - mae: 0.9079 - val_loss: 1.7876 - val_mse: 1.7876 - val_mae: 1.1214\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 451us/step - loss: 1.6365 - mse: 1.6365 - mae: 0.9050 - val_loss: 1.7896 - val_mse: 1.7896 - val_mae: 1.1290\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 301us/step - loss: 1.6216 - mse: 1.6216 - mae: 0.9031 - val_loss: 1.7916 - val_mse: 1.7916 - val_mae: 1.1361\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 298us/step - loss: 1.6073 - mse: 1.6073 - mae: 0.9021 - val_loss: 1.7951 - val_mse: 1.7951 - val_mae: 1.1432\n",
      "58\n",
      "[58]\n",
      "Train on 88 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 1s 11ms/step - loss: 1.6849 - mse: 1.6849 - mae: 0.9245 - val_loss: 0.5818 - val_mse: 0.5818 - val_mae: 0.6129\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 375us/step - loss: 1.4687 - mse: 1.4687 - mae: 0.8401 - val_loss: 0.6604 - val_mse: 0.6604 - val_mae: 0.6772\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 244us/step - loss: 1.3719 - mse: 1.3719 - mae: 0.8290 - val_loss: 0.8004 - val_mse: 0.8004 - val_mae: 0.7597\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 496us/step - loss: 1.3535 - mse: 1.3535 - mae: 0.8529 - val_loss: 0.8892 - val_mse: 0.8892 - val_mae: 0.8002\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 381us/step - loss: 1.3522 - mse: 1.3522 - mae: 0.8715 - val_loss: 0.8889 - val_mse: 0.8889 - val_mae: 0.8039\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 308us/step - loss: 1.3315 - mse: 1.3315 - mae: 0.8667 - val_loss: 0.8289 - val_mse: 0.8289 - val_mae: 0.7801\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 355us/step - loss: 1.2993 - mse: 1.2993 - mae: 0.8482 - val_loss: 0.7487 - val_mse: 0.7487 - val_mae: 0.7454\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 538us/step - loss: 1.2705 - mse: 1.2705 - mae: 0.8250 - val_loss: 0.6773 - val_mse: 0.6773 - val_mae: 0.7126\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 298us/step - loss: 1.2495 - mse: 1.2495 - mae: 0.8058 - val_loss: 0.6274 - val_mse: 0.6274 - val_mae: 0.6869\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 321us/step - loss: 1.2337 - mse: 1.2337 - mae: 0.7920 - val_loss: 0.5985 - val_mse: 0.5985 - val_mae: 0.6711\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 438us/step - loss: 1.2186 - mse: 1.2186 - mae: 0.7833 - val_loss: 0.5855 - val_mse: 0.5855 - val_mae: 0.6643\n",
      "59\n",
      "[59]\n",
      "Train on 103 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "103/103 [==============================] - 1s 10ms/step - loss: 9.2242 - mse: 9.2242 - mae: 2.3819 - val_loss: 4.9668 - val_mse: 4.9668 - val_mae: 1.8660\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 446us/step - loss: 6.8823 - mse: 6.8823 - mae: 1.9516 - val_loss: 3.5331 - val_mse: 3.5331 - val_mae: 1.4938\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 594us/step - loss: 5.3680 - mse: 5.3680 - mae: 1.6945 - val_loss: 2.7000 - val_mse: 2.7000 - val_mae: 1.3034\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 292us/step - loss: 4.5641 - mse: 4.5641 - mae: 1.5723 - val_loss: 2.2836 - val_mse: 2.2836 - val_mae: 1.2058\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 323us/step - loss: 4.2525 - mse: 4.2525 - mae: 1.5525 - val_loss: 2.1136 - val_mse: 2.1136 - val_mae: 1.1902\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 496us/step - loss: 4.1943 - mse: 4.1943 - mae: 1.5799 - val_loss: 2.0532 - val_mse: 2.0532 - val_mae: 1.1894\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 498us/step - loss: 4.1833 - mse: 4.1833 - mae: 1.5987 - val_loss: 2.0236 - val_mse: 2.0236 - val_mae: 1.1843\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 317us/step - loss: 4.1365 - mse: 4.1365 - mae: 1.5933 - val_loss: 1.9907 - val_mse: 1.9907 - val_mae: 1.1768\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 612us/step - loss: 4.0441 - mse: 4.0441 - mae: 1.5707 - val_loss: 1.9521 - val_mse: 1.9521 - val_mae: 1.1612\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 368us/step - loss: 3.9335 - mse: 3.9335 - mae: 1.5381 - val_loss: 1.9197 - val_mse: 1.9197 - val_mae: 1.1426\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 330us/step - loss: 3.8297 - mse: 3.8297 - mae: 1.5021 - val_loss: 1.8979 - val_mse: 1.8979 - val_mae: 1.1273\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 454us/step - loss: 3.7448 - mse: 3.7448 - mae: 1.4748 - val_loss: 1.8848 - val_mse: 1.8848 - val_mae: 1.1165\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 181us/step - loss: 3.6754 - mse: 3.6754 - mae: 1.4583 - val_loss: 1.8732 - val_mse: 1.8732 - val_mae: 1.1129\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 310us/step - loss: 3.6194 - mse: 3.6194 - mae: 1.4444 - val_loss: 1.8585 - val_mse: 1.8585 - val_mae: 1.1113\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 391us/step - loss: 3.5697 - mse: 3.5697 - mae: 1.4326 - val_loss: 1.8392 - val_mse: 1.8392 - val_mae: 1.1078\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 321us/step - loss: 3.5224 - mse: 3.5224 - mae: 1.4226 - val_loss: 1.8165 - val_mse: 1.8165 - val_mae: 1.1028\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 400us/step - loss: 3.4755 - mse: 3.4755 - mae: 1.4135 - val_loss: 1.7944 - val_mse: 1.7944 - val_mae: 1.0988\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 343us/step - loss: 3.4305 - mse: 3.4305 - mae: 1.4047 - val_loss: 1.7752 - val_mse: 1.7752 - val_mae: 1.0957\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 350us/step - loss: 3.3892 - mse: 3.3892 - mae: 1.3963 - val_loss: 1.7577 - val_mse: 1.7577 - val_mae: 1.0927\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 321us/step - loss: 3.3503 - mse: 3.3503 - mae: 1.3875 - val_loss: 1.7425 - val_mse: 1.7425 - val_mae: 1.0909\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 575us/step - loss: 3.3132 - mse: 3.3132 - mae: 1.3780 - val_loss: 1.7295 - val_mse: 1.7295 - val_mae: 1.0883\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 439us/step - loss: 3.2780 - mse: 3.2780 - mae: 1.3687 - val_loss: 1.7192 - val_mse: 1.7192 - val_mae: 1.0856\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 699us/step - loss: 3.2442 - mse: 3.2442 - mae: 1.3593 - val_loss: 1.7110 - val_mse: 1.7110 - val_mae: 1.0832\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 223us/step - loss: 3.2114 - mse: 3.2114 - mae: 1.3501 - val_loss: 1.7041 - val_mse: 1.7041 - val_mae: 1.0811\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 341us/step - loss: 3.1806 - mse: 3.1806 - mae: 1.3414 - val_loss: 1.6981 - val_mse: 1.6981 - val_mae: 1.0796\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 308us/step - loss: 3.1515 - mse: 3.1515 - mae: 1.3330 - val_loss: 1.6916 - val_mse: 1.6916 - val_mae: 1.0787\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 264us/step - loss: 3.1233 - mse: 3.1233 - mae: 1.3250 - val_loss: 1.6858 - val_mse: 1.6858 - val_mae: 1.0779\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 533us/step - loss: 3.0958 - mse: 3.0958 - mae: 1.3175 - val_loss: 1.6806 - val_mse: 1.6806 - val_mae: 1.0773\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 273us/step - loss: 3.0692 - mse: 3.0692 - mae: 1.3107 - val_loss: 1.6761 - val_mse: 1.6761 - val_mae: 1.0796\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 671us/step - loss: 3.0436 - mse: 3.0436 - mae: 1.3033 - val_loss: 1.6723 - val_mse: 1.6723 - val_mae: 1.0830\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 3.0197 - mse: 3.0197 - mae: 1.2955 - val_loss: 1.6694 - val_mse: 1.6694 - val_mae: 1.0865\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 261us/step - loss: 2.9986 - mse: 2.9986 - mae: 1.2890 - val_loss: 1.6673 - val_mse: 1.6673 - val_mae: 1.0893\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 339us/step - loss: 2.9786 - mse: 2.9786 - mae: 1.2835 - val_loss: 1.6648 - val_mse: 1.6648 - val_mae: 1.0925\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 607us/step - loss: 2.9594 - mse: 2.9594 - mae: 1.2788 - val_loss: 1.6620 - val_mse: 1.6620 - val_mae: 1.0957\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 310us/step - loss: 2.9417 - mse: 2.9417 - mae: 1.2744 - val_loss: 1.6583 - val_mse: 1.6583 - val_mae: 1.0978\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 307us/step - loss: 2.9251 - mse: 2.9251 - mae: 1.2702 - val_loss: 1.6553 - val_mse: 1.6553 - val_mae: 1.0995\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 430us/step - loss: 2.9088 - mse: 2.9088 - mae: 1.2666 - val_loss: 1.6530 - val_mse: 1.6530 - val_mae: 1.1009\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 290us/step - loss: 2.8938 - mse: 2.8938 - mae: 1.2633 - val_loss: 1.6513 - val_mse: 1.6513 - val_mae: 1.1023\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 311us/step - loss: 2.8796 - mse: 2.8796 - mae: 1.2601 - val_loss: 1.6501 - val_mse: 1.6501 - val_mae: 1.1036\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 275us/step - loss: 2.8657 - mse: 2.8657 - mae: 1.2569 - val_loss: 1.6488 - val_mse: 1.6488 - val_mae: 1.1062\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 274us/step - loss: 2.8525 - mse: 2.8525 - mae: 1.2539 - val_loss: 1.6475 - val_mse: 1.6475 - val_mae: 1.1095\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 349us/step - loss: 2.8404 - mse: 2.8404 - mae: 1.2512 - val_loss: 1.6460 - val_mse: 1.6460 - val_mae: 1.1100\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 343us/step - loss: 2.8279 - mse: 2.8279 - mae: 1.2482 - val_loss: 1.6439 - val_mse: 1.6439 - val_mae: 1.1092\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 290us/step - loss: 2.8164 - mse: 2.8164 - mae: 1.2451 - val_loss: 1.6414 - val_mse: 1.6414 - val_mae: 1.1099\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 252us/step - loss: 2.8057 - mse: 2.8057 - mae: 1.2416 - val_loss: 1.6393 - val_mse: 1.6393 - val_mae: 1.1111\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 282us/step - loss: 2.7954 - mse: 2.7954 - mae: 1.2388 - val_loss: 1.6379 - val_mse: 1.6379 - val_mae: 1.1113\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 419us/step - loss: 2.7850 - mse: 2.7850 - mae: 1.2363 - val_loss: 1.6368 - val_mse: 1.6368 - val_mae: 1.1113\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 540us/step - loss: 2.7751 - mse: 2.7751 - mae: 1.2343 - val_loss: 1.6344 - val_mse: 1.6344 - val_mae: 1.1128\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 332us/step - loss: 2.7659 - mse: 2.7659 - mae: 1.2318 - val_loss: 1.6328 - val_mse: 1.6328 - val_mae: 1.1145\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 438us/step - loss: 2.7565 - mse: 2.7565 - mae: 1.2292 - val_loss: 1.6321 - val_mse: 1.6321 - val_mae: 1.1142\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 283us/step - loss: 2.7459 - mse: 2.7459 - mae: 1.2269 - val_loss: 1.6318 - val_mse: 1.6318 - val_mae: 1.1129\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 390us/step - loss: 2.7372 - mse: 2.7372 - mae: 1.2253 - val_loss: 1.6312 - val_mse: 1.6312 - val_mae: 1.1134\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 255us/step - loss: 2.7266 - mse: 2.7266 - mae: 1.2227 - val_loss: 1.6298 - val_mse: 1.6298 - val_mae: 1.1145\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 599us/step - loss: 2.7181 - mse: 2.7181 - mae: 1.2204 - val_loss: 1.6289 - val_mse: 1.6289 - val_mae: 1.1143\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 301us/step - loss: 2.7088 - mse: 2.7088 - mae: 1.2179 - val_loss: 1.6282 - val_mse: 1.6282 - val_mae: 1.1131\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 290us/step - loss: 2.7010 - mse: 2.7010 - mae: 1.2161 - val_loss: 1.6279 - val_mse: 1.6279 - val_mae: 1.1140\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 378us/step - loss: 2.6900 - mse: 2.6900 - mae: 1.2136 - val_loss: 1.6257 - val_mse: 1.6257 - val_mae: 1.1150\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 274us/step - loss: 2.6810 - mse: 2.6810 - mae: 1.2107 - val_loss: 1.6231 - val_mse: 1.6231 - val_mae: 1.1138\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 311us/step - loss: 2.6715 - mse: 2.6715 - mae: 1.2081 - val_loss: 1.6198 - val_mse: 1.6198 - val_mae: 1.1129\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 330us/step - loss: 2.6593 - mse: 2.6593 - mae: 1.2055 - val_loss: 1.6168 - val_mse: 1.6168 - val_mae: 1.1124\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 338us/step - loss: 2.6471 - mse: 2.6471 - mae: 1.2032 - val_loss: 1.6135 - val_mse: 1.6135 - val_mae: 1.1116\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 359us/step - loss: 2.6358 - mse: 2.6358 - mae: 1.2008 - val_loss: 1.6088 - val_mse: 1.6088 - val_mae: 1.1093\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 323us/step - loss: 2.6226 - mse: 2.6226 - mae: 1.1979 - val_loss: 1.6031 - val_mse: 1.6031 - val_mae: 1.1068\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 612us/step - loss: 2.6092 - mse: 2.6092 - mae: 1.1942 - val_loss: 1.5963 - val_mse: 1.5963 - val_mae: 1.1053\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 302us/step - loss: 2.5966 - mse: 2.5966 - mae: 1.1900 - val_loss: 1.5916 - val_mse: 1.5916 - val_mae: 1.1034\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 381us/step - loss: 2.5850 - mse: 2.5850 - mae: 1.1860 - val_loss: 1.5874 - val_mse: 1.5874 - val_mae: 1.1014\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 532us/step - loss: 2.5724 - mse: 2.5724 - mae: 1.1834 - val_loss: 1.5843 - val_mse: 1.5843 - val_mae: 1.1023\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 434us/step - loss: 2.5612 - mse: 2.5612 - mae: 1.1821 - val_loss: 1.5817 - val_mse: 1.5817 - val_mae: 1.1033\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 232us/step - loss: 2.5513 - mse: 2.5513 - mae: 1.1797 - val_loss: 1.5796 - val_mse: 1.5796 - val_mae: 1.1015\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 340us/step - loss: 2.5400 - mse: 2.5400 - mae: 1.1764 - val_loss: 1.5775 - val_mse: 1.5775 - val_mae: 1.0990\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 581us/step - loss: 2.5304 - mse: 2.5304 - mae: 1.1739 - val_loss: 1.5770 - val_mse: 1.5770 - val_mae: 1.0994\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 267us/step - loss: 2.5210 - mse: 2.5210 - mae: 1.1722 - val_loss: 1.5767 - val_mse: 1.5767 - val_mae: 1.0998\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 279us/step - loss: 2.5120 - mse: 2.5120 - mae: 1.1701 - val_loss: 1.5766 - val_mse: 1.5766 - val_mae: 1.0994\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 269us/step - loss: 2.5034 - mse: 2.5034 - mae: 1.1676 - val_loss: 1.5763 - val_mse: 1.5763 - val_mae: 1.0999\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 363us/step - loss: 2.4948 - mse: 2.4948 - mae: 1.1655 - val_loss: 1.5755 - val_mse: 1.5755 - val_mae: 1.1010\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 305us/step - loss: 2.4863 - mse: 2.4863 - mae: 1.1629 - val_loss: 1.5739 - val_mse: 1.5739 - val_mae: 1.1003\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 295us/step - loss: 2.4778 - mse: 2.4778 - mae: 1.1603 - val_loss: 1.5718 - val_mse: 1.5718 - val_mae: 1.0993\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 409us/step - loss: 2.4697 - mse: 2.4697 - mae: 1.1579 - val_loss: 1.5707 - val_mse: 1.5707 - val_mae: 1.0992\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 271us/step - loss: 2.4614 - mse: 2.4614 - mae: 1.1558 - val_loss: 1.5702 - val_mse: 1.5702 - val_mae: 1.0998\n",
      "Epoch 80/100\n",
      "103/103 [==============================] - 0s 368us/step - loss: 2.4532 - mse: 2.4532 - mae: 1.1536 - val_loss: 1.5706 - val_mse: 1.5706 - val_mae: 1.0999\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 0s 388us/step - loss: 2.4455 - mse: 2.4455 - mae: 1.1509 - val_loss: 1.5703 - val_mse: 1.5703 - val_mae: 1.0986\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 320us/step - loss: 2.4379 - mse: 2.4379 - mae: 1.1490 - val_loss: 1.5707 - val_mse: 1.5707 - val_mae: 1.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 529us/step - loss: 2.4301 - mse: 2.4301 - mae: 1.1473 - val_loss: 1.5717 - val_mse: 1.5717 - val_mae: 1.1013\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 245us/step - loss: 2.4223 - mse: 2.4223 - mae: 1.1446 - val_loss: 1.5720 - val_mse: 1.5720 - val_mae: 1.0998\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 377us/step - loss: 2.4153 - mse: 2.4153 - mae: 1.1423 - val_loss: 1.5730 - val_mse: 1.5730 - val_mae: 1.1009\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 468us/step - loss: 2.4074 - mse: 2.4074 - mae: 1.1406 - val_loss: 1.5736 - val_mse: 1.5736 - val_mae: 1.1030\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 494us/step - loss: 2.4004 - mse: 2.4004 - mae: 1.1388 - val_loss: 1.5750 - val_mse: 1.5750 - val_mae: 1.1032\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 304us/step - loss: 2.3927 - mse: 2.3927 - mae: 1.1368 - val_loss: 1.5771 - val_mse: 1.5771 - val_mae: 1.1033\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - 0s 378us/step - loss: 2.3852 - mse: 2.3852 - mae: 1.1349 - val_loss: 1.5777 - val_mse: 1.5777 - val_mae: 1.1035\n",
      "60\n",
      "[60]\n",
      "Train on 114 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 3.8432 - mse: 3.8432 - mae: 1.4661 - val_loss: 2.6232 - val_mse: 2.6232 - val_mae: 1.2339\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 0s 402us/step - loss: 3.4130 - mse: 3.4130 - mae: 1.4049 - val_loss: 2.2447 - val_mse: 2.2447 - val_mae: 1.1433\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 0s 544us/step - loss: 3.2319 - mse: 3.2319 - mae: 1.3975 - val_loss: 2.0864 - val_mse: 2.0864 - val_mae: 1.1123\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 0s 245us/step - loss: 3.1618 - mse: 3.1618 - mae: 1.4019 - val_loss: 2.0354 - val_mse: 2.0354 - val_mae: 1.1033\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 0s 550us/step - loss: 3.0835 - mse: 3.0835 - mae: 1.3868 - val_loss: 2.0148 - val_mse: 2.0148 - val_mae: 1.0957\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 0s 325us/step - loss: 2.9809 - mse: 2.9809 - mae: 1.3543 - val_loss: 2.0175 - val_mse: 2.0175 - val_mae: 1.0903\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 0s 270us/step - loss: 2.8871 - mse: 2.8871 - mae: 1.3175 - val_loss: 2.0464 - val_mse: 2.0464 - val_mae: 1.0933\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 0s 436us/step - loss: 2.8193 - mse: 2.8193 - mae: 1.2915 - val_loss: 2.0723 - val_mse: 2.0723 - val_mae: 1.0959\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 0s 493us/step - loss: 2.7640 - mse: 2.7640 - mae: 1.2718 - val_loss: 2.0745 - val_mse: 2.0745 - val_mae: 1.0969\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 0s 576us/step - loss: 2.7074 - mse: 2.7074 - mae: 1.2576 - val_loss: 2.0514 - val_mse: 2.0514 - val_mae: 1.0877\n",
      "Epoch 11/100\n",
      "114/114 [==============================] - 0s 483us/step - loss: 2.6528 - mse: 2.6528 - mae: 1.2477 - val_loss: 2.0300 - val_mse: 2.0300 - val_mae: 1.0758\n",
      "Epoch 12/100\n",
      "114/114 [==============================] - 0s 420us/step - loss: 2.6065 - mse: 2.6065 - mae: 1.2391 - val_loss: 2.0240 - val_mse: 2.0240 - val_mae: 1.0705\n",
      "Epoch 13/100\n",
      "114/114 [==============================] - 0s 283us/step - loss: 2.5647 - mse: 2.5647 - mae: 1.2290 - val_loss: 2.0315 - val_mse: 2.0315 - val_mae: 1.0702\n",
      "Epoch 14/100\n",
      "114/114 [==============================] - 0s 369us/step - loss: 2.5246 - mse: 2.5246 - mae: 1.2156 - val_loss: 2.0469 - val_mse: 2.0469 - val_mae: 1.0740\n",
      "Epoch 15/100\n",
      "114/114 [==============================] - 0s 252us/step - loss: 2.4877 - mse: 2.4877 - mae: 1.2012 - val_loss: 2.0638 - val_mse: 2.0638 - val_mae: 1.0778\n",
      "61\n",
      "[61]\n",
      "Train on 73 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 9.5831 - mse: 9.5831 - mae: 2.9581 - val_loss: 9.3393 - val_mse: 9.3393 - val_mae: 2.9832\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 348us/step - loss: 8.2504 - mse: 8.2504 - mae: 2.7255 - val_loss: 7.4469 - val_mse: 7.4469 - val_mae: 2.6566\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 262us/step - loss: 7.0977 - mse: 7.0977 - mae: 2.5077 - val_loss: 5.9887 - val_mse: 5.9887 - val_mae: 2.3772\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 374us/step - loss: 6.1385 - mse: 6.1385 - mae: 2.3086 - val_loss: 4.8946 - val_mse: 4.8946 - val_mae: 2.1457\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 453us/step - loss: 5.3429 - mse: 5.3429 - mae: 2.1306 - val_loss: 4.0743 - val_mse: 4.0743 - val_mae: 1.9551\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 554us/step - loss: 4.6982 - mse: 4.6982 - mae: 1.9768 - val_loss: 3.3784 - val_mse: 3.3784 - val_mae: 1.7736\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 344us/step - loss: 4.1544 - mse: 4.1544 - mae: 1.8391 - val_loss: 2.8345 - val_mse: 2.8345 - val_mae: 1.6209\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 410us/step - loss: 3.6794 - mse: 3.6794 - mae: 1.7106 - val_loss: 2.3637 - val_mse: 2.3637 - val_mae: 1.4752\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 694us/step - loss: 3.2848 - mse: 3.2848 - mae: 1.5909 - val_loss: 1.9094 - val_mse: 1.9094 - val_mae: 1.3098\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 738us/step - loss: 2.9294 - mse: 2.9294 - mae: 1.4714 - val_loss: 1.4644 - val_mse: 1.4644 - val_mae: 1.1176\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 688us/step - loss: 2.5676 - mse: 2.5676 - mae: 1.3375 - val_loss: 1.0626 - val_mse: 1.0626 - val_mae: 0.9031\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 576us/step - loss: 2.1795 - mse: 2.1795 - mae: 1.1869 - val_loss: 0.7472 - val_mse: 0.7472 - val_mae: 0.6777\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 673us/step - loss: 1.7985 - mse: 1.7985 - mae: 1.0198 - val_loss: 0.5348 - val_mse: 0.5348 - val_mae: 0.5397\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 386us/step - loss: 1.4487 - mse: 1.4487 - mae: 0.8636 - val_loss: 0.4040 - val_mse: 0.4040 - val_mae: 0.4785\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 538us/step - loss: 1.1708 - mse: 1.1708 - mae: 0.7455 - val_loss: 0.3867 - val_mse: 0.3867 - val_mae: 0.5259\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 706us/step - loss: 0.9800 - mse: 0.9800 - mae: 0.6972 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.6020\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 519us/step - loss: 0.8754 - mse: 0.8754 - mae: 0.6976 - val_loss: 0.6721 - val_mse: 0.6721 - val_mae: 0.6931\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 425us/step - loss: 0.8413 - mse: 0.8413 - mae: 0.7171 - val_loss: 0.8820 - val_mse: 0.8820 - val_mae: 0.7944\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 644us/step - loss: 0.8480 - mse: 0.8480 - mae: 0.7386 - val_loss: 1.0539 - val_mse: 1.0539 - val_mae: 0.8785\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.8643 - mse: 0.8643 - mae: 0.7533 - val_loss: 1.1450 - val_mse: 1.1450 - val_mae: 0.9217\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 439us/step - loss: 0.8708 - mse: 0.8708 - mae: 0.7588 - val_loss: 1.1553 - val_mse: 1.1553 - val_mae: 0.9261\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 388us/step - loss: 0.8626 - mse: 0.8626 - mae: 0.7550 - val_loss: 1.1056 - val_mse: 1.1056 - val_mae: 0.9018\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 617us/step - loss: 0.8445 - mse: 0.8445 - mae: 0.7451 - val_loss: 1.0217 - val_mse: 1.0217 - val_mae: 0.8593\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.8242 - mse: 0.8242 - mae: 0.7317 - val_loss: 0.9282 - val_mse: 0.9282 - val_mae: 0.8185\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 468us/step - loss: 0.8072 - mse: 0.8072 - mae: 0.7182 - val_loss: 0.8434 - val_mse: 0.8434 - val_mae: 0.7848\n",
      "62\n",
      "[62]\n",
      "Train on 99 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 12.4718 - mse: 12.4718 - mae: 3.0746 - val_loss: 6.9626 - val_mse: 6.9626 - val_mae: 2.2699\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 373us/step - loss: 9.3884 - mse: 9.3884 - mae: 2.5584 - val_loss: 5.1879 - val_mse: 5.1879 - val_mae: 1.8758\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 379us/step - loss: 7.1661 - mse: 7.1661 - mae: 2.1453 - val_loss: 3.9181 - val_mse: 3.9181 - val_mae: 1.5608\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 746us/step - loss: 5.6157 - mse: 5.6157 - mae: 1.8139 - val_loss: 3.1035 - val_mse: 3.1035 - val_mae: 1.3415\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 405us/step - loss: 4.5650 - mse: 4.5650 - mae: 1.5834 - val_loss: 2.5967 - val_mse: 2.5967 - val_mae: 1.2232\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 393us/step - loss: 3.8835 - mse: 3.8835 - mae: 1.4344 - val_loss: 2.3087 - val_mse: 2.3087 - val_mae: 1.1460\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 465us/step - loss: 3.4640 - mse: 3.4640 - mae: 1.3635 - val_loss: 2.1700 - val_mse: 2.1700 - val_mae: 1.1448\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 373us/step - loss: 3.2411 - mse: 3.2411 - mae: 1.3377 - val_loss: 2.1102 - val_mse: 2.1102 - val_mae: 1.1502\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 617us/step - loss: 3.1132 - mse: 3.1132 - mae: 1.3302 - val_loss: 2.0775 - val_mse: 2.0775 - val_mae: 1.1477\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 608us/step - loss: 3.0340 - mse: 3.0340 - mae: 1.3277 - val_loss: 2.0534 - val_mse: 2.0534 - val_mae: 1.1438\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 383us/step - loss: 2.9726 - mse: 2.9726 - mae: 1.3267 - val_loss: 2.0237 - val_mse: 2.0237 - val_mae: 1.1378\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 515us/step - loss: 2.9118 - mse: 2.9118 - mae: 1.3203 - val_loss: 1.9868 - val_mse: 1.9868 - val_mae: 1.1307\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 446us/step - loss: 2.8468 - mse: 2.8468 - mae: 1.3080 - val_loss: 1.9449 - val_mse: 1.9449 - val_mae: 1.1219\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 346us/step - loss: 2.7803 - mse: 2.7803 - mae: 1.2926 - val_loss: 1.9065 - val_mse: 1.9065 - val_mae: 1.1131\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 347us/step - loss: 2.7213 - mse: 2.7213 - mae: 1.2781 - val_loss: 1.8745 - val_mse: 1.8745 - val_mae: 1.1050\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 334us/step - loss: 2.6687 - mse: 2.6687 - mae: 1.2639 - val_loss: 1.8494 - val_mse: 1.8494 - val_mae: 1.0976\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 403us/step - loss: 2.6219 - mse: 2.6219 - mae: 1.2510 - val_loss: 1.8294 - val_mse: 1.8294 - val_mae: 1.0912\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 334us/step - loss: 2.5769 - mse: 2.5769 - mae: 1.2390 - val_loss: 1.8144 - val_mse: 1.8144 - val_mae: 1.0856\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 304us/step - loss: 2.5342 - mse: 2.5342 - mae: 1.2293 - val_loss: 1.8016 - val_mse: 1.8016 - val_mae: 1.0804\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 364us/step - loss: 2.4966 - mse: 2.4966 - mae: 1.2213 - val_loss: 1.7898 - val_mse: 1.7898 - val_mae: 1.0755\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 2.4624 - mse: 2.4624 - mae: 1.2146 - val_loss: 1.7789 - val_mse: 1.7789 - val_mae: 1.0712\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 416us/step - loss: 2.4290 - mse: 2.4290 - mae: 1.2081 - val_loss: 1.7683 - val_mse: 1.7683 - val_mae: 1.0671\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 375us/step - loss: 2.3980 - mse: 2.3980 - mae: 1.2028 - val_loss: 1.7582 - val_mse: 1.7582 - val_mae: 1.0631\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 414us/step - loss: 2.3678 - mse: 2.3678 - mae: 1.1982 - val_loss: 1.7490 - val_mse: 1.7490 - val_mae: 1.0591\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 515us/step - loss: 2.3385 - mse: 2.3385 - mae: 1.1940 - val_loss: 1.7463 - val_mse: 1.7463 - val_mae: 1.0587\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 487us/step - loss: 2.3106 - mse: 2.3106 - mae: 1.1906 - val_loss: 1.7440 - val_mse: 1.7440 - val_mae: 1.0583\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 438us/step - loss: 2.2840 - mse: 2.2840 - mae: 1.1874 - val_loss: 1.7411 - val_mse: 1.7411 - val_mae: 1.0574\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 550us/step - loss: 2.2586 - mse: 2.2586 - mae: 1.1838 - val_loss: 1.7381 - val_mse: 1.7381 - val_mae: 1.0565\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 274us/step - loss: 2.2354 - mse: 2.2354 - mae: 1.1802 - val_loss: 1.7366 - val_mse: 1.7366 - val_mae: 1.0560\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 647us/step - loss: 2.2132 - mse: 2.2132 - mae: 1.1760 - val_loss: 1.7360 - val_mse: 1.7360 - val_mae: 1.0557\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 475us/step - loss: 2.1913 - mse: 2.1913 - mae: 1.1712 - val_loss: 1.7366 - val_mse: 1.7366 - val_mae: 1.0557\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 807us/step - loss: 2.1698 - mse: 2.1698 - mae: 1.1662 - val_loss: 1.7396 - val_mse: 1.7396 - val_mae: 1.0567\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 330us/step - loss: 2.1512 - mse: 2.1512 - mae: 1.1612 - val_loss: 1.7378 - val_mse: 1.7378 - val_mae: 1.0563\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 393us/step - loss: 2.1335 - mse: 2.1335 - mae: 1.1575 - val_loss: 1.7333 - val_mse: 1.7333 - val_mae: 1.0553\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 344us/step - loss: 2.1161 - mse: 2.1161 - mae: 1.1547 - val_loss: 1.7240 - val_mse: 1.7240 - val_mae: 1.0532\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 293us/step - loss: 2.0983 - mse: 2.0983 - mae: 1.1521 - val_loss: 1.7109 - val_mse: 1.7109 - val_mae: 1.0504\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 357us/step - loss: 2.0822 - mse: 2.0822 - mae: 1.1484 - val_loss: 1.7051 - val_mse: 1.7051 - val_mae: 1.0494\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 362us/step - loss: 2.0636 - mse: 2.0636 - mae: 1.1429 - val_loss: 1.7057 - val_mse: 1.7057 - val_mae: 1.0507\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 386us/step - loss: 2.0472 - mse: 2.0472 - mae: 1.1381 - val_loss: 1.7008 - val_mse: 1.7008 - val_mae: 1.0512\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 264us/step - loss: 2.0331 - mse: 2.0331 - mae: 1.1341 - val_loss: 1.6924 - val_mse: 1.6924 - val_mae: 1.0512\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 303us/step - loss: 2.0181 - mse: 2.0181 - mae: 1.1304 - val_loss: 1.6867 - val_mse: 1.6867 - val_mae: 1.0514\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 2.0047 - mse: 2.0047 - mae: 1.1265 - val_loss: 1.6839 - val_mse: 1.6839 - val_mae: 1.0519\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 312us/step - loss: 1.9915 - mse: 1.9915 - mae: 1.1219 - val_loss: 1.6817 - val_mse: 1.6817 - val_mae: 1.0527\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 371us/step - loss: 1.9790 - mse: 1.9790 - mae: 1.1178 - val_loss: 1.6776 - val_mse: 1.6776 - val_mae: 1.0530\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 354us/step - loss: 1.9673 - mse: 1.9673 - mae: 1.1150 - val_loss: 1.6761 - val_mse: 1.6761 - val_mae: 1.0530\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 908us/step - loss: 1.9550 - mse: 1.9550 - mae: 1.1119 - val_loss: 1.6723 - val_mse: 1.6723 - val_mae: 1.0520\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 330us/step - loss: 1.9433 - mse: 1.9433 - mae: 1.1083 - val_loss: 1.6686 - val_mse: 1.6686 - val_mae: 1.0515\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 271us/step - loss: 1.9318 - mse: 1.9318 - mae: 1.1046 - val_loss: 1.6697 - val_mse: 1.6697 - val_mae: 1.0526\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 184us/step - loss: 1.9206 - mse: 1.9206 - mae: 1.1005 - val_loss: 1.6685 - val_mse: 1.6685 - val_mae: 1.0540\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 352us/step - loss: 1.9096 - mse: 1.9096 - mae: 1.0970 - val_loss: 1.6653 - val_mse: 1.6653 - val_mae: 1.0547\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 589us/step - loss: 1.8992 - mse: 1.8992 - mae: 1.0942 - val_loss: 1.6649 - val_mse: 1.6649 - val_mae: 1.0561\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 292us/step - loss: 1.8881 - mse: 1.8881 - mae: 1.0899 - val_loss: 1.6631 - val_mse: 1.6631 - val_mae: 1.0568\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.8786 - mse: 1.8786 - mae: 1.0860 - val_loss: 1.6590 - val_mse: 1.6590 - val_mae: 1.0560\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 367us/step - loss: 1.8686 - mse: 1.8686 - mae: 1.0829 - val_loss: 1.6564 - val_mse: 1.6564 - val_mae: 1.0553\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 393us/step - loss: 1.8597 - mse: 1.8597 - mae: 1.0793 - val_loss: 1.6584 - val_mse: 1.6584 - val_mae: 1.0560\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 1.8488 - mse: 1.8488 - mae: 1.0749 - val_loss: 1.6573 - val_mse: 1.6573 - val_mae: 1.0569\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 453us/step - loss: 1.8402 - mse: 1.8402 - mae: 1.0709 - val_loss: 1.6542 - val_mse: 1.6542 - val_mae: 1.0571\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 304us/step - loss: 1.8314 - mse: 1.8314 - mae: 1.0682 - val_loss: 1.6574 - val_mse: 1.6574 - val_mae: 1.0588\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 299us/step - loss: 1.8239 - mse: 1.8239 - mae: 1.0663 - val_loss: 1.6586 - val_mse: 1.6586 - val_mae: 1.0600\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.8159 - mse: 1.8159 - mae: 1.0644 - val_loss: 1.6632 - val_mse: 1.6632 - val_mae: 1.0614\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 332us/step - loss: 1.8064 - mse: 1.8064 - mae: 1.0609 - val_loss: 1.6614 - val_mse: 1.6614 - val_mae: 1.0613\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 282us/step - loss: 1.7978 - mse: 1.7978 - mae: 1.0573 - val_loss: 1.6587 - val_mse: 1.6587 - val_mae: 1.0607\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 262us/step - loss: 1.7899 - mse: 1.7899 - mae: 1.0552 - val_loss: 1.6611 - val_mse: 1.6611 - val_mae: 1.0612\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 666us/step - loss: 1.7823 - mse: 1.7823 - mae: 1.0534 - val_loss: 1.6680 - val_mse: 1.6680 - val_mae: 1.0628\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 453us/step - loss: 1.7746 - mse: 1.7746 - mae: 1.0502 - val_loss: 1.6671 - val_mse: 1.6671 - val_mae: 1.0625\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 383us/step - loss: 1.7661 - mse: 1.7661 - mae: 1.0480 - val_loss: 1.6689 - val_mse: 1.6689 - val_mae: 1.0631\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 627us/step - loss: 1.7582 - mse: 1.7582 - mae: 1.0445 - val_loss: 1.6706 - val_mse: 1.6706 - val_mae: 1.0640\n",
      "63\n",
      "[63]\n",
      "Train on 94 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 12.5942 - mse: 12.5942 - mae: 3.2487 - val_loss: 14.0875 - val_mse: 14.0875 - val_mae: 3.4668\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 653us/step - loss: 9.6968 - mse: 9.6968 - mae: 2.7836 - val_loss: 10.3024 - val_mse: 10.3024 - val_mae: 2.8940\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 492us/step - loss: 7.3075 - mse: 7.3075 - mae: 2.3339 - val_loss: 7.3750 - val_mse: 7.3750 - val_mae: 2.3410\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 374us/step - loss: 5.4348 - mse: 5.4348 - mae: 1.9363 - val_loss: 5.2858 - val_mse: 5.2858 - val_mae: 1.8879\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 500us/step - loss: 4.0486 - mse: 4.0486 - mae: 1.5910 - val_loss: 3.8280 - val_mse: 3.8280 - val_mae: 1.5697\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 371us/step - loss: 3.0992 - mse: 3.0992 - mae: 1.3467 - val_loss: 2.8766 - val_mse: 2.8766 - val_mae: 1.2780\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 352us/step - loss: 2.4691 - mse: 2.4691 - mae: 1.1878 - val_loss: 2.3088 - val_mse: 2.3088 - val_mae: 1.1016\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 287us/step - loss: 2.0773 - mse: 2.0773 - mae: 1.0789 - val_loss: 2.0676 - val_mse: 2.0676 - val_mae: 1.0267\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 520us/step - loss: 1.8786 - mse: 1.8786 - mae: 1.0449 - val_loss: 2.0694 - val_mse: 2.0694 - val_mae: 1.0692\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 332us/step - loss: 1.8135 - mse: 1.8135 - mae: 1.0620 - val_loss: 2.2095 - val_mse: 2.2095 - val_mae: 1.1530\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 340us/step - loss: 1.8247 - mse: 1.8247 - mae: 1.0909 - val_loss: 2.3888 - val_mse: 2.3888 - val_mae: 1.2135\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 443us/step - loss: 1.8614 - mse: 1.8614 - mae: 1.1187 - val_loss: 2.5413 - val_mse: 2.5413 - val_mae: 1.2532\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 456us/step - loss: 1.8859 - mse: 1.8859 - mae: 1.1401 - val_loss: 2.6340 - val_mse: 2.6340 - val_mae: 1.2816\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 571us/step - loss: 1.8789 - mse: 1.8789 - mae: 1.1449 - val_loss: 2.6750 - val_mse: 2.6750 - val_mae: 1.2953\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 320us/step - loss: 1.8443 - mse: 1.8443 - mae: 1.1369 - val_loss: 2.6733 - val_mse: 2.6733 - val_mae: 1.2897\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 402us/step - loss: 1.7949 - mse: 1.7949 - mae: 1.1196 - val_loss: 2.6556 - val_mse: 2.6556 - val_mae: 1.2736\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 360us/step - loss: 1.7406 - mse: 1.7406 - mae: 1.0977 - val_loss: 2.6236 - val_mse: 2.6236 - val_mae: 1.2488\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 544us/step - loss: 1.6917 - mse: 1.6917 - mae: 1.0758 - val_loss: 2.5962 - val_mse: 2.5962 - val_mae: 1.2242\n",
      "64\n",
      "[64]\n",
      "Train on 78 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 4.7072 - mse: 4.7072 - mae: 1.7920 - val_loss: 2.4350 - val_mse: 2.4350 - val_mae: 1.3418\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 523us/step - loss: 3.9918 - mse: 3.9918 - mae: 1.5796 - val_loss: 2.0252 - val_mse: 2.0252 - val_mae: 1.1718\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 411us/step - loss: 3.3608 - mse: 3.3608 - mae: 1.3769 - val_loss: 1.6766 - val_mse: 1.6766 - val_mae: 1.0046\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 309us/step - loss: 2.8386 - mse: 2.8386 - mae: 1.2192 - val_loss: 1.3960 - val_mse: 1.3960 - val_mae: 0.8432\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 486us/step - loss: 2.4225 - mse: 2.4225 - mae: 1.0978 - val_loss: 1.1856 - val_mse: 1.1856 - val_mae: 0.7116\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 512us/step - loss: 2.1121 - mse: 2.1121 - mae: 1.0132 - val_loss: 1.0323 - val_mse: 1.0323 - val_mae: 0.6470\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 392us/step - loss: 1.8890 - mse: 1.8890 - mae: 0.9660 - val_loss: 0.9221 - val_mse: 0.9221 - val_mae: 0.6317\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 615us/step - loss: 1.7363 - mse: 1.7363 - mae: 0.9376 - val_loss: 0.8490 - val_mse: 0.8490 - val_mae: 0.6496\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 502us/step - loss: 1.6373 - mse: 1.6373 - mae: 0.9303 - val_loss: 0.8048 - val_mse: 0.8048 - val_mae: 0.6662\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 294us/step - loss: 1.5778 - mse: 1.5778 - mae: 0.9289 - val_loss: 0.7846 - val_mse: 0.7846 - val_mae: 0.6888\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 428us/step - loss: 1.5491 - mse: 1.5491 - mae: 0.9335 - val_loss: 0.7746 - val_mse: 0.7746 - val_mae: 0.7060\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 368us/step - loss: 1.5316 - mse: 1.5316 - mae: 0.9386 - val_loss: 0.7647 - val_mse: 0.7647 - val_mae: 0.7139\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 435us/step - loss: 1.5173 - mse: 1.5173 - mae: 0.9405 - val_loss: 0.7566 - val_mse: 0.7566 - val_mae: 0.7167\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 503us/step - loss: 1.5022 - mse: 1.5022 - mae: 0.9373 - val_loss: 0.7504 - val_mse: 0.7504 - val_mae: 0.7158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 794us/step - loss: 1.4857 - mse: 1.4857 - mae: 0.9303 - val_loss: 0.7452 - val_mse: 0.7452 - val_mae: 0.7121\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 514us/step - loss: 1.4686 - mse: 1.4686 - mae: 0.9208 - val_loss: 0.7413 - val_mse: 0.7413 - val_mae: 0.7066\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 398us/step - loss: 1.4525 - mse: 1.4525 - mae: 0.9105 - val_loss: 0.7387 - val_mse: 0.7387 - val_mae: 0.7004\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 427us/step - loss: 1.4392 - mse: 1.4392 - mae: 0.9004 - val_loss: 0.7370 - val_mse: 0.7370 - val_mae: 0.6940\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 362us/step - loss: 1.4270 - mse: 1.4270 - mae: 0.8904 - val_loss: 0.7358 - val_mse: 0.7358 - val_mae: 0.6880\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 362us/step - loss: 1.4176 - mse: 1.4176 - mae: 0.8824 - val_loss: 0.7360 - val_mse: 0.7360 - val_mae: 0.6833\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 467us/step - loss: 1.4091 - mse: 1.4091 - mae: 0.8757 - val_loss: 0.7365 - val_mse: 0.7365 - val_mae: 0.6797\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 345us/step - loss: 1.4018 - mse: 1.4018 - mae: 0.8699 - val_loss: 0.7366 - val_mse: 0.7366 - val_mae: 0.6773\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 444us/step - loss: 1.3952 - mse: 1.3952 - mae: 0.8652 - val_loss: 0.7364 - val_mse: 0.7364 - val_mae: 0.6763\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 614us/step - loss: 1.3888 - mse: 1.3888 - mae: 0.8617 - val_loss: 0.7358 - val_mse: 0.7358 - val_mae: 0.6764\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 384us/step - loss: 1.3825 - mse: 1.3825 - mae: 0.8591 - val_loss: 0.7350 - val_mse: 0.7350 - val_mae: 0.6776\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 345us/step - loss: 1.3761 - mse: 1.3761 - mae: 0.8571 - val_loss: 0.7339 - val_mse: 0.7339 - val_mae: 0.6793\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 415us/step - loss: 1.3696 - mse: 1.3696 - mae: 0.8556 - val_loss: 0.7332 - val_mse: 0.7332 - val_mae: 0.6816\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 0s 491us/step - loss: 1.3631 - mse: 1.3631 - mae: 0.8545 - val_loss: 0.7327 - val_mse: 0.7327 - val_mae: 0.6842\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 0s 294us/step - loss: 1.3567 - mse: 1.3567 - mae: 0.8535 - val_loss: 0.7323 - val_mse: 0.7323 - val_mae: 0.6869\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 0s 334us/step - loss: 1.3508 - mse: 1.3508 - mae: 0.8527 - val_loss: 0.7320 - val_mse: 0.7320 - val_mae: 0.6894\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 0s 409us/step - loss: 1.3453 - mse: 1.3453 - mae: 0.8517 - val_loss: 0.7319 - val_mse: 0.7319 - val_mae: 0.6915\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 0s 398us/step - loss: 1.3398 - mse: 1.3398 - mae: 0.8506 - val_loss: 0.7313 - val_mse: 0.7313 - val_mae: 0.6929\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 0s 590us/step - loss: 1.3346 - mse: 1.3346 - mae: 0.8493 - val_loss: 0.7310 - val_mse: 0.7310 - val_mae: 0.6942\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 0s 524us/step - loss: 1.3294 - mse: 1.3294 - mae: 0.8477 - val_loss: 0.7307 - val_mse: 0.7307 - val_mae: 0.6952\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 0s 592us/step - loss: 1.3242 - mse: 1.3242 - mae: 0.8460 - val_loss: 0.7306 - val_mse: 0.7306 - val_mae: 0.6959\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 0s 296us/step - loss: 1.3191 - mse: 1.3191 - mae: 0.8439 - val_loss: 0.7304 - val_mse: 0.7304 - val_mae: 0.6962\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 0s 420us/step - loss: 1.3141 - mse: 1.3141 - mae: 0.8418 - val_loss: 0.7304 - val_mse: 0.7304 - val_mae: 0.6964\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 0s 267us/step - loss: 1.3090 - mse: 1.3090 - mae: 0.8393 - val_loss: 0.7307 - val_mse: 0.7307 - val_mae: 0.6967\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 0s 321us/step - loss: 1.3040 - mse: 1.3040 - mae: 0.8368 - val_loss: 0.7310 - val_mse: 0.7310 - val_mae: 0.6969\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 0s 371us/step - loss: 1.2989 - mse: 1.2989 - mae: 0.8344 - val_loss: 0.7314 - val_mse: 0.7314 - val_mae: 0.6973\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 0s 385us/step - loss: 1.2940 - mse: 1.2940 - mae: 0.8319 - val_loss: 0.7316 - val_mse: 0.7316 - val_mae: 0.6976\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 0s 345us/step - loss: 1.2889 - mse: 1.2889 - mae: 0.8293 - val_loss: 0.7314 - val_mse: 0.7314 - val_mae: 0.6974\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 0s 307us/step - loss: 1.2837 - mse: 1.2837 - mae: 0.8267 - val_loss: 0.7310 - val_mse: 0.7310 - val_mae: 0.6974\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 0s 473us/step - loss: 1.2785 - mse: 1.2785 - mae: 0.8243 - val_loss: 0.7306 - val_mse: 0.7306 - val_mae: 0.6975\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 0s 315us/step - loss: 1.2733 - mse: 1.2733 - mae: 0.8220 - val_loss: 0.7302 - val_mse: 0.7302 - val_mae: 0.6979\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 0s 330us/step - loss: 1.2680 - mse: 1.2680 - mae: 0.8198 - val_loss: 0.7298 - val_mse: 0.7298 - val_mae: 0.6986\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 0s 745us/step - loss: 1.2627 - mse: 1.2627 - mae: 0.8176 - val_loss: 0.7294 - val_mse: 0.7294 - val_mae: 0.6993\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 0s 424us/step - loss: 1.2561 - mse: 1.2561 - mae: 0.8149 - val_loss: 0.7287 - val_mse: 0.7287 - val_mae: 0.6996\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 0s 438us/step - loss: 1.2488 - mse: 1.2488 - mae: 0.8116 - val_loss: 0.7283 - val_mse: 0.7283 - val_mae: 0.6999\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 0s 362us/step - loss: 1.2417 - mse: 1.2417 - mae: 0.8085 - val_loss: 0.7281 - val_mse: 0.7281 - val_mae: 0.7004\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 0s 409us/step - loss: 1.2347 - mse: 1.2347 - mae: 0.8060 - val_loss: 0.7278 - val_mse: 0.7278 - val_mae: 0.7011\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 0s 402us/step - loss: 1.2277 - mse: 1.2277 - mae: 0.8034 - val_loss: 0.7274 - val_mse: 0.7274 - val_mae: 0.7020\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 0s 286us/step - loss: 1.2222 - mse: 1.2222 - mae: 0.8020 - val_loss: 0.7270 - val_mse: 0.7270 - val_mae: 0.7035\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 0s 252us/step - loss: 1.2167 - mse: 1.2167 - mae: 0.8007 - val_loss: 0.7265 - val_mse: 0.7265 - val_mae: 0.7055\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 0s 375us/step - loss: 1.2110 - mse: 1.2110 - mae: 0.7994 - val_loss: 0.7263 - val_mse: 0.7263 - val_mae: 0.7076\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 0s 320us/step - loss: 1.2053 - mse: 1.2053 - mae: 0.7978 - val_loss: 0.7263 - val_mse: 0.7263 - val_mae: 0.7099\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 0s 345us/step - loss: 1.1990 - mse: 1.1990 - mae: 0.7960 - val_loss: 0.7261 - val_mse: 0.7261 - val_mae: 0.7114\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 0s 486us/step - loss: 1.1924 - mse: 1.1924 - mae: 0.7938 - val_loss: 0.7259 - val_mse: 0.7259 - val_mae: 0.7118\n",
      "Epoch 59/100\n",
      "78/78 [==============================] - 0s 345us/step - loss: 1.1856 - mse: 1.1856 - mae: 0.7913 - val_loss: 0.7261 - val_mse: 0.7261 - val_mae: 0.7115\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 0s 303us/step - loss: 1.1782 - mse: 1.1782 - mae: 0.7880 - val_loss: 0.7266 - val_mse: 0.7266 - val_mae: 0.7102\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 0s 578us/step - loss: 1.1707 - mse: 1.1707 - mae: 0.7839 - val_loss: 0.7271 - val_mse: 0.7271 - val_mae: 0.7090\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 0s 346us/step - loss: 1.1641 - mse: 1.1641 - mae: 0.7805 - val_loss: 0.7274 - val_mse: 0.7274 - val_mae: 0.7083\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 0s 371us/step - loss: 1.1562 - mse: 1.1562 - mae: 0.7770 - val_loss: 0.7261 - val_mse: 0.7261 - val_mae: 0.7065\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 0s 309us/step - loss: 1.1472 - mse: 1.1472 - mae: 0.7732 - val_loss: 0.7240 - val_mse: 0.7240 - val_mae: 0.7043\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 0s 374us/step - loss: 1.1382 - mse: 1.1382 - mae: 0.7701 - val_loss: 0.7222 - val_mse: 0.7222 - val_mae: 0.7032\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 0s 409us/step - loss: 1.1301 - mse: 1.1301 - mae: 0.7678 - val_loss: 0.7208 - val_mse: 0.7208 - val_mae: 0.7025\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 0s 362us/step - loss: 1.1225 - mse: 1.1225 - mae: 0.7655 - val_loss: 0.7202 - val_mse: 0.7202 - val_mae: 0.7014\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 0s 360us/step - loss: 1.1159 - mse: 1.1159 - mae: 0.7645 - val_loss: 0.7209 - val_mse: 0.7209 - val_mae: 0.7015\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 0s 459us/step - loss: 1.1095 - mse: 1.1095 - mae: 0.7640 - val_loss: 0.7215 - val_mse: 0.7215 - val_mae: 0.7026\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 0s 419us/step - loss: 1.1026 - mse: 1.1026 - mae: 0.7643 - val_loss: 0.7221 - val_mse: 0.7221 - val_mae: 0.7048\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 0s 334us/step - loss: 1.0958 - mse: 1.0958 - mae: 0.7646 - val_loss: 0.7226 - val_mse: 0.7226 - val_mae: 0.7067\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 0s 747us/step - loss: 1.0889 - mse: 1.0889 - mae: 0.7650 - val_loss: 0.7232 - val_mse: 0.7232 - val_mae: 0.7091\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 0s 519us/step - loss: 1.0830 - mse: 1.0830 - mae: 0.7650 - val_loss: 0.7237 - val_mse: 0.7237 - val_mae: 0.7099\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 0s 334us/step - loss: 1.0774 - mse: 1.0774 - mae: 0.7641 - val_loss: 0.7243 - val_mse: 0.7243 - val_mae: 0.7102\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 0s 627us/step - loss: 1.0716 - mse: 1.0716 - mae: 0.7628 - val_loss: 0.7251 - val_mse: 0.7251 - val_mae: 0.7102\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 0s 705us/step - loss: 1.0661 - mse: 1.0661 - mae: 0.7608 - val_loss: 0.7256 - val_mse: 0.7256 - val_mae: 0.7093\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 0s 347us/step - loss: 1.0607 - mse: 1.0607 - mae: 0.7591 - val_loss: 0.7266 - val_mse: 0.7266 - val_mae: 0.7099\n",
      "65\n",
      "[65]\n",
      "Train on 101 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.3087 - mse: 4.3087 - mae: 1.4151 - val_loss: 1.2539 - val_mse: 1.2539 - val_mae: 0.8603\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 153us/step - loss: 3.8292 - mse: 3.8292 - mae: 1.3189 - val_loss: 1.0455 - val_mse: 1.0455 - val_mae: 0.8562\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 467us/step - loss: 3.6862 - mse: 3.6862 - mae: 1.3417 - val_loss: 0.9880 - val_mse: 0.9880 - val_mae: 0.8542\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 853us/step - loss: 3.5703 - mse: 3.5703 - mae: 1.3495 - val_loss: 0.9607 - val_mse: 0.9607 - val_mae: 0.8469\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 580us/step - loss: 3.4016 - mse: 3.4016 - mae: 1.3208 - val_loss: 0.9492 - val_mse: 0.9492 - val_mae: 0.8397\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 247us/step - loss: 3.2334 - mse: 3.2334 - mae: 1.2812 - val_loss: 0.9563 - val_mse: 0.9563 - val_mae: 0.8334\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 329us/step - loss: 3.1001 - mse: 3.1001 - mae: 1.2502 - val_loss: 0.9604 - val_mse: 0.9604 - val_mae: 0.8272\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 624us/step - loss: 2.9966 - mse: 2.9966 - mae: 1.2272 - val_loss: 0.9516 - val_mse: 0.9516 - val_mae: 0.8227\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 619us/step - loss: 2.9017 - mse: 2.9017 - mae: 1.2092 - val_loss: 0.9399 - val_mse: 0.9399 - val_mae: 0.8217\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 395us/step - loss: 2.8142 - mse: 2.8142 - mae: 1.1965 - val_loss: 0.9385 - val_mse: 0.9385 - val_mae: 0.8328\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 387us/step - loss: 2.7406 - mse: 2.7406 - mae: 1.1894 - val_loss: 0.9435 - val_mse: 0.9435 - val_mae: 0.8427\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 257us/step - loss: 2.6782 - mse: 2.6782 - mae: 1.1823 - val_loss: 0.9462 - val_mse: 0.9462 - val_mae: 0.8454\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 486us/step - loss: 2.6165 - mse: 2.6165 - mae: 1.1710 - val_loss: 0.9444 - val_mse: 0.9444 - val_mae: 0.8424\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 342us/step - loss: 2.5566 - mse: 2.5566 - mae: 1.1572 - val_loss: 0.9395 - val_mse: 0.9395 - val_mae: 0.8371\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 278us/step - loss: 2.5076 - mse: 2.5076 - mae: 1.1439 - val_loss: 0.9281 - val_mse: 0.9281 - val_mae: 0.8295\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 508us/step - loss: 2.4661 - mse: 2.4661 - mae: 1.1327 - val_loss: 0.9177 - val_mse: 0.9177 - val_mae: 0.8261\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 685us/step - loss: 2.4304 - mse: 2.4304 - mae: 1.1249 - val_loss: 0.9121 - val_mse: 0.9121 - val_mae: 0.8246\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 353us/step - loss: 2.3990 - mse: 2.3990 - mae: 1.1186 - val_loss: 0.9194 - val_mse: 0.9194 - val_mae: 0.8291\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 405us/step - loss: 2.3701 - mse: 2.3701 - mae: 1.1133 - val_loss: 0.9263 - val_mse: 0.9263 - val_mae: 0.8320\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 360us/step - loss: 2.3409 - mse: 2.3409 - mae: 1.1063 - val_loss: 0.9328 - val_mse: 0.9328 - val_mae: 0.8342\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 555us/step - loss: 2.3133 - mse: 2.3133 - mae: 1.0967 - val_loss: 0.9430 - val_mse: 0.9430 - val_mae: 0.8392\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 619us/step - loss: 2.2877 - mse: 2.2877 - mae: 1.0875 - val_loss: 0.9502 - val_mse: 0.9502 - val_mae: 0.8421\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 306us/step - loss: 2.2646 - mse: 2.2646 - mae: 1.0803 - val_loss: 0.9547 - val_mse: 0.9547 - val_mae: 0.8430\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 549us/step - loss: 2.2437 - mse: 2.2437 - mae: 1.0740 - val_loss: 0.9604 - val_mse: 0.9604 - val_mae: 0.8444\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 516us/step - loss: 2.2244 - mse: 2.2244 - mae: 1.0680 - val_loss: 0.9618 - val_mse: 0.9618 - val_mae: 0.8431\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 257us/step - loss: 2.2048 - mse: 2.2048 - mae: 1.0609 - val_loss: 0.9610 - val_mse: 0.9610 - val_mae: 0.8407\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 498us/step - loss: 2.1854 - mse: 2.1854 - mae: 1.0536 - val_loss: 0.9610 - val_mse: 0.9610 - val_mae: 0.8386\n",
      "66\n",
      "[66]\n",
      "Train on 98 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 3.6482 - mse: 3.6482 - mae: 1.4671 - val_loss: 2.0143 - val_mse: 2.0143 - val_mae: 1.2656\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 500us/step - loss: 3.2273 - mse: 3.2273 - mae: 1.4000 - val_loss: 1.7163 - val_mse: 1.7163 - val_mae: 1.1431\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 328us/step - loss: 3.0037 - mse: 3.0037 - mae: 1.3705 - val_loss: 1.5685 - val_mse: 1.5685 - val_mae: 1.0727\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 366us/step - loss: 2.8759 - mse: 2.8759 - mae: 1.3438 - val_loss: 1.4862 - val_mse: 1.4862 - val_mae: 1.0351\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 610us/step - loss: 2.7728 - mse: 2.7728 - mae: 1.3169 - val_loss: 1.4457 - val_mse: 1.4457 - val_mae: 1.0244\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 757us/step - loss: 2.6773 - mse: 2.6773 - mae: 1.2861 - val_loss: 1.4290 - val_mse: 1.4290 - val_mae: 1.0208\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 435us/step - loss: 2.6043 - mse: 2.6043 - mae: 1.2598 - val_loss: 1.4237 - val_mse: 1.4237 - val_mae: 1.0192\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 474us/step - loss: 2.5492 - mse: 2.5492 - mae: 1.2378 - val_loss: 1.4162 - val_mse: 1.4162 - val_mae: 1.0155\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 340us/step - loss: 2.5061 - mse: 2.5061 - mae: 1.2210 - val_loss: 1.4029 - val_mse: 1.4029 - val_mae: 1.0099\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 561us/step - loss: 2.4702 - mse: 2.4702 - mae: 1.2091 - val_loss: 1.3843 - val_mse: 1.3843 - val_mae: 1.0027\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 620us/step - loss: 2.4395 - mse: 2.4395 - mae: 1.2008 - val_loss: 1.3643 - val_mse: 1.3643 - val_mae: 0.9951\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 285us/step - loss: 2.4118 - mse: 2.4118 - mae: 1.1952 - val_loss: 1.3464 - val_mse: 1.3464 - val_mae: 0.9936\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 623us/step - loss: 2.3863 - mse: 2.3863 - mae: 1.1920 - val_loss: 1.3344 - val_mse: 1.3344 - val_mae: 0.9925\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 264us/step - loss: 2.3641 - mse: 2.3641 - mae: 1.1884 - val_loss: 1.3286 - val_mse: 1.3286 - val_mae: 0.9917\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 319us/step - loss: 2.3428 - mse: 2.3428 - mae: 1.1839 - val_loss: 1.3278 - val_mse: 1.3278 - val_mae: 0.9912\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 594us/step - loss: 2.3208 - mse: 2.3208 - mae: 1.1784 - val_loss: 1.3303 - val_mse: 1.3303 - val_mae: 0.9910\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 342us/step - loss: 2.2987 - mse: 2.2987 - mae: 1.1725 - val_loss: 1.3346 - val_mse: 1.3346 - val_mae: 0.9910\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 407us/step - loss: 2.2780 - mse: 2.2780 - mae: 1.1674 - val_loss: 1.3385 - val_mse: 1.3385 - val_mae: 0.9909\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 142us/step - loss: 2.2587 - mse: 2.2587 - mae: 1.1628 - val_loss: 1.3414 - val_mse: 1.3414 - val_mae: 0.9910\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 285us/step - loss: 2.2407 - mse: 2.2407 - mae: 1.1588 - val_loss: 1.3435 - val_mse: 1.3435 - val_mae: 0.9912\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 339us/step - loss: 2.2234 - mse: 2.2234 - mae: 1.1552 - val_loss: 1.3441 - val_mse: 1.3441 - val_mae: 0.9913\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 570us/step - loss: 2.2072 - mse: 2.2072 - mae: 1.1521 - val_loss: 1.3446 - val_mse: 1.3446 - val_mae: 0.9913\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 412us/step - loss: 2.1908 - mse: 2.1908 - mae: 1.1487 - val_loss: 1.3457 - val_mse: 1.3457 - val_mae: 0.9912\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 286us/step - loss: 2.1740 - mse: 2.1740 - mae: 1.1448 - val_loss: 1.3459 - val_mse: 1.3459 - val_mae: 0.9907\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 488us/step - loss: 2.1592 - mse: 2.1592 - mae: 1.1416 - val_loss: 1.3456 - val_mse: 1.3456 - val_mae: 0.9902\n",
      "67\n",
      "[67]\n",
      "Train on 99 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 8.6542 - mse: 8.6542 - mae: 2.4387 - val_loss: 4.9669 - val_mse: 4.9669 - val_mae: 1.7163\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 443us/step - loss: 6.4796 - mse: 6.4796 - mae: 1.9917 - val_loss: 3.8779 - val_mse: 3.8779 - val_mae: 1.4101\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 573us/step - loss: 4.9209 - mse: 4.9209 - mae: 1.6197 - val_loss: 3.0665 - val_mse: 3.0665 - val_mae: 1.1906\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 231us/step - loss: 3.8787 - mse: 3.8787 - mae: 1.3355 - val_loss: 2.5089 - val_mse: 2.5089 - val_mae: 1.0651\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 578us/step - loss: 3.2200 - mse: 3.2200 - mae: 1.2006 - val_loss: 2.1674 - val_mse: 2.1674 - val_mae: 1.0211\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 373us/step - loss: 2.8587 - mse: 2.8587 - mae: 1.1750 - val_loss: 1.9709 - val_mse: 1.9709 - val_mae: 1.0010\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 384us/step - loss: 2.7145 - mse: 2.7145 - mae: 1.1898 - val_loss: 1.8801 - val_mse: 1.8801 - val_mae: 1.0261\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 433us/step - loss: 2.6901 - mse: 2.6901 - mae: 1.2326 - val_loss: 1.8461 - val_mse: 1.8461 - val_mae: 1.0545\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 344us/step - loss: 2.6932 - mse: 2.6932 - mae: 1.2628 - val_loss: 1.8248 - val_mse: 1.8248 - val_mae: 1.0633\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 408us/step - loss: 2.6738 - mse: 2.6738 - mae: 1.2691 - val_loss: 1.7982 - val_mse: 1.7982 - val_mae: 1.0546\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 464us/step - loss: 2.6228 - mse: 2.6228 - mae: 1.2530 - val_loss: 1.7714 - val_mse: 1.7714 - val_mae: 1.0351\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 653us/step - loss: 2.5587 - mse: 2.5587 - mae: 1.2249 - val_loss: 1.7509 - val_mse: 1.7509 - val_mae: 1.0117\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 448us/step - loss: 2.5035 - mse: 2.5035 - mae: 1.1955 - val_loss: 1.7411 - val_mse: 1.7411 - val_mae: 0.9943\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 284us/step - loss: 2.4599 - mse: 2.4599 - mae: 1.1685 - val_loss: 1.7406 - val_mse: 1.7406 - val_mae: 0.9874\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 293us/step - loss: 2.4203 - mse: 2.4203 - mae: 1.1457 - val_loss: 1.7406 - val_mse: 1.7406 - val_mae: 0.9828\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 285us/step - loss: 2.3892 - mse: 2.3892 - mae: 1.1297 - val_loss: 1.7346 - val_mse: 1.7346 - val_mae: 0.9795\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 429us/step - loss: 2.3574 - mse: 2.3574 - mae: 1.1193 - val_loss: 1.7229 - val_mse: 1.7229 - val_mae: 0.9782\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 247us/step - loss: 2.3239 - mse: 2.3239 - mae: 1.1136 - val_loss: 1.7101 - val_mse: 1.7101 - val_mae: 0.9783\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 535us/step - loss: 2.2904 - mse: 2.2904 - mae: 1.1105 - val_loss: 1.6971 - val_mse: 1.6971 - val_mae: 0.9795\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 636us/step - loss: 2.2580 - mse: 2.2580 - mae: 1.1084 - val_loss: 1.6843 - val_mse: 1.6843 - val_mae: 0.9806\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 685us/step - loss: 2.2295 - mse: 2.2295 - mae: 1.1067 - val_loss: 1.6715 - val_mse: 1.6715 - val_mae: 0.9811\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 312us/step - loss: 2.2016 - mse: 2.2016 - mae: 1.1036 - val_loss: 1.6608 - val_mse: 1.6608 - val_mae: 0.9813\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 323us/step - loss: 2.1754 - mse: 2.1754 - mae: 1.0993 - val_loss: 1.6515 - val_mse: 1.6515 - val_mae: 0.9810\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 473us/step - loss: 2.1505 - mse: 2.1505 - mae: 1.0936 - val_loss: 1.6433 - val_mse: 1.6433 - val_mae: 0.9803\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 322us/step - loss: 2.1254 - mse: 2.1254 - mae: 1.0862 - val_loss: 1.6358 - val_mse: 1.6358 - val_mae: 0.9798\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 518us/step - loss: 2.1014 - mse: 2.1014 - mae: 1.0789 - val_loss: 1.6273 - val_mse: 1.6273 - val_mae: 0.9792\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 533us/step - loss: 2.0807 - mse: 2.0807 - mae: 1.0729 - val_loss: 1.6188 - val_mse: 1.6188 - val_mae: 0.9790\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 324us/step - loss: 2.0601 - mse: 2.0601 - mae: 1.0687 - val_loss: 1.6093 - val_mse: 1.6093 - val_mae: 0.9784\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 327us/step - loss: 2.0413 - mse: 2.0413 - mae: 1.0656 - val_loss: 1.5992 - val_mse: 1.5992 - val_mae: 0.9775\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 332us/step - loss: 2.0234 - mse: 2.0234 - mae: 1.0629 - val_loss: 1.5902 - val_mse: 1.5902 - val_mae: 0.9766\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 279us/step - loss: 2.0063 - mse: 2.0063 - mae: 1.0597 - val_loss: 1.5813 - val_mse: 1.5813 - val_mae: 0.9753\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 439us/step - loss: 1.9890 - mse: 1.9890 - mae: 1.0556 - val_loss: 1.5727 - val_mse: 1.5727 - val_mae: 0.9737\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 237us/step - loss: 1.9725 - mse: 1.9725 - mae: 1.0508 - val_loss: 1.5656 - val_mse: 1.5656 - val_mae: 0.9723\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.9562 - mse: 1.9562 - mae: 1.0452 - val_loss: 1.5598 - val_mse: 1.5598 - val_mae: 0.9709\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 435us/step - loss: 1.9404 - mse: 1.9404 - mae: 1.0394 - val_loss: 1.5544 - val_mse: 1.5544 - val_mae: 0.9696\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 332us/step - loss: 1.9248 - mse: 1.9248 - mae: 1.0336 - val_loss: 1.5494 - val_mse: 1.5494 - val_mae: 0.9688\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 344us/step - loss: 1.9101 - mse: 1.9101 - mae: 1.0285 - val_loss: 1.5425 - val_mse: 1.5425 - val_mae: 0.9678\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 302us/step - loss: 1.8959 - mse: 1.8959 - mae: 1.0247 - val_loss: 1.5333 - val_mse: 1.5333 - val_mae: 0.9666\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 305us/step - loss: 1.8818 - mse: 1.8818 - mae: 1.0213 - val_loss: 1.5227 - val_mse: 1.5227 - val_mae: 0.9649\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.8684 - mse: 1.8684 - mae: 1.0176 - val_loss: 1.5134 - val_mse: 1.5134 - val_mae: 0.9632\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 317us/step - loss: 1.8559 - mse: 1.8559 - mae: 1.0138 - val_loss: 1.5044 - val_mse: 1.5044 - val_mae: 0.9609\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 627us/step - loss: 1.8439 - mse: 1.8439 - mae: 1.0099 - val_loss: 1.4978 - val_mse: 1.4978 - val_mae: 0.9592\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 426us/step - loss: 1.8321 - mse: 1.8321 - mae: 1.0052 - val_loss: 1.4880 - val_mse: 1.4880 - val_mae: 0.9570\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 406us/step - loss: 1.8199 - mse: 1.8199 - mae: 1.0006 - val_loss: 1.4756 - val_mse: 1.4756 - val_mae: 0.9546\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 453us/step - loss: 1.8090 - mse: 1.8090 - mae: 0.9971 - val_loss: 1.4669 - val_mse: 1.4669 - val_mae: 0.9535\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 457us/step - loss: 1.7981 - mse: 1.7981 - mae: 0.9933 - val_loss: 1.4639 - val_mse: 1.4639 - val_mae: 0.9534\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 314us/step - loss: 1.7873 - mse: 1.7873 - mae: 0.9893 - val_loss: 1.4555 - val_mse: 1.4555 - val_mae: 0.9523\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 334us/step - loss: 1.7769 - mse: 1.7769 - mae: 0.9866 - val_loss: 1.4498 - val_mse: 1.4498 - val_mae: 0.9518\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 310us/step - loss: 1.7671 - mse: 1.7671 - mae: 0.9841 - val_loss: 1.4417 - val_mse: 1.4417 - val_mae: 0.9512\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 432us/step - loss: 1.7579 - mse: 1.7579 - mae: 0.9814 - val_loss: 1.4386 - val_mse: 1.4386 - val_mae: 0.9518\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 334us/step - loss: 1.7486 - mse: 1.7486 - mae: 0.9787 - val_loss: 1.4372 - val_mse: 1.4372 - val_mae: 0.9526\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 395us/step - loss: 1.7388 - mse: 1.7388 - mae: 0.9759 - val_loss: 1.4302 - val_mse: 1.4302 - val_mae: 0.9523\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 383us/step - loss: 1.7282 - mse: 1.7282 - mae: 0.9737 - val_loss: 1.4198 - val_mse: 1.4198 - val_mae: 0.9512\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 324us/step - loss: 1.7198 - mse: 1.7198 - mae: 0.9718 - val_loss: 1.4161 - val_mse: 1.4161 - val_mae: 0.9515\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 332us/step - loss: 1.7104 - mse: 1.7104 - mae: 0.9688 - val_loss: 1.4156 - val_mse: 1.4156 - val_mae: 0.9516\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 284us/step - loss: 1.7004 - mse: 1.7004 - mae: 0.9645 - val_loss: 1.4137 - val_mse: 1.4137 - val_mae: 0.9514\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 313us/step - loss: 1.6908 - mse: 1.6908 - mae: 0.9606 - val_loss: 1.4047 - val_mse: 1.4047 - val_mae: 0.9497\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 324us/step - loss: 1.6820 - mse: 1.6820 - mae: 0.9586 - val_loss: 1.3938 - val_mse: 1.3938 - val_mae: 0.9487\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 286us/step - loss: 1.6732 - mse: 1.6732 - mae: 0.9580 - val_loss: 1.3898 - val_mse: 1.3898 - val_mae: 0.9485\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 336us/step - loss: 1.6634 - mse: 1.6634 - mae: 0.9547 - val_loss: 1.3881 - val_mse: 1.3881 - val_mae: 0.9483\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 403us/step - loss: 1.6547 - mse: 1.6547 - mae: 0.9510 - val_loss: 1.3792 - val_mse: 1.3792 - val_mae: 0.9468\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 314us/step - loss: 1.6453 - mse: 1.6453 - mae: 0.9494 - val_loss: 1.3733 - val_mse: 1.3733 - val_mae: 0.9460\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 452us/step - loss: 1.6383 - mse: 1.6383 - mae: 0.9489 - val_loss: 1.3677 - val_mse: 1.3677 - val_mae: 0.9453\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 355us/step - loss: 1.6284 - mse: 1.6284 - mae: 0.9462 - val_loss: 1.3655 - val_mse: 1.3655 - val_mae: 0.9443\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 393us/step - loss: 1.6190 - mse: 1.6190 - mae: 0.9405 - val_loss: 1.3616 - val_mse: 1.3616 - val_mae: 0.9427\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 553us/step - loss: 1.6110 - mse: 1.6110 - mae: 0.9371 - val_loss: 1.3551 - val_mse: 1.3551 - val_mae: 0.9413\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 433us/step - loss: 1.6025 - mse: 1.6025 - mae: 0.9364 - val_loss: 1.3486 - val_mse: 1.3486 - val_mae: 0.9409\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 730us/step - loss: 1.5935 - mse: 1.5935 - mae: 0.9359 - val_loss: 1.3446 - val_mse: 1.3446 - val_mae: 0.9399\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 483us/step - loss: 1.5835 - mse: 1.5835 - mae: 0.9320 - val_loss: 1.3413 - val_mse: 1.3413 - val_mae: 0.9394\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 319us/step - loss: 1.5758 - mse: 1.5758 - mae: 0.9295 - val_loss: 1.3365 - val_mse: 1.3365 - val_mae: 0.9388\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 240us/step - loss: 1.5676 - mse: 1.5676 - mae: 0.9275 - val_loss: 1.3340 - val_mse: 1.3340 - val_mae: 0.9378\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 536us/step - loss: 1.5570 - mse: 1.5570 - mae: 0.9227 - val_loss: 1.3320 - val_mse: 1.3320 - val_mae: 0.9374\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 392us/step - loss: 1.5485 - mse: 1.5485 - mae: 0.9203 - val_loss: 1.3288 - val_mse: 1.3288 - val_mae: 0.9379\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - ETA: 0s - loss: 2.4114 - mse: 2.4114 - mae: 1.092 - 0s 554us/step - loss: 1.5406 - mse: 1.5406 - mae: 0.9205 - val_loss: 1.3238 - val_mse: 1.3238 - val_mae: 0.9365\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 403us/step - loss: 1.5324 - mse: 1.5324 - mae: 0.9181 - val_loss: 1.3235 - val_mse: 1.3235 - val_mae: 0.9359\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 303us/step - loss: 1.5224 - mse: 1.5224 - mae: 0.9132 - val_loss: 1.3216 - val_mse: 1.3216 - val_mae: 0.9367\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 294us/step - loss: 1.5149 - mse: 1.5149 - mae: 0.9121 - val_loss: 1.3166 - val_mse: 1.3166 - val_mae: 0.9373\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 407us/step - loss: 1.5062 - mse: 1.5062 - mae: 0.9130 - val_loss: 1.3101 - val_mse: 1.3101 - val_mae: 0.9360\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 445us/step - loss: 1.4960 - mse: 1.4960 - mae: 0.9104 - val_loss: 1.3072 - val_mse: 1.3072 - val_mae: 0.9348\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 332us/step - loss: 1.4863 - mse: 1.4863 - mae: 0.9062 - val_loss: 1.3043 - val_mse: 1.3043 - val_mae: 0.9341\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 967us/step - loss: 1.4782 - mse: 1.4782 - mae: 0.9033 - val_loss: 1.3011 - val_mse: 1.3011 - val_mae: 0.9327\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 482us/step - loss: 1.4702 - mse: 1.4702 - mae: 0.8999 - val_loss: 1.2977 - val_mse: 1.2977 - val_mae: 0.9314\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.4599 - mse: 1.4599 - mae: 0.8957 - val_loss: 1.2970 - val_mse: 1.2970 - val_mae: 0.9319\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 374us/step - loss: 1.4539 - mse: 1.4539 - mae: 0.8937 - val_loss: 1.2933 - val_mse: 1.2933 - val_mae: 0.9316\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 437us/step - loss: 1.4440 - mse: 1.4440 - mae: 0.8915 - val_loss: 1.2888 - val_mse: 1.2888 - val_mae: 0.9300\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 395us/step - loss: 1.4345 - mse: 1.4345 - mae: 0.8893 - val_loss: 1.2849 - val_mse: 1.2849 - val_mae: 0.9288\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 278us/step - loss: 1.4270 - mse: 1.4270 - mae: 0.8867 - val_loss: 1.2856 - val_mse: 1.2856 - val_mae: 0.9292\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 424us/step - loss: 1.4191 - mse: 1.4191 - mae: 0.8832 - val_loss: 1.2834 - val_mse: 1.2834 - val_mae: 0.9284\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 569us/step - loss: 1.4093 - mse: 1.4093 - mae: 0.8794 - val_loss: 1.2802 - val_mse: 1.2802 - val_mae: 0.9264\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 399us/step - loss: 1.4031 - mse: 1.4031 - mae: 0.8771 - val_loss: 1.2765 - val_mse: 1.2765 - val_mae: 0.9239\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 613us/step - loss: 1.3947 - mse: 1.3947 - mae: 0.8723 - val_loss: 1.2754 - val_mse: 1.2754 - val_mae: 0.9235\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 485us/step - loss: 1.3852 - mse: 1.3852 - mae: 0.8685 - val_loss: 1.2774 - val_mse: 1.2774 - val_mae: 0.9261\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 367us/step - loss: 1.3815 - mse: 1.3815 - mae: 0.8688 - val_loss: 1.2741 - val_mse: 1.2741 - val_mae: 0.9260\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 578us/step - loss: 1.3708 - mse: 1.3708 - mae: 0.8650 - val_loss: 1.2701 - val_mse: 1.2701 - val_mae: 0.9234\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 604us/step - loss: 1.3613 - mse: 1.3613 - mae: 0.8603 - val_loss: 1.2698 - val_mse: 1.2698 - val_mae: 0.9228\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 684us/step - loss: 1.3583 - mse: 1.3583 - mae: 0.8596 - val_loss: 1.2656 - val_mse: 1.2656 - val_mae: 0.9239\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 593us/step - loss: 1.3503 - mse: 1.3503 - mae: 0.8594 - val_loss: 1.2627 - val_mse: 1.2627 - val_mae: 0.9238\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 1.3383 - mse: 1.3383 - mae: 0.8555 - val_loss: 1.2682 - val_mse: 1.2682 - val_mae: 0.9229\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.3330 - mse: 1.3330 - mae: 0.8503 - val_loss: 1.2636 - val_mse: 1.2636 - val_mae: 0.9201\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 567us/step - loss: 1.3260 - mse: 1.3260 - mae: 0.8462 - val_loss: 1.2586 - val_mse: 1.2586 - val_mae: 0.9193\n",
      "68\n",
      "[68]\n",
      "Train on 70 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 3.9222 - mse: 3.9222 - mae: 1.4640 - val_loss: 2.4189 - val_mse: 2.4189 - val_mae: 1.0946\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 652us/step - loss: 3.5291 - mse: 3.5291 - mae: 1.3982 - val_loss: 2.1694 - val_mse: 2.1694 - val_mae: 1.0624\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 342us/step - loss: 3.2579 - mse: 3.2579 - mae: 1.3453 - val_loss: 2.0048 - val_mse: 2.0048 - val_mae: 1.0226\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 583us/step - loss: 3.0910 - mse: 3.0910 - mae: 1.3047 - val_loss: 1.9007 - val_mse: 1.9007 - val_mae: 0.9922\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 446us/step - loss: 2.9759 - mse: 2.9759 - mae: 1.2672 - val_loss: 1.8392 - val_mse: 1.8392 - val_mae: 0.9762\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 446us/step - loss: 2.8796 - mse: 2.8796 - mae: 1.2355 - val_loss: 1.8079 - val_mse: 1.8079 - val_mae: 0.9654\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 223us/step - loss: 2.8035 - mse: 2.8035 - mae: 1.2148 - val_loss: 1.8115 - val_mse: 1.8115 - val_mae: 0.9598\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 940us/step - loss: 2.7425 - mse: 2.7425 - mae: 1.1969 - val_loss: 1.8360 - val_mse: 1.8360 - val_mae: 0.9570\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 642us/step - loss: 2.6954 - mse: 2.6954 - mae: 1.1804 - val_loss: 1.8711 - val_mse: 1.8711 - val_mae: 0.9555\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 348us/step - loss: 2.6611 - mse: 2.6611 - mae: 1.1655 - val_loss: 1.9057 - val_mse: 1.9057 - val_mae: 0.9545\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 482us/step - loss: 2.6348 - mse: 2.6348 - mae: 1.1528 - val_loss: 1.9283 - val_mse: 1.9283 - val_mae: 0.9537\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 401us/step - loss: 2.6069 - mse: 2.6069 - mae: 1.1413 - val_loss: 1.9361 - val_mse: 1.9361 - val_mae: 0.9564\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 584us/step - loss: 2.5764 - mse: 2.5764 - mae: 1.1316 - val_loss: 1.9313 - val_mse: 1.9313 - val_mae: 0.9597\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 529us/step - loss: 2.5444 - mse: 2.5444 - mae: 1.1242 - val_loss: 1.9185 - val_mse: 1.9185 - val_mae: 0.9637\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 355us/step - loss: 2.5120 - mse: 2.5120 - mae: 1.1176 - val_loss: 1.9014 - val_mse: 1.9014 - val_mae: 0.9674\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 370us/step - loss: 2.4818 - mse: 2.4818 - mae: 1.1129 - val_loss: 1.8859 - val_mse: 1.8859 - val_mae: 0.9710\n",
      "69\n",
      "[69]\n",
      "Train on 96 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 4.7770 - mse: 4.7770 - mae: 1.6298 - val_loss: 2.4546 - val_mse: 2.4546 - val_mae: 1.2969\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 720us/step - loss: 4.1743 - mse: 4.1743 - mae: 1.4761 - val_loss: 2.0161 - val_mse: 2.0161 - val_mae: 1.1625\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 226us/step - loss: 3.6948 - mse: 3.6948 - mae: 1.3611 - val_loss: 1.6857 - val_mse: 1.6857 - val_mae: 1.0372\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 543us/step - loss: 3.2990 - mse: 3.2990 - mae: 1.2741 - val_loss: 1.4349 - val_mse: 1.4349 - val_mae: 0.9487\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 308us/step - loss: 2.9852 - mse: 2.9852 - mae: 1.2046 - val_loss: 1.2494 - val_mse: 1.2494 - val_mae: 0.8873\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 313us/step - loss: 2.7483 - mse: 2.7483 - mae: 1.1560 - val_loss: 1.1166 - val_mse: 1.1166 - val_mae: 0.8444\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 431us/step - loss: 2.5813 - mse: 2.5813 - mae: 1.1293 - val_loss: 1.0312 - val_mse: 1.0312 - val_mae: 0.8349\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 2.4711 - mse: 2.4711 - mae: 1.1150 - val_loss: 0.9774 - val_mse: 0.9774 - val_mae: 0.8301\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 597us/step - loss: 2.3998 - mse: 2.3998 - mae: 1.1097 - val_loss: 0.9430 - val_mse: 0.9430 - val_mae: 0.8226\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 312us/step - loss: 2.3569 - mse: 2.3569 - mae: 1.1087 - val_loss: 0.9247 - val_mse: 0.9247 - val_mae: 0.8198\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 579us/step - loss: 2.3325 - mse: 2.3325 - mae: 1.1101 - val_loss: 0.9152 - val_mse: 0.9152 - val_mae: 0.8177\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 338us/step - loss: 2.3168 - mse: 2.3168 - mae: 1.1121 - val_loss: 0.9103 - val_mse: 0.9103 - val_mae: 0.8157\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 429us/step - loss: 2.3039 - mse: 2.3039 - mae: 1.1117 - val_loss: 0.9074 - val_mse: 0.9074 - val_mae: 0.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 262us/step - loss: 2.2928 - mse: 2.2928 - mae: 1.1091 - val_loss: 0.9056 - val_mse: 0.9056 - val_mae: 0.8122\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 334us/step - loss: 2.2830 - mse: 2.2830 - mae: 1.1053 - val_loss: 0.9050 - val_mse: 0.9050 - val_mae: 0.8106\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 387us/step - loss: 2.2740 - mse: 2.2740 - mae: 1.1010 - val_loss: 0.9054 - val_mse: 0.9054 - val_mae: 0.8090\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 543us/step - loss: 2.2658 - mse: 2.2658 - mae: 1.0972 - val_loss: 0.9061 - val_mse: 0.9061 - val_mae: 0.8074\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 396us/step - loss: 2.2585 - mse: 2.2585 - mae: 1.0943 - val_loss: 0.9069 - val_mse: 0.9069 - val_mae: 0.8057\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 292us/step - loss: 2.2528 - mse: 2.2528 - mae: 1.0926 - val_loss: 0.9079 - val_mse: 0.9079 - val_mae: 0.8044\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 2.2471 - mse: 2.2471 - mae: 1.0911 - val_loss: 0.9089 - val_mse: 0.9089 - val_mae: 0.8035\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 440us/step - loss: 2.2409 - mse: 2.2409 - mae: 1.0896 - val_loss: 0.9097 - val_mse: 0.9097 - val_mae: 0.8032\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 635us/step - loss: 2.2339 - mse: 2.2339 - mae: 1.0884 - val_loss: 0.9098 - val_mse: 0.9098 - val_mae: 0.8022\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 906us/step - loss: 2.2266 - mse: 2.2266 - mae: 1.0875 - val_loss: 0.9088 - val_mse: 0.9088 - val_mae: 0.8002\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 374us/step - loss: 2.2171 - mse: 2.2171 - mae: 1.0858 - val_loss: 0.9064 - val_mse: 0.9064 - val_mae: 0.7965\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 323us/step - loss: 2.2070 - mse: 2.2070 - mae: 1.0837 - val_loss: 0.9041 - val_mse: 0.9041 - val_mae: 0.7931\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 392us/step - loss: 2.1973 - mse: 2.1973 - mae: 1.0820 - val_loss: 0.9023 - val_mse: 0.9023 - val_mae: 0.7901\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 605us/step - loss: 2.1881 - mse: 2.1881 - mae: 1.0805 - val_loss: 0.9007 - val_mse: 0.9007 - val_mae: 0.7874\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 470us/step - loss: 2.1799 - mse: 2.1799 - mae: 1.0792 - val_loss: 0.9000 - val_mse: 0.9000 - val_mae: 0.7854\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 625us/step - loss: 2.1722 - mse: 2.1722 - mae: 1.0781 - val_loss: 0.8991 - val_mse: 0.8991 - val_mae: 0.7834\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 2.1653 - mse: 2.1653 - mae: 1.0771 - val_loss: 0.8981 - val_mse: 0.8981 - val_mae: 0.7811\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 2.1588 - mse: 2.1588 - mae: 1.0757 - val_loss: 0.8964 - val_mse: 0.8964 - val_mae: 0.7785\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 602us/step - loss: 2.1512 - mse: 2.1512 - mae: 1.0739 - val_loss: 0.8945 - val_mse: 0.8945 - val_mae: 0.7762\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 294us/step - loss: 2.1444 - mse: 2.1444 - mae: 1.0721 - val_loss: 0.8922 - val_mse: 0.8922 - val_mae: 0.7736\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 427us/step - loss: 2.1371 - mse: 2.1371 - mae: 1.0701 - val_loss: 0.8898 - val_mse: 0.8898 - val_mae: 0.7706\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 378us/step - loss: 2.1297 - mse: 2.1297 - mae: 1.0682 - val_loss: 0.8887 - val_mse: 0.8887 - val_mae: 0.7682\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 451us/step - loss: 2.1226 - mse: 2.1226 - mae: 1.0660 - val_loss: 0.8884 - val_mse: 0.8884 - val_mae: 0.7664\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 489us/step - loss: 2.1156 - mse: 2.1156 - mae: 1.0641 - val_loss: 0.8905 - val_mse: 0.8905 - val_mae: 0.7667\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 382us/step - loss: 2.1079 - mse: 2.1079 - mae: 1.0626 - val_loss: 0.8949 - val_mse: 0.8949 - val_mae: 0.7680\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 344us/step - loss: 2.0994 - mse: 2.0994 - mae: 1.0608 - val_loss: 0.8989 - val_mse: 0.8989 - val_mae: 0.7683\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 374us/step - loss: 2.0904 - mse: 2.0904 - mae: 1.0591 - val_loss: 0.9017 - val_mse: 0.9017 - val_mae: 0.7676\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 421us/step - loss: 2.0812 - mse: 2.0812 - mae: 1.0568 - val_loss: 0.9016 - val_mse: 0.9016 - val_mae: 0.7653\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 321us/step - loss: 2.0716 - mse: 2.0716 - mae: 1.0541 - val_loss: 0.9038 - val_mse: 0.9038 - val_mae: 0.7640\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 544us/step - loss: 2.0615 - mse: 2.0615 - mae: 1.0515 - val_loss: 0.9064 - val_mse: 0.9064 - val_mae: 0.7629\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 293us/step - loss: 2.0518 - mse: 2.0518 - mae: 1.0490 - val_loss: 0.9102 - val_mse: 0.9102 - val_mae: 0.7623\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.7453 - mse: 1.7453 - mae: 1.022 - 0s 344us/step - loss: 2.0423 - mse: 2.0423 - mae: 1.0467 - val_loss: 0.9139 - val_mse: 0.9139 - val_mae: 0.7617\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 497us/step - loss: 2.0337 - mse: 2.0337 - mae: 1.0444 - val_loss: 0.9179 - val_mse: 0.9179 - val_mae: 0.7605\n",
      "70\n",
      "[70]\n",
      "Train on 90 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 2.4997 - mse: 2.4997 - mae: 1.2401 - val_loss: 0.5115 - val_mse: 0.5115 - val_mae: 0.5377\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 601us/step - loss: 2.1581 - mse: 2.1581 - mae: 1.1400 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.4382\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 491us/step - loss: 1.9679 - mse: 1.9679 - mae: 1.0846 - val_loss: 0.4510 - val_mse: 0.4510 - val_mae: 0.4148\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 210us/step - loss: 1.8726 - mse: 1.8726 - mae: 1.0703 - val_loss: 0.4417 - val_mse: 0.4417 - val_mae: 0.4307\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 291us/step - loss: 1.8007 - mse: 1.8007 - mae: 1.0668 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4391\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 614us/step - loss: 1.7212 - mse: 1.7212 - mae: 1.0526 - val_loss: 0.3838 - val_mse: 0.3838 - val_mae: 0.4259\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 663us/step - loss: 1.6379 - mse: 1.6379 - mae: 1.0306 - val_loss: 0.3419 - val_mse: 0.3419 - val_mae: 0.3982\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 328us/step - loss: 1.5549 - mse: 1.5549 - mae: 1.0050 - val_loss: 0.3115 - val_mse: 0.3115 - val_mae: 0.3702\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 388us/step - loss: 1.4823 - mse: 1.4823 - mae: 0.9813 - val_loss: 0.2914 - val_mse: 0.2914 - val_mae: 0.3492\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 266us/step - loss: 1.4220 - mse: 1.4220 - mae: 0.9608 - val_loss: 0.2763 - val_mse: 0.2763 - val_mae: 0.3357\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 469us/step - loss: 1.3733 - mse: 1.3733 - mae: 0.9438 - val_loss: 0.2644 - val_mse: 0.2644 - val_mae: 0.3277\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 346us/step - loss: 1.3348 - mse: 1.3348 - mae: 0.9308 - val_loss: 0.2557 - val_mse: 0.2557 - val_mae: 0.3250\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 541us/step - loss: 1.3028 - mse: 1.3028 - mae: 0.9216 - val_loss: 0.2496 - val_mse: 0.2496 - val_mae: 0.3262\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 378us/step - loss: 1.2738 - mse: 1.2738 - mae: 0.9135 - val_loss: 0.2452 - val_mse: 0.2452 - val_mae: 0.3305\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 368us/step - loss: 1.2479 - mse: 1.2479 - mae: 0.9059 - val_loss: 0.2413 - val_mse: 0.2413 - val_mae: 0.3369\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 421us/step - loss: 1.2259 - mse: 1.2259 - mae: 0.8987 - val_loss: 0.2371 - val_mse: 0.2371 - val_mae: 0.3413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 553us/step - loss: 1.2063 - mse: 1.2063 - mae: 0.8921 - val_loss: 0.2318 - val_mse: 0.2318 - val_mae: 0.3426\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 346us/step - loss: 1.1875 - mse: 1.1875 - mae: 0.8851 - val_loss: 0.2257 - val_mse: 0.2257 - val_mae: 0.3395\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 322us/step - loss: 1.1693 - mse: 1.1693 - mae: 0.8771 - val_loss: 0.2182 - val_mse: 0.2182 - val_mae: 0.3325\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 321us/step - loss: 1.1525 - mse: 1.1525 - mae: 0.8690 - val_loss: 0.2103 - val_mse: 0.2103 - val_mae: 0.3239\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 273us/step - loss: 1.1379 - mse: 1.1379 - mae: 0.8622 - val_loss: 0.2038 - val_mse: 0.2038 - val_mae: 0.3184\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 1.1242 - mse: 1.1242 - mae: 0.8561 - val_loss: 0.1989 - val_mse: 0.1989 - val_mae: 0.3172\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 567us/step - loss: 1.1113 - mse: 1.1113 - mae: 0.8513 - val_loss: 0.1955 - val_mse: 0.1955 - val_mae: 0.3188\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 379us/step - loss: 1.1000 - mse: 1.1000 - mae: 0.8476 - val_loss: 0.1930 - val_mse: 0.1930 - val_mae: 0.3218\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 394us/step - loss: 1.0896 - mse: 1.0896 - mae: 0.8448 - val_loss: 0.1907 - val_mse: 0.1907 - val_mae: 0.3251\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 304us/step - loss: 1.0800 - mse: 1.0800 - mae: 0.8421 - val_loss: 0.1883 - val_mse: 0.1883 - val_mae: 0.3266\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 1.0710 - mse: 1.0710 - mae: 0.8389 - val_loss: 0.1854 - val_mse: 0.1854 - val_mae: 0.3266\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 637us/step - loss: 1.0626 - mse: 1.0626 - mae: 0.8355 - val_loss: 0.1825 - val_mse: 0.1825 - val_mae: 0.3263\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 565us/step - loss: 1.0550 - mse: 1.0550 - mae: 0.8321 - val_loss: 0.1800 - val_mse: 0.1800 - val_mae: 0.3263\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 392us/step - loss: 1.0476 - mse: 1.0476 - mae: 0.8289 - val_loss: 0.1782 - val_mse: 0.1782 - val_mae: 0.3273\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 389us/step - loss: 1.0406 - mse: 1.0406 - mae: 0.8259 - val_loss: 0.1768 - val_mse: 0.1768 - val_mae: 0.3284\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 322us/step - loss: 1.0340 - mse: 1.0340 - mae: 0.8228 - val_loss: 0.1755 - val_mse: 0.1755 - val_mae: 0.3292\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 1.0277 - mse: 1.0277 - mae: 0.8198 - val_loss: 0.1743 - val_mse: 0.1743 - val_mae: 0.3301\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 301us/step - loss: 1.0217 - mse: 1.0217 - mae: 0.8174 - val_loss: 0.1733 - val_mse: 0.1733 - val_mae: 0.3310\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 432us/step - loss: 1.0160 - mse: 1.0160 - mae: 0.8151 - val_loss: 0.1725 - val_mse: 0.1725 - val_mae: 0.3323\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 288us/step - loss: 1.0106 - mse: 1.0106 - mae: 0.8128 - val_loss: 0.1720 - val_mse: 0.1720 - val_mae: 0.3338\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 356us/step - loss: 1.0054 - mse: 1.0054 - mae: 0.8105 - val_loss: 0.1715 - val_mse: 0.1715 - val_mae: 0.3353\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 503us/step - loss: 1.0005 - mse: 1.0005 - mae: 0.8083 - val_loss: 0.1711 - val_mse: 0.1711 - val_mae: 0.3368\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 278us/step - loss: 0.9959 - mse: 0.9959 - mae: 0.8060 - val_loss: 0.1709 - val_mse: 0.1709 - val_mae: 0.3384\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 367us/step - loss: 0.9910 - mse: 0.9910 - mae: 0.8035 - val_loss: 0.1708 - val_mse: 0.1708 - val_mae: 0.3400\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 824us/step - loss: 0.9866 - mse: 0.9866 - mae: 0.8008 - val_loss: 0.1700 - val_mse: 0.1700 - val_mae: 0.3402\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 249us/step - loss: 0.9826 - mse: 0.9826 - mae: 0.7981 - val_loss: 0.1689 - val_mse: 0.1689 - val_mae: 0.3398\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 446us/step - loss: 0.9784 - mse: 0.9784 - mae: 0.7954 - val_loss: 0.1681 - val_mse: 0.1681 - val_mae: 0.3397\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 290us/step - loss: 0.9743 - mse: 0.9743 - mae: 0.7930 - val_loss: 0.1677 - val_mse: 0.1677 - val_mae: 0.3405\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.9704 - mse: 0.9704 - mae: 0.7910 - val_loss: 0.1679 - val_mse: 0.1679 - val_mae: 0.3422\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 299us/step - loss: 0.9664 - mse: 0.9664 - mae: 0.7891 - val_loss: 0.1685 - val_mse: 0.1685 - val_mae: 0.3444\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 367us/step - loss: 0.9624 - mse: 0.9624 - mae: 0.7870 - val_loss: 0.1691 - val_mse: 0.1691 - val_mae: 0.3463\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 220us/step - loss: 0.9590 - mse: 0.9590 - mae: 0.7850 - val_loss: 0.1694 - val_mse: 0.1694 - val_mae: 0.3478\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 0.9556 - mse: 0.9556 - mae: 0.7830 - val_loss: 0.1694 - val_mse: 0.1694 - val_mae: 0.3487\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 266us/step - loss: 0.9524 - mse: 0.9524 - mae: 0.7812 - val_loss: 0.1694 - val_mse: 0.1694 - val_mae: 0.3493\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 323us/step - loss: 0.9489 - mse: 0.9489 - mae: 0.7790 - val_loss: 0.1694 - val_mse: 0.1694 - val_mae: 0.3501\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 630us/step - loss: 0.9456 - mse: 0.9456 - mae: 0.7769 - val_loss: 0.1695 - val_mse: 0.1695 - val_mae: 0.3511\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 432us/step - loss: 0.9423 - mse: 0.9423 - mae: 0.7751 - val_loss: 0.1700 - val_mse: 0.1700 - val_mae: 0.3526\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 368us/step - loss: 0.9391 - mse: 0.9391 - mae: 0.7735 - val_loss: 0.1703 - val_mse: 0.1703 - val_mae: 0.3538\n",
      "71\n",
      "[71]\n",
      "Train on 90 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 0.8975 - mse: 0.8975 - mae: 0.7532 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.6487\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 324us/step - loss: 0.7203 - mse: 0.7203 - mae: 0.6419 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.5502\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 345us/step - loss: 0.5794 - mse: 0.5794 - mae: 0.5516 - val_loss: 0.3241 - val_mse: 0.3241 - val_mae: 0.4717\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 167us/step - loss: 0.4788 - mse: 0.4788 - mae: 0.4843 - val_loss: 0.2545 - val_mse: 0.2545 - val_mae: 0.4106\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 379us/step - loss: 0.4166 - mse: 0.4166 - mae: 0.4345 - val_loss: 0.2087 - val_mse: 0.2087 - val_mae: 0.3618\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 334us/step - loss: 0.3814 - mse: 0.3814 - mae: 0.4056 - val_loss: 0.1819 - val_mse: 0.1819 - val_mae: 0.3557\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 368us/step - loss: 0.3665 - mse: 0.3665 - mae: 0.3934 - val_loss: 0.1695 - val_mse: 0.1695 - val_mae: 0.3542\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 281us/step - loss: 0.3636 - mse: 0.3636 - mae: 0.3930 - val_loss: 0.1659 - val_mse: 0.1659 - val_mae: 0.3563\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 729us/step - loss: 0.3646 - mse: 0.3646 - mae: 0.3982 - val_loss: 0.1654 - val_mse: 0.1654 - val_mae: 0.3585\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 582us/step - loss: 0.3645 - mse: 0.3645 - mae: 0.4014 - val_loss: 0.1648 - val_mse: 0.1648 - val_mae: 0.3585\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 425us/step - loss: 0.3612 - mse: 0.3612 - mae: 0.4001 - val_loss: 0.1636 - val_mse: 0.1636 - val_mae: 0.3571\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 397us/step - loss: 0.3554 - mse: 0.3554 - mae: 0.3958 - val_loss: 0.1616 - val_mse: 0.1616 - val_mae: 0.3542\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 379us/step - loss: 0.3487 - mse: 0.3487 - mae: 0.3893 - val_loss: 0.1603 - val_mse: 0.1603 - val_mae: 0.3513\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 304us/step - loss: 0.3427 - mse: 0.3427 - mae: 0.3825 - val_loss: 0.1596 - val_mse: 0.1596 - val_mae: 0.3485\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 337us/step - loss: 0.3378 - mse: 0.3378 - mae: 0.3763 - val_loss: 0.1596 - val_mse: 0.1596 - val_mae: 0.3459\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 380us/step - loss: 0.3341 - mse: 0.3341 - mae: 0.3714 - val_loss: 0.1600 - val_mse: 0.1600 - val_mae: 0.3435\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 394us/step - loss: 0.3312 - mse: 0.3312 - mae: 0.3682 - val_loss: 0.1602 - val_mse: 0.1602 - val_mae: 0.3418\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.3285 - mse: 0.3285 - mae: 0.3657 - val_loss: 0.1601 - val_mse: 0.1601 - val_mae: 0.3408\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 338us/step - loss: 0.3257 - mse: 0.3257 - mae: 0.3639 - val_loss: 0.1598 - val_mse: 0.1598 - val_mae: 0.3409\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 472us/step - loss: 0.3227 - mse: 0.3227 - mae: 0.3623 - val_loss: 0.1594 - val_mse: 0.1594 - val_mae: 0.3416\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 257us/step - loss: 0.3198 - mse: 0.3198 - mae: 0.3609 - val_loss: 0.1588 - val_mse: 0.1588 - val_mae: 0.3426\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 399us/step - loss: 0.3172 - mse: 0.3172 - mae: 0.3599 - val_loss: 0.1580 - val_mse: 0.1580 - val_mae: 0.3434\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 423us/step - loss: 0.3149 - mse: 0.3149 - mae: 0.3589 - val_loss: 0.1571 - val_mse: 0.1571 - val_mae: 0.3438\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 403us/step - loss: 0.3127 - mse: 0.3127 - mae: 0.3579 - val_loss: 0.1556 - val_mse: 0.1556 - val_mae: 0.3436\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 308us/step - loss: 0.3106 - mse: 0.3106 - mae: 0.3569 - val_loss: 0.1543 - val_mse: 0.1543 - val_mae: 0.3430\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 266us/step - loss: 0.3088 - mse: 0.3088 - mae: 0.3560 - val_loss: 0.1529 - val_mse: 0.1529 - val_mae: 0.3421\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 500us/step - loss: 0.3069 - mse: 0.3069 - mae: 0.3551 - val_loss: 0.1516 - val_mse: 0.1516 - val_mae: 0.3408\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 391us/step - loss: 0.3052 - mse: 0.3052 - mae: 0.3542 - val_loss: 0.1504 - val_mse: 0.1504 - val_mae: 0.3394\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 334us/step - loss: 0.3034 - mse: 0.3034 - mae: 0.3532 - val_loss: 0.1493 - val_mse: 0.1493 - val_mae: 0.3380\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 390us/step - loss: 0.3015 - mse: 0.3015 - mae: 0.3521 - val_loss: 0.1484 - val_mse: 0.1484 - val_mae: 0.3369\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 554us/step - loss: 0.2997 - mse: 0.2997 - mae: 0.3510 - val_loss: 0.1476 - val_mse: 0.1476 - val_mae: 0.3361\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 327us/step - loss: 0.2980 - mse: 0.2980 - mae: 0.3500 - val_loss: 0.1470 - val_mse: 0.1470 - val_mae: 0.3355\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 337us/step - loss: 0.2963 - mse: 0.2963 - mae: 0.3492 - val_loss: 0.1462 - val_mse: 0.1462 - val_mae: 0.3348\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 421us/step - loss: 0.2947 - mse: 0.2947 - mae: 0.3484 - val_loss: 0.1454 - val_mse: 0.1454 - val_mae: 0.3343\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 0.2931 - mse: 0.2931 - mae: 0.3476 - val_loss: 0.1447 - val_mse: 0.1447 - val_mae: 0.3337\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 478us/step - loss: 0.2916 - mse: 0.2916 - mae: 0.3468 - val_loss: 0.1442 - val_mse: 0.1442 - val_mae: 0.3333\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 302us/step - loss: 0.2901 - mse: 0.2901 - mae: 0.3460 - val_loss: 0.1437 - val_mse: 0.1437 - val_mae: 0.3330\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 0.2887 - mse: 0.2887 - mae: 0.3451 - val_loss: 0.1433 - val_mse: 0.1433 - val_mae: 0.3325\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 388us/step - loss: 0.2873 - mse: 0.2873 - mae: 0.3442 - val_loss: 0.1426 - val_mse: 0.1426 - val_mae: 0.3319\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 435us/step - loss: 0.2859 - mse: 0.2859 - mae: 0.3433 - val_loss: 0.1419 - val_mse: 0.1419 - val_mae: 0.3313\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 299us/step - loss: 0.2845 - mse: 0.2845 - mae: 0.3425 - val_loss: 0.1413 - val_mse: 0.1413 - val_mae: 0.3309\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 362us/step - loss: 0.2832 - mse: 0.2832 - mae: 0.3419 - val_loss: 0.1407 - val_mse: 0.1407 - val_mae: 0.3303\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 0.2819 - mse: 0.2819 - mae: 0.3412 - val_loss: 0.1401 - val_mse: 0.1401 - val_mae: 0.3299\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 489us/step - loss: 0.2807 - mse: 0.2807 - mae: 0.3405 - val_loss: 0.1397 - val_mse: 0.1397 - val_mae: 0.3296\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 389us/step - loss: 0.2794 - mse: 0.2794 - mae: 0.3396 - val_loss: 0.1395 - val_mse: 0.1395 - val_mae: 0.3293\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 377us/step - loss: 0.2781 - mse: 0.2781 - mae: 0.3386 - val_loss: 0.1391 - val_mse: 0.1391 - val_mae: 0.3287\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 309us/step - loss: 0.2769 - mse: 0.2769 - mae: 0.3376 - val_loss: 0.1387 - val_mse: 0.1387 - val_mae: 0.3282\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 432us/step - loss: 0.2756 - mse: 0.2756 - mae: 0.3366 - val_loss: 0.1383 - val_mse: 0.1383 - val_mae: 0.3279\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 332us/step - loss: 0.2743 - mse: 0.2743 - mae: 0.3357 - val_loss: 0.1380 - val_mse: 0.1380 - val_mae: 0.3276\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 386us/step - loss: 0.2731 - mse: 0.2731 - mae: 0.3348 - val_loss: 0.1377 - val_mse: 0.1377 - val_mae: 0.3274\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 290us/step - loss: 0.2720 - mse: 0.2720 - mae: 0.3339 - val_loss: 0.1375 - val_mse: 0.1375 - val_mae: 0.3272\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 0.2707 - mse: 0.2707 - mae: 0.3329 - val_loss: 0.1372 - val_mse: 0.1372 - val_mae: 0.3270\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 534us/step - loss: 0.2695 - mse: 0.2695 - mae: 0.3319 - val_loss: 0.1369 - val_mse: 0.1369 - val_mae: 0.3268\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 434us/step - loss: 0.2682 - mse: 0.2682 - mae: 0.3311 - val_loss: 0.1367 - val_mse: 0.1367 - val_mae: 0.3268\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 511us/step - loss: 0.2670 - mse: 0.2670 - mae: 0.3303 - val_loss: 0.1363 - val_mse: 0.1363 - val_mae: 0.3266\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.2658 - mse: 0.2658 - mae: 0.3296 - val_loss: 0.1361 - val_mse: 0.1361 - val_mae: 0.3264\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 221us/step - loss: 0.2647 - mse: 0.2647 - mae: 0.3288 - val_loss: 0.1358 - val_mse: 0.1358 - val_mae: 0.3261\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 429us/step - loss: 0.2634 - mse: 0.2634 - mae: 0.3277 - val_loss: 0.1355 - val_mse: 0.1355 - val_mae: 0.3258\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 533us/step - loss: 0.2623 - mse: 0.2623 - mae: 0.3267 - val_loss: 0.1352 - val_mse: 0.1352 - val_mae: 0.3254\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 529us/step - loss: 0.2611 - mse: 0.2611 - mae: 0.3256 - val_loss: 0.1351 - val_mse: 0.1351 - val_mae: 0.3252\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 355us/step - loss: 0.2599 - mse: 0.2599 - mae: 0.3246 - val_loss: 0.1349 - val_mse: 0.1349 - val_mae: 0.3250\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 486us/step - loss: 0.2588 - mse: 0.2588 - mae: 0.3237 - val_loss: 0.1347 - val_mse: 0.1347 - val_mae: 0.3247\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 743us/step - loss: 0.2576 - mse: 0.2576 - mae: 0.3228 - val_loss: 0.1344 - val_mse: 0.1344 - val_mae: 0.3245\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 313us/step - loss: 0.2565 - mse: 0.2565 - mae: 0.3219 - val_loss: 0.1343 - val_mse: 0.1343 - val_mae: 0.3244\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 358us/step - loss: 0.2553 - mse: 0.2553 - mae: 0.3208 - val_loss: 0.1341 - val_mse: 0.1341 - val_mae: 0.3242\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 281us/step - loss: 0.2543 - mse: 0.2543 - mae: 0.3194 - val_loss: 0.1341 - val_mse: 0.1341 - val_mae: 0.3241\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 253us/step - loss: 0.2532 - mse: 0.2532 - mae: 0.3182 - val_loss: 0.1339 - val_mse: 0.1339 - val_mae: 0.3239\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 423us/step - loss: 0.2520 - mse: 0.2520 - mae: 0.3174 - val_loss: 0.1338 - val_mse: 0.1338 - val_mae: 0.3238\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 357us/step - loss: 0.2509 - mse: 0.2509 - mae: 0.3168 - val_loss: 0.1337 - val_mse: 0.1337 - val_mae: 0.3240\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 408us/step - loss: 0.2498 - mse: 0.2498 - mae: 0.3162 - val_loss: 0.1338 - val_mse: 0.1338 - val_mae: 0.3242\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 0.2488 - mse: 0.2488 - mae: 0.3153 - val_loss: 0.1338 - val_mse: 0.1338 - val_mae: 0.3242\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 310us/step - loss: 0.2478 - mse: 0.2478 - mae: 0.3142 - val_loss: 0.1339 - val_mse: 0.1339 - val_mae: 0.3243\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 299us/step - loss: 0.2468 - mse: 0.2468 - mae: 0.3130 - val_loss: 0.1339 - val_mse: 0.1339 - val_mae: 0.3242\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 328us/step - loss: 0.2457 - mse: 0.2457 - mae: 0.3119 - val_loss: 0.1339 - val_mse: 0.1339 - val_mae: 0.3243\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 290us/step - loss: 0.2446 - mse: 0.2446 - mae: 0.3110 - val_loss: 0.1341 - val_mse: 0.1341 - val_mae: 0.3245\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 370us/step - loss: 0.2436 - mse: 0.2436 - mae: 0.3101 - val_loss: 0.1343 - val_mse: 0.1343 - val_mae: 0.3248\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 525us/step - loss: 0.2427 - mse: 0.2427 - mae: 0.3093 - val_loss: 0.1343 - val_mse: 0.1343 - val_mae: 0.3248\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 327us/step - loss: 0.2416 - mse: 0.2416 - mae: 0.3084 - val_loss: 0.1340 - val_mse: 0.1340 - val_mae: 0.3246\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 261us/step - loss: 0.2406 - mse: 0.2406 - mae: 0.3077 - val_loss: 0.1338 - val_mse: 0.1338 - val_mae: 0.3243\n",
      "72\n",
      "[72]\n",
      "Train on 102 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 12ms/step - loss: 9.2426 - mse: 9.2426 - mae: 2.5038 - val_loss: 3.0391 - val_mse: 3.0391 - val_mae: 1.5384\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 393us/step - loss: 8.4010 - mse: 8.4010 - mae: 2.3326 - val_loss: 2.7151 - val_mse: 2.7151 - val_mae: 1.4196\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 258us/step - loss: 7.6288 - mse: 7.6288 - mae: 2.1594 - val_loss: 2.4074 - val_mse: 2.4074 - val_mae: 1.3040\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 293us/step - loss: 6.9207 - mse: 6.9207 - mae: 1.9859 - val_loss: 2.1134 - val_mse: 2.1134 - val_mae: 1.1829\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 755us/step - loss: 6.2511 - mse: 6.2511 - mae: 1.8172 - val_loss: 1.8378 - val_mse: 1.8378 - val_mae: 1.0504\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 314us/step - loss: 5.5845 - mse: 5.5845 - mae: 1.6615 - val_loss: 1.5947 - val_mse: 1.5947 - val_mae: 0.9123\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 447us/step - loss: 4.9329 - mse: 4.9329 - mae: 1.5347 - val_loss: 1.3719 - val_mse: 1.3719 - val_mae: 0.7993\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 483us/step - loss: 4.3559 - mse: 4.3559 - mae: 1.4440 - val_loss: 1.1905 - val_mse: 1.1905 - val_mae: 0.7620\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 284us/step - loss: 3.8933 - mse: 3.8933 - mae: 1.3755 - val_loss: 1.0482 - val_mse: 1.0482 - val_mae: 0.7760\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 492us/step - loss: 3.5541 - mse: 3.5541 - mae: 1.3373 - val_loss: 0.9576 - val_mse: 0.9576 - val_mae: 0.7922\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 329us/step - loss: 3.3518 - mse: 3.3518 - mae: 1.3272 - val_loss: 0.9129 - val_mse: 0.9129 - val_mae: 0.8151\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 315us/step - loss: 3.2577 - mse: 3.2577 - mae: 1.3321 - val_loss: 0.8991 - val_mse: 0.8991 - val_mae: 0.8323\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 440us/step - loss: 3.2260 - mse: 3.2260 - mae: 1.3433 - val_loss: 0.8979 - val_mse: 0.8979 - val_mae: 0.8496\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 337us/step - loss: 3.2129 - mse: 3.2129 - mae: 1.3559 - val_loss: 0.8992 - val_mse: 0.8992 - val_mae: 0.8589\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 373us/step - loss: 3.1940 - mse: 3.1940 - mae: 1.3581 - val_loss: 0.8981 - val_mse: 0.8981 - val_mae: 0.8608\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 380us/step - loss: 3.1631 - mse: 3.1631 - mae: 1.3512 - val_loss: 0.8952 - val_mse: 0.8952 - val_mae: 0.8576\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 437us/step - loss: 3.1265 - mse: 3.1265 - mae: 1.3384 - val_loss: 0.8927 - val_mse: 0.8927 - val_mae: 0.8518\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 500us/step - loss: 3.0944 - mse: 3.0944 - mae: 1.3244 - val_loss: 0.8917 - val_mse: 0.8917 - val_mae: 0.8454\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 295us/step - loss: 3.0694 - mse: 3.0694 - mae: 1.3117 - val_loss: 0.8921 - val_mse: 0.8921 - val_mae: 0.8398\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 315us/step - loss: 3.0499 - mse: 3.0499 - mae: 1.3009 - val_loss: 0.8931 - val_mse: 0.8931 - val_mae: 0.8359\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 324us/step - loss: 3.0334 - mse: 3.0334 - mae: 1.2934 - val_loss: 0.8938 - val_mse: 0.8938 - val_mae: 0.8339\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 362us/step - loss: 3.0184 - mse: 3.0184 - mae: 1.2882 - val_loss: 0.8936 - val_mse: 0.8936 - val_mae: 0.8337\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 551us/step - loss: 3.0027 - mse: 3.0027 - mae: 1.2844 - val_loss: 0.8921 - val_mse: 0.8921 - val_mae: 0.8350\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 303us/step - loss: 2.9858 - mse: 2.9858 - mae: 1.2814 - val_loss: 0.8896 - val_mse: 0.8896 - val_mae: 0.8370\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 344us/step - loss: 2.9685 - mse: 2.9685 - mae: 1.2798 - val_loss: 0.8860 - val_mse: 0.8860 - val_mae: 0.8391\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 295us/step - loss: 2.9511 - mse: 2.9511 - mae: 1.2783 - val_loss: 0.8822 - val_mse: 0.8822 - val_mae: 0.8409\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 518us/step - loss: 2.9349 - mse: 2.9349 - mae: 1.2767 - val_loss: 0.8787 - val_mse: 0.8787 - val_mae: 0.8421\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 453us/step - loss: 2.9193 - mse: 2.9193 - mae: 1.2748 - val_loss: 0.8762 - val_mse: 0.8762 - val_mae: 0.8428\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 510us/step - loss: 2.9050 - mse: 2.9050 - mae: 1.2728 - val_loss: 0.8745 - val_mse: 0.8745 - val_mae: 0.8431\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 332us/step - loss: 2.8914 - mse: 2.8914 - mae: 1.2702 - val_loss: 0.8735 - val_mse: 0.8735 - val_mae: 0.8431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 304us/step - loss: 2.8776 - mse: 2.8776 - mae: 1.2672 - val_loss: 0.8730 - val_mse: 0.8730 - val_mae: 0.8430\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 546us/step - loss: 2.8642 - mse: 2.8642 - mae: 1.2640 - val_loss: 0.8730 - val_mse: 0.8730 - val_mae: 0.8430\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 589us/step - loss: 2.8513 - mse: 2.8513 - mae: 1.2610 - val_loss: 0.8729 - val_mse: 0.8729 - val_mae: 0.8433\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 320us/step - loss: 2.8388 - mse: 2.8388 - mae: 1.2587 - val_loss: 0.8726 - val_mse: 0.8726 - val_mae: 0.8439\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 313us/step - loss: 2.8267 - mse: 2.8267 - mae: 1.2570 - val_loss: 0.8728 - val_mse: 0.8728 - val_mae: 0.8448\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 295us/step - loss: 2.8145 - mse: 2.8145 - mae: 1.2553 - val_loss: 0.8732 - val_mse: 0.8732 - val_mae: 0.8461\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 488us/step - loss: 2.8027 - mse: 2.8027 - mae: 1.2539 - val_loss: 0.8737 - val_mse: 0.8737 - val_mae: 0.8474\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 266us/step - loss: 2.7912 - mse: 2.7912 - mae: 1.2526 - val_loss: 0.8743 - val_mse: 0.8743 - val_mae: 0.8487\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 365us/step - loss: 2.7798 - mse: 2.7798 - mae: 1.2514 - val_loss: 0.8751 - val_mse: 0.8751 - val_mae: 0.8500\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 265us/step - loss: 2.7686 - mse: 2.7686 - mae: 1.2500 - val_loss: 0.8755 - val_mse: 0.8755 - val_mae: 0.8510\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 520us/step - loss: 2.7575 - mse: 2.7575 - mae: 1.2485 - val_loss: 0.8758 - val_mse: 0.8758 - val_mae: 0.8517\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 377us/step - loss: 2.7465 - mse: 2.7465 - mae: 1.2469 - val_loss: 0.8760 - val_mse: 0.8760 - val_mae: 0.8524\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 275us/step - loss: 2.7357 - mse: 2.7357 - mae: 1.2452 - val_loss: 0.8764 - val_mse: 0.8764 - val_mae: 0.8530\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 412us/step - loss: 2.7252 - mse: 2.7252 - mae: 1.2434 - val_loss: 0.8771 - val_mse: 0.8771 - val_mae: 0.8535\n",
      "73\n",
      "[73]\n",
      "Train on 71 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 1s 18ms/step - loss: 4.9395 - mse: 4.9395 - mae: 1.7778 - val_loss: 5.3424 - val_mse: 5.3424 - val_mae: 1.7119\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 477us/step - loss: 4.0227 - mse: 4.0227 - mae: 1.5252 - val_loss: 4.5791 - val_mse: 4.5791 - val_mae: 1.5096\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 379us/step - loss: 3.3011 - mse: 3.3011 - mae: 1.3085 - val_loss: 3.9689 - val_mse: 3.9689 - val_mae: 1.3518\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 497us/step - loss: 2.7315 - mse: 2.7315 - mae: 1.1714 - val_loss: 3.5296 - val_mse: 3.5296 - val_mae: 1.2540\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 367us/step - loss: 2.3229 - mse: 2.3229 - mae: 1.0782 - val_loss: 3.2587 - val_mse: 3.2587 - val_mae: 1.2381\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 522us/step - loss: 2.0638 - mse: 2.0638 - mae: 1.0427 - val_loss: 3.1267 - val_mse: 3.1267 - val_mae: 1.2757\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 596us/step - loss: 1.9325 - mse: 1.9325 - mae: 1.0567 - val_loss: 3.0886 - val_mse: 3.0886 - val_mae: 1.3098\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 362us/step - loss: 1.8978 - mse: 1.8978 - mae: 1.0941 - val_loss: 3.1116 - val_mse: 3.1116 - val_mae: 1.3357\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 688us/step - loss: 1.9150 - mse: 1.9150 - mae: 1.1235 - val_loss: 3.1518 - val_mse: 3.1518 - val_mae: 1.3520\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 550us/step - loss: 1.9474 - mse: 1.9474 - mae: 1.1480 - val_loss: 3.1785 - val_mse: 3.1785 - val_mae: 1.3623\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 255us/step - loss: 1.9702 - mse: 1.9702 - mae: 1.1648 - val_loss: 3.1729 - val_mse: 3.1729 - val_mae: 1.3695\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 404us/step - loss: 1.9703 - mse: 1.9703 - mae: 1.1674 - val_loss: 3.1365 - val_mse: 3.1365 - val_mae: 1.3591\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 423us/step - loss: 1.9482 - mse: 1.9482 - mae: 1.1582 - val_loss: 3.0764 - val_mse: 3.0764 - val_mae: 1.3373\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 510us/step - loss: 1.9107 - mse: 1.9107 - mae: 1.1400 - val_loss: 2.9957 - val_mse: 2.9957 - val_mae: 1.3121\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 390us/step - loss: 1.8703 - mse: 1.8703 - mae: 1.1173 - val_loss: 2.9224 - val_mse: 2.9224 - val_mae: 1.2916\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 351us/step - loss: 1.8335 - mse: 1.8335 - mae: 1.0932 - val_loss: 2.8592 - val_mse: 2.8592 - val_mae: 1.2716\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 423us/step - loss: 1.8022 - mse: 1.8022 - mae: 1.0706 - val_loss: 2.8074 - val_mse: 2.8074 - val_mae: 1.2539\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 365us/step - loss: 1.7764 - mse: 1.7764 - mae: 1.0510 - val_loss: 2.7659 - val_mse: 2.7659 - val_mae: 1.2395\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 367us/step - loss: 1.7563 - mse: 1.7563 - mae: 1.0340 - val_loss: 2.7347 - val_mse: 2.7347 - val_mae: 1.2284\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 446us/step - loss: 1.7415 - mse: 1.7415 - mae: 1.0220 - val_loss: 2.7108 - val_mse: 2.7108 - val_mae: 1.2212\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 492us/step - loss: 1.7292 - mse: 1.7292 - mae: 1.0157 - val_loss: 2.6922 - val_mse: 2.6922 - val_mae: 1.2165\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 372us/step - loss: 1.7182 - mse: 1.7182 - mae: 1.0117 - val_loss: 2.6771 - val_mse: 2.6771 - val_mae: 1.2134\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 482us/step - loss: 1.7077 - mse: 1.7077 - mae: 1.0094 - val_loss: 2.6652 - val_mse: 2.6652 - val_mae: 1.2116\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 409us/step - loss: 1.6983 - mse: 1.6983 - mae: 1.0082 - val_loss: 2.6553 - val_mse: 2.6553 - val_mae: 1.2102\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 482us/step - loss: 1.6900 - mse: 1.6900 - mae: 1.0088 - val_loss: 2.6465 - val_mse: 2.6465 - val_mae: 1.2084\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 314us/step - loss: 1.6825 - mse: 1.6825 - mae: 1.0091 - val_loss: 2.6379 - val_mse: 2.6379 - val_mae: 1.2061\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 407us/step - loss: 1.6753 - mse: 1.6753 - mae: 1.0085 - val_loss: 2.6279 - val_mse: 2.6279 - val_mae: 1.2031\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 379us/step - loss: 1.6680 - mse: 1.6680 - mae: 1.0070 - val_loss: 2.6145 - val_mse: 2.6145 - val_mae: 1.1987\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 426us/step - loss: 1.6599 - mse: 1.6599 - mae: 1.0034 - val_loss: 2.5966 - val_mse: 2.5966 - val_mae: 1.1928\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 460us/step - loss: 1.6513 - mse: 1.6513 - mae: 0.9988 - val_loss: 2.5792 - val_mse: 2.5792 - val_mae: 1.1871\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 482us/step - loss: 1.6427 - mse: 1.6427 - mae: 0.9939 - val_loss: 2.5630 - val_mse: 2.5630 - val_mae: 1.1812\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 389us/step - loss: 1.6344 - mse: 1.6344 - mae: 0.9892 - val_loss: 2.5467 - val_mse: 2.5467 - val_mae: 1.1751\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 1.6260 - mse: 1.6260 - mae: 0.9838 - val_loss: 2.5302 - val_mse: 2.5302 - val_mae: 1.1691\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 361us/step - loss: 1.6181 - mse: 1.6181 - mae: 0.9795 - val_loss: 2.5164 - val_mse: 2.5164 - val_mae: 1.1636\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 469us/step - loss: 1.6107 - mse: 1.6107 - mae: 0.9761 - val_loss: 2.5033 - val_mse: 2.5033 - val_mae: 1.1584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 466us/step - loss: 1.6036 - mse: 1.6036 - mae: 0.9727 - val_loss: 2.4882 - val_mse: 2.4882 - val_mae: 1.1532\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 467us/step - loss: 1.5971 - mse: 1.5971 - mae: 0.9694 - val_loss: 2.4720 - val_mse: 2.4720 - val_mae: 1.1475\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 465us/step - loss: 1.5910 - mse: 1.5910 - mae: 0.9667 - val_loss: 2.4595 - val_mse: 2.4595 - val_mae: 1.1427\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 451us/step - loss: 1.5853 - mse: 1.5853 - mae: 0.9646 - val_loss: 2.4478 - val_mse: 2.4478 - val_mae: 1.1383\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 393us/step - loss: 1.5797 - mse: 1.5797 - mae: 0.9626 - val_loss: 2.4325 - val_mse: 2.4325 - val_mae: 1.1331\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 773us/step - loss: 1.5745 - mse: 1.5745 - mae: 0.9604 - val_loss: 2.4174 - val_mse: 2.4174 - val_mae: 1.1280\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 421us/step - loss: 1.5697 - mse: 1.5697 - mae: 0.9584 - val_loss: 2.4046 - val_mse: 2.4046 - val_mae: 1.1233\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 440us/step - loss: 1.5643 - mse: 1.5643 - mae: 0.9564 - val_loss: 2.3903 - val_mse: 2.3903 - val_mae: 1.1180\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 550us/step - loss: 1.5591 - mse: 1.5591 - mae: 0.9542 - val_loss: 2.3776 - val_mse: 2.3776 - val_mae: 1.1131\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 550us/step - loss: 1.5531 - mse: 1.5531 - mae: 0.9518 - val_loss: 2.3699 - val_mse: 2.3699 - val_mae: 1.1094\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 340us/step - loss: 1.5480 - mse: 1.5480 - mae: 0.9501 - val_loss: 2.3636 - val_mse: 2.3636 - val_mae: 1.1057\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 509us/step - loss: 1.5424 - mse: 1.5424 - mae: 0.9483 - val_loss: 2.3544 - val_mse: 2.3544 - val_mae: 1.1012\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 669us/step - loss: 1.5367 - mse: 1.5367 - mae: 0.9458 - val_loss: 2.3435 - val_mse: 2.3435 - val_mae: 1.0960\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 510us/step - loss: 1.5312 - mse: 1.5312 - mae: 0.9432 - val_loss: 2.3333 - val_mse: 2.3333 - val_mae: 1.0900\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 333us/step - loss: 1.5262 - mse: 1.5262 - mae: 0.9408 - val_loss: 2.3283 - val_mse: 2.3283 - val_mae: 1.0850\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 709us/step - loss: 1.5210 - mse: 1.5210 - mae: 0.9386 - val_loss: 2.3247 - val_mse: 2.3247 - val_mae: 1.0805\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 437us/step - loss: 1.5162 - mse: 1.5162 - mae: 0.9367 - val_loss: 2.3222 - val_mse: 2.3222 - val_mae: 1.0766\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 368us/step - loss: 1.5113 - mse: 1.5113 - mae: 0.9351 - val_loss: 2.3190 - val_mse: 2.3190 - val_mae: 1.0723\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 467us/step - loss: 1.5070 - mse: 1.5070 - mae: 0.9332 - val_loss: 2.3164 - val_mse: 2.3164 - val_mae: 1.0685\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 393us/step - loss: 1.5027 - mse: 1.5027 - mae: 0.9307 - val_loss: 2.3150 - val_mse: 2.3150 - val_mae: 1.0665\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 365us/step - loss: 1.4983 - mse: 1.4983 - mae: 0.9283 - val_loss: 2.3155 - val_mse: 2.3155 - val_mae: 1.0672\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 365us/step - loss: 1.4941 - mse: 1.4941 - mae: 0.9268 - val_loss: 2.3163 - val_mse: 2.3163 - val_mae: 1.0678\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 787us/step - loss: 1.4900 - mse: 1.4900 - mae: 0.9256 - val_loss: 2.3161 - val_mse: 2.3161 - val_mae: 1.0687\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 379us/step - loss: 1.4858 - mse: 1.4858 - mae: 0.9241 - val_loss: 2.3156 - val_mse: 2.3156 - val_mae: 1.0698\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 386us/step - loss: 1.4816 - mse: 1.4816 - mae: 0.9221 - val_loss: 2.3150 - val_mse: 2.3150 - val_mae: 1.0707\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 405us/step - loss: 1.4773 - mse: 1.4773 - mae: 0.9197 - val_loss: 2.3161 - val_mse: 2.3161 - val_mae: 1.0717\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 365us/step - loss: 1.4734 - mse: 1.4734 - mae: 0.9177 - val_loss: 2.3183 - val_mse: 2.3183 - val_mae: 1.0724\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 663us/step - loss: 1.4692 - mse: 1.4692 - mae: 0.9161 - val_loss: 2.3195 - val_mse: 2.3195 - val_mae: 1.0734\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 602us/step - loss: 1.4650 - mse: 1.4650 - mae: 0.9142 - val_loss: 2.3210 - val_mse: 2.3210 - val_mae: 1.0747\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 604us/step - loss: 1.4613 - mse: 1.4613 - mae: 0.9123 - val_loss: 2.3241 - val_mse: 2.3241 - val_mae: 1.0751\n",
      "74\n",
      "[74]\n",
      "Train on 70 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 29.9576 - mse: 29.9576 - mae: 5.2815 - val_loss: 30.1820 - val_mse: 30.1820 - val_mae: 5.2493\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 363us/step - loss: 27.0075 - mse: 27.0075 - mae: 5.0054 - val_loss: 27.8294 - val_mse: 27.8294 - val_mae: 5.0277\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 329us/step - loss: 24.4812 - mse: 24.4812 - mae: 4.7558 - val_loss: 25.7605 - val_mse: 25.7605 - val_mae: 4.8246\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 500us/step - loss: 22.2651 - mse: 22.2651 - mae: 4.5246 - val_loss: 23.9656 - val_mse: 23.9656 - val_mae: 4.6482\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 469us/step - loss: 20.3243 - mse: 20.3243 - mae: 4.3114 - val_loss: 22.3058 - val_mse: 22.3058 - val_mae: 4.4789\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 560us/step - loss: 18.6035 - mse: 18.6035 - mae: 4.1113 - val_loss: 20.7591 - val_mse: 20.7591 - val_mae: 4.3177\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 17.0636 - mse: 17.0636 - mae: 3.9220 - val_loss: 19.3656 - val_mse: 19.3656 - val_mae: 4.1663\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 529us/step - loss: 15.6532 - mse: 15.6532 - mae: 3.7392 - val_loss: 18.0959 - val_mse: 18.0959 - val_mae: 4.0232\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 597us/step - loss: 14.3707 - mse: 14.3707 - mae: 3.5658 - val_loss: 16.8812 - val_mse: 16.8812 - val_mae: 3.8814\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 374us/step - loss: 13.2151 - mse: 13.2151 - mae: 3.4012 - val_loss: 15.7731 - val_mse: 15.7731 - val_mae: 3.7446\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 659us/step - loss: 12.1562 - mse: 12.1562 - mae: 3.2417 - val_loss: 14.7300 - val_mse: 14.7300 - val_mae: 3.6105\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 472us/step - loss: 11.1788 - mse: 11.1788 - mae: 3.0868 - val_loss: 13.7763 - val_mse: 13.7763 - val_mae: 3.4829\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 427us/step - loss: 10.3132 - mse: 10.3132 - mae: 2.9419 - val_loss: 12.8842 - val_mse: 12.8842 - val_mae: 3.3604\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 401us/step - loss: 9.5261 - mse: 9.5261 - mae: 2.8054 - val_loss: 12.0743 - val_mse: 12.0743 - val_mae: 3.2446\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 628us/step - loss: 8.8238 - mse: 8.8238 - mae: 2.6809 - val_loss: 11.3611 - val_mse: 11.3611 - val_mae: 3.1385\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 545us/step - loss: 8.1899 - mse: 8.1899 - mae: 2.5635 - val_loss: 10.7348 - val_mse: 10.7348 - val_mae: 3.0426\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 482us/step - loss: 7.6615 - mse: 7.6615 - mae: 2.4627 - val_loss: 10.1819 - val_mse: 10.1819 - val_mae: 2.9559\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 630us/step - loss: 7.2494 - mse: 7.2494 - mae: 2.3797 - val_loss: 9.6695 - val_mse: 9.6695 - val_mae: 2.8722\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 546us/step - loss: 6.8954 - mse: 6.8954 - mae: 2.3053 - val_loss: 9.2230 - val_mse: 9.2230 - val_mae: 2.7944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 400us/step - loss: 6.5961 - mse: 6.5961 - mae: 2.2406 - val_loss: 8.8687 - val_mse: 8.8687 - val_mae: 2.7282\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 603us/step - loss: 6.3514 - mse: 6.3514 - mae: 2.1872 - val_loss: 8.5596 - val_mse: 8.5596 - val_mae: 2.6708\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 513us/step - loss: 6.1477 - mse: 6.1477 - mae: 2.1424 - val_loss: 8.3634 - val_mse: 8.3634 - val_mae: 2.6349\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 489us/step - loss: 5.9759 - mse: 5.9759 - mae: 2.1038 - val_loss: 8.1951 - val_mse: 8.1951 - val_mae: 2.6034\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 455us/step - loss: 5.8209 - mse: 5.8209 - mae: 2.0676 - val_loss: 8.0347 - val_mse: 8.0347 - val_mae: 2.5713\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 930us/step - loss: 5.6695 - mse: 5.6695 - mae: 2.0313 - val_loss: 7.8832 - val_mse: 7.8832 - val_mae: 2.5398\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 458us/step - loss: 5.5226 - mse: 5.5226 - mae: 1.9946 - val_loss: 7.7284 - val_mse: 7.7284 - val_mae: 2.5068\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 276us/step - loss: 5.3657 - mse: 5.3657 - mae: 1.9543 - val_loss: 7.5602 - val_mse: 7.5602 - val_mae: 2.4707\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 588us/step - loss: 5.1980 - mse: 5.1980 - mae: 1.9102 - val_loss: 7.3640 - val_mse: 7.3640 - val_mae: 2.4301\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 655us/step - loss: 5.0183 - mse: 5.0183 - mae: 1.8616 - val_loss: 7.1430 - val_mse: 7.1430 - val_mae: 2.3853\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 458us/step - loss: 4.8308 - mse: 4.8308 - mae: 1.8095 - val_loss: 6.9084 - val_mse: 6.9084 - val_mae: 2.3376\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 859us/step - loss: 4.6432 - mse: 4.6432 - mae: 1.7554 - val_loss: 6.6666 - val_mse: 6.6666 - val_mae: 2.2874\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 469us/step - loss: 4.4540 - mse: 4.4540 - mae: 1.6988 - val_loss: 6.4276 - val_mse: 6.4276 - val_mae: 2.2366\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 387us/step - loss: 4.2649 - mse: 4.2649 - mae: 1.6400 - val_loss: 6.1898 - val_mse: 6.1898 - val_mae: 2.1851\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 427us/step - loss: 4.0745 - mse: 4.0745 - mae: 1.5795 - val_loss: 5.9514 - val_mse: 5.9514 - val_mae: 2.1324\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 0s 354us/step - loss: 3.8843 - mse: 3.8843 - mae: 1.5192 - val_loss: 5.7133 - val_mse: 5.7133 - val_mae: 2.0786\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 0s 671us/step - loss: 3.6960 - mse: 3.6960 - mae: 1.4588 - val_loss: 5.4752 - val_mse: 5.4752 - val_mae: 2.0235\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 3.5125 - mse: 3.5125 - mae: 1.4025 - val_loss: 5.2415 - val_mse: 5.2415 - val_mae: 1.9677\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 0s 866us/step - loss: 3.3346 - mse: 3.3346 - mae: 1.3467 - val_loss: 5.0164 - val_mse: 5.0164 - val_mae: 1.9119\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 0s 332us/step - loss: 3.1644 - mse: 3.1644 - mae: 1.2918 - val_loss: 4.7941 - val_mse: 4.7941 - val_mae: 1.8554\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 0s 537us/step - loss: 3.0034 - mse: 3.0034 - mae: 1.2399 - val_loss: 4.5763 - val_mse: 4.5763 - val_mae: 1.7985\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 0s 385us/step - loss: 2.8527 - mse: 2.8527 - mae: 1.1941 - val_loss: 4.3651 - val_mse: 4.3651 - val_mae: 1.7414\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 0s 474us/step - loss: 2.7129 - mse: 2.7129 - mae: 1.1599 - val_loss: 4.1610 - val_mse: 4.1610 - val_mae: 1.6838\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 0s 464us/step - loss: 2.5845 - mse: 2.5845 - mae: 1.1352 - val_loss: 3.9657 - val_mse: 3.9657 - val_mae: 1.6269\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 0s 485us/step - loss: 2.4677 - mse: 2.4677 - mae: 1.1152 - val_loss: 3.7800 - val_mse: 3.7800 - val_mae: 1.5768\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 0s 614us/step - loss: 2.3625 - mse: 2.3625 - mae: 1.0956 - val_loss: 3.6049 - val_mse: 3.6049 - val_mae: 1.5314\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 0s 403us/step - loss: 2.2688 - mse: 2.2688 - mae: 1.0804 - val_loss: 3.4404 - val_mse: 3.4404 - val_mae: 1.5052\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 0s 415us/step - loss: 2.1867 - mse: 2.1867 - mae: 1.0723 - val_loss: 3.2878 - val_mse: 3.2878 - val_mae: 1.4838\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 0s 442us/step - loss: 2.1166 - mse: 2.1166 - mae: 1.0669 - val_loss: 3.1477 - val_mse: 3.1477 - val_mae: 1.4639\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 0s 425us/step - loss: 2.0574 - mse: 2.0574 - mae: 1.0617 - val_loss: 3.0202 - val_mse: 3.0202 - val_mae: 1.4450\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 0s 445us/step - loss: 2.0086 - mse: 2.0086 - mae: 1.0569 - val_loss: 2.9056 - val_mse: 2.9056 - val_mae: 1.4274\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 0s 359us/step - loss: 1.9690 - mse: 1.9690 - mae: 1.0534 - val_loss: 2.8035 - val_mse: 2.8035 - val_mae: 1.4111\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 0s 515us/step - loss: 1.9374 - mse: 1.9374 - mae: 1.0506 - val_loss: 2.7139 - val_mse: 2.7139 - val_mae: 1.3963\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 0s 404us/step - loss: 1.9126 - mse: 1.9126 - mae: 1.0499 - val_loss: 2.6359 - val_mse: 2.6359 - val_mae: 1.3830\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 0s 485us/step - loss: 1.8931 - mse: 1.8931 - mae: 1.0521 - val_loss: 2.5689 - val_mse: 2.5689 - val_mae: 1.3713\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 0s 820us/step - loss: 1.8780 - mse: 1.8780 - mae: 1.0549 - val_loss: 2.5119 - val_mse: 2.5119 - val_mae: 1.3610\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 0s 340us/step - loss: 1.8663 - mse: 1.8663 - mae: 1.0572 - val_loss: 2.4642 - val_mse: 2.4642 - val_mae: 1.3521\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 0s 598us/step - loss: 1.8571 - mse: 1.8571 - mae: 1.0589 - val_loss: 2.4247 - val_mse: 2.4247 - val_mae: 1.3446\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 1.8498 - mse: 1.8498 - mae: 1.0601 - val_loss: 2.3926 - val_mse: 2.3926 - val_mae: 1.3384\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 0s 415us/step - loss: 1.8439 - mse: 1.8439 - mae: 1.0608 - val_loss: 2.3673 - val_mse: 2.3673 - val_mae: 1.3334\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 0s 487us/step - loss: 1.8390 - mse: 1.8390 - mae: 1.0612 - val_loss: 2.3476 - val_mse: 2.3476 - val_mae: 1.3294\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 0s 715us/step - loss: 1.8347 - mse: 1.8347 - mae: 1.0613 - val_loss: 2.3326 - val_mse: 2.3326 - val_mae: 1.3263\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 0s 480us/step - loss: 1.8308 - mse: 1.8308 - mae: 1.0611 - val_loss: 2.3216 - val_mse: 2.3216 - val_mae: 1.3239\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 1.8273 - mse: 1.8273 - mae: 1.0606 - val_loss: 2.3137 - val_mse: 2.3137 - val_mae: 1.3222\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 0s 212us/step - loss: 1.8241 - mse: 1.8241 - mae: 1.0600 - val_loss: 2.3083 - val_mse: 2.3083 - val_mae: 1.3209\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 0s 429us/step - loss: 1.8210 - mse: 1.8210 - mae: 1.0592 - val_loss: 2.3049 - val_mse: 2.3049 - val_mae: 1.3200\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 0s 413us/step - loss: 1.8185 - mse: 1.8185 - mae: 1.0585 - val_loss: 2.3032 - val_mse: 2.3032 - val_mae: 1.3195\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 0s 492us/step - loss: 1.8162 - mse: 1.8162 - mae: 1.0577 - val_loss: 2.3026 - val_mse: 2.3026 - val_mae: 1.3193\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 0s 443us/step - loss: 1.8140 - mse: 1.8140 - mae: 1.0569 - val_loss: 2.3028 - val_mse: 2.3028 - val_mae: 1.3193\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 0s 429us/step - loss: 1.8119 - mse: 1.8119 - mae: 1.0560 - val_loss: 2.3035 - val_mse: 2.3035 - val_mae: 1.3194\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 0s 383us/step - loss: 1.8098 - mse: 1.8098 - mae: 1.0551 - val_loss: 2.3042 - val_mse: 2.3042 - val_mae: 1.3195\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 0s 429us/step - loss: 1.8078 - mse: 1.8078 - mae: 1.0542 - val_loss: 2.3049 - val_mse: 2.3049 - val_mae: 1.3196\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 0s 816us/step - loss: 1.8058 - mse: 1.8058 - mae: 1.0533 - val_loss: 2.3054 - val_mse: 2.3054 - val_mae: 1.3197\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 0s 373us/step - loss: 1.8038 - mse: 1.8038 - mae: 1.0525 - val_loss: 2.3056 - val_mse: 2.3056 - val_mae: 1.3198\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 0s 356us/step - loss: 1.8019 - mse: 1.8019 - mae: 1.0517 - val_loss: 2.3055 - val_mse: 2.3055 - val_mae: 1.3198\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 0s 515us/step - loss: 1.7999 - mse: 1.7999 - mae: 1.0510 - val_loss: 2.3049 - val_mse: 2.3049 - val_mae: 1.3198\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 0s 561us/step - loss: 1.7979 - mse: 1.7979 - mae: 1.0503 - val_loss: 2.3039 - val_mse: 2.3039 - val_mae: 1.3196\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 0s 358us/step - loss: 1.7959 - mse: 1.7959 - mae: 1.0496 - val_loss: 2.3026 - val_mse: 2.3026 - val_mae: 1.3194\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 0s 354us/step - loss: 1.7938 - mse: 1.7938 - mae: 1.0490 - val_loss: 2.3009 - val_mse: 2.3009 - val_mae: 1.3191\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 0s 484us/step - loss: 1.7918 - mse: 1.7918 - mae: 1.0484 - val_loss: 2.2990 - val_mse: 2.2990 - val_mae: 1.3189\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 0s 598us/step - loss: 1.7898 - mse: 1.7898 - mae: 1.0478 - val_loss: 2.2969 - val_mse: 2.2969 - val_mae: 1.3185\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 0s 480us/step - loss: 1.7876 - mse: 1.7876 - mae: 1.0472 - val_loss: 2.2947 - val_mse: 2.2947 - val_mae: 1.3182\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 0s 432us/step - loss: 1.7854 - mse: 1.7854 - mae: 1.0465 - val_loss: 2.2924 - val_mse: 2.2924 - val_mae: 1.3178\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 0s 357us/step - loss: 1.7831 - mse: 1.7831 - mae: 1.0458 - val_loss: 2.2899 - val_mse: 2.2899 - val_mae: 1.3174\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 0s 470us/step - loss: 1.7807 - mse: 1.7807 - mae: 1.0451 - val_loss: 2.2875 - val_mse: 2.2875 - val_mae: 1.3172\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 0s 344us/step - loss: 1.7784 - mse: 1.7784 - mae: 1.0444 - val_loss: 2.2850 - val_mse: 2.2850 - val_mae: 1.3169\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.3795 - mse: 1.3795 - mae: 0.933 - 0s 738us/step - loss: 1.7760 - mse: 1.7760 - mae: 1.0437 - val_loss: 2.2821 - val_mse: 2.2821 - val_mae: 1.3165\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 0s 399us/step - loss: 1.7737 - mse: 1.7737 - mae: 1.0431 - val_loss: 2.2788 - val_mse: 2.2788 - val_mae: 1.3159\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 0s 725us/step - loss: 1.7713 - mse: 1.7713 - mae: 1.0425 - val_loss: 2.2751 - val_mse: 2.2751 - val_mae: 1.3152\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 0s 742us/step - loss: 1.7688 - mse: 1.7688 - mae: 1.0419 - val_loss: 2.2714 - val_mse: 2.2714 - val_mae: 1.3145\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 0s 790us/step - loss: 1.7664 - mse: 1.7664 - mae: 1.0413 - val_loss: 2.2679 - val_mse: 2.2679 - val_mae: 1.3138\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 0s 344us/step - loss: 1.7639 - mse: 1.7639 - mae: 1.0407 - val_loss: 2.2646 - val_mse: 2.2646 - val_mae: 1.3131\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 0s 652us/step - loss: 1.7615 - mse: 1.7615 - mae: 1.0400 - val_loss: 2.2612 - val_mse: 2.2612 - val_mae: 1.3125\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 0s 618us/step - loss: 1.7590 - mse: 1.7590 - mae: 1.0394 - val_loss: 2.2577 - val_mse: 2.2577 - val_mae: 1.3118\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 0s 661us/step - loss: 1.7566 - mse: 1.7566 - mae: 1.0387 - val_loss: 2.2543 - val_mse: 2.2543 - val_mae: 1.3112\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 0s 468us/step - loss: 1.7541 - mse: 1.7541 - mae: 1.0380 - val_loss: 2.2513 - val_mse: 2.2513 - val_mae: 1.3106\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 0s 556us/step - loss: 1.7517 - mse: 1.7517 - mae: 1.0373 - val_loss: 2.2484 - val_mse: 2.2484 - val_mae: 1.3101\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 0s 711us/step - loss: 1.7492 - mse: 1.7492 - mae: 1.0365 - val_loss: 2.2456 - val_mse: 2.2456 - val_mae: 1.3096\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 0s 338us/step - loss: 1.7468 - mse: 1.7468 - mae: 1.0358 - val_loss: 2.2428 - val_mse: 2.2428 - val_mae: 1.3091\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 0s 460us/step - loss: 1.7443 - mse: 1.7443 - mae: 1.0350 - val_loss: 2.2397 - val_mse: 2.2397 - val_mae: 1.3085\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 0s 443us/step - loss: 1.7418 - mse: 1.7418 - mae: 1.0343 - val_loss: 2.2368 - val_mse: 2.2368 - val_mae: 1.3080\n",
      "75\n",
      "[75]\n",
      "Train on 94 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 5.8915 - mse: 5.8915 - mae: 1.9621 - val_loss: 2.9333 - val_mse: 2.9333 - val_mae: 1.4720\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 371us/step - loss: 4.7510 - mse: 4.7510 - mae: 1.6816 - val_loss: 2.1643 - val_mse: 2.1643 - val_mae: 1.1971\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 373us/step - loss: 3.9014 - mse: 3.9014 - mae: 1.4578 - val_loss: 1.5977 - val_mse: 1.5977 - val_mae: 0.9616\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 491us/step - loss: 3.2874 - mse: 3.2874 - mae: 1.3150 - val_loss: 1.1996 - val_mse: 1.1996 - val_mae: 0.7665\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 746us/step - loss: 2.9014 - mse: 2.9014 - mae: 1.2221 - val_loss: 0.9456 - val_mse: 0.9456 - val_mae: 0.7412\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 290us/step - loss: 2.7185 - mse: 2.7185 - mae: 1.1691 - val_loss: 0.8084 - val_mse: 0.8084 - val_mae: 0.7444\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 681us/step - loss: 2.6874 - mse: 2.6874 - mae: 1.1756 - val_loss: 0.7615 - val_mse: 0.7615 - val_mae: 0.7494\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 273us/step - loss: 2.7255 - mse: 2.7255 - mae: 1.1959 - val_loss: 0.7541 - val_mse: 0.7541 - val_mae: 0.7505\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 757us/step - loss: 2.7512 - mse: 2.7512 - mae: 1.2115 - val_loss: 0.7533 - val_mse: 0.7533 - val_mae: 0.7504\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 376us/step - loss: 2.7299 - mse: 2.7299 - mae: 1.2087 - val_loss: 0.7493 - val_mse: 0.7493 - val_mae: 0.7491\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 348us/step - loss: 2.6714 - mse: 2.6714 - mae: 1.1920 - val_loss: 0.7471 - val_mse: 0.7471 - val_mae: 0.7473\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 343us/step - loss: 2.6025 - mse: 2.6025 - mae: 1.1687 - val_loss: 0.7503 - val_mse: 0.7503 - val_mae: 0.7451\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 566us/step - loss: 2.5430 - mse: 2.5430 - mae: 1.1455 - val_loss: 0.7576 - val_mse: 0.7576 - val_mae: 0.7429\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 415us/step - loss: 2.4989 - mse: 2.4989 - mae: 1.1277 - val_loss: 0.7644 - val_mse: 0.7644 - val_mae: 0.7407\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 419us/step - loss: 2.4650 - mse: 2.4650 - mae: 1.1146 - val_loss: 0.7686 - val_mse: 0.7686 - val_mae: 0.7402\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 489us/step - loss: 2.4365 - mse: 2.4365 - mae: 1.1042 - val_loss: 0.7686 - val_mse: 0.7686 - val_mae: 0.7404\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 523us/step - loss: 2.4148 - mse: 2.4148 - mae: 1.0969 - val_loss: 0.7646 - val_mse: 0.7646 - val_mae: 0.7402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 528us/step - loss: 2.3953 - mse: 2.3953 - mae: 1.0913 - val_loss: 0.7593 - val_mse: 0.7593 - val_mae: 0.7397\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 426us/step - loss: 2.3769 - mse: 2.3769 - mae: 1.0868 - val_loss: 0.7538 - val_mse: 0.7538 - val_mae: 0.7388\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 424us/step - loss: 2.3595 - mse: 2.3595 - mae: 1.0826 - val_loss: 0.7487 - val_mse: 0.7487 - val_mae: 0.7378\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 337us/step - loss: 2.3431 - mse: 2.3431 - mae: 1.0785 - val_loss: 0.7444 - val_mse: 0.7444 - val_mae: 0.7367\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 406us/step - loss: 2.3267 - mse: 2.3267 - mae: 1.0744 - val_loss: 0.7413 - val_mse: 0.7413 - val_mae: 0.7351\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 330us/step - loss: 2.3102 - mse: 2.3102 - mae: 1.0698 - val_loss: 0.7401 - val_mse: 0.7401 - val_mae: 0.7334\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 617us/step - loss: 2.2942 - mse: 2.2942 - mae: 1.0647 - val_loss: 0.7398 - val_mse: 0.7398 - val_mae: 0.7314\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 365us/step - loss: 2.2784 - mse: 2.2784 - mae: 1.0594 - val_loss: 0.7403 - val_mse: 0.7403 - val_mae: 0.7295\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 364us/step - loss: 2.2623 - mse: 2.2623 - mae: 1.0537 - val_loss: 0.7405 - val_mse: 0.7405 - val_mae: 0.7276\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 361us/step - loss: 2.2476 - mse: 2.2476 - mae: 1.0488 - val_loss: 0.7403 - val_mse: 0.7403 - val_mae: 0.7259\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 309us/step - loss: 2.2333 - mse: 2.2333 - mae: 1.0443 - val_loss: 0.7394 - val_mse: 0.7394 - val_mae: 0.7238\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 440us/step - loss: 2.2194 - mse: 2.2194 - mae: 1.0400 - val_loss: 0.7388 - val_mse: 0.7388 - val_mae: 0.7224\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 499us/step - loss: 2.2069 - mse: 2.2069 - mae: 1.0363 - val_loss: 0.7390 - val_mse: 0.7390 - val_mae: 0.7214\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 518us/step - loss: 2.1941 - mse: 2.1941 - mae: 1.0324 - val_loss: 0.7395 - val_mse: 0.7395 - val_mae: 0.7198\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 542us/step - loss: 2.1819 - mse: 2.1819 - mae: 1.0286 - val_loss: 0.7409 - val_mse: 0.7409 - val_mae: 0.7181\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 350us/step - loss: 2.1702 - mse: 2.1702 - mae: 1.0249 - val_loss: 0.7421 - val_mse: 0.7421 - val_mae: 0.7171\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 424us/step - loss: 2.1587 - mse: 2.1587 - mae: 1.0214 - val_loss: 0.7435 - val_mse: 0.7435 - val_mae: 0.7164\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 393us/step - loss: 2.1470 - mse: 2.1470 - mae: 1.0179 - val_loss: 0.7447 - val_mse: 0.7447 - val_mae: 0.7158\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 765us/step - loss: 2.1358 - mse: 2.1358 - mae: 1.0144 - val_loss: 0.7450 - val_mse: 0.7450 - val_mae: 0.7150\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 334us/step - loss: 2.1244 - mse: 2.1244 - mae: 1.0108 - val_loss: 0.7456 - val_mse: 0.7456 - val_mae: 0.7146\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 404us/step - loss: 2.1136 - mse: 2.1136 - mae: 1.0076 - val_loss: 0.7465 - val_mse: 0.7465 - val_mae: 0.7142\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 312us/step - loss: 2.1033 - mse: 2.1033 - mae: 1.0045 - val_loss: 0.7472 - val_mse: 0.7472 - val_mae: 0.7137\n",
      "76\n",
      "[76]\n",
      "Train on 105 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 10.5032 - mse: 10.5032 - mae: 2.9179 - val_loss: 10.1077 - val_mse: 10.1077 - val_mae: 2.9289\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 629us/step - loss: 9.3065 - mse: 9.3065 - mae: 2.7043 - val_loss: 8.8674 - val_mse: 8.8674 - val_mae: 2.7112\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 443us/step - loss: 8.2596 - mse: 8.2596 - mae: 2.5028 - val_loss: 7.7535 - val_mse: 7.7535 - val_mae: 2.4989\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 574us/step - loss: 7.3732 - mse: 7.3732 - mae: 2.3197 - val_loss: 6.7693 - val_mse: 6.7693 - val_mae: 2.2950\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 399us/step - loss: 6.6271 - mse: 6.6271 - mae: 2.1564 - val_loss: 5.9474 - val_mse: 5.9474 - val_mae: 2.1053\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 374us/step - loss: 5.9840 - mse: 5.9840 - mae: 2.0046 - val_loss: 5.2593 - val_mse: 5.2593 - val_mae: 1.9312\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 400us/step - loss: 5.3994 - mse: 5.3994 - mae: 1.8604 - val_loss: 4.6987 - val_mse: 4.6987 - val_mae: 1.7742\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 308us/step - loss: 4.8673 - mse: 4.8673 - mae: 1.7313 - val_loss: 4.1801 - val_mse: 4.1801 - val_mae: 1.6278\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 502us/step - loss: 4.3680 - mse: 4.3680 - mae: 1.6018 - val_loss: 3.7228 - val_mse: 3.7228 - val_mae: 1.5044\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 297us/step - loss: 3.8902 - mse: 3.8902 - mae: 1.4719 - val_loss: 3.2908 - val_mse: 3.2908 - val_mae: 1.3968\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 406us/step - loss: 3.4344 - mse: 3.4344 - mae: 1.3474 - val_loss: 2.8906 - val_mse: 2.8906 - val_mae: 1.2969\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 327us/step - loss: 3.0229 - mse: 3.0229 - mae: 1.2429 - val_loss: 2.5383 - val_mse: 2.5383 - val_mae: 1.2267\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 535us/step - loss: 2.6844 - mse: 2.6844 - mae: 1.1708 - val_loss: 2.2573 - val_mse: 2.2573 - val_mae: 1.1833\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 479us/step - loss: 2.4335 - mse: 2.4335 - mae: 1.1357 - val_loss: 2.0728 - val_mse: 2.0728 - val_mae: 1.1797\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 2.2708 - mse: 2.2708 - mae: 1.1270 - val_loss: 1.9810 - val_mse: 1.9810 - val_mae: 1.1836\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 340us/step - loss: 2.1872 - mse: 2.1872 - mae: 1.1325 - val_loss: 1.9631 - val_mse: 1.9631 - val_mae: 1.2017\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 338us/step - loss: 2.1585 - mse: 2.1585 - mae: 1.1384 - val_loss: 1.9816 - val_mse: 1.9816 - val_mae: 1.2185\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 393us/step - loss: 2.1562 - mse: 2.1562 - mae: 1.1403 - val_loss: 2.0037 - val_mse: 2.0037 - val_mae: 1.2336\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 334us/step - loss: 2.1555 - mse: 2.1555 - mae: 1.1423 - val_loss: 2.0060 - val_mse: 2.0060 - val_mae: 1.2373\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 334us/step - loss: 2.1449 - mse: 2.1449 - mae: 1.1391 - val_loss: 1.9918 - val_mse: 1.9918 - val_mae: 1.2333\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 796us/step - loss: 2.1260 - mse: 2.1260 - mae: 1.1317 - val_loss: 1.9687 - val_mse: 1.9687 - val_mae: 1.2244\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 502us/step - loss: 2.1052 - mse: 2.1052 - mae: 1.1222 - val_loss: 1.9469 - val_mse: 1.9469 - val_mae: 1.2142\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 457us/step - loss: 2.0873 - mse: 2.0873 - mae: 1.1131 - val_loss: 1.9300 - val_mse: 1.9300 - val_mae: 1.2048\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 2.0732 - mse: 2.0732 - mae: 1.1058 - val_loss: 1.9181 - val_mse: 1.9181 - val_mae: 1.1975\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 307us/step - loss: 2.0615 - mse: 2.0615 - mae: 1.1006 - val_loss: 1.9100 - val_mse: 1.9100 - val_mae: 1.1937\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 382us/step - loss: 2.0507 - mse: 2.0507 - mae: 1.0962 - val_loss: 1.9041 - val_mse: 1.9041 - val_mae: 1.1916\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 372us/step - loss: 2.0400 - mse: 2.0400 - mae: 1.0924 - val_loss: 1.8999 - val_mse: 1.8999 - val_mae: 1.1909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 2.0293 - mse: 2.0293 - mae: 1.0891 - val_loss: 1.8966 - val_mse: 1.8966 - val_mae: 1.1922\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 437us/step - loss: 2.0190 - mse: 2.0190 - mae: 1.0862 - val_loss: 1.8939 - val_mse: 1.8939 - val_mae: 1.1939\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 306us/step - loss: 2.0094 - mse: 2.0094 - mae: 1.0837 - val_loss: 1.8914 - val_mse: 1.8914 - val_mae: 1.1953\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 375us/step - loss: 2.0004 - mse: 2.0004 - mae: 1.0814 - val_loss: 1.8890 - val_mse: 1.8890 - val_mae: 1.1963\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 354us/step - loss: 1.9916 - mse: 1.9916 - mae: 1.0792 - val_loss: 1.8863 - val_mse: 1.8863 - val_mae: 1.1967\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 460us/step - loss: 1.9829 - mse: 1.9829 - mae: 1.0768 - val_loss: 1.8832 - val_mse: 1.8832 - val_mae: 1.1964\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 519us/step - loss: 1.9740 - mse: 1.9740 - mae: 1.0741 - val_loss: 1.8799 - val_mse: 1.8799 - val_mae: 1.1957\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 1.9650 - mse: 1.9650 - mae: 1.0712 - val_loss: 1.8765 - val_mse: 1.8765 - val_mae: 1.1950\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 343us/step - loss: 1.9561 - mse: 1.9561 - mae: 1.0686 - val_loss: 1.8732 - val_mse: 1.8732 - val_mae: 1.1944\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 449us/step - loss: 1.9475 - mse: 1.9475 - mae: 1.0661 - val_loss: 1.8700 - val_mse: 1.8700 - val_mae: 1.1937\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 278us/step - loss: 1.9395 - mse: 1.9395 - mae: 1.0637 - val_loss: 1.8670 - val_mse: 1.8670 - val_mae: 1.1930\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 391us/step - loss: 1.9317 - mse: 1.9317 - mae: 1.0612 - val_loss: 1.8640 - val_mse: 1.8640 - val_mae: 1.1921\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 516us/step - loss: 1.9241 - mse: 1.9241 - mae: 1.0588 - val_loss: 1.8610 - val_mse: 1.8610 - val_mae: 1.1911\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 353us/step - loss: 1.9167 - mse: 1.9167 - mae: 1.0563 - val_loss: 1.8579 - val_mse: 1.8579 - val_mae: 1.1900\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 329us/step - loss: 1.9096 - mse: 1.9096 - mae: 1.0539 - val_loss: 1.8548 - val_mse: 1.8548 - val_mae: 1.1889\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 360us/step - loss: 1.9027 - mse: 1.9027 - mae: 1.0517 - val_loss: 1.8522 - val_mse: 1.8522 - val_mae: 1.1882\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 309us/step - loss: 1.8962 - mse: 1.8962 - mae: 1.0499 - val_loss: 1.8498 - val_mse: 1.8498 - val_mae: 1.1875\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 345us/step - loss: 1.8898 - mse: 1.8898 - mae: 1.0482 - val_loss: 1.8477 - val_mse: 1.8477 - val_mae: 1.1870\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 372us/step - loss: 1.8836 - mse: 1.8836 - mae: 1.0465 - val_loss: 1.8457 - val_mse: 1.8457 - val_mae: 1.1864\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 312us/step - loss: 1.8777 - mse: 1.8777 - mae: 1.0449 - val_loss: 1.8438 - val_mse: 1.8438 - val_mae: 1.1858\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 1.8719 - mse: 1.8719 - mae: 1.0433 - val_loss: 1.8420 - val_mse: 1.8420 - val_mae: 1.1850\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 319us/step - loss: 1.8663 - mse: 1.8663 - mae: 1.0418 - val_loss: 1.8402 - val_mse: 1.8402 - val_mae: 1.1842\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 1.8607 - mse: 1.8607 - mae: 1.0404 - val_loss: 1.8386 - val_mse: 1.8386 - val_mae: 1.1834\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 391us/step - loss: 1.8552 - mse: 1.8552 - mae: 1.0388 - val_loss: 1.8370 - val_mse: 1.8370 - val_mae: 1.1826\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 414us/step - loss: 1.8499 - mse: 1.8499 - mae: 1.0373 - val_loss: 1.8357 - val_mse: 1.8357 - val_mae: 1.1818\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 572us/step - loss: 1.8445 - mse: 1.8445 - mae: 1.0357 - val_loss: 1.8343 - val_mse: 1.8343 - val_mae: 1.1809\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 287us/step - loss: 1.8390 - mse: 1.8390 - mae: 1.0340 - val_loss: 1.8329 - val_mse: 1.8329 - val_mae: 1.1799\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 389us/step - loss: 1.8335 - mse: 1.8335 - mae: 1.0322 - val_loss: 1.8316 - val_mse: 1.8316 - val_mae: 1.1790\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 429us/step - loss: 1.8281 - mse: 1.8281 - mae: 1.0306 - val_loss: 1.8306 - val_mse: 1.8306 - val_mae: 1.1783\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 425us/step - loss: 1.8228 - mse: 1.8228 - mae: 1.0290 - val_loss: 1.8297 - val_mse: 1.8297 - val_mae: 1.1776\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 410us/step - loss: 1.8176 - mse: 1.8176 - mae: 1.0275 - val_loss: 1.8287 - val_mse: 1.8287 - val_mae: 1.1769\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 339us/step - loss: 1.8126 - mse: 1.8126 - mae: 1.0261 - val_loss: 1.8276 - val_mse: 1.8276 - val_mae: 1.1761\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 1.8077 - mse: 1.8077 - mae: 1.0249 - val_loss: 1.8266 - val_mse: 1.8266 - val_mae: 1.1755\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 315us/step - loss: 1.8030 - mse: 1.8030 - mae: 1.0236 - val_loss: 1.8257 - val_mse: 1.8257 - val_mae: 1.1748\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 315us/step - loss: 1.7985 - mse: 1.7985 - mae: 1.0224 - val_loss: 1.8251 - val_mse: 1.8251 - val_mae: 1.1742\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 491us/step - loss: 1.7939 - mse: 1.7939 - mae: 1.0213 - val_loss: 1.8247 - val_mse: 1.8247 - val_mae: 1.1737\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 423us/step - loss: 1.7895 - mse: 1.7895 - mae: 1.0200 - val_loss: 1.8242 - val_mse: 1.8242 - val_mae: 1.1730\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 1.7851 - mse: 1.7851 - mae: 1.0187 - val_loss: 1.8239 - val_mse: 1.8239 - val_mae: 1.1723\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 365us/step - loss: 1.7808 - mse: 1.7808 - mae: 1.0174 - val_loss: 1.8240 - val_mse: 1.8240 - val_mae: 1.1718\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 1.7763 - mse: 1.7763 - mae: 1.0163 - val_loss: 1.8242 - val_mse: 1.8242 - val_mae: 1.1711\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 503us/step - loss: 1.7715 - mse: 1.7715 - mae: 1.0151 - val_loss: 1.8244 - val_mse: 1.8244 - val_mae: 1.1705\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 381us/step - loss: 1.7669 - mse: 1.7669 - mae: 1.0140 - val_loss: 1.8247 - val_mse: 1.8247 - val_mae: 1.1696\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 551us/step - loss: 1.7624 - mse: 1.7624 - mae: 1.0129 - val_loss: 1.8253 - val_mse: 1.8253 - val_mae: 1.1690\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 527us/step - loss: 1.7577 - mse: 1.7577 - mae: 1.0118 - val_loss: 1.8264 - val_mse: 1.8264 - val_mae: 1.1687\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 901us/step - loss: 1.7534 - mse: 1.7534 - mae: 1.0108 - val_loss: 1.8284 - val_mse: 1.8284 - val_mae: 1.1688\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 312us/step - loss: 1.7490 - mse: 1.7490 - mae: 1.0095 - val_loss: 1.8291 - val_mse: 1.8291 - val_mae: 1.1683\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 1.7445 - mse: 1.7445 - mae: 1.0081 - val_loss: 1.8291 - val_mse: 1.8291 - val_mae: 1.1672\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 353us/step - loss: 1.7398 - mse: 1.7398 - mae: 1.0065 - val_loss: 1.8283 - val_mse: 1.8283 - val_mae: 1.1658\n",
      "77\n",
      "[77]\n",
      "Train on 88 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 2.7917 - mse: 2.7917 - mae: 1.3188 - val_loss: 3.1990 - val_mse: 3.1990 - val_mae: 1.3814\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 529us/step - loss: 2.3417 - mse: 2.3417 - mae: 1.1714 - val_loss: 2.6171 - val_mse: 2.6171 - val_mae: 1.2166\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 545us/step - loss: 1.9716 - mse: 1.9716 - mae: 1.0373 - val_loss: 2.1686 - val_mse: 2.1686 - val_mae: 1.1386\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 453us/step - loss: 1.6918 - mse: 1.6918 - mae: 0.9334 - val_loss: 1.8607 - val_mse: 1.8607 - val_mae: 1.0738\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 283us/step - loss: 1.5111 - mse: 1.5111 - mae: 0.8611 - val_loss: 1.6660 - val_mse: 1.6660 - val_mae: 1.0381\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 421us/step - loss: 1.4147 - mse: 1.4147 - mae: 0.8363 - val_loss: 1.5872 - val_mse: 1.5872 - val_mae: 1.0413\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 442us/step - loss: 1.3873 - mse: 1.3873 - mae: 0.8426 - val_loss: 1.5793 - val_mse: 1.5793 - val_mae: 1.0743\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 405us/step - loss: 1.3814 - mse: 1.3814 - mae: 0.8530 - val_loss: 1.5734 - val_mse: 1.5734 - val_mae: 1.0851\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 455us/step - loss: 1.3620 - mse: 1.3620 - mae: 0.8522 - val_loss: 1.5528 - val_mse: 1.5528 - val_mae: 1.0785\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 354us/step - loss: 1.3208 - mse: 1.3208 - mae: 0.8380 - val_loss: 1.5251 - val_mse: 1.5251 - val_mae: 1.0608\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 256us/step - loss: 1.2714 - mse: 1.2714 - mae: 0.8167 - val_loss: 1.5024 - val_mse: 1.5024 - val_mae: 1.0377\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 432us/step - loss: 1.2286 - mse: 1.2286 - mae: 0.7969 - val_loss: 1.4861 - val_mse: 1.4861 - val_mae: 1.0144\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 340us/step - loss: 1.1972 - mse: 1.1972 - mae: 0.7825 - val_loss: 1.4720 - val_mse: 1.4720 - val_mae: 1.0026\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 374us/step - loss: 1.1746 - mse: 1.1746 - mae: 0.7728 - val_loss: 1.4593 - val_mse: 1.4593 - val_mae: 0.9964\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 594us/step - loss: 1.1576 - mse: 1.1576 - mae: 0.7655 - val_loss: 1.4455 - val_mse: 1.4455 - val_mae: 0.9925\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 261us/step - loss: 1.1416 - mse: 1.1416 - mae: 0.7600 - val_loss: 1.4315 - val_mse: 1.4315 - val_mae: 0.9899\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 365us/step - loss: 1.1246 - mse: 1.1246 - mae: 0.7550 - val_loss: 1.4135 - val_mse: 1.4135 - val_mae: 0.9878\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 421us/step - loss: 1.1077 - mse: 1.1077 - mae: 0.7510 - val_loss: 1.3940 - val_mse: 1.3940 - val_mae: 0.9844\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 522us/step - loss: 1.0920 - mse: 1.0920 - mae: 0.7481 - val_loss: 1.3794 - val_mse: 1.3794 - val_mae: 0.9821\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 326us/step - loss: 1.0782 - mse: 1.0782 - mae: 0.7472 - val_loss: 1.3679 - val_mse: 1.3679 - val_mae: 0.9801\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 435us/step - loss: 1.0663 - mse: 1.0663 - mae: 0.7472 - val_loss: 1.3612 - val_mse: 1.3612 - val_mae: 0.9814\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 439us/step - loss: 1.0556 - mse: 1.0556 - mae: 0.7468 - val_loss: 1.3577 - val_mse: 1.3577 - val_mae: 0.9821\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 478us/step - loss: 1.0454 - mse: 1.0454 - mae: 0.7455 - val_loss: 1.3557 - val_mse: 1.3557 - val_mae: 0.9825\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 426us/step - loss: 1.0354 - mse: 1.0354 - mae: 0.7427 - val_loss: 1.3535 - val_mse: 1.3535 - val_mae: 0.9821\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 647us/step - loss: 1.0254 - mse: 1.0254 - mae: 0.7390 - val_loss: 1.3513 - val_mse: 1.3513 - val_mae: 0.9811\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 444us/step - loss: 1.0157 - mse: 1.0157 - mae: 0.7346 - val_loss: 1.3482 - val_mse: 1.3482 - val_mae: 0.9793\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 331us/step - loss: 1.0067 - mse: 1.0067 - mae: 0.7301 - val_loss: 1.3437 - val_mse: 1.3437 - val_mae: 0.9764\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 333us/step - loss: 0.9986 - mse: 0.9986 - mae: 0.7260 - val_loss: 1.3405 - val_mse: 1.3405 - val_mae: 0.9742\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 363us/step - loss: 0.9914 - mse: 0.9914 - mae: 0.7229 - val_loss: 1.3382 - val_mse: 1.3382 - val_mae: 0.9729\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 309us/step - loss: 0.9842 - mse: 0.9842 - mae: 0.7200 - val_loss: 1.3352 - val_mse: 1.3352 - val_mae: 0.9718\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 377us/step - loss: 0.9773 - mse: 0.9773 - mae: 0.7176 - val_loss: 1.3332 - val_mse: 1.3332 - val_mae: 0.9714\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 399us/step - loss: 0.9711 - mse: 0.9711 - mae: 0.7158 - val_loss: 1.3316 - val_mse: 1.3316 - val_mae: 0.9715\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 489us/step - loss: 0.9648 - mse: 0.9648 - mae: 0.7141 - val_loss: 1.3292 - val_mse: 1.3292 - val_mae: 0.9716\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 375us/step - loss: 0.9586 - mse: 0.9586 - mae: 0.7126 - val_loss: 1.3262 - val_mse: 1.3262 - val_mae: 0.9717\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 263us/step - loss: 0.9519 - mse: 0.9519 - mae: 0.7108 - val_loss: 1.3229 - val_mse: 1.3229 - val_mae: 0.9713\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 0s 343us/step - loss: 0.9461 - mse: 0.9461 - mae: 0.7097 - val_loss: 1.3210 - val_mse: 1.3210 - val_mae: 0.9708\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 0s 481us/step - loss: 0.9403 - mse: 0.9403 - mae: 0.7082 - val_loss: 1.3219 - val_mse: 1.3219 - val_mae: 0.9707\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 0s 387us/step - loss: 0.9350 - mse: 0.9350 - mae: 0.7065 - val_loss: 1.3222 - val_mse: 1.3222 - val_mae: 0.9704\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 0s 626us/step - loss: 0.9294 - mse: 0.9294 - mae: 0.7048 - val_loss: 1.3200 - val_mse: 1.3200 - val_mae: 0.9695\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 0s 385us/step - loss: 0.9245 - mse: 0.9245 - mae: 0.7037 - val_loss: 1.3181 - val_mse: 1.3181 - val_mae: 0.9689\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 0s 452us/step - loss: 0.9194 - mse: 0.9194 - mae: 0.7026 - val_loss: 1.3179 - val_mse: 1.3179 - val_mae: 0.9689\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 0s 398us/step - loss: 0.9142 - mse: 0.9142 - mae: 0.7013 - val_loss: 1.3183 - val_mse: 1.3183 - val_mae: 0.9690\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 0s 387us/step - loss: 0.9085 - mse: 0.9085 - mae: 0.6997 - val_loss: 1.3176 - val_mse: 1.3176 - val_mae: 0.9685\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 0s 361us/step - loss: 0.9028 - mse: 0.9028 - mae: 0.6980 - val_loss: 1.3184 - val_mse: 1.3184 - val_mae: 0.9682\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 0s 366us/step - loss: 0.8971 - mse: 0.8971 - mae: 0.6962 - val_loss: 1.3196 - val_mse: 1.3196 - val_mae: 0.9676\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 0s 422us/step - loss: 0.8916 - mse: 0.8916 - mae: 0.6944 - val_loss: 1.3216 - val_mse: 1.3216 - val_mae: 0.9675\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 0s 365us/step - loss: 0.8861 - mse: 0.8861 - mae: 0.6927 - val_loss: 1.3243 - val_mse: 1.3243 - val_mae: 0.9679\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 0s 719us/step - loss: 0.8803 - mse: 0.8803 - mae: 0.6906 - val_loss: 1.3278 - val_mse: 1.3278 - val_mae: 0.9685\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 0s 501us/step - loss: 0.8742 - mse: 0.8742 - mae: 0.6881 - val_loss: 1.3257 - val_mse: 1.3257 - val_mae: 0.9674\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 591us/step - loss: 0.8683 - mse: 0.8683 - mae: 0.6855 - val_loss: 1.3225 - val_mse: 1.3225 - val_mae: 0.9659\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 0s 330us/step - loss: 0.8634 - mse: 0.8634 - mae: 0.6836 - val_loss: 1.3201 - val_mse: 1.3201 - val_mae: 0.9646\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 0s 466us/step - loss: 0.8588 - mse: 0.8588 - mae: 0.6819 - val_loss: 1.3195 - val_mse: 1.3195 - val_mae: 0.9638\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 0s 525us/step - loss: 0.8543 - mse: 0.8543 - mae: 0.6800 - val_loss: 1.3208 - val_mse: 1.3208 - val_mae: 0.9634\n",
      "78\n",
      "[78]\n",
      "Train on 81 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 3.0760 - mse: 3.0760 - mae: 1.1730 - val_loss: 0.8094 - val_mse: 0.8094 - val_mae: 0.6805\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 0s 272us/step - loss: 2.7649 - mse: 2.7649 - mae: 1.1131 - val_loss: 0.6481 - val_mse: 0.6481 - val_mae: 0.6508\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 0s 359us/step - loss: 2.5230 - mse: 2.5230 - mae: 1.0886 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.6404\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 0s 751us/step - loss: 2.3588 - mse: 2.3588 - mae: 1.0770 - val_loss: 0.5191 - val_mse: 0.5191 - val_mae: 0.6309\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 0s 383us/step - loss: 2.2632 - mse: 2.2632 - mae: 1.0746 - val_loss: 0.5224 - val_mse: 0.5224 - val_mae: 0.6211\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 0s 318us/step - loss: 2.2223 - mse: 2.2223 - mae: 1.0879 - val_loss: 0.5459 - val_mse: 0.5459 - val_mae: 0.6232\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 0s 387us/step - loss: 2.2058 - mse: 2.2058 - mae: 1.1071 - val_loss: 0.5672 - val_mse: 0.5672 - val_mae: 0.6260\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 0s 456us/step - loss: 2.1916 - mse: 2.1916 - mae: 1.1180 - val_loss: 0.5734 - val_mse: 0.5734 - val_mae: 0.6242\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 0s 375us/step - loss: 2.1705 - mse: 2.1705 - mae: 1.1175 - val_loss: 0.5656 - val_mse: 0.5656 - val_mae: 0.6195\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 0s 384us/step - loss: 2.1436 - mse: 2.1436 - mae: 1.1092 - val_loss: 0.5482 - val_mse: 0.5482 - val_mae: 0.6129\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 0s 509us/step - loss: 2.1137 - mse: 2.1137 - mae: 1.0957 - val_loss: 0.5266 - val_mse: 0.5266 - val_mae: 0.6051\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 2.0847 - mse: 2.0847 - mae: 1.0797 - val_loss: 0.5057 - val_mse: 0.5057 - val_mae: 0.5966\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 2.0598 - mse: 2.0598 - mae: 1.0640 - val_loss: 0.4887 - val_mse: 0.4887 - val_mae: 0.5885\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 0s 447us/step - loss: 2.0393 - mse: 2.0393 - mae: 1.0496 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.5822\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 0s 310us/step - loss: 2.0217 - mse: 2.0217 - mae: 1.0378 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5768\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 2.0058 - mse: 2.0058 - mae: 1.0292 - val_loss: 0.4644 - val_mse: 0.4644 - val_mae: 0.5732\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 0s 433us/step - loss: 1.9907 - mse: 1.9907 - mae: 1.0243 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.5705\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 0s 419us/step - loss: 1.9755 - mse: 1.9755 - mae: 1.0218 - val_loss: 0.4621 - val_mse: 0.4621 - val_mae: 0.5683\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 0s 385us/step - loss: 1.9606 - mse: 1.9606 - mae: 1.0209 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.5662\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 0s 436us/step - loss: 1.9451 - mse: 1.9451 - mae: 1.0203 - val_loss: 0.4635 - val_mse: 0.4635 - val_mae: 0.5641\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 0s 614us/step - loss: 1.9302 - mse: 1.9302 - mae: 1.0198 - val_loss: 0.4648 - val_mse: 0.4648 - val_mae: 0.5621\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - 0s 394us/step - loss: 1.9164 - mse: 1.9164 - mae: 1.0192 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.5599\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - 0s 377us/step - loss: 1.9030 - mse: 1.9030 - mae: 1.0178 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.5575\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - 0s 357us/step - loss: 1.8896 - mse: 1.8896 - mae: 1.0153 - val_loss: 0.4651 - val_mse: 0.4651 - val_mae: 0.5550\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - 0s 456us/step - loss: 1.8763 - mse: 1.8763 - mae: 1.0119 - val_loss: 0.4642 - val_mse: 0.4642 - val_mae: 0.5524\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 1.8630 - mse: 1.8630 - mae: 1.0077 - val_loss: 0.4629 - val_mse: 0.4629 - val_mae: 0.5496\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - 0s 629us/step - loss: 1.8496 - mse: 1.8496 - mae: 1.0028 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.5465\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - 0s 371us/step - loss: 1.8365 - mse: 1.8365 - mae: 0.9979 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.5438\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - 0s 354us/step - loss: 1.8236 - mse: 1.8236 - mae: 0.9931 - val_loss: 0.4617 - val_mse: 0.4617 - val_mae: 0.5420\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - 0s 180us/step - loss: 1.8117 - mse: 1.8117 - mae: 0.9887 - val_loss: 0.4627 - val_mse: 0.4627 - val_mae: 0.5409\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - 0s 369us/step - loss: 1.7992 - mse: 1.7992 - mae: 0.9843 - val_loss: 0.4641 - val_mse: 0.4641 - val_mae: 0.5397\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - 0s 443us/step - loss: 1.7873 - mse: 1.7873 - mae: 0.9803 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.5391\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - 0s 600us/step - loss: 1.7754 - mse: 1.7754 - mae: 0.9768 - val_loss: 0.4692 - val_mse: 0.4692 - val_mae: 0.5387\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - 0s 434us/step - loss: 1.7631 - mse: 1.7631 - mae: 0.9736 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.5384\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - 0s 419us/step - loss: 1.7529 - mse: 1.7529 - mae: 0.9702 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5375\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - 0s 366us/step - loss: 1.7428 - mse: 1.7428 - mae: 0.9667 - val_loss: 0.4757 - val_mse: 0.4757 - val_mae: 0.5368\n",
      "Epoch 37/100\n",
      "81/81 [==============================] - 0s 340us/step - loss: 1.7313 - mse: 1.7313 - mae: 0.9629 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5361\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - 0s 408us/step - loss: 1.7201 - mse: 1.7201 - mae: 0.9592 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.5359\n",
      "79\n",
      "[79]\n",
      "Train on 87 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.1755 - mse: 5.1755 - mae: 2.0876 - val_loss: 4.7172 - val_mse: 4.7172 - val_mae: 1.8659\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 265us/step - loss: 4.8156 - mse: 4.8156 - mae: 1.9998 - val_loss: 4.4915 - val_mse: 4.4915 - val_mae: 1.7991\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 586us/step - loss: 4.5249 - mse: 4.5249 - mae: 1.9270 - val_loss: 4.2973 - val_mse: 4.2973 - val_mae: 1.7422\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 636us/step - loss: 4.2902 - mse: 4.2902 - mae: 1.8671 - val_loss: 4.1565 - val_mse: 4.1565 - val_mae: 1.7020\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 429us/step - loss: 4.1211 - mse: 4.1211 - mae: 1.8233 - val_loss: 4.0851 - val_mse: 4.0851 - val_mae: 1.6783\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 651us/step - loss: 4.0028 - mse: 4.0028 - mae: 1.7924 - val_loss: 4.0393 - val_mse: 4.0393 - val_mae: 1.6599\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 336us/step - loss: 3.9227 - mse: 3.9227 - mae: 1.7707 - val_loss: 3.9988 - val_mse: 3.9988 - val_mae: 1.6431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 407us/step - loss: 3.8669 - mse: 3.8669 - mae: 1.7555 - val_loss: 3.9717 - val_mse: 3.9717 - val_mae: 1.6306\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 373us/step - loss: 3.8273 - mse: 3.8273 - mae: 1.7444 - val_loss: 3.9451 - val_mse: 3.9451 - val_mae: 1.6176\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 300us/step - loss: 3.7956 - mse: 3.7956 - mae: 1.7353 - val_loss: 3.9213 - val_mse: 3.9213 - val_mae: 1.6059\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 310us/step - loss: 3.7744 - mse: 3.7744 - mae: 1.7289 - val_loss: 3.8994 - val_mse: 3.8994 - val_mae: 1.5949\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 399us/step - loss: 3.7577 - mse: 3.7577 - mae: 1.7235 - val_loss: 3.8795 - val_mse: 3.8795 - val_mae: 1.5849\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 518us/step - loss: 3.7407 - mse: 3.7407 - mae: 1.7182 - val_loss: 3.8505 - val_mse: 3.8505 - val_mae: 1.5700\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 528us/step - loss: 3.7202 - mse: 3.7202 - mae: 1.7115 - val_loss: 3.8043 - val_mse: 3.8043 - val_mae: 1.5471\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 388us/step - loss: 3.6906 - mse: 3.6906 - mae: 1.7016 - val_loss: 3.7544 - val_mse: 3.7544 - val_mae: 1.5201\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 494us/step - loss: 3.6444 - mse: 3.6444 - mae: 1.6855 - val_loss: 3.6967 - val_mse: 3.6967 - val_mae: 1.4840\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 248us/step - loss: 3.5769 - mse: 3.5769 - mae: 1.6617 - val_loss: 3.5923 - val_mse: 3.5923 - val_mae: 1.4241\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 386us/step - loss: 3.4682 - mse: 3.4682 - mae: 1.6232 - val_loss: 3.4159 - val_mse: 3.4159 - val_mae: 1.3466\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 426us/step - loss: 3.2452 - mse: 3.2452 - mae: 1.5423 - val_loss: 3.1502 - val_mse: 3.1502 - val_mae: 1.2804\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 0s 231us/step - loss: 2.9255 - mse: 2.9255 - mae: 1.4123 - val_loss: 2.8838 - val_mse: 2.8838 - val_mae: 1.2206\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 0s 560us/step - loss: 2.5105 - mse: 2.5105 - mae: 1.2475 - val_loss: 2.6355 - val_mse: 2.6355 - val_mae: 1.1478\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 2.0645 - mse: 2.0645 - mae: 1.1274 - val_loss: 2.5836 - val_mse: 2.5836 - val_mae: 1.1600\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 0s 427us/step - loss: 1.7955 - mse: 1.7955 - mae: 1.0880 - val_loss: 2.7110 - val_mse: 2.7110 - val_mae: 1.2723\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 0s 576us/step - loss: 1.7614 - mse: 1.7614 - mae: 1.0896 - val_loss: 2.8941 - val_mse: 2.8941 - val_mae: 1.3784\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 0s 334us/step - loss: 1.8114 - mse: 1.8114 - mae: 1.1077 - val_loss: 2.9418 - val_mse: 2.9418 - val_mae: 1.4109\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 0s 486us/step - loss: 1.7907 - mse: 1.7907 - mae: 1.1003 - val_loss: 2.8512 - val_mse: 2.8512 - val_mae: 1.3822\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 0s 347us/step - loss: 1.7001 - mse: 1.7001 - mae: 1.0727 - val_loss: 2.7015 - val_mse: 2.7015 - val_mae: 1.3178\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 0s 553us/step - loss: 1.5965 - mse: 1.5965 - mae: 1.0428 - val_loss: 2.5654 - val_mse: 2.5654 - val_mae: 1.2433\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 0s 392us/step - loss: 1.5220 - mse: 1.5220 - mae: 1.0174 - val_loss: 2.4581 - val_mse: 2.4581 - val_mae: 1.1715\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 0s 334us/step - loss: 1.4800 - mse: 1.4800 - mae: 0.9953 - val_loss: 2.3935 - val_mse: 2.3935 - val_mae: 1.1263\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 0s 462us/step - loss: 1.4506 - mse: 1.4506 - mae: 0.9791 - val_loss: 2.3544 - val_mse: 2.3544 - val_mae: 1.1028\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 0s 623us/step - loss: 1.4164 - mse: 1.4164 - mae: 0.9655 - val_loss: 2.3303 - val_mse: 2.3303 - val_mae: 1.0955\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 0s 513us/step - loss: 1.3751 - mse: 1.3751 - mae: 0.9525 - val_loss: 2.3161 - val_mse: 2.3161 - val_mae: 1.1047\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 0s 347us/step - loss: 1.3327 - mse: 1.3327 - mae: 0.9411 - val_loss: 2.2958 - val_mse: 2.2958 - val_mae: 1.1219\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 0s 368us/step - loss: 1.2964 - mse: 1.2964 - mae: 0.9352 - val_loss: 2.2804 - val_mse: 2.2804 - val_mae: 1.1442\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 1.2641 - mse: 1.2641 - mae: 0.9289 - val_loss: 2.2648 - val_mse: 2.2648 - val_mae: 1.1589\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 0s 445us/step - loss: 1.2349 - mse: 1.2349 - mae: 0.9209 - val_loss: 2.2447 - val_mse: 2.2447 - val_mae: 1.1636\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 0s 421us/step - loss: 1.2063 - mse: 1.2063 - mae: 0.9106 - val_loss: 2.2188 - val_mse: 2.2188 - val_mae: 1.1580\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 0s 357us/step - loss: 1.1774 - mse: 1.1774 - mae: 0.8995 - val_loss: 2.1897 - val_mse: 2.1897 - val_mae: 1.1452\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 0s 400us/step - loss: 1.1486 - mse: 1.1486 - mae: 0.8878 - val_loss: 2.1618 - val_mse: 2.1618 - val_mae: 1.1301\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 0s 347us/step - loss: 1.1223 - mse: 1.1223 - mae: 0.8764 - val_loss: 2.1373 - val_mse: 2.1373 - val_mae: 1.1178\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 0s 357us/step - loss: 1.0977 - mse: 1.0977 - mae: 0.8657 - val_loss: 2.1165 - val_mse: 2.1165 - val_mae: 1.1103\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 0s 451us/step - loss: 1.0748 - mse: 1.0748 - mae: 0.8560 - val_loss: 2.0995 - val_mse: 2.0995 - val_mae: 1.1068\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 0s 803us/step - loss: 1.0523 - mse: 1.0523 - mae: 0.8469 - val_loss: 2.0854 - val_mse: 2.0854 - val_mae: 1.1060\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 0s 777us/step - loss: 1.0307 - mse: 1.0307 - mae: 0.8381 - val_loss: 2.0728 - val_mse: 2.0728 - val_mae: 1.1057\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 0s 312us/step - loss: 1.0097 - mse: 1.0097 - mae: 0.8293 - val_loss: 2.0606 - val_mse: 2.0606 - val_mae: 1.1053\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 0s 334us/step - loss: 0.9900 - mse: 0.9900 - mae: 0.8206 - val_loss: 2.0493 - val_mse: 2.0493 - val_mae: 1.1040\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 0s 323us/step - loss: 0.9711 - mse: 0.9711 - mae: 0.8126 - val_loss: 2.0382 - val_mse: 2.0382 - val_mae: 1.1010\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 0s 369us/step - loss: 0.9536 - mse: 0.9536 - mae: 0.8053 - val_loss: 2.0275 - val_mse: 2.0275 - val_mae: 1.0967\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 0s 380us/step - loss: 0.9378 - mse: 0.9378 - mae: 0.7984 - val_loss: 2.0166 - val_mse: 2.0166 - val_mae: 1.0916\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 0s 467us/step - loss: 0.9230 - mse: 0.9230 - mae: 0.7916 - val_loss: 2.0058 - val_mse: 2.0058 - val_mae: 1.0864\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 0s 474us/step - loss: 0.9086 - mse: 0.9086 - mae: 0.7847 - val_loss: 1.9964 - val_mse: 1.9964 - val_mae: 1.0833\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 0s 298us/step - loss: 0.8947 - mse: 0.8947 - mae: 0.7781 - val_loss: 1.9885 - val_mse: 1.9885 - val_mae: 1.0825\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 0s 335us/step - loss: 0.8815 - mse: 0.8815 - mae: 0.7718 - val_loss: 1.9816 - val_mse: 1.9816 - val_mae: 1.0811\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 0s 380us/step - loss: 0.8688 - mse: 0.8688 - mae: 0.7659 - val_loss: 1.9754 - val_mse: 1.9754 - val_mae: 1.0807\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 0s 311us/step - loss: 0.8565 - mse: 0.8565 - mae: 0.7601 - val_loss: 1.9695 - val_mse: 1.9695 - val_mae: 1.0797\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 0s 362us/step - loss: 0.8446 - mse: 0.8446 - mae: 0.7542 - val_loss: 1.9644 - val_mse: 1.9644 - val_mae: 1.0775\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.8334 - mse: 0.8334 - mae: 0.7482 - val_loss: 1.9610 - val_mse: 1.9610 - val_mae: 1.0758\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 0s 615us/step - loss: 0.8229 - mse: 0.8229 - mae: 0.7424 - val_loss: 1.9587 - val_mse: 1.9587 - val_mae: 1.0752\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 0s 427us/step - loss: 0.8137 - mse: 0.8137 - mae: 0.7373 - val_loss: 1.9573 - val_mse: 1.9573 - val_mae: 1.0765\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 0s 322us/step - loss: 0.8050 - mse: 0.8050 - mae: 0.7327 - val_loss: 1.9558 - val_mse: 1.9558 - val_mae: 1.0782\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 0s 401us/step - loss: 0.7969 - mse: 0.7969 - mae: 0.7283 - val_loss: 1.9546 - val_mse: 1.9546 - val_mae: 1.0796\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 0s 140us/step - loss: 0.7893 - mse: 0.7893 - mae: 0.7239 - val_loss: 1.9536 - val_mse: 1.9536 - val_mae: 1.0800\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 0s 723us/step - loss: 0.7822 - mse: 0.7822 - mae: 0.7197 - val_loss: 1.9523 - val_mse: 1.9523 - val_mae: 1.0797\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 0s 462us/step - loss: 0.7755 - mse: 0.7755 - mae: 0.7156 - val_loss: 1.9511 - val_mse: 1.9511 - val_mae: 1.0788\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 0s 664us/step - loss: 0.7694 - mse: 0.7694 - mae: 0.7115 - val_loss: 1.9504 - val_mse: 1.9504 - val_mae: 1.0779\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 0s 328us/step - loss: 0.7637 - mse: 0.7637 - mae: 0.7074 - val_loss: 1.9495 - val_mse: 1.9495 - val_mae: 1.0772\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 0s 495us/step - loss: 0.7584 - mse: 0.7584 - mae: 0.7036 - val_loss: 1.9487 - val_mse: 1.9487 - val_mae: 1.0769\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 0s 734us/step - loss: 0.7535 - mse: 0.7535 - mae: 0.7001 - val_loss: 1.9482 - val_mse: 1.9482 - val_mae: 1.0772\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 0s 359us/step - loss: 0.7489 - mse: 0.7489 - mae: 0.6970 - val_loss: 1.9478 - val_mse: 1.9478 - val_mae: 1.0781\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 0s 525us/step - loss: 0.7446 - mse: 0.7446 - mae: 0.6942 - val_loss: 1.9473 - val_mse: 1.9473 - val_mae: 1.0784\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 0s 413us/step - loss: 0.7404 - mse: 0.7404 - mae: 0.6913 - val_loss: 1.9467 - val_mse: 1.9467 - val_mae: 1.0778\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 0s 427us/step - loss: 0.7364 - mse: 0.7364 - mae: 0.6885 - val_loss: 1.9458 - val_mse: 1.9458 - val_mae: 1.0771\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.7327 - mse: 0.7327 - mae: 0.6857 - val_loss: 1.9450 - val_mse: 1.9450 - val_mae: 1.0759\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 0s 426us/step - loss: 0.7291 - mse: 0.7291 - mae: 0.6830 - val_loss: 1.9443 - val_mse: 1.9443 - val_mae: 1.0745\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 0s 426us/step - loss: 0.7257 - mse: 0.7257 - mae: 0.6804 - val_loss: 1.9435 - val_mse: 1.9435 - val_mae: 1.0732\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 0s 460us/step - loss: 0.7225 - mse: 0.7225 - mae: 0.6779 - val_loss: 1.9428 - val_mse: 1.9428 - val_mae: 1.0726\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 0s 427us/step - loss: 0.7196 - mse: 0.7196 - mae: 0.6757 - val_loss: 1.9423 - val_mse: 1.9423 - val_mae: 1.0721\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 0s 471us/step - loss: 0.7167 - mse: 0.7167 - mae: 0.6735 - val_loss: 1.9419 - val_mse: 1.9419 - val_mae: 1.0715\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 0s 322us/step - loss: 0.7140 - mse: 0.7140 - mae: 0.6715 - val_loss: 1.9416 - val_mse: 1.9416 - val_mae: 1.0706\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 0s 493us/step - loss: 0.7114 - mse: 0.7114 - mae: 0.6694 - val_loss: 1.9413 - val_mse: 1.9413 - val_mae: 1.0697\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 0s 332us/step - loss: 0.7089 - mse: 0.7089 - mae: 0.6674 - val_loss: 1.9410 - val_mse: 1.9410 - val_mae: 1.0687\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 0s 367us/step - loss: 0.7065 - mse: 0.7065 - mae: 0.6654 - val_loss: 1.9410 - val_mse: 1.9410 - val_mae: 1.0679\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 0s 413us/step - loss: 0.7041 - mse: 0.7041 - mae: 0.6636 - val_loss: 1.9416 - val_mse: 1.9416 - val_mae: 1.0677\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 0s 322us/step - loss: 0.7017 - mse: 0.7017 - mae: 0.6618 - val_loss: 1.9424 - val_mse: 1.9424 - val_mae: 1.0677\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 0s 336us/step - loss: 0.6994 - mse: 0.6994 - mae: 0.6600 - val_loss: 1.9431 - val_mse: 1.9431 - val_mae: 1.0677\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 0s 437us/step - loss: 0.6972 - mse: 0.6972 - mae: 0.6584 - val_loss: 1.9439 - val_mse: 1.9439 - val_mae: 1.0677\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 0s 517us/step - loss: 0.6950 - mse: 0.6950 - mae: 0.6568 - val_loss: 1.9447 - val_mse: 1.9447 - val_mae: 1.0678\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 0s 473us/step - loss: 0.6929 - mse: 0.6929 - mae: 0.6552 - val_loss: 1.9456 - val_mse: 1.9456 - val_mae: 1.0678\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 0s 513us/step - loss: 0.6908 - mse: 0.6908 - mae: 0.6537 - val_loss: 1.9464 - val_mse: 1.9464 - val_mae: 1.0677\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 0s 429us/step - loss: 0.6887 - mse: 0.6887 - mae: 0.6521 - val_loss: 1.9472 - val_mse: 1.9472 - val_mae: 1.0678\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 0s 437us/step - loss: 0.6865 - mse: 0.6865 - mae: 0.6505 - val_loss: 1.9479 - val_mse: 1.9479 - val_mae: 1.0685\n",
      "80\n",
      "[80]\n",
      "Train on 89 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 1s 16ms/step - loss: 8.2697 - mse: 8.2697 - mae: 2.1042 - val_loss: 2.9006 - val_mse: 2.9006 - val_mae: 1.3556\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 442us/step - loss: 7.1578 - mse: 7.1578 - mae: 1.9322 - val_loss: 2.4617 - val_mse: 2.4617 - val_mae: 1.2396\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 370us/step - loss: 6.3331 - mse: 6.3331 - mae: 1.8033 - val_loss: 2.1225 - val_mse: 2.1225 - val_mae: 1.1397\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 546us/step - loss: 5.7381 - mse: 5.7381 - mae: 1.7018 - val_loss: 1.9242 - val_mse: 1.9242 - val_mae: 1.0975\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 419us/step - loss: 5.3427 - mse: 5.3427 - mae: 1.6350 - val_loss: 1.8427 - val_mse: 1.8427 - val_mae: 1.0744\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 459us/step - loss: 5.0759 - mse: 5.0759 - mae: 1.6095 - val_loss: 1.8103 - val_mse: 1.8103 - val_mae: 1.0518\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 450us/step - loss: 4.9247 - mse: 4.9247 - mae: 1.6094 - val_loss: 1.7695 - val_mse: 1.7695 - val_mae: 1.0513\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 360us/step - loss: 4.8457 - mse: 4.8457 - mae: 1.6228 - val_loss: 1.7423 - val_mse: 1.7423 - val_mae: 1.0420\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 4.7905 - mse: 4.7905 - mae: 1.6320 - val_loss: 1.7121 - val_mse: 1.7121 - val_mae: 1.0282\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 450us/step - loss: 4.7246 - mse: 4.7246 - mae: 1.6275 - val_loss: 1.6781 - val_mse: 1.6781 - val_mae: 1.0140\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 382us/step - loss: 4.6418 - mse: 4.6418 - mae: 1.6124 - val_loss: 1.6408 - val_mse: 1.6408 - val_mae: 1.0029\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 411us/step - loss: 4.5493 - mse: 4.5493 - mae: 1.5884 - val_loss: 1.6040 - val_mse: 1.6040 - val_mae: 0.9892\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 452us/step - loss: 4.4570 - mse: 4.4570 - mae: 1.5604 - val_loss: 1.5705 - val_mse: 1.5705 - val_mae: 0.9746\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 574us/step - loss: 4.3731 - mse: 4.3731 - mae: 1.5336 - val_loss: 1.5450 - val_mse: 1.5450 - val_mae: 0.9627\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 291us/step - loss: 4.3034 - mse: 4.3034 - mae: 1.5088 - val_loss: 1.5273 - val_mse: 1.5273 - val_mae: 0.9520\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 528us/step - loss: 4.2426 - mse: 4.2426 - mae: 1.4862 - val_loss: 1.5134 - val_mse: 1.5134 - val_mae: 0.9420\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 351us/step - loss: 4.1906 - mse: 4.1906 - mae: 1.4676 - val_loss: 1.5012 - val_mse: 1.5012 - val_mae: 0.9333\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 426us/step - loss: 4.1425 - mse: 4.1425 - mae: 1.4532 - val_loss: 1.4880 - val_mse: 1.4880 - val_mae: 0.9244\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 429us/step - loss: 4.0967 - mse: 4.0967 - mae: 1.4422 - val_loss: 1.4763 - val_mse: 1.4763 - val_mae: 0.9172\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 382us/step - loss: 4.0524 - mse: 4.0524 - mae: 1.4339 - val_loss: 1.4650 - val_mse: 1.4650 - val_mae: 0.9133\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 372us/step - loss: 4.0086 - mse: 4.0086 - mae: 1.4285 - val_loss: 1.4533 - val_mse: 1.4533 - val_mae: 0.9097\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 493us/step - loss: 3.9662 - mse: 3.9662 - mae: 1.4253 - val_loss: 1.4438 - val_mse: 1.4438 - val_mae: 0.9067\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 307us/step - loss: 3.9261 - mse: 3.9261 - mae: 1.4224 - val_loss: 1.4355 - val_mse: 1.4355 - val_mae: 0.9040\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 392us/step - loss: 3.8893 - mse: 3.8893 - mae: 1.4190 - val_loss: 1.4277 - val_mse: 1.4277 - val_mae: 0.9041\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 304us/step - loss: 3.8552 - mse: 3.8552 - mae: 1.4157 - val_loss: 1.4207 - val_mse: 1.4207 - val_mae: 0.9075\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 594us/step - loss: 3.8181 - mse: 3.8181 - mae: 1.4128 - val_loss: 1.4150 - val_mse: 1.4150 - val_mae: 0.9112\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 505us/step - loss: 3.7809 - mse: 3.7809 - mae: 1.4092 - val_loss: 1.4090 - val_mse: 1.4090 - val_mae: 0.9140\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 486us/step - loss: 3.7462 - mse: 3.7462 - mae: 1.4049 - val_loss: 1.4049 - val_mse: 1.4049 - val_mae: 0.9173\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 304us/step - loss: 3.7134 - mse: 3.7134 - mae: 1.4003 - val_loss: 1.4029 - val_mse: 1.4029 - val_mae: 0.9214\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 578us/step - loss: 3.6804 - mse: 3.6804 - mae: 1.3941 - val_loss: 1.4005 - val_mse: 1.4005 - val_mae: 0.9236\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 529us/step - loss: 3.6496 - mse: 3.6496 - mae: 1.3868 - val_loss: 1.3997 - val_mse: 1.3997 - val_mae: 0.9256\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 538us/step - loss: 3.6208 - mse: 3.6208 - mae: 1.3787 - val_loss: 1.4026 - val_mse: 1.4026 - val_mae: 0.9305\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 336us/step - loss: 3.5910 - mse: 3.5910 - mae: 1.3703 - val_loss: 1.4052 - val_mse: 1.4052 - val_mae: 0.9352\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 529us/step - loss: 3.5628 - mse: 3.5628 - mae: 1.3619 - val_loss: 1.4068 - val_mse: 1.4068 - val_mae: 0.9398\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 419us/step - loss: 3.5362 - mse: 3.5362 - mae: 1.3542 - val_loss: 1.4077 - val_mse: 1.4077 - val_mae: 0.9443\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 487us/step - loss: 3.5116 - mse: 3.5116 - mae: 1.3476 - val_loss: 1.4082 - val_mse: 1.4082 - val_mae: 0.9493\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 677us/step - loss: 3.4871 - mse: 3.4871 - mae: 1.3423 - val_loss: 1.4070 - val_mse: 1.4070 - val_mae: 0.9540\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 450us/step - loss: 3.4625 - mse: 3.4625 - mae: 1.3380 - val_loss: 1.4061 - val_mse: 1.4061 - val_mae: 0.9588\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 674us/step - loss: 3.4389 - mse: 3.4389 - mae: 1.3343 - val_loss: 1.4074 - val_mse: 1.4074 - val_mae: 0.9640\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 405us/step - loss: 3.4161 - mse: 3.4161 - mae: 1.3304 - val_loss: 1.4088 - val_mse: 1.4088 - val_mae: 0.9686\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 336us/step - loss: 3.3941 - mse: 3.3941 - mae: 1.3258 - val_loss: 1.4095 - val_mse: 1.4095 - val_mae: 0.9722\n",
      "81\n",
      "[81]\n",
      "Train on 93 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s 15ms/step - loss: 62.8755 - mse: 62.8755 - mae: 7.3046 - val_loss: 16.1502 - val_mse: 16.1502 - val_mae: 3.8714\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 376us/step - loss: 53.4654 - mse: 53.4654 - mae: 6.6995 - val_loss: 13.7017 - val_mse: 13.7017 - val_mae: 3.5400\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 398us/step - loss: 45.4811 - mse: 45.4811 - mae: 6.1442 - val_loss: 11.7142 - val_mse: 11.7142 - val_mae: 3.2500\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 324us/step - loss: 38.9705 - mse: 38.9705 - mae: 5.6538 - val_loss: 10.1336 - val_mse: 10.1336 - val_mae: 2.9991\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 745us/step - loss: 33.6811 - mse: 33.6811 - mae: 5.2209 - val_loss: 8.9046 - val_mse: 8.9046 - val_mae: 2.7877\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 377us/step - loss: 29.3561 - mse: 29.3561 - mae: 4.8422 - val_loss: 7.8399 - val_mse: 7.8399 - val_mae: 2.5876\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 437us/step - loss: 25.7834 - mse: 25.7834 - mae: 4.4985 - val_loss: 6.9605 - val_mse: 6.9605 - val_mae: 2.4112\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 652us/step - loss: 22.7993 - mse: 22.7993 - mae: 4.1875 - val_loss: 6.2187 - val_mse: 6.2187 - val_mae: 2.2498\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 334us/step - loss: 20.3553 - mse: 20.3553 - mae: 3.9098 - val_loss: 5.5837 - val_mse: 5.5837 - val_mae: 2.1016\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 539us/step - loss: 18.3031 - mse: 18.3031 - mae: 3.6576 - val_loss: 5.0319 - val_mse: 5.0319 - val_mae: 1.9676\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 16.5577 - mse: 16.5577 - mae: 3.4284 - val_loss: 4.5417 - val_mse: 4.5417 - val_mae: 1.8396\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 350us/step - loss: 15.0886 - mse: 15.0886 - mae: 3.2198 - val_loss: 4.1060 - val_mse: 4.1060 - val_mae: 1.7166\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 13.7825 - mse: 13.7825 - mae: 3.0246 - val_loss: 3.7127 - val_mse: 3.7127 - val_mae: 1.5957\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 579us/step - loss: 12.5937 - mse: 12.5937 - mae: 2.8371 - val_loss: 3.3550 - val_mse: 3.3550 - val_mae: 1.4798\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 332us/step - loss: 11.5419 - mse: 11.5419 - mae: 2.6630 - val_loss: 3.0463 - val_mse: 3.0463 - val_mae: 1.3709\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 530us/step - loss: 10.6019 - mse: 10.6019 - mae: 2.5078 - val_loss: 2.7856 - val_mse: 2.7856 - val_mae: 1.2719\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 344us/step - loss: 9.7431 - mse: 9.7431 - mae: 2.3689 - val_loss: 2.5576 - val_mse: 2.5576 - val_mae: 1.1812\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 527us/step - loss: 8.9457 - mse: 8.9457 - mae: 2.2409 - val_loss: 2.3505 - val_mse: 2.3505 - val_mae: 1.0920\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 596us/step - loss: 8.2284 - mse: 8.2284 - mae: 2.1266 - val_loss: 2.1694 - val_mse: 2.1694 - val_mae: 1.0077\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 427us/step - loss: 7.5709 - mse: 7.5709 - mae: 2.0259 - val_loss: 2.0075 - val_mse: 2.0075 - val_mae: 0.9422\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 409us/step - loss: 6.9384 - mse: 6.9384 - mae: 1.9296 - val_loss: 1.8555 - val_mse: 1.8555 - val_mae: 0.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 456us/step - loss: 6.3501 - mse: 6.3501 - mae: 1.8301 - val_loss: 1.7222 - val_mse: 1.7222 - val_mae: 0.8530\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 358us/step - loss: 5.8301 - mse: 5.8301 - mae: 1.7472 - val_loss: 1.6206 - val_mse: 1.6206 - val_mae: 0.8187\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 441us/step - loss: 5.3876 - mse: 5.3876 - mae: 1.6855 - val_loss: 1.5557 - val_mse: 1.5557 - val_mae: 0.8064\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 486us/step - loss: 5.0216 - mse: 5.0216 - mae: 1.6337 - val_loss: 1.5287 - val_mse: 1.5287 - val_mae: 0.7984\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 613us/step - loss: 4.7576 - mse: 4.7576 - mae: 1.5976 - val_loss: 1.5156 - val_mse: 1.5156 - val_mae: 0.8134\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 384us/step - loss: 4.5859 - mse: 4.5859 - mae: 1.5652 - val_loss: 1.4977 - val_mse: 1.4977 - val_mae: 0.8233\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 655us/step - loss: 4.4697 - mse: 4.4697 - mae: 1.5364 - val_loss: 1.4955 - val_mse: 1.4955 - val_mae: 0.8287\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 455us/step - loss: 4.4031 - mse: 4.4031 - mae: 1.5202 - val_loss: 1.4986 - val_mse: 1.4986 - val_mae: 0.8313\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 831us/step - loss: 4.3681 - mse: 4.3681 - mae: 1.5149 - val_loss: 1.4997 - val_mse: 1.4997 - val_mae: 0.8310\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 4.3448 - mse: 4.3448 - mae: 1.5114 - val_loss: 1.4970 - val_mse: 1.4970 - val_mae: 0.8296\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 599us/step - loss: 4.3238 - mse: 4.3238 - mae: 1.5081 - val_loss: 1.4912 - val_mse: 1.4912 - val_mae: 0.8275\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 636us/step - loss: 4.3053 - mse: 4.3053 - mae: 1.5044 - val_loss: 1.4848 - val_mse: 1.4848 - val_mae: 0.8249\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 592us/step - loss: 4.2915 - mse: 4.2915 - mae: 1.5021 - val_loss: 1.4790 - val_mse: 1.4790 - val_mae: 0.8220\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 604us/step - loss: 4.2829 - mse: 4.2829 - mae: 1.5004 - val_loss: 1.4747 - val_mse: 1.4747 - val_mae: 0.8198\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 498us/step - loss: 4.2734 - mse: 4.2734 - mae: 1.4982 - val_loss: 1.4701 - val_mse: 1.4701 - val_mae: 0.8174\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 475us/step - loss: 4.2629 - mse: 4.2629 - mae: 1.4958 - val_loss: 1.4660 - val_mse: 1.4660 - val_mae: 0.8154\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 259us/step - loss: 4.2505 - mse: 4.2505 - mae: 1.4932 - val_loss: 1.4626 - val_mse: 1.4626 - val_mae: 0.8138\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 353us/step - loss: 4.2362 - mse: 4.2362 - mae: 1.4908 - val_loss: 1.4598 - val_mse: 1.4598 - val_mae: 0.8127\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 424us/step - loss: 4.2197 - mse: 4.2197 - mae: 1.4883 - val_loss: 1.4577 - val_mse: 1.4577 - val_mae: 0.8123\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 548us/step - loss: 4.2019 - mse: 4.2019 - mae: 1.4858 - val_loss: 1.4563 - val_mse: 1.4563 - val_mae: 0.8122\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 507us/step - loss: 4.1846 - mse: 4.1846 - mae: 1.4834 - val_loss: 1.4550 - val_mse: 1.4550 - val_mae: 0.8122\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 502us/step - loss: 4.1675 - mse: 4.1675 - mae: 1.4810 - val_loss: 1.4539 - val_mse: 1.4539 - val_mae: 0.8121\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 445us/step - loss: 4.1507 - mse: 4.1507 - mae: 1.4786 - val_loss: 1.4527 - val_mse: 1.4527 - val_mae: 0.8119\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 4.1356 - mse: 4.1356 - mae: 1.4766 - val_loss: 1.4512 - val_mse: 1.4512 - val_mae: 0.8115\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 270us/step - loss: 4.1214 - mse: 4.1214 - mae: 1.4746 - val_loss: 1.4495 - val_mse: 1.4495 - val_mae: 0.8107\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 709us/step - loss: 4.1069 - mse: 4.1069 - mae: 1.4725 - val_loss: 1.4474 - val_mse: 1.4474 - val_mae: 0.8098\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 366us/step - loss: 4.0920 - mse: 4.0920 - mae: 1.4702 - val_loss: 1.4450 - val_mse: 1.4450 - val_mae: 0.8087\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 381us/step - loss: 4.0774 - mse: 4.0774 - mae: 1.4680 - val_loss: 1.4425 - val_mse: 1.4425 - val_mae: 0.8075\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 504us/step - loss: 4.0635 - mse: 4.0635 - mae: 1.4657 - val_loss: 1.4399 - val_mse: 1.4399 - val_mae: 0.8061\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 545us/step - loss: 4.0509 - mse: 4.0509 - mae: 1.4635 - val_loss: 1.4380 - val_mse: 1.4380 - val_mae: 0.8049\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 778us/step - loss: 4.0391 - mse: 4.0391 - mae: 1.4613 - val_loss: 1.4365 - val_mse: 1.4365 - val_mae: 0.8038\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 727us/step - loss: 4.0280 - mse: 4.0280 - mae: 1.4592 - val_loss: 1.4352 - val_mse: 1.4352 - val_mae: 0.8029\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 375us/step - loss: 4.0164 - mse: 4.0164 - mae: 1.4574 - val_loss: 1.4341 - val_mse: 1.4341 - val_mae: 0.8023\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 477us/step - loss: 4.0035 - mse: 4.0035 - mae: 1.4555 - val_loss: 1.4331 - val_mse: 1.4331 - val_mae: 0.8019\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 808us/step - loss: 3.9908 - mse: 3.9908 - mae: 1.4538 - val_loss: 1.4332 - val_mse: 1.4332 - val_mae: 0.8019\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 876us/step - loss: 3.9771 - mse: 3.9771 - mae: 1.4517 - val_loss: 1.4341 - val_mse: 1.4341 - val_mae: 0.8023\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 486us/step - loss: 3.9646 - mse: 3.9646 - mae: 1.4498 - val_loss: 1.4347 - val_mse: 1.4347 - val_mae: 0.8026\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 592us/step - loss: 3.9520 - mse: 3.9520 - mae: 1.4479 - val_loss: 1.4349 - val_mse: 1.4349 - val_mae: 0.8027\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 490us/step - loss: 3.9400 - mse: 3.9400 - mae: 1.4459 - val_loss: 1.4349 - val_mse: 1.4349 - val_mae: 0.8026\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 0s 529us/step - loss: 3.9283 - mse: 3.9283 - mae: 1.4439 - val_loss: 1.4350 - val_mse: 1.4350 - val_mae: 0.8025\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 0s 418us/step - loss: 3.9165 - mse: 3.9165 - mae: 1.4418 - val_loss: 1.4353 - val_mse: 1.4353 - val_mae: 0.8025\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 301us/step - loss: 3.9052 - mse: 3.9052 - mae: 1.4398 - val_loss: 1.4353 - val_mse: 1.4353 - val_mae: 0.8025\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 0s 409us/step - loss: 3.8935 - mse: 3.8935 - mae: 1.4378 - val_loss: 1.4356 - val_mse: 1.4356 - val_mae: 0.8028\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 0s 442us/step - loss: 3.8813 - mse: 3.8813 - mae: 1.4356 - val_loss: 1.4363 - val_mse: 1.4363 - val_mae: 0.8033\n",
      "82\n",
      "[82]\n",
      "Train on 70 samples, validate on 11 samples\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 1.5166 - mse: 1.5166 - mae: 0.9218 - val_loss: 0.9135 - val_mse: 0.9135 - val_mae: 0.8498\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 731us/step - loss: 1.4752 - mse: 1.4752 - mae: 0.9239 - val_loss: 0.9035 - val_mse: 0.9035 - val_mae: 0.8489\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 504us/step - loss: 1.4413 - mse: 1.4413 - mae: 0.9151 - val_loss: 0.9032 - val_mse: 0.9032 - val_mae: 0.8505\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 792us/step - loss: 1.4126 - mse: 1.4126 - mae: 0.9035 - val_loss: 0.9070 - val_mse: 0.9070 - val_mae: 0.8530\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 502us/step - loss: 1.3852 - mse: 1.3852 - mae: 0.8911 - val_loss: 0.9108 - val_mse: 0.9108 - val_mae: 0.8546\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 561us/step - loss: 1.3602 - mse: 1.3602 - mae: 0.8804 - val_loss: 0.9129 - val_mse: 0.9129 - val_mae: 0.8552\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 385us/step - loss: 1.3363 - mse: 1.3363 - mae: 0.8714 - val_loss: 0.9144 - val_mse: 0.9144 - val_mae: 0.8563\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 429us/step - loss: 1.3127 - mse: 1.3127 - mae: 0.8644 - val_loss: 0.9158 - val_mse: 0.9158 - val_mae: 0.8575\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 327us/step - loss: 1.2907 - mse: 1.2907 - mae: 0.8582 - val_loss: 0.9141 - val_mse: 0.9141 - val_mae: 0.8567\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 572us/step - loss: 1.2700 - mse: 1.2700 - mae: 0.8532 - val_loss: 0.9127 - val_mse: 0.9127 - val_mae: 0.8555\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 501us/step - loss: 1.2503 - mse: 1.2503 - mae: 0.8477 - val_loss: 0.9114 - val_mse: 0.9114 - val_mae: 0.8531\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 407us/step - loss: 1.2325 - mse: 1.2325 - mae: 0.8424 - val_loss: 0.9111 - val_mse: 0.9111 - val_mae: 0.8502\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 385us/step - loss: 1.2162 - mse: 1.2162 - mae: 0.8369 - val_loss: 0.9100 - val_mse: 0.9100 - val_mae: 0.8470\n",
      "83\n",
      "[83]\n",
      "Train on 94 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 2.8095 - mse: 2.8095 - mae: 1.3080 - val_loss: 2.6800 - val_mse: 2.6800 - val_mae: 1.3197\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 685us/step - loss: 2.4123 - mse: 2.4123 - mae: 1.1649 - val_loss: 2.1187 - val_mse: 2.1187 - val_mae: 1.1463\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 204us/step - loss: 2.0797 - mse: 2.0797 - mae: 1.0387 - val_loss: 1.6989 - val_mse: 1.6989 - val_mae: 1.0283\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 491us/step - loss: 1.8215 - mse: 1.8215 - mae: 0.9501 - val_loss: 1.4275 - val_mse: 1.4275 - val_mae: 0.9987\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 500us/step - loss: 1.6534 - mse: 1.6534 - mae: 0.8925 - val_loss: 1.2915 - val_mse: 1.2915 - val_mae: 0.9823\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 395us/step - loss: 1.5504 - mse: 1.5504 - mae: 0.8675 - val_loss: 1.2339 - val_mse: 1.2339 - val_mae: 0.9792\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 478us/step - loss: 1.4879 - mse: 1.4879 - mae: 0.8660 - val_loss: 1.2334 - val_mse: 1.2334 - val_mae: 0.9821\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 403us/step - loss: 1.4475 - mse: 1.4475 - mae: 0.8690 - val_loss: 1.2564 - val_mse: 1.2564 - val_mae: 0.9865\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 404us/step - loss: 1.4191 - mse: 1.4191 - mae: 0.8683 - val_loss: 1.2830 - val_mse: 1.2830 - val_mae: 0.9954\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 450us/step - loss: 1.3909 - mse: 1.3909 - mae: 0.8636 - val_loss: 1.2945 - val_mse: 1.2945 - val_mae: 0.9961\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 468us/step - loss: 1.3617 - mse: 1.3617 - mae: 0.8542 - val_loss: 1.2967 - val_mse: 1.2967 - val_mae: 0.9880\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 557us/step - loss: 1.3360 - mse: 1.3360 - mae: 0.8451 - val_loss: 1.3084 - val_mse: 1.3084 - val_mae: 0.9841\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 546us/step - loss: 1.3143 - mse: 1.3143 - mae: 0.8367 - val_loss: 1.3266 - val_mse: 1.3266 - val_mae: 0.9835\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 767us/step - loss: 1.2949 - mse: 1.2949 - mae: 0.8295 - val_loss: 1.3447 - val_mse: 1.3447 - val_mae: 0.9823\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 442us/step - loss: 1.2757 - mse: 1.2757 - mae: 0.8217 - val_loss: 1.3397 - val_mse: 1.3397 - val_mae: 0.9741\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 467us/step - loss: 1.2553 - mse: 1.2553 - mae: 0.8136 - val_loss: 1.3110 - val_mse: 1.3110 - val_mae: 0.9600\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 406us/step - loss: 1.2372 - mse: 1.2372 - mae: 0.8066 - val_loss: 1.2837 - val_mse: 1.2837 - val_mae: 0.9491\n",
      "84\n",
      "[84]\n",
      "Train on 90 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5272 - mse: 1.5272 - mae: 0.9833 - val_loss: 0.7494 - val_mse: 0.7494 - val_mae: 0.7756\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 377us/step - loss: 1.4207 - mse: 1.4207 - mae: 0.9574 - val_loss: 0.7303 - val_mse: 0.7303 - val_mae: 0.7674\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 703us/step - loss: 1.3512 - mse: 1.3512 - mae: 0.9434 - val_loss: 0.7179 - val_mse: 0.7179 - val_mae: 0.7650\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 359us/step - loss: 1.2931 - mse: 1.2931 - mae: 0.9242 - val_loss: 0.7013 - val_mse: 0.7013 - val_mae: 0.7556\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 495us/step - loss: 1.2357 - mse: 1.2357 - mae: 0.9022 - val_loss: 0.6870 - val_mse: 0.6870 - val_mae: 0.7442\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 395us/step - loss: 1.1847 - mse: 1.1847 - mae: 0.8816 - val_loss: 0.6775 - val_mse: 0.6775 - val_mae: 0.7343\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 348us/step - loss: 1.1407 - mse: 1.1407 - mae: 0.8636 - val_loss: 0.6687 - val_mse: 0.6687 - val_mae: 0.7265\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 620us/step - loss: 1.1029 - mse: 1.1029 - mae: 0.8488 - val_loss: 0.6615 - val_mse: 0.6615 - val_mae: 0.7210\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 565us/step - loss: 1.0708 - mse: 1.0708 - mae: 0.8372 - val_loss: 0.6559 - val_mse: 0.6559 - val_mae: 0.7185\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 441us/step - loss: 1.0429 - mse: 1.0429 - mae: 0.8270 - val_loss: 0.6495 - val_mse: 0.6495 - val_mae: 0.7135\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 406us/step - loss: 1.0178 - mse: 1.0178 - mae: 0.8163 - val_loss: 0.6429 - val_mse: 0.6429 - val_mae: 0.7055\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 586us/step - loss: 0.9945 - mse: 0.9945 - mae: 0.8059 - val_loss: 0.6370 - val_mse: 0.6370 - val_mae: 0.6968\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 655us/step - loss: 0.9735 - mse: 0.9735 - mae: 0.7962 - val_loss: 0.6329 - val_mse: 0.6329 - val_mae: 0.6902\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 567us/step - loss: 0.9535 - mse: 0.9535 - mae: 0.7874 - val_loss: 0.6297 - val_mse: 0.6297 - val_mae: 0.6867\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 423us/step - loss: 0.9358 - mse: 0.9358 - mae: 0.7804 - val_loss: 0.6275 - val_mse: 0.6275 - val_mae: 0.6840\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 802us/step - loss: 0.9209 - mse: 0.9209 - mae: 0.7752 - val_loss: 0.6260 - val_mse: 0.6260 - val_mae: 0.6823\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 363us/step - loss: 0.9079 - mse: 0.9079 - mae: 0.7703 - val_loss: 0.6237 - val_mse: 0.6237 - val_mae: 0.6786\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 0.8957 - mse: 0.8957 - mae: 0.7645 - val_loss: 0.6204 - val_mse: 0.6204 - val_mae: 0.6735\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 466us/step - loss: 0.8840 - mse: 0.8840 - mae: 0.7592 - val_loss: 0.6172 - val_mse: 0.6172 - val_mae: 0.6697\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 458us/step - loss: 0.8730 - mse: 0.8730 - mae: 0.7540 - val_loss: 0.6155 - val_mse: 0.6155 - val_mae: 0.6674\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 355us/step - loss: 0.8628 - mse: 0.8628 - mae: 0.7496 - val_loss: 0.6148 - val_mse: 0.6148 - val_mae: 0.6655\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 527us/step - loss: 0.8536 - mse: 0.8536 - mae: 0.7461 - val_loss: 0.6142 - val_mse: 0.6142 - val_mae: 0.6634\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 410us/step - loss: 0.8452 - mse: 0.8452 - mae: 0.7434 - val_loss: 0.6131 - val_mse: 0.6131 - val_mae: 0.6613\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 402us/step - loss: 0.8375 - mse: 0.8375 - mae: 0.7406 - val_loss: 0.6115 - val_mse: 0.6115 - val_mae: 0.6592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 387us/step - loss: 0.8304 - mse: 0.8304 - mae: 0.7372 - val_loss: 0.6100 - val_mse: 0.6100 - val_mae: 0.6574\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 291us/step - loss: 0.8240 - mse: 0.8240 - mae: 0.7335 - val_loss: 0.6093 - val_mse: 0.6093 - val_mae: 0.6560\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 433us/step - loss: 0.8175 - mse: 0.8175 - mae: 0.7297 - val_loss: 0.6099 - val_mse: 0.6099 - val_mae: 0.6553\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 398us/step - loss: 0.8107 - mse: 0.8107 - mae: 0.7261 - val_loss: 0.6111 - val_mse: 0.6111 - val_mae: 0.6551\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 412us/step - loss: 0.8051 - mse: 0.8051 - mae: 0.7235 - val_loss: 0.6126 - val_mse: 0.6126 - val_mae: 0.6558\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 378us/step - loss: 0.7997 - mse: 0.7997 - mae: 0.7209 - val_loss: 0.6132 - val_mse: 0.6132 - val_mae: 0.6560\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 317us/step - loss: 0.7943 - mse: 0.7943 - mae: 0.7183 - val_loss: 0.6128 - val_mse: 0.6128 - val_mae: 0.6555\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 500us/step - loss: 0.7890 - mse: 0.7890 - mae: 0.7156 - val_loss: 0.6115 - val_mse: 0.6115 - val_mae: 0.6544\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 401us/step - loss: 0.7843 - mse: 0.7843 - mae: 0.7129 - val_loss: 0.6104 - val_mse: 0.6104 - val_mae: 0.6536\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 345us/step - loss: 0.7793 - mse: 0.7793 - mae: 0.7102 - val_loss: 0.6087 - val_mse: 0.6087 - val_mae: 0.6526\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 388us/step - loss: 0.7746 - mse: 0.7746 - mae: 0.7077 - val_loss: 0.6068 - val_mse: 0.6068 - val_mae: 0.6515\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 321us/step - loss: 0.7702 - mse: 0.7702 - mae: 0.7055 - val_loss: 0.6043 - val_mse: 0.6043 - val_mae: 0.6499\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 412us/step - loss: 0.7656 - mse: 0.7656 - mae: 0.7032 - val_loss: 0.6022 - val_mse: 0.6022 - val_mae: 0.6483\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 477us/step - loss: 0.7614 - mse: 0.7614 - mae: 0.7008 - val_loss: 0.5999 - val_mse: 0.5999 - val_mae: 0.6469\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 323us/step - loss: 0.7567 - mse: 0.7567 - mae: 0.6979 - val_loss: 0.5979 - val_mse: 0.5979 - val_mae: 0.6455\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 366us/step - loss: 0.7530 - mse: 0.7530 - mae: 0.6956 - val_loss: 0.5955 - val_mse: 0.5955 - val_mae: 0.6443\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 378us/step - loss: 0.7487 - mse: 0.7487 - mae: 0.6932 - val_loss: 0.5939 - val_mse: 0.5939 - val_mae: 0.6430\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 356us/step - loss: 0.7450 - mse: 0.7450 - mae: 0.6914 - val_loss: 0.5929 - val_mse: 0.5929 - val_mae: 0.6425\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 345us/step - loss: 0.7414 - mse: 0.7414 - mae: 0.6895 - val_loss: 0.5929 - val_mse: 0.5929 - val_mae: 0.6430\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 456us/step - loss: 0.7372 - mse: 0.7372 - mae: 0.6871 - val_loss: 0.5930 - val_mse: 0.5930 - val_mae: 0.6429\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 453us/step - loss: 0.7335 - mse: 0.7335 - mae: 0.6848 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.6417\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 334us/step - loss: 0.7304 - mse: 0.7304 - mae: 0.6826 - val_loss: 0.5897 - val_mse: 0.5897 - val_mae: 0.6406\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 697us/step - loss: 0.7263 - mse: 0.7263 - mae: 0.6800 - val_loss: 0.5889 - val_mse: 0.5889 - val_mae: 0.6398\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.7220 - mse: 0.7220 - mae: 0.6783 - val_loss: 0.5889 - val_mse: 0.5889 - val_mae: 0.6392\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 432us/step - loss: 0.7188 - mse: 0.7188 - mae: 0.6769 - val_loss: 0.5883 - val_mse: 0.5883 - val_mae: 0.6387\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 471us/step - loss: 0.7156 - mse: 0.7156 - mae: 0.6744 - val_loss: 0.5867 - val_mse: 0.5867 - val_mae: 0.6381\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 523us/step - loss: 0.7125 - mse: 0.7125 - mae: 0.6717 - val_loss: 0.5860 - val_mse: 0.5860 - val_mae: 0.6377\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 450us/step - loss: 0.7084 - mse: 0.7084 - mae: 0.6700 - val_loss: 0.5864 - val_mse: 0.5864 - val_mae: 0.6375\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 378us/step - loss: 0.7054 - mse: 0.7054 - mae: 0.6693 - val_loss: 0.5860 - val_mse: 0.5860 - val_mae: 0.6367\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 503us/step - loss: 0.7029 - mse: 0.7029 - mae: 0.6678 - val_loss: 0.5844 - val_mse: 0.5844 - val_mae: 0.6357\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 290us/step - loss: 0.6999 - mse: 0.6999 - mae: 0.6652 - val_loss: 0.5829 - val_mse: 0.5829 - val_mae: 0.6353\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 361us/step - loss: 0.6957 - mse: 0.6957 - mae: 0.6630 - val_loss: 0.5830 - val_mse: 0.5830 - val_mae: 0.6343\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 526us/step - loss: 0.6929 - mse: 0.6929 - mae: 0.6626 - val_loss: 0.5827 - val_mse: 0.5827 - val_mae: 0.6334\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 513us/step - loss: 0.6905 - mse: 0.6905 - mae: 0.6615 - val_loss: 0.5813 - val_mse: 0.5813 - val_mae: 0.6327\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 402us/step - loss: 0.6874 - mse: 0.6874 - mae: 0.6591 - val_loss: 0.5803 - val_mse: 0.5803 - val_mae: 0.6322\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 481us/step - loss: 0.6841 - mse: 0.6841 - mae: 0.6566 - val_loss: 0.5804 - val_mse: 0.5804 - val_mae: 0.6326\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 432us/step - loss: 0.6803 - mse: 0.6803 - mae: 0.6553 - val_loss: 0.5812 - val_mse: 0.5812 - val_mae: 0.6323\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 499us/step - loss: 0.6777 - mse: 0.6777 - mae: 0.6548 - val_loss: 0.5810 - val_mse: 0.5810 - val_mae: 0.6323\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 347us/step - loss: 0.6746 - mse: 0.6746 - mae: 0.6528 - val_loss: 0.5805 - val_mse: 0.5805 - val_mae: 0.6321\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 380us/step - loss: 0.6706 - mse: 0.6706 - mae: 0.6500 - val_loss: 0.5817 - val_mse: 0.5817 - val_mae: 0.6319\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 519us/step - loss: 0.6682 - mse: 0.6682 - mae: 0.6487 - val_loss: 0.5816 - val_mse: 0.5816 - val_mae: 0.6321\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 415us/step - loss: 0.6652 - mse: 0.6652 - mae: 0.6473 - val_loss: 0.5802 - val_mse: 0.5802 - val_mae: 0.6316\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 356us/step - loss: 0.6616 - mse: 0.6616 - mae: 0.6462 - val_loss: 0.5792 - val_mse: 0.5792 - val_mae: 0.6298\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 356us/step - loss: 0.6580 - mse: 0.6580 - mae: 0.6451 - val_loss: 0.5790 - val_mse: 0.5790 - val_mae: 0.6285\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 568us/step - loss: 0.6559 - mse: 0.6559 - mae: 0.6435 - val_loss: 0.5779 - val_mse: 0.5779 - val_mae: 0.6277\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 412us/step - loss: 0.6532 - mse: 0.6532 - mae: 0.6411 - val_loss: 0.5765 - val_mse: 0.5765 - val_mae: 0.6279\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 452us/step - loss: 0.6494 - mse: 0.6494 - mae: 0.6396 - val_loss: 0.5765 - val_mse: 0.5765 - val_mae: 0.6279\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 391us/step - loss: 0.6456 - mse: 0.6456 - mae: 0.6387 - val_loss: 0.5773 - val_mse: 0.5773 - val_mae: 0.6274\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 478us/step - loss: 0.6432 - mse: 0.6432 - mae: 0.6382 - val_loss: 0.5755 - val_mse: 0.5755 - val_mae: 0.6257\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 294us/step - loss: 0.6404 - mse: 0.6404 - mae: 0.6365 - val_loss: 0.5725 - val_mse: 0.5725 - val_mae: 0.6242\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 265us/step - loss: 0.6371 - mse: 0.6371 - mae: 0.6337 - val_loss: 0.5721 - val_mse: 0.5721 - val_mae: 0.6247\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6336 - mse: 0.6336 - mae: 0.6322 - val_loss: 0.5739 - val_mse: 0.5739 - val_mae: 0.6258\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 454us/step - loss: 0.6311 - mse: 0.6311 - mae: 0.6316 - val_loss: 0.5745 - val_mse: 0.5745 - val_mae: 0.6265\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 680us/step - loss: 0.6284 - mse: 0.6284 - mae: 0.6306 - val_loss: 0.5722 - val_mse: 0.5722 - val_mae: 0.6254\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 993us/step - loss: 0.6252 - mse: 0.6252 - mae: 0.6287 - val_loss: 0.5711 - val_mse: 0.5711 - val_mae: 0.6240\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 507us/step - loss: 0.6225 - mse: 0.6225 - mae: 0.6273 - val_loss: 0.5708 - val_mse: 0.5708 - val_mae: 0.6235\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 565us/step - loss: 0.6194 - mse: 0.6194 - mae: 0.6256 - val_loss: 0.5718 - val_mse: 0.5718 - val_mae: 0.6243\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 375us/step - loss: 0.6167 - mse: 0.6167 - mae: 0.6238 - val_loss: 0.5724 - val_mse: 0.5724 - val_mae: 0.6250\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 531us/step - loss: 0.6139 - mse: 0.6139 - mae: 0.6231 - val_loss: 0.5722 - val_mse: 0.5722 - val_mae: 0.6243\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 390us/step - loss: 0.6112 - mse: 0.6112 - mae: 0.6226 - val_loss: 0.5710 - val_mse: 0.5710 - val_mae: 0.6235\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 359us/step - loss: 0.6079 - mse: 0.6079 - mae: 0.6209 - val_loss: 0.5698 - val_mse: 0.5698 - val_mae: 0.6225\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 443us/step - loss: 0.6051 - mse: 0.6051 - mae: 0.6193 - val_loss: 0.5688 - val_mse: 0.5688 - val_mae: 0.6218\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 426us/step - loss: 0.6015 - mse: 0.6015 - mae: 0.6175 - val_loss: 0.5696 - val_mse: 0.5696 - val_mae: 0.6213\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 632us/step - loss: 0.5990 - mse: 0.5990 - mae: 0.6169 - val_loss: 0.5693 - val_mse: 0.5693 - val_mae: 0.6209\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 514us/step - loss: 0.5967 - mse: 0.5967 - mae: 0.6161 - val_loss: 0.5675 - val_mse: 0.5675 - val_mae: 0.6204\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 422us/step - loss: 0.5929 - mse: 0.5929 - mae: 0.6142 - val_loss: 0.5675 - val_mse: 0.5675 - val_mae: 0.6190\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 456us/step - loss: 0.5908 - mse: 0.5908 - mae: 0.6139 - val_loss: 0.5661 - val_mse: 0.5661 - val_mae: 0.6182\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 389us/step - loss: 0.5883 - mse: 0.5883 - mae: 0.6126 - val_loss: 0.5647 - val_mse: 0.5647 - val_mae: 0.6183\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 501us/step - loss: 0.5847 - mse: 0.5847 - mae: 0.6105 - val_loss: 0.5664 - val_mse: 0.5664 - val_mae: 0.6181\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 643us/step - loss: 0.5815 - mse: 0.5815 - mae: 0.6101 - val_loss: 0.5665 - val_mse: 0.5665 - val_mae: 0.6166\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 446us/step - loss: 0.5794 - mse: 0.5794 - mae: 0.6091 - val_loss: 0.5644 - val_mse: 0.5644 - val_mae: 0.6150\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 499us/step - loss: 0.5767 - mse: 0.5767 - mae: 0.6065 - val_loss: 0.5630 - val_mse: 0.5630 - val_mae: 0.6145\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 322us/step - loss: 0.5730 - mse: 0.5730 - mae: 0.6044 - val_loss: 0.5639 - val_mse: 0.5639 - val_mae: 0.6136\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 436us/step - loss: 0.5709 - mse: 0.5709 - mae: 0.6046 - val_loss: 0.5632 - val_mse: 0.5632 - val_mae: 0.6133\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 413us/step - loss: 0.5681 - mse: 0.5681 - mae: 0.6030 - val_loss: 0.5628 - val_mse: 0.5628 - val_mae: 0.6135\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 344us/step - loss: 0.5646 - mse: 0.5646 - mae: 0.6008 - val_loss: 0.5637 - val_mse: 0.5637 - val_mae: 0.6132\n",
      "85\n",
      "[85]\n",
      "Train on 77 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 8.0765 - mse: 8.0765 - mae: 2.3383 - val_loss: 7.3817 - val_mse: 7.3817 - val_mae: 2.4379\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 725us/step - loss: 7.4973 - mse: 7.4973 - mae: 2.2223 - val_loss: 6.7427 - val_mse: 6.7427 - val_mae: 2.2973\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 544us/step - loss: 7.0041 - mse: 7.0041 - mae: 2.1163 - val_loss: 6.1942 - val_mse: 6.1942 - val_mae: 2.1682\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 414us/step - loss: 6.5686 - mse: 6.5686 - mae: 2.0168 - val_loss: 5.7158 - val_mse: 5.7158 - val_mae: 2.0514\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 375us/step - loss: 6.1747 - mse: 6.1747 - mae: 1.9178 - val_loss: 5.2904 - val_mse: 5.2904 - val_mae: 1.9393\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 5.8161 - mse: 5.8161 - mae: 1.8196 - val_loss: 4.8547 - val_mse: 4.8547 - val_mae: 1.8103\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 409us/step - loss: 5.4732 - mse: 5.4732 - mae: 1.7221 - val_loss: 4.4266 - val_mse: 4.4266 - val_mae: 1.6768\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 737us/step - loss: 5.1077 - mse: 5.1077 - mae: 1.6222 - val_loss: 3.9964 - val_mse: 3.9964 - val_mae: 1.5377\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 766us/step - loss: 4.7301 - mse: 4.7301 - mae: 1.5174 - val_loss: 3.5695 - val_mse: 3.5695 - val_mae: 1.3844\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 429us/step - loss: 4.3553 - mse: 4.3553 - mae: 1.4064 - val_loss: 3.1289 - val_mse: 3.1289 - val_mae: 1.2459\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 430us/step - loss: 3.9989 - mse: 3.9989 - mae: 1.2949 - val_loss: 2.6952 - val_mse: 2.6952 - val_mae: 1.1303\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 560us/step - loss: 3.6454 - mse: 3.6454 - mae: 1.2029 - val_loss: 2.3340 - val_mse: 2.3340 - val_mae: 1.0119\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 5.7377 - mse: 5.7377 - mae: 1.453 - 0s 365us/step - loss: 3.3245 - mse: 3.3245 - mae: 1.1389 - val_loss: 2.0549 - val_mse: 2.0549 - val_mae: 0.9552\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 492us/step - loss: 3.0566 - mse: 3.0566 - mae: 1.0912 - val_loss: 1.8744 - val_mse: 1.8744 - val_mae: 0.9806\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 382us/step - loss: 2.8469 - mse: 2.8469 - mae: 1.0625 - val_loss: 1.7851 - val_mse: 1.7851 - val_mae: 1.0245\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 407us/step - loss: 2.6924 - mse: 2.6924 - mae: 1.0496 - val_loss: 1.7702 - val_mse: 1.7702 - val_mae: 1.0638\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 626us/step - loss: 2.5826 - mse: 2.5826 - mae: 1.0486 - val_loss: 1.8045 - val_mse: 1.8045 - val_mae: 1.0968\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 455us/step - loss: 2.5045 - mse: 2.5045 - mae: 1.0534 - val_loss: 1.8604 - val_mse: 1.8604 - val_mae: 1.1271\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 346us/step - loss: 2.4454 - mse: 2.4454 - mae: 1.0599 - val_loss: 1.9230 - val_mse: 1.9230 - val_mae: 1.1481\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 468us/step - loss: 2.3947 - mse: 2.3947 - mae: 1.0669 - val_loss: 1.9883 - val_mse: 1.9883 - val_mae: 1.1718\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 442us/step - loss: 2.3457 - mse: 2.3457 - mae: 1.0686 - val_loss: 2.0468 - val_mse: 2.0468 - val_mae: 1.1892\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 468us/step - loss: 2.2961 - mse: 2.2961 - mae: 1.0647 - val_loss: 2.0970 - val_mse: 2.0970 - val_mae: 1.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 654us/step - loss: 2.2482 - mse: 2.2482 - mae: 1.0564 - val_loss: 2.1420 - val_mse: 2.1420 - val_mae: 1.2181\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 429us/step - loss: 2.2051 - mse: 2.2051 - mae: 1.0469 - val_loss: 2.1698 - val_mse: 2.1698 - val_mae: 1.2226\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 492us/step - loss: 2.1634 - mse: 2.1634 - mae: 1.0357 - val_loss: 2.1920 - val_mse: 2.1920 - val_mae: 1.2234\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 312us/step - loss: 2.1246 - mse: 2.1246 - mae: 1.0239 - val_loss: 2.2098 - val_mse: 2.2098 - val_mae: 1.2215\n",
      "86\n",
      "[86]\n",
      "Train on 86 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 1.5215 - mse: 1.5215 - mae: 0.9263 - val_loss: 0.7519 - val_mse: 0.7519 - val_mae: 0.5466\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 382us/step - loss: 1.2002 - mse: 1.2002 - mae: 0.8122 - val_loss: 0.6670 - val_mse: 0.6670 - val_mae: 0.5379\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 372us/step - loss: 1.0150 - mse: 1.0150 - mae: 0.7702 - val_loss: 0.6771 - val_mse: 0.6771 - val_mae: 0.6064\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.9378 - mse: 0.9378 - mae: 0.7699 - val_loss: 0.7423 - val_mse: 0.7423 - val_mae: 0.6884\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 361us/step - loss: 0.9251 - mse: 0.9251 - mae: 0.7800 - val_loss: 0.8089 - val_mse: 0.8089 - val_mae: 0.7627\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 432us/step - loss: 0.9315 - mse: 0.9315 - mae: 0.7889 - val_loss: 0.8382 - val_mse: 0.8382 - val_mae: 0.7943\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 394us/step - loss: 0.9258 - mse: 0.9258 - mae: 0.7868 - val_loss: 0.8222 - val_mse: 0.8222 - val_mae: 0.7857\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 396us/step - loss: 0.9043 - mse: 0.9043 - mae: 0.7737 - val_loss: 0.7751 - val_mse: 0.7751 - val_mae: 0.7489\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.8772 - mse: 0.8772 - mae: 0.7545 - val_loss: 0.7215 - val_mse: 0.7215 - val_mae: 0.6990\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 411us/step - loss: 0.8559 - mse: 0.8559 - mae: 0.7365 - val_loss: 0.6761 - val_mse: 0.6761 - val_mae: 0.6575\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 403us/step - loss: 0.8444 - mse: 0.8444 - mae: 0.7210 - val_loss: 0.6450 - val_mse: 0.6450 - val_mae: 0.6238\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.8389 - mse: 0.8389 - mae: 0.7115 - val_loss: 0.6263 - val_mse: 0.6263 - val_mae: 0.6010\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.8344 - mse: 0.8344 - mae: 0.7056 - val_loss: 0.6188 - val_mse: 0.6188 - val_mae: 0.5919\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 373us/step - loss: 0.8278 - mse: 0.8278 - mae: 0.7009 - val_loss: 0.6201 - val_mse: 0.6201 - val_mae: 0.5962\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 396us/step - loss: 0.8188 - mse: 0.8188 - mae: 0.6972 - val_loss: 0.6273 - val_mse: 0.6273 - val_mae: 0.6092\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 464us/step - loss: 0.8088 - mse: 0.8088 - mae: 0.6945 - val_loss: 0.6373 - val_mse: 0.6373 - val_mae: 0.6254\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 417us/step - loss: 0.8002 - mse: 0.8002 - mae: 0.6928 - val_loss: 0.6468 - val_mse: 0.6468 - val_mae: 0.6394\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 397us/step - loss: 0.7930 - mse: 0.7930 - mae: 0.6906 - val_loss: 0.6521 - val_mse: 0.6521 - val_mae: 0.6475\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 368us/step - loss: 0.7863 - mse: 0.7863 - mae: 0.6872 - val_loss: 0.6513 - val_mse: 0.6513 - val_mae: 0.6487\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.7801 - mse: 0.7801 - mae: 0.6829 - val_loss: 0.6463 - val_mse: 0.6463 - val_mae: 0.6444\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 431us/step - loss: 0.7741 - mse: 0.7741 - mae: 0.6786 - val_loss: 0.6396 - val_mse: 0.6396 - val_mae: 0.6376\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 382us/step - loss: 0.7686 - mse: 0.7686 - mae: 0.6745 - val_loss: 0.6337 - val_mse: 0.6337 - val_mae: 0.6308\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 406us/step - loss: 0.7639 - mse: 0.7639 - mae: 0.6708 - val_loss: 0.6289 - val_mse: 0.6289 - val_mae: 0.6256\n",
      "87\n",
      "[87]\n",
      "Train on 91 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 2s 17ms/step - loss: 14.6637 - mse: 14.6637 - mae: 3.1513 - val_loss: 3.6585 - val_mse: 3.6585 - val_mae: 1.7648\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 529us/step - loss: 12.9563 - mse: 12.9563 - mae: 2.8827 - val_loss: 3.1178 - val_mse: 3.1178 - val_mae: 1.6047\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 462us/step - loss: 11.4633 - mse: 11.4633 - mae: 2.6221 - val_loss: 2.6140 - val_mse: 2.6140 - val_mae: 1.4391\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 352us/step - loss: 10.1868 - mse: 10.1868 - mae: 2.3828 - val_loss: 2.1636 - val_mse: 2.1636 - val_mae: 1.2731\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 406us/step - loss: 9.1073 - mse: 9.1073 - mae: 2.1533 - val_loss: 1.7800 - val_mse: 1.7800 - val_mae: 1.1094\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 442us/step - loss: 8.2377 - mse: 8.2377 - mae: 1.9642 - val_loss: 1.4646 - val_mse: 1.4646 - val_mae: 0.9758\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 480us/step - loss: 7.5087 - mse: 7.5087 - mae: 1.8183 - val_loss: 1.2151 - val_mse: 1.2151 - val_mae: 0.8696\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 370us/step - loss: 6.8974 - mse: 6.8974 - mae: 1.7089 - val_loss: 1.0266 - val_mse: 1.0266 - val_mae: 0.7777\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 538us/step - loss: 6.4144 - mse: 6.4144 - mae: 1.6234 - val_loss: 0.8882 - val_mse: 0.8882 - val_mae: 0.7185\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 471us/step - loss: 6.0510 - mse: 6.0510 - mae: 1.5706 - val_loss: 0.7894 - val_mse: 0.7894 - val_mae: 0.6807\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 482us/step - loss: 5.7774 - mse: 5.7774 - mae: 1.5395 - val_loss: 0.7222 - val_mse: 0.7222 - val_mae: 0.6635\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 438us/step - loss: 5.5742 - mse: 5.5742 - mae: 1.5172 - val_loss: 0.6765 - val_mse: 0.6765 - val_mae: 0.6550\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 417us/step - loss: 5.4245 - mse: 5.4245 - mae: 1.4999 - val_loss: 0.6434 - val_mse: 0.6434 - val_mae: 0.6494\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 424us/step - loss: 5.3117 - mse: 5.3117 - mae: 1.4869 - val_loss: 0.6190 - val_mse: 0.6190 - val_mae: 0.6425\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 502us/step - loss: 5.2261 - mse: 5.2261 - mae: 1.4751 - val_loss: 0.5991 - val_mse: 0.5991 - val_mae: 0.6338\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 402us/step - loss: 5.1564 - mse: 5.1564 - mae: 1.4645 - val_loss: 0.5838 - val_mse: 0.5838 - val_mae: 0.6265\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 449us/step - loss: 5.0944 - mse: 5.0944 - mae: 1.4546 - val_loss: 0.5697 - val_mse: 0.5697 - val_mae: 0.6190\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 467us/step - loss: 5.0324 - mse: 5.0324 - mae: 1.4436 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.6108\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 345us/step - loss: 4.9785 - mse: 4.9785 - mae: 1.4338 - val_loss: 0.5419 - val_mse: 0.5419 - val_mae: 0.6028\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 875us/step - loss: 4.9289 - mse: 4.9289 - mae: 1.4243 - val_loss: 0.5298 - val_mse: 0.5298 - val_mae: 0.5955\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 484us/step - loss: 4.8803 - mse: 4.8803 - mae: 1.4148 - val_loss: 0.5201 - val_mse: 0.5201 - val_mae: 0.5893\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 648us/step - loss: 4.8307 - mse: 4.8307 - mae: 1.4067 - val_loss: 0.5109 - val_mse: 0.5109 - val_mae: 0.5835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 629us/step - loss: 4.7797 - mse: 4.7797 - mae: 1.3983 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.5780\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 503us/step - loss: 4.7285 - mse: 4.7285 - mae: 1.3905 - val_loss: 0.4946 - val_mse: 0.4946 - val_mae: 0.5726\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 405us/step - loss: 4.6789 - mse: 4.6789 - mae: 1.3833 - val_loss: 0.4869 - val_mse: 0.4869 - val_mae: 0.5670\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 375us/step - loss: 4.6318 - mse: 4.6318 - mae: 1.3768 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.5619\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 447us/step - loss: 4.5868 - mse: 4.5868 - mae: 1.3704 - val_loss: 0.4744 - val_mse: 0.4744 - val_mae: 0.5572\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 473us/step - loss: 4.5438 - mse: 4.5438 - mae: 1.3648 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5528\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 521us/step - loss: 4.5031 - mse: 4.5031 - mae: 1.3587 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.5481\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 553us/step - loss: 4.4635 - mse: 4.4635 - mae: 1.3520 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.5436\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 449us/step - loss: 4.4242 - mse: 4.4242 - mae: 1.3450 - val_loss: 0.4536 - val_mse: 0.4536 - val_mae: 0.5418\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 381us/step - loss: 4.3841 - mse: 4.3841 - mae: 1.3384 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.5412\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 274us/step - loss: 4.3455 - mse: 4.3455 - mae: 1.3316 - val_loss: 0.4472 - val_mse: 0.4472 - val_mae: 0.5409\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 602us/step - loss: 4.3080 - mse: 4.3080 - mae: 1.3254 - val_loss: 0.4461 - val_mse: 0.4461 - val_mae: 0.5415\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 769us/step - loss: 4.2711 - mse: 4.2711 - mae: 1.3190 - val_loss: 0.4467 - val_mse: 0.4467 - val_mae: 0.5440\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 729us/step - loss: 4.2348 - mse: 4.2348 - mae: 1.3129 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.5478\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 431us/step - loss: 4.1990 - mse: 4.1990 - mae: 1.3071 - val_loss: 0.4510 - val_mse: 0.4510 - val_mae: 0.5518\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 599us/step - loss: 4.1642 - mse: 4.1642 - mae: 1.3004 - val_loss: 0.4528 - val_mse: 0.4528 - val_mae: 0.5552\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 667us/step - loss: 4.1277 - mse: 4.1277 - mae: 1.2927 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.5589\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 732us/step - loss: 4.0888 - mse: 4.0888 - mae: 1.2841 - val_loss: 0.4585 - val_mse: 0.4585 - val_mae: 0.5634\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 535us/step - loss: 4.0501 - mse: 4.0501 - mae: 1.2751 - val_loss: 0.4623 - val_mse: 0.4623 - val_mae: 0.5677\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 756us/step - loss: 4.0129 - mse: 4.0129 - mae: 1.2656 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.5725\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 410us/step - loss: 3.9751 - mse: 3.9751 - mae: 1.2573 - val_loss: 0.4736 - val_mse: 0.4736 - val_mae: 0.5794\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 484us/step - loss: 3.9363 - mse: 3.9363 - mae: 1.2495 - val_loss: 0.4820 - val_mse: 0.4820 - val_mae: 0.5887\n",
      "88\n",
      "[88]\n",
      "Train on 102 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 10.6894 - mse: 10.6894 - mae: 2.8672 - val_loss: 5.0363 - val_mse: 5.0363 - val_mae: 1.9528\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 316us/step - loss: 9.0073 - mse: 9.0073 - mae: 2.5773 - val_loss: 4.1383 - val_mse: 4.1383 - val_mae: 1.7295\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 383us/step - loss: 7.7243 - mse: 7.7243 - mae: 2.3439 - val_loss: 3.5438 - val_mse: 3.5438 - val_mae: 1.5521\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 581us/step - loss: 6.8259 - mse: 6.8259 - mae: 2.1664 - val_loss: 3.0774 - val_mse: 3.0774 - val_mae: 1.4054\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 378us/step - loss: 6.2266 - mse: 6.2266 - mae: 2.0328 - val_loss: 2.7253 - val_mse: 2.7253 - val_mae: 1.2892\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 443us/step - loss: 5.7271 - mse: 5.7271 - mae: 1.9139 - val_loss: 2.4392 - val_mse: 2.4392 - val_mae: 1.1813\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 398us/step - loss: 5.2821 - mse: 5.2821 - mae: 1.8053 - val_loss: 2.2064 - val_mse: 2.2064 - val_mae: 1.0949\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 469us/step - loss: 4.8723 - mse: 4.8723 - mae: 1.7065 - val_loss: 1.9978 - val_mse: 1.9978 - val_mae: 1.0166\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 461us/step - loss: 4.4680 - mse: 4.4680 - mae: 1.6097 - val_loss: 1.8020 - val_mse: 1.8020 - val_mae: 0.9479\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 438us/step - loss: 4.0576 - mse: 4.0576 - mae: 1.5182 - val_loss: 1.6328 - val_mse: 1.6328 - val_mae: 0.9237\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 393us/step - loss: 3.6524 - mse: 3.6524 - mae: 1.4413 - val_loss: 1.5045 - val_mse: 1.5045 - val_mae: 0.9122\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 391us/step - loss: 3.2760 - mse: 3.2760 - mae: 1.3722 - val_loss: 1.4246 - val_mse: 1.4246 - val_mae: 0.9194\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 372us/step - loss: 2.9749 - mse: 2.9749 - mae: 1.3339 - val_loss: 1.3887 - val_mse: 1.3887 - val_mae: 0.9521\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 401us/step - loss: 2.7654 - mse: 2.7654 - mae: 1.3197 - val_loss: 1.3792 - val_mse: 1.3792 - val_mae: 0.9848\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 2.6336 - mse: 2.6336 - mae: 1.3130 - val_loss: 1.4057 - val_mse: 1.4057 - val_mae: 1.0128\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 394us/step - loss: 2.5652 - mse: 2.5652 - mae: 1.3141 - val_loss: 1.4444 - val_mse: 1.4444 - val_mae: 1.0406\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 448us/step - loss: 2.5367 - mse: 2.5367 - mae: 1.3190 - val_loss: 1.4730 - val_mse: 1.4730 - val_mae: 1.0549\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 468us/step - loss: 2.5115 - mse: 2.5115 - mae: 1.3169 - val_loss: 1.4857 - val_mse: 1.4857 - val_mae: 1.0600\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 479us/step - loss: 2.4759 - mse: 2.4759 - mae: 1.3079 - val_loss: 1.4843 - val_mse: 1.4843 - val_mae: 1.0584\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 658us/step - loss: 2.4340 - mse: 2.4340 - mae: 1.2947 - val_loss: 1.4741 - val_mse: 1.4741 - val_mae: 1.0522\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 493us/step - loss: 2.3925 - mse: 2.3925 - mae: 1.2799 - val_loss: 1.4626 - val_mse: 1.4626 - val_mae: 1.0447\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 338us/step - loss: 2.3546 - mse: 2.3546 - mae: 1.2667 - val_loss: 1.4548 - val_mse: 1.4548 - val_mae: 1.0384\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 507us/step - loss: 2.3199 - mse: 2.3199 - mae: 1.2550 - val_loss: 1.4516 - val_mse: 1.4516 - val_mae: 1.0351\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 410us/step - loss: 2.2871 - mse: 2.2871 - mae: 1.2448 - val_loss: 1.4509 - val_mse: 1.4509 - val_mae: 1.0363\n",
      "89\n",
      "[89]\n",
      "Train on 128 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "128/128 [==============================] - 2s 13ms/step - loss: 4.2546 - mse: 4.2546 - mae: 1.6978 - val_loss: 2.4782 - val_mse: 2.4782 - val_mae: 1.0973\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 0s 404us/step - loss: 3.0947 - mse: 3.0947 - mae: 1.3931 - val_loss: 1.9106 - val_mse: 1.9106 - val_mae: 0.9339\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 0s 554us/step - loss: 2.2927 - mse: 2.2927 - mae: 1.1618 - val_loss: 1.6562 - val_mse: 1.6562 - val_mae: 0.9500\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 0s 465us/step - loss: 1.9147 - mse: 1.9147 - mae: 1.0719 - val_loss: 1.6642 - val_mse: 1.6642 - val_mae: 1.0719\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 0s 371us/step - loss: 1.8772 - mse: 1.8772 - mae: 1.0950 - val_loss: 1.7516 - val_mse: 1.7516 - val_mae: 1.1573\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 0s 362us/step - loss: 1.9248 - mse: 1.9248 - mae: 1.1245 - val_loss: 1.7588 - val_mse: 1.7588 - val_mae: 1.1656\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 0s 312us/step - loss: 1.8940 - mse: 1.8940 - mae: 1.1102 - val_loss: 1.6966 - val_mse: 1.6966 - val_mae: 1.1204\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 0s 372us/step - loss: 1.8273 - mse: 1.8273 - mae: 1.0791 - val_loss: 1.6393 - val_mse: 1.6393 - val_mae: 1.0616\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 0s 459us/step - loss: 1.7868 - mse: 1.7868 - mae: 1.0506 - val_loss: 1.6125 - val_mse: 1.6125 - val_mae: 1.0210\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 0s 288us/step - loss: 1.7709 - mse: 1.7709 - mae: 1.0359 - val_loss: 1.6027 - val_mse: 1.6027 - val_mae: 1.0028\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 0s 344us/step - loss: 1.7569 - mse: 1.7569 - mae: 1.0284 - val_loss: 1.5995 - val_mse: 1.5995 - val_mae: 1.0023\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 0s 404us/step - loss: 1.7367 - mse: 1.7367 - mae: 1.0229 - val_loss: 1.6001 - val_mse: 1.6001 - val_mae: 1.0112\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 0s 805us/step - loss: 1.7174 - mse: 1.7174 - mae: 1.0197 - val_loss: 1.6018 - val_mse: 1.6018 - val_mae: 1.0259\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 0s 306us/step - loss: 1.7031 - mse: 1.7031 - mae: 1.0193 - val_loss: 1.6032 - val_mse: 1.6032 - val_mae: 1.0337\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 0s 451us/step - loss: 1.6921 - mse: 1.6921 - mae: 1.0178 - val_loss: 1.6010 - val_mse: 1.6010 - val_mae: 1.0317\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 0s 744us/step - loss: 1.6806 - mse: 1.6806 - mae: 1.0131 - val_loss: 1.5964 - val_mse: 1.5964 - val_mae: 1.0241\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 0s 849us/step - loss: 1.6694 - mse: 1.6694 - mae: 1.0073 - val_loss: 1.5927 - val_mse: 1.5927 - val_mae: 1.0176\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 0s 492us/step - loss: 1.6596 - mse: 1.6596 - mae: 1.0025 - val_loss: 1.5914 - val_mse: 1.5914 - val_mae: 1.0154\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 0s 620us/step - loss: 1.6499 - mse: 1.6499 - mae: 0.9986 - val_loss: 1.5922 - val_mse: 1.5922 - val_mae: 1.0169\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 0s 456us/step - loss: 1.6404 - mse: 1.6404 - mae: 0.9958 - val_loss: 1.5943 - val_mse: 1.5943 - val_mae: 1.0194\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 0s 337us/step - loss: 1.6314 - mse: 1.6314 - mae: 0.9933 - val_loss: 1.5969 - val_mse: 1.5969 - val_mae: 1.0216\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 0s 454us/step - loss: 1.6227 - mse: 1.6227 - mae: 0.9908 - val_loss: 1.5994 - val_mse: 1.5994 - val_mae: 1.0231\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 0s 449us/step - loss: 1.6144 - mse: 1.6144 - mae: 0.9882 - val_loss: 1.6022 - val_mse: 1.6022 - val_mae: 1.0241\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 0s 237us/step - loss: 1.6063 - mse: 1.6063 - mae: 0.9854 - val_loss: 1.6055 - val_mse: 1.6055 - val_mae: 1.0251\n",
      "Epoch 25/100\n",
      "128/128 [==============================] - 0s 447us/step - loss: 1.5984 - mse: 1.5984 - mae: 0.9825 - val_loss: 1.6093 - val_mse: 1.6093 - val_mae: 1.0260\n",
      "Epoch 26/100\n",
      "128/128 [==============================] - 0s 430us/step - loss: 1.5906 - mse: 1.5906 - mae: 0.9802 - val_loss: 1.6136 - val_mse: 1.6136 - val_mae: 1.0270\n",
      "Epoch 27/100\n",
      "128/128 [==============================] - 0s 508us/step - loss: 1.5831 - mse: 1.5831 - mae: 0.9782 - val_loss: 1.6182 - val_mse: 1.6182 - val_mae: 1.0286\n",
      "Epoch 28/100\n",
      "128/128 [==============================] - 0s 612us/step - loss: 1.5756 - mse: 1.5756 - mae: 0.9763 - val_loss: 1.6226 - val_mse: 1.6226 - val_mae: 1.0300\n",
      "90\n",
      "[90]\n",
      "Train on 75 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 23.9451 - mse: 23.9451 - mae: 4.5691 - val_loss: 19.8462 - val_mse: 19.8462 - val_mae: 4.2684\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 640us/step - loss: 21.9121 - mse: 21.9121 - mae: 4.3513 - val_loss: 18.2101 - val_mse: 18.2101 - val_mae: 4.0695\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 634us/step - loss: 20.0619 - mse: 20.0619 - mae: 4.1408 - val_loss: 16.7167 - val_mse: 16.7167 - val_mae: 3.8776\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 729us/step - loss: 18.3676 - mse: 18.3676 - mae: 3.9378 - val_loss: 15.3365 - val_mse: 15.3365 - val_mae: 3.6899\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 588us/step - loss: 16.8458 - mse: 16.8458 - mae: 3.7466 - val_loss: 14.1514 - val_mse: 14.1514 - val_mae: 3.5199\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 696us/step - loss: 15.4609 - mse: 15.4609 - mae: 3.5630 - val_loss: 13.1037 - val_mse: 13.1037 - val_mae: 3.3611\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 397us/step - loss: 14.2001 - mse: 14.2001 - mae: 3.3863 - val_loss: 12.1547 - val_mse: 12.1547 - val_mae: 3.2081\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 537us/step - loss: 13.0445 - mse: 13.0445 - mae: 3.2161 - val_loss: 11.2505 - val_mse: 11.2505 - val_mae: 3.0558\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 454us/step - loss: 11.9928 - mse: 11.9928 - mae: 3.0556 - val_loss: 10.4559 - val_mse: 10.4559 - val_mae: 2.9147\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 496us/step - loss: 11.0569 - mse: 11.0569 - mae: 2.9055 - val_loss: 9.7393 - val_mse: 9.7393 - val_mae: 2.7819\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 495us/step - loss: 10.2169 - mse: 10.2169 - mae: 2.7655 - val_loss: 9.1043 - val_mse: 9.1043 - val_mae: 2.6561\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 585us/step - loss: 9.4825 - mse: 9.4825 - mae: 2.6375 - val_loss: 8.5739 - val_mse: 8.5739 - val_mae: 2.5459\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 428us/step - loss: 8.8589 - mse: 8.8589 - mae: 2.5249 - val_loss: 8.0967 - val_mse: 8.0967 - val_mae: 2.4455\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 442us/step - loss: 8.3224 - mse: 8.3224 - mae: 2.4260 - val_loss: 7.6567 - val_mse: 7.6567 - val_mae: 2.3549\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 7.8481 - mse: 7.8481 - mae: 2.3367 - val_loss: 7.2510 - val_mse: 7.2510 - val_mae: 2.2692\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 471us/step - loss: 7.4708 - mse: 7.4708 - mae: 2.2613 - val_loss: 6.8740 - val_mse: 6.8740 - val_mae: 2.1928\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 454us/step - loss: 7.1572 - mse: 7.1572 - mae: 2.1975 - val_loss: 6.5373 - val_mse: 6.5373 - val_mae: 2.1277\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 414us/step - loss: 6.8958 - mse: 6.8958 - mae: 2.1414 - val_loss: 6.2556 - val_mse: 6.2556 - val_mae: 2.0727\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 876us/step - loss: 6.6643 - mse: 6.6643 - mae: 2.0895 - val_loss: 6.0019 - val_mse: 6.0019 - val_mae: 2.0204\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 997us/step - loss: 6.4681 - mse: 6.4681 - mae: 2.0437 - val_loss: 5.7973 - val_mse: 5.7973 - val_mae: 1.9726\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 6.2918 - mse: 6.2918 - mae: 2.0010 - val_loss: 5.6169 - val_mse: 5.6169 - val_mae: 1.9270\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 452us/step - loss: 6.1215 - mse: 6.1215 - mae: 1.9586 - val_loss: 5.4429 - val_mse: 5.4429 - val_mae: 1.8811\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 456us/step - loss: 5.9532 - mse: 5.9532 - mae: 1.9159 - val_loss: 5.2765 - val_mse: 5.2765 - val_mae: 1.8362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 545us/step - loss: 5.7858 - mse: 5.7858 - mae: 1.8721 - val_loss: 5.1110 - val_mse: 5.1110 - val_mae: 1.7906\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 716us/step - loss: 5.6270 - mse: 5.6270 - mae: 1.8282 - val_loss: 4.9615 - val_mse: 4.9615 - val_mae: 1.7465\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 454us/step - loss: 5.4683 - mse: 5.4683 - mae: 1.7838 - val_loss: 4.8108 - val_mse: 4.8108 - val_mae: 1.7007\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 442us/step - loss: 5.3086 - mse: 5.3086 - mae: 1.7377 - val_loss: 4.6524 - val_mse: 4.6524 - val_mae: 1.6517\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 480us/step - loss: 5.1447 - mse: 5.1447 - mae: 1.6891 - val_loss: 4.5003 - val_mse: 4.5003 - val_mae: 1.6023\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 4.9767 - mse: 4.9767 - mae: 1.6379 - val_loss: 4.3405 - val_mse: 4.3405 - val_mae: 1.5493\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 505us/step - loss: 4.8026 - mse: 4.8026 - mae: 1.5860 - val_loss: 4.1691 - val_mse: 4.1691 - val_mae: 1.5019\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 573us/step - loss: 4.6262 - mse: 4.6262 - mae: 1.5320 - val_loss: 3.9953 - val_mse: 3.9953 - val_mae: 1.4532\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 533us/step - loss: 4.4478 - mse: 4.4478 - mae: 1.4768 - val_loss: 3.8194 - val_mse: 3.8194 - val_mae: 1.4074\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 456us/step - loss: 4.2659 - mse: 4.2659 - mae: 1.4215 - val_loss: 3.6435 - val_mse: 3.6435 - val_mae: 1.3696\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 520us/step - loss: 4.0830 - mse: 4.0830 - mae: 1.3679 - val_loss: 3.4705 - val_mse: 3.4705 - val_mae: 1.3548\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 637us/step - loss: 3.8989 - mse: 3.8989 - mae: 1.3208 - val_loss: 3.2999 - val_mse: 3.2999 - val_mae: 1.3455\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 443us/step - loss: 3.7175 - mse: 3.7175 - mae: 1.2799 - val_loss: 3.1353 - val_mse: 3.1353 - val_mae: 1.3358\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 522us/step - loss: 3.5417 - mse: 3.5417 - mae: 1.2426 - val_loss: 2.9801 - val_mse: 2.9801 - val_mae: 1.3267\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 534us/step - loss: 3.3738 - mse: 3.3738 - mae: 1.2123 - val_loss: 2.8369 - val_mse: 2.8369 - val_mae: 1.3174\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 442us/step - loss: 3.2170 - mse: 3.2170 - mae: 1.1858 - val_loss: 2.7072 - val_mse: 2.7072 - val_mae: 1.3081\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 520us/step - loss: 3.0734 - mse: 3.0734 - mae: 1.1624 - val_loss: 2.5915 - val_mse: 2.5915 - val_mae: 1.2985\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 524us/step - loss: 2.9455 - mse: 2.9455 - mae: 1.1427 - val_loss: 2.4884 - val_mse: 2.4884 - val_mae: 1.2886\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 373us/step - loss: 2.8350 - mse: 2.8350 - mae: 1.1268 - val_loss: 2.4027 - val_mse: 2.4027 - val_mae: 1.2792\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 399us/step - loss: 2.7423 - mse: 2.7423 - mae: 1.1131 - val_loss: 2.3337 - val_mse: 2.3337 - val_mae: 1.2703\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 441us/step - loss: 2.6666 - mse: 2.6666 - mae: 1.0998 - val_loss: 2.2802 - val_mse: 2.2802 - val_mae: 1.2616\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 558us/step - loss: 2.6069 - mse: 2.6069 - mae: 1.0889 - val_loss: 2.2408 - val_mse: 2.2408 - val_mae: 1.2535\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 449us/step - loss: 2.5615 - mse: 2.5615 - mae: 1.0816 - val_loss: 2.2137 - val_mse: 2.2137 - val_mae: 1.2459\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 441us/step - loss: 2.5286 - mse: 2.5286 - mae: 1.0792 - val_loss: 2.1966 - val_mse: 2.1966 - val_mae: 1.2390\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 481us/step - loss: 2.5055 - mse: 2.5055 - mae: 1.0790 - val_loss: 2.1871 - val_mse: 2.1871 - val_mae: 1.2410\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 640us/step - loss: 2.4899 - mse: 2.4899 - mae: 1.0788 - val_loss: 2.1830 - val_mse: 2.1830 - val_mae: 1.2426\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 493us/step - loss: 2.4795 - mse: 2.4795 - mae: 1.0799 - val_loss: 2.1824 - val_mse: 2.1824 - val_mae: 1.2472\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 376us/step - loss: 2.4726 - mse: 2.4726 - mae: 1.0806 - val_loss: 2.1835 - val_mse: 2.1835 - val_mae: 1.2526\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 468us/step - loss: 2.4674 - mse: 2.4674 - mae: 1.0821 - val_loss: 2.1853 - val_mse: 2.1853 - val_mae: 1.2567\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 440us/step - loss: 2.4626 - mse: 2.4626 - mae: 1.0833 - val_loss: 2.1870 - val_mse: 2.1870 - val_mae: 1.2594\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 651us/step - loss: 2.4576 - mse: 2.4576 - mae: 1.0837 - val_loss: 2.1880 - val_mse: 2.1880 - val_mae: 1.2610\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 564us/step - loss: 2.4522 - mse: 2.4522 - mae: 1.0832 - val_loss: 2.1884 - val_mse: 2.1884 - val_mae: 1.2618\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 441us/step - loss: 2.4459 - mse: 2.4459 - mae: 1.0819 - val_loss: 2.1880 - val_mse: 2.1880 - val_mae: 1.2619\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 625us/step - loss: 2.4388 - mse: 2.4388 - mae: 1.0801 - val_loss: 2.1870 - val_mse: 2.1870 - val_mae: 1.2616\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 413us/step - loss: 2.4313 - mse: 2.4313 - mae: 1.0776 - val_loss: 2.1859 - val_mse: 2.1859 - val_mae: 1.2611\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 505us/step - loss: 2.4248 - mse: 2.4248 - mae: 1.0749 - val_loss: 2.1847 - val_mse: 2.1847 - val_mae: 1.2605\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 637us/step - loss: 2.4204 - mse: 2.4204 - mae: 1.0727 - val_loss: 2.1835 - val_mse: 2.1835 - val_mae: 1.2593\n",
      "91\n",
      "[91]\n",
      "Train on 108 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 10.5856 - mse: 10.5856 - mae: 2.7711 - val_loss: 4.8023 - val_mse: 4.8023 - val_mae: 1.8528\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 461us/step - loss: 8.9210 - mse: 8.9210 - mae: 2.4557 - val_loss: 4.0515 - val_mse: 4.0515 - val_mae: 1.6648\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 306us/step - loss: 7.8453 - mse: 7.8453 - mae: 2.2399 - val_loss: 3.6528 - val_mse: 3.6528 - val_mae: 1.5667\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 900us/step - loss: 7.1598 - mse: 7.1598 - mae: 2.1047 - val_loss: 3.3974 - val_mse: 3.3974 - val_mae: 1.4945\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 579us/step - loss: 6.6530 - mse: 6.6530 - mae: 1.9986 - val_loss: 3.1598 - val_mse: 3.1598 - val_mae: 1.4213\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 368us/step - loss: 6.2181 - mse: 6.2181 - mae: 1.8983 - val_loss: 2.9502 - val_mse: 2.9502 - val_mae: 1.3484\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 509us/step - loss: 5.8258 - mse: 5.8258 - mae: 1.8014 - val_loss: 2.7504 - val_mse: 2.7504 - val_mae: 1.2810\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 223us/step - loss: 5.4751 - mse: 5.4751 - mae: 1.7123 - val_loss: 2.5580 - val_mse: 2.5580 - val_mae: 1.2122\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 438us/step - loss: 5.1541 - mse: 5.1541 - mae: 1.6260 - val_loss: 2.3723 - val_mse: 2.3723 - val_mae: 1.1398\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 488us/step - loss: 4.8533 - mse: 4.8533 - mae: 1.5444 - val_loss: 2.1948 - val_mse: 2.1948 - val_mae: 1.0800\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 434us/step - loss: 4.5714 - mse: 4.5714 - mae: 1.4720 - val_loss: 2.0241 - val_mse: 2.0241 - val_mae: 1.0229\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 551us/step - loss: 4.3181 - mse: 4.3181 - mae: 1.4044 - val_loss: 1.8671 - val_mse: 1.8671 - val_mae: 0.9799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 416us/step - loss: 4.0771 - mse: 4.0771 - mae: 1.3435 - val_loss: 1.7252 - val_mse: 1.7252 - val_mae: 0.9389\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 411us/step - loss: 3.8594 - mse: 3.8594 - mae: 1.2923 - val_loss: 1.6017 - val_mse: 1.6017 - val_mae: 0.9004\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 502us/step - loss: 3.6716 - mse: 3.6716 - mae: 1.2552 - val_loss: 1.4977 - val_mse: 1.4977 - val_mae: 0.8749\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 294us/step - loss: 3.5175 - mse: 3.5175 - mae: 1.2283 - val_loss: 1.4129 - val_mse: 1.4129 - val_mae: 0.8693\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 451us/step - loss: 3.3966 - mse: 3.3966 - mae: 1.2114 - val_loss: 1.3489 - val_mse: 1.3489 - val_mae: 0.8726\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 579us/step - loss: 3.3047 - mse: 3.3047 - mae: 1.1975 - val_loss: 1.3035 - val_mse: 1.3035 - val_mae: 0.8801\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 251us/step - loss: 3.2374 - mse: 3.2374 - mae: 1.1863 - val_loss: 1.2731 - val_mse: 1.2731 - val_mae: 0.8893\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 341us/step - loss: 3.1897 - mse: 3.1897 - mae: 1.1816 - val_loss: 1.2534 - val_mse: 1.2534 - val_mae: 0.8967\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 452us/step - loss: 3.1519 - mse: 3.1519 - mae: 1.1816 - val_loss: 1.2398 - val_mse: 1.2398 - val_mae: 0.9022\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 379us/step - loss: 3.1204 - mse: 3.1204 - mae: 1.1828 - val_loss: 1.2261 - val_mse: 1.2261 - val_mae: 0.9045\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 587us/step - loss: 3.0925 - mse: 3.0925 - mae: 1.1822 - val_loss: 1.2114 - val_mse: 1.2114 - val_mae: 0.9044\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 511us/step - loss: 3.0634 - mse: 3.0634 - mae: 1.1793 - val_loss: 1.1954 - val_mse: 1.1954 - val_mae: 0.9024\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 418us/step - loss: 3.0329 - mse: 3.0329 - mae: 1.1752 - val_loss: 1.1773 - val_mse: 1.1773 - val_mae: 0.8992\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 369us/step - loss: 3.0018 - mse: 3.0018 - mae: 1.1699 - val_loss: 1.1605 - val_mse: 1.1605 - val_mae: 0.8964\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 436us/step - loss: 2.9713 - mse: 2.9713 - mae: 1.1639 - val_loss: 1.1447 - val_mse: 1.1447 - val_mae: 0.8937\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 474us/step - loss: 2.9436 - mse: 2.9436 - mae: 1.1573 - val_loss: 1.1300 - val_mse: 1.1300 - val_mae: 0.8910\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 535us/step - loss: 2.9160 - mse: 2.9160 - mae: 1.1500 - val_loss: 1.1188 - val_mse: 1.1188 - val_mae: 0.8893\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 466us/step - loss: 2.8917 - mse: 2.8917 - mae: 1.1434 - val_loss: 1.1098 - val_mse: 1.1098 - val_mae: 0.8880\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 408us/step - loss: 2.8704 - mse: 2.8704 - mae: 1.1377 - val_loss: 1.1019 - val_mse: 1.1019 - val_mae: 0.8864\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 288us/step - loss: 2.8524 - mse: 2.8524 - mae: 1.1325 - val_loss: 1.0950 - val_mse: 1.0950 - val_mae: 0.8844\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 618us/step - loss: 2.8350 - mse: 2.8350 - mae: 1.1273 - val_loss: 1.0879 - val_mse: 1.0879 - val_mae: 0.8824\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 2.8183 - mse: 2.8183 - mae: 1.1224 - val_loss: 1.0814 - val_mse: 1.0814 - val_mae: 0.8806\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 472us/step - loss: 2.8024 - mse: 2.8024 - mae: 1.1179 - val_loss: 1.0755 - val_mse: 1.0755 - val_mae: 0.8791\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 480us/step - loss: 2.7871 - mse: 2.7871 - mae: 1.1136 - val_loss: 1.0701 - val_mse: 1.0701 - val_mae: 0.8781\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 490us/step - loss: 2.7724 - mse: 2.7724 - mae: 1.1098 - val_loss: 1.0652 - val_mse: 1.0652 - val_mae: 0.8773\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 472us/step - loss: 2.7581 - mse: 2.7581 - mae: 1.1062 - val_loss: 1.0605 - val_mse: 1.0605 - val_mae: 0.8767\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 463us/step - loss: 2.7441 - mse: 2.7441 - mae: 1.1028 - val_loss: 1.0562 - val_mse: 1.0562 - val_mae: 0.8762\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 513us/step - loss: 2.7306 - mse: 2.7306 - mae: 1.1000 - val_loss: 1.0521 - val_mse: 1.0521 - val_mae: 0.8759\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 488us/step - loss: 2.7176 - mse: 2.7176 - mae: 1.0977 - val_loss: 1.0483 - val_mse: 1.0483 - val_mae: 0.8757\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 2.7049 - mse: 2.7049 - mae: 1.0957 - val_loss: 1.0446 - val_mse: 1.0446 - val_mae: 0.8756\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 0s 518us/step - loss: 2.6923 - mse: 2.6923 - mae: 1.0938 - val_loss: 1.0412 - val_mse: 1.0412 - val_mae: 0.8755\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 0s 555us/step - loss: 2.6800 - mse: 2.6800 - mae: 1.0919 - val_loss: 1.0380 - val_mse: 1.0380 - val_mae: 0.8754\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 0s 371us/step - loss: 2.6678 - mse: 2.6678 - mae: 1.0900 - val_loss: 1.0348 - val_mse: 1.0348 - val_mae: 0.8752\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 0s 680us/step - loss: 2.6561 - mse: 2.6561 - mae: 1.0881 - val_loss: 1.0315 - val_mse: 1.0315 - val_mae: 0.8751\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 0s 523us/step - loss: 2.6444 - mse: 2.6444 - mae: 1.0863 - val_loss: 1.0282 - val_mse: 1.0282 - val_mae: 0.8748\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 0s 523us/step - loss: 2.6329 - mse: 2.6329 - mae: 1.0844 - val_loss: 1.0249 - val_mse: 1.0249 - val_mae: 0.8746\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 0s 601us/step - loss: 2.6217 - mse: 2.6217 - mae: 1.0825 - val_loss: 1.0217 - val_mse: 1.0217 - val_mae: 0.8743\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 0s 428us/step - loss: 2.6106 - mse: 2.6106 - mae: 1.0805 - val_loss: 1.0185 - val_mse: 1.0185 - val_mae: 0.8739\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 0s 259us/step - loss: 2.6001 - mse: 2.6001 - mae: 1.0785 - val_loss: 1.0156 - val_mse: 1.0156 - val_mae: 0.8735\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 0s 369us/step - loss: 2.5896 - mse: 2.5896 - mae: 1.0764 - val_loss: 1.0130 - val_mse: 1.0130 - val_mae: 0.8732\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 0s 453us/step - loss: 2.5791 - mse: 2.5791 - mae: 1.0743 - val_loss: 1.0106 - val_mse: 1.0106 - val_mae: 0.8729\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 0s 360us/step - loss: 2.5686 - mse: 2.5686 - mae: 1.0722 - val_loss: 1.0082 - val_mse: 1.0082 - val_mae: 0.8726\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 0s 360us/step - loss: 2.5582 - mse: 2.5582 - mae: 1.0702 - val_loss: 1.0057 - val_mse: 1.0057 - val_mae: 0.8721\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 0s 548us/step - loss: 2.5479 - mse: 2.5479 - mae: 1.0682 - val_loss: 1.0032 - val_mse: 1.0032 - val_mae: 0.8716\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 0s 517us/step - loss: 2.5378 - mse: 2.5378 - mae: 1.0663 - val_loss: 1.0009 - val_mse: 1.0009 - val_mae: 0.8715\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 0s 484us/step - loss: 2.5278 - mse: 2.5278 - mae: 1.0644 - val_loss: 0.9992 - val_mse: 0.9992 - val_mae: 0.8716\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 0s 342us/step - loss: 2.5176 - mse: 2.5176 - mae: 1.0625 - val_loss: 0.9979 - val_mse: 0.9979 - val_mae: 0.8718\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 0s 355us/step - loss: 2.5074 - mse: 2.5074 - mae: 1.0608 - val_loss: 0.9964 - val_mse: 0.9964 - val_mae: 0.8720\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 0s 337us/step - loss: 2.4974 - mse: 2.4974 - mae: 1.0591 - val_loss: 0.9952 - val_mse: 0.9952 - val_mae: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "108/108 [==============================] - 0s 332us/step - loss: 2.4875 - mse: 2.4875 - mae: 1.0575 - val_loss: 0.9941 - val_mse: 0.9941 - val_mae: 0.8726\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 0s 419us/step - loss: 2.4778 - mse: 2.4778 - mae: 1.0561 - val_loss: 0.9929 - val_mse: 0.9929 - val_mae: 0.8728\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 0s 550us/step - loss: 2.4683 - mse: 2.4683 - mae: 1.0546 - val_loss: 0.9923 - val_mse: 0.9923 - val_mae: 0.8732\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 0s 680us/step - loss: 2.4589 - mse: 2.4589 - mae: 1.0530 - val_loss: 0.9915 - val_mse: 0.9915 - val_mae: 0.8735\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 0s 637us/step - loss: 2.4497 - mse: 2.4497 - mae: 1.0518 - val_loss: 0.9900 - val_mse: 0.9900 - val_mae: 0.8739\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 0s 502us/step - loss: 2.4407 - mse: 2.4407 - mae: 1.0508 - val_loss: 0.9884 - val_mse: 0.9884 - val_mae: 0.8746\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 0s 433us/step - loss: 2.4316 - mse: 2.4316 - mae: 1.0500 - val_loss: 0.9874 - val_mse: 0.9874 - val_mae: 0.8754\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 0s 342us/step - loss: 2.4228 - mse: 2.4228 - mae: 1.0492 - val_loss: 0.9869 - val_mse: 0.9869 - val_mae: 0.8760\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 0s 362us/step - loss: 2.4143 - mse: 2.4143 - mae: 1.0481 - val_loss: 0.9871 - val_mse: 0.9871 - val_mae: 0.8765\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - 0s 693us/step - loss: 2.4057 - mse: 2.4057 - mae: 1.0470 - val_loss: 0.9863 - val_mse: 0.9863 - val_mae: 0.8768\n",
      "Epoch 72/100\n",
      "108/108 [==============================] - 0s 509us/step - loss: 2.3974 - mse: 2.3974 - mae: 1.0458 - val_loss: 0.9849 - val_mse: 0.9849 - val_mae: 0.8771\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 0s 521us/step - loss: 2.3892 - mse: 2.3892 - mae: 1.0447 - val_loss: 0.9836 - val_mse: 0.9836 - val_mae: 0.8774\n",
      "Epoch 74/100\n",
      "108/108 [==============================] - 0s 362us/step - loss: 2.3811 - mse: 2.3811 - mae: 1.0434 - val_loss: 0.9828 - val_mse: 0.9828 - val_mae: 0.8773\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 0s 345us/step - loss: 2.3730 - mse: 2.3730 - mae: 1.0418 - val_loss: 0.9830 - val_mse: 0.9830 - val_mae: 0.8772\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 0s 368us/step - loss: 2.3657 - mse: 2.3657 - mae: 1.0402 - val_loss: 0.9828 - val_mse: 0.9828 - val_mae: 0.8771\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 0s 456us/step - loss: 2.3577 - mse: 2.3577 - mae: 1.0384 - val_loss: 0.9813 - val_mse: 0.9813 - val_mae: 0.8769\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 0s 371us/step - loss: 2.3501 - mse: 2.3501 - mae: 1.0369 - val_loss: 0.9801 - val_mse: 0.9801 - val_mae: 0.8769\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 0s 324us/step - loss: 2.3425 - mse: 2.3425 - mae: 1.0353 - val_loss: 0.9799 - val_mse: 0.9799 - val_mae: 0.8765\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 0s 353us/step - loss: 2.3347 - mse: 2.3347 - mae: 1.0335 - val_loss: 0.9793 - val_mse: 0.9793 - val_mae: 0.8760\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 0s 308us/step - loss: 2.3268 - mse: 2.3268 - mae: 1.0320 - val_loss: 0.9777 - val_mse: 0.9777 - val_mae: 0.8755\n",
      "Epoch 82/100\n",
      "108/108 [==============================] - 0s 389us/step - loss: 2.3189 - mse: 2.3189 - mae: 1.0305 - val_loss: 0.9765 - val_mse: 0.9765 - val_mae: 0.8748\n",
      "Epoch 83/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 2.3114 - mse: 2.3114 - mae: 1.0289 - val_loss: 0.9760 - val_mse: 0.9760 - val_mae: 0.8743\n",
      "Epoch 84/100\n",
      "108/108 [==============================] - 0s 584us/step - loss: 2.3038 - mse: 2.3038 - mae: 1.0273 - val_loss: 0.9759 - val_mse: 0.9759 - val_mae: 0.8740\n",
      "Epoch 85/100\n",
      "108/108 [==============================] - 0s 498us/step - loss: 2.2961 - mse: 2.2961 - mae: 1.0255 - val_loss: 0.9744 - val_mse: 0.9744 - val_mae: 0.8736\n",
      "Epoch 86/100\n",
      "108/108 [==============================] - 0s 406us/step - loss: 2.2888 - mse: 2.2888 - mae: 1.0239 - val_loss: 0.9737 - val_mse: 0.9737 - val_mae: 0.8731\n",
      "Epoch 87/100\n",
      "108/108 [==============================] - 0s 438us/step - loss: 2.2807 - mse: 2.2807 - mae: 1.0220 - val_loss: 0.9735 - val_mse: 0.9735 - val_mae: 0.8724\n",
      "Epoch 88/100\n",
      "108/108 [==============================] - 0s 427us/step - loss: 2.2723 - mse: 2.2723 - mae: 1.0201 - val_loss: 0.9721 - val_mse: 0.9721 - val_mae: 0.8717\n",
      "Epoch 89/100\n",
      "108/108 [==============================] - 0s 590us/step - loss: 2.2645 - mse: 2.2645 - mae: 1.0185 - val_loss: 0.9713 - val_mse: 0.9713 - val_mae: 0.8710\n",
      "Epoch 90/100\n",
      "108/108 [==============================] - 0s 486us/step - loss: 2.2560 - mse: 2.2560 - mae: 1.0163 - val_loss: 0.9719 - val_mse: 0.9719 - val_mae: 0.8705\n",
      "Epoch 91/100\n",
      "108/108 [==============================] - 0s 478us/step - loss: 2.2489 - mse: 2.2489 - mae: 1.0142 - val_loss: 0.9724 - val_mse: 0.9724 - val_mae: 0.8700\n",
      "Epoch 92/100\n",
      "108/108 [==============================] - 0s 295us/step - loss: 2.2407 - mse: 2.2407 - mae: 1.0120 - val_loss: 0.9721 - val_mse: 0.9721 - val_mae: 0.8696\n",
      "Epoch 93/100\n",
      "108/108 [==============================] - 0s 408us/step - loss: 2.2325 - mse: 2.2325 - mae: 1.0100 - val_loss: 0.9730 - val_mse: 0.9730 - val_mae: 0.8692\n",
      "Epoch 94/100\n",
      "108/108 [==============================] - 0s 285us/step - loss: 2.2247 - mse: 2.2247 - mae: 1.0079 - val_loss: 0.9740 - val_mse: 0.9740 - val_mae: 0.8689\n",
      "Epoch 95/100\n",
      "108/108 [==============================] - 0s 632us/step - loss: 2.2162 - mse: 2.2162 - mae: 1.0059 - val_loss: 0.9744 - val_mse: 0.9744 - val_mae: 0.8689\n",
      "Epoch 96/100\n",
      "108/108 [==============================] - 0s 442us/step - loss: 2.2083 - mse: 2.2083 - mae: 1.0038 - val_loss: 0.9764 - val_mse: 0.9764 - val_mae: 0.8690\n",
      "Epoch 97/100\n",
      "108/108 [==============================] - 0s 480us/step - loss: 2.2008 - mse: 2.2008 - mae: 1.0015 - val_loss: 0.9776 - val_mse: 0.9776 - val_mae: 0.8691\n",
      "Epoch 98/100\n",
      "108/108 [==============================] - 0s 551us/step - loss: 2.1922 - mse: 2.1922 - mae: 0.9998 - val_loss: 0.9776 - val_mse: 0.9776 - val_mae: 0.8692\n",
      "Epoch 99/100\n",
      "108/108 [==============================] - 0s 437us/step - loss: 2.1841 - mse: 2.1841 - mae: 0.9980 - val_loss: 0.9793 - val_mse: 0.9793 - val_mae: 0.8690\n",
      "92\n",
      "[92]\n",
      "Train on 84 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 4.4735 - mse: 4.4735 - mae: 1.6345 - val_loss: 3.8640 - val_mse: 3.8640 - val_mae: 1.6913\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 437us/step - loss: 3.9416 - mse: 3.9416 - mae: 1.5276 - val_loss: 3.3288 - val_mse: 3.3288 - val_mae: 1.5725\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 445us/step - loss: 3.5386 - mse: 3.5386 - mae: 1.4707 - val_loss: 2.9082 - val_mse: 2.9082 - val_mae: 1.4472\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 331us/step - loss: 3.2649 - mse: 3.2649 - mae: 1.4241 - val_loss: 2.5916 - val_mse: 2.5916 - val_mae: 1.3271\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 509us/step - loss: 3.0715 - mse: 3.0715 - mae: 1.3862 - val_loss: 2.3640 - val_mse: 2.3640 - val_mae: 1.2646\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 353us/step - loss: 2.9319 - mse: 2.9319 - mae: 1.3559 - val_loss: 2.1917 - val_mse: 2.1917 - val_mae: 1.2218\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 639us/step - loss: 2.8123 - mse: 2.8123 - mae: 1.3259 - val_loss: 2.0555 - val_mse: 2.0555 - val_mae: 1.1862\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 188us/step - loss: 2.6895 - mse: 2.6895 - mae: 1.2935 - val_loss: 1.9512 - val_mse: 1.9512 - val_mae: 1.1593\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 404us/step - loss: 2.5588 - mse: 2.5588 - mae: 1.2563 - val_loss: 1.8781 - val_mse: 1.8781 - val_mae: 1.1413\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 541us/step - loss: 2.4267 - mse: 2.4267 - mae: 1.2141 - val_loss: 1.8215 - val_mse: 1.8215 - val_mae: 1.1258\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 417us/step - loss: 2.3079 - mse: 2.3079 - mae: 1.1734 - val_loss: 1.7821 - val_mse: 1.7821 - val_mae: 1.1138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 476us/step - loss: 2.2088 - mse: 2.2088 - mae: 1.1347 - val_loss: 1.7607 - val_mse: 1.7607 - val_mae: 1.1046\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 465us/step - loss: 2.1236 - mse: 2.1236 - mae: 1.0979 - val_loss: 1.7435 - val_mse: 1.7435 - val_mae: 1.0932\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 410us/step - loss: 2.0559 - mse: 2.0559 - mae: 1.0688 - val_loss: 1.7220 - val_mse: 1.7220 - val_mae: 1.0786\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 501us/step - loss: 1.9986 - mse: 1.9986 - mae: 1.0500 - val_loss: 1.6999 - val_mse: 1.6999 - val_mae: 1.0629\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 417us/step - loss: 1.9494 - mse: 1.9494 - mae: 1.0404 - val_loss: 1.6752 - val_mse: 1.6752 - val_mae: 1.0459\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 284us/step - loss: 1.9055 - mse: 1.9055 - mae: 1.0372 - val_loss: 1.6500 - val_mse: 1.6500 - val_mae: 1.0352\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 503us/step - loss: 1.8680 - mse: 1.8680 - mae: 1.0362 - val_loss: 1.6279 - val_mse: 1.6279 - val_mae: 1.0305\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 475us/step - loss: 1.8340 - mse: 1.8340 - mae: 1.0349 - val_loss: 1.6134 - val_mse: 1.6134 - val_mae: 1.0265\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 430us/step - loss: 1.8045 - mse: 1.8045 - mae: 1.0309 - val_loss: 1.6052 - val_mse: 1.6052 - val_mae: 1.0248\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 658us/step - loss: 1.7780 - mse: 1.7780 - mae: 1.0242 - val_loss: 1.6035 - val_mse: 1.6035 - val_mae: 1.0276\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 572us/step - loss: 1.7529 - mse: 1.7529 - mae: 1.0143 - val_loss: 1.6131 - val_mse: 1.6131 - val_mae: 1.0330\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 387us/step - loss: 1.7288 - mse: 1.7288 - mae: 1.0026 - val_loss: 1.6255 - val_mse: 1.6255 - val_mae: 1.0388\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 384us/step - loss: 1.7066 - mse: 1.7066 - mae: 0.9908 - val_loss: 1.6379 - val_mse: 1.6379 - val_mae: 1.0445\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 417us/step - loss: 1.6877 - mse: 1.6877 - mae: 0.9809 - val_loss: 1.6393 - val_mse: 1.6393 - val_mae: 1.0458\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 380us/step - loss: 1.6699 - mse: 1.6699 - mae: 0.9746 - val_loss: 1.6306 - val_mse: 1.6306 - val_mae: 1.0431\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 416us/step - loss: 1.6516 - mse: 1.6516 - mae: 0.9707 - val_loss: 1.6183 - val_mse: 1.6183 - val_mae: 1.0386\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 746us/step - loss: 1.6336 - mse: 1.6336 - mae: 0.9669 - val_loss: 1.6121 - val_mse: 1.6121 - val_mae: 1.0363\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 375us/step - loss: 1.6163 - mse: 1.6163 - mae: 0.9620 - val_loss: 1.6062 - val_mse: 1.6062 - val_mae: 1.0335\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 935us/step - loss: 1.5995 - mse: 1.5995 - mae: 0.9561 - val_loss: 1.6057 - val_mse: 1.6057 - val_mae: 1.0327\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 791us/step - loss: 1.5828 - mse: 1.5828 - mae: 0.9485 - val_loss: 1.6065 - val_mse: 1.6065 - val_mae: 1.0320\n",
      "93\n",
      "[93]\n",
      "Train on 78 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 12.4001 - mse: 12.4001 - mae: 3.2853 - val_loss: 7.9036 - val_mse: 7.9036 - val_mae: 2.5284\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 367us/step - loss: 10.2793 - mse: 10.2793 - mae: 2.9629 - val_loss: 6.6045 - val_mse: 6.6045 - val_mae: 2.2684\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 518us/step - loss: 8.4901 - mse: 8.4901 - mae: 2.6643 - val_loss: 5.5287 - val_mse: 5.5287 - val_mae: 2.0277\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 425us/step - loss: 6.9903 - mse: 6.9903 - mae: 2.3850 - val_loss: 4.6594 - val_mse: 4.6594 - val_mae: 1.8184\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 240us/step - loss: 5.7503 - mse: 5.7503 - mae: 2.1264 - val_loss: 3.9372 - val_mse: 3.9372 - val_mae: 1.6369\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 641us/step - loss: 4.7360 - mse: 4.7360 - mae: 1.8887 - val_loss: 3.3453 - val_mse: 3.3453 - val_mae: 1.4765\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 547us/step - loss: 3.9187 - mse: 3.9187 - mae: 1.6752 - val_loss: 2.8523 - val_mse: 2.8523 - val_mae: 1.3280\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 883us/step - loss: 3.2827 - mse: 3.2827 - mae: 1.4893 - val_loss: 2.4584 - val_mse: 2.4584 - val_mae: 1.1917\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 2.8021 - mse: 2.8021 - mae: 1.3317 - val_loss: 2.1855 - val_mse: 2.1855 - val_mae: 1.0777\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 704us/step - loss: 2.4244 - mse: 2.4244 - mae: 1.1977 - val_loss: 1.9609 - val_mse: 1.9609 - val_mae: 0.9842\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 390us/step - loss: 2.1315 - mse: 2.1315 - mae: 1.0835 - val_loss: 1.7742 - val_mse: 1.7742 - val_mae: 0.8978\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 402us/step - loss: 1.9056 - mse: 1.9056 - mae: 0.9917 - val_loss: 1.6239 - val_mse: 1.6239 - val_mae: 0.8194\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 304us/step - loss: 1.7250 - mse: 1.7250 - mae: 0.9110 - val_loss: 1.5046 - val_mse: 1.5046 - val_mae: 0.7551\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 335us/step - loss: 1.5731 - mse: 1.5731 - mae: 0.8455 - val_loss: 1.4141 - val_mse: 1.4141 - val_mae: 0.7024\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 371us/step - loss: 1.4478 - mse: 1.4478 - mae: 0.7924 - val_loss: 1.3428 - val_mse: 1.3428 - val_mae: 0.6860\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 750us/step - loss: 1.3458 - mse: 1.3458 - mae: 0.7475 - val_loss: 1.2845 - val_mse: 1.2845 - val_mae: 0.6849\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 562us/step - loss: 1.2671 - mse: 1.2671 - mae: 0.7200 - val_loss: 1.2380 - val_mse: 1.2380 - val_mae: 0.6845\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 603us/step - loss: 1.2065 - mse: 1.2065 - mae: 0.7020 - val_loss: 1.2002 - val_mse: 1.2002 - val_mae: 0.6830\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 436us/step - loss: 1.1567 - mse: 1.1567 - mae: 0.6934 - val_loss: 1.1713 - val_mse: 1.1713 - val_mae: 0.6810\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 703us/step - loss: 1.1174 - mse: 1.1174 - mae: 0.6932 - val_loss: 1.1514 - val_mse: 1.1514 - val_mae: 0.6899\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 489us/step - loss: 1.0897 - mse: 1.0897 - mae: 0.6996 - val_loss: 1.1373 - val_mse: 1.1373 - val_mae: 0.7065\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 349us/step - loss: 1.0716 - mse: 1.0716 - mae: 0.7098 - val_loss: 1.1312 - val_mse: 1.1312 - val_mae: 0.7231\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 475us/step - loss: 1.0608 - mse: 1.0608 - mae: 0.7196 - val_loss: 1.1269 - val_mse: 1.1269 - val_mae: 0.7429\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 644us/step - loss: 1.0549 - mse: 1.0549 - mae: 0.7282 - val_loss: 1.1268 - val_mse: 1.1268 - val_mae: 0.7588\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 428us/step - loss: 1.0506 - mse: 1.0506 - mae: 0.7338 - val_loss: 1.1271 - val_mse: 1.1271 - val_mae: 0.7695\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 922us/step - loss: 1.0468 - mse: 1.0468 - mae: 0.7373 - val_loss: 1.1287 - val_mse: 1.1287 - val_mae: 0.7773\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 403us/step - loss: 1.0432 - mse: 1.0432 - mae: 0.7390 - val_loss: 1.1283 - val_mse: 1.1283 - val_mae: 0.7799\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.0385 - mse: 1.0385 - mae: 0.7384 - val_loss: 1.1266 - val_mse: 1.1266 - val_mae: 0.7790\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 0s 505us/step - loss: 1.0326 - mse: 1.0326 - mae: 0.7363 - val_loss: 1.1247 - val_mse: 1.1247 - val_mae: 0.7765\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 0s 685us/step - loss: 1.0264 - mse: 1.0264 - mae: 0.7335 - val_loss: 1.1231 - val_mse: 1.1231 - val_mae: 0.7732\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 0s 727us/step - loss: 1.0202 - mse: 1.0202 - mae: 0.7303 - val_loss: 1.1223 - val_mse: 1.1223 - val_mae: 0.7698\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 0s 622us/step - loss: 1.0141 - mse: 1.0141 - mae: 0.7270 - val_loss: 1.1224 - val_mse: 1.1224 - val_mae: 0.7668\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 0s 604us/step - loss: 1.0083 - mse: 1.0083 - mae: 0.7238 - val_loss: 1.1230 - val_mse: 1.1230 - val_mae: 0.7640\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 0s 590us/step - loss: 1.0026 - mse: 1.0026 - mae: 0.7205 - val_loss: 1.1246 - val_mse: 1.1246 - val_mae: 0.7620\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 0s 373us/step - loss: 0.9971 - mse: 0.9971 - mae: 0.7176 - val_loss: 1.1268 - val_mse: 1.1268 - val_mae: 0.7607\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 0s 420us/step - loss: 0.9921 - mse: 0.9921 - mae: 0.7152 - val_loss: 1.1294 - val_mse: 1.1294 - val_mae: 0.7598\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 0s 706us/step - loss: 0.9875 - mse: 0.9875 - mae: 0.7130 - val_loss: 1.1322 - val_mse: 1.1322 - val_mae: 0.7592\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 0s 476us/step - loss: 0.9835 - mse: 0.9835 - mae: 0.7111 - val_loss: 1.1350 - val_mse: 1.1350 - val_mae: 0.7589\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 0s 640us/step - loss: 0.9798 - mse: 0.9798 - mae: 0.7093 - val_loss: 1.1378 - val_mse: 1.1378 - val_mae: 0.7588\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 0s 465us/step - loss: 0.9761 - mse: 0.9761 - mae: 0.7077 - val_loss: 1.1409 - val_mse: 1.1409 - val_mae: 0.7592\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 0s 705us/step - loss: 0.9726 - mse: 0.9726 - mae: 0.7065 - val_loss: 1.1442 - val_mse: 1.1442 - val_mae: 0.7601\n",
      "94\n",
      "[94]\n",
      "Train on 75 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 1.0587 - mse: 1.0587 - mae: 0.8779 - val_loss: 1.7292 - val_mse: 1.7292 - val_mae: 1.0790\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 704us/step - loss: 0.8985 - mse: 0.8985 - mae: 0.7917 - val_loss: 1.5410 - val_mse: 1.5410 - val_mae: 1.0114\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 574us/step - loss: 0.7837 - mse: 0.7837 - mae: 0.7069 - val_loss: 1.4294 - val_mse: 1.4294 - val_mae: 0.9541\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 521us/step - loss: 0.7212 - mse: 0.7212 - mae: 0.6372 - val_loss: 1.3776 - val_mse: 1.3776 - val_mae: 0.9357\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 585us/step - loss: 0.6987 - mse: 0.6987 - mae: 0.5880 - val_loss: 1.3663 - val_mse: 1.3663 - val_mae: 0.9327\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 872us/step - loss: 0.7004 - mse: 0.7004 - mae: 0.5590 - val_loss: 1.3727 - val_mse: 1.3727 - val_mae: 0.9298\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 620us/step - loss: 0.7109 - mse: 0.7109 - mae: 0.5488 - val_loss: 1.3785 - val_mse: 1.3785 - val_mae: 0.9270\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 405us/step - loss: 0.7182 - mse: 0.7182 - mae: 0.5454 - val_loss: 1.3746 - val_mse: 1.3746 - val_mae: 0.9239\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 480us/step - loss: 0.7177 - mse: 0.7177 - mae: 0.5451 - val_loss: 1.3604 - val_mse: 1.3604 - val_mae: 0.9207\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 653us/step - loss: 0.7108 - mse: 0.7108 - mae: 0.5466 - val_loss: 1.3412 - val_mse: 1.3412 - val_mae: 0.9175\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 799us/step - loss: 0.7013 - mse: 0.7013 - mae: 0.5498 - val_loss: 1.3230 - val_mse: 1.3230 - val_mae: 0.9149\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 601us/step - loss: 0.6933 - mse: 0.6933 - mae: 0.5553 - val_loss: 1.3073 - val_mse: 1.3073 - val_mae: 0.9117\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 410us/step - loss: 0.6879 - mse: 0.6879 - mae: 0.5620 - val_loss: 1.2947 - val_mse: 1.2947 - val_mae: 0.9082\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 618us/step - loss: 0.6849 - mse: 0.6849 - mae: 0.5701 - val_loss: 1.2844 - val_mse: 1.2844 - val_mae: 0.9046\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 406us/step - loss: 0.6828 - mse: 0.6828 - mae: 0.5762 - val_loss: 1.2750 - val_mse: 1.2750 - val_mae: 0.9013\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 841us/step - loss: 0.6809 - mse: 0.6809 - mae: 0.5785 - val_loss: 1.2662 - val_mse: 1.2662 - val_mae: 0.8982\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 467us/step - loss: 0.6788 - mse: 0.6788 - mae: 0.5775 - val_loss: 1.2581 - val_mse: 1.2581 - val_mae: 0.8955\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 429us/step - loss: 0.6766 - mse: 0.6766 - mae: 0.5741 - val_loss: 1.2506 - val_mse: 1.2506 - val_mae: 0.8930\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 452us/step - loss: 0.6746 - mse: 0.6746 - mae: 0.5689 - val_loss: 1.2437 - val_mse: 1.2437 - val_mae: 0.8904\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 708us/step - loss: 0.6729 - mse: 0.6729 - mae: 0.5631 - val_loss: 1.2367 - val_mse: 1.2367 - val_mae: 0.8872\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 602us/step - loss: 0.6719 - mse: 0.6719 - mae: 0.5581 - val_loss: 1.2302 - val_mse: 1.2302 - val_mae: 0.8841\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 654us/step - loss: 0.6710 - mse: 0.6710 - mae: 0.5548 - val_loss: 1.2240 - val_mse: 1.2240 - val_mae: 0.8812\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 534us/step - loss: 0.6699 - mse: 0.6699 - mae: 0.5532 - val_loss: 1.2177 - val_mse: 1.2177 - val_mae: 0.8784\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 691us/step - loss: 0.6686 - mse: 0.6686 - mae: 0.5528 - val_loss: 1.2113 - val_mse: 1.2113 - val_mae: 0.8758\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 631us/step - loss: 0.6670 - mse: 0.6670 - mae: 0.5535 - val_loss: 1.2051 - val_mse: 1.2051 - val_mae: 0.8731\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 527us/step - loss: 0.6653 - mse: 0.6653 - mae: 0.5546 - val_loss: 1.1986 - val_mse: 1.1986 - val_mae: 0.8702\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 585us/step - loss: 0.6635 - mse: 0.6635 - mae: 0.5553 - val_loss: 1.1924 - val_mse: 1.1924 - val_mae: 0.8673\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 494us/step - loss: 0.6616 - mse: 0.6616 - mae: 0.5555 - val_loss: 1.1878 - val_mse: 1.1878 - val_mae: 0.8656\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 560us/step - loss: 0.6597 - mse: 0.6597 - mae: 0.5549 - val_loss: 1.1842 - val_mse: 1.1842 - val_mae: 0.8639\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 481us/step - loss: 0.6581 - mse: 0.6581 - mae: 0.5537 - val_loss: 1.1809 - val_mse: 1.1809 - val_mae: 0.8627\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 507us/step - loss: 0.6567 - mse: 0.6567 - mae: 0.5531 - val_loss: 1.1767 - val_mse: 1.1767 - val_mae: 0.8622\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 615us/step - loss: 0.6553 - mse: 0.6553 - mae: 0.5536 - val_loss: 1.1725 - val_mse: 1.1725 - val_mae: 0.8618\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 480us/step - loss: 0.6535 - mse: 0.6535 - mae: 0.5536 - val_loss: 1.1694 - val_mse: 1.1694 - val_mae: 0.8611\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 452us/step - loss: 0.6520 - mse: 0.6520 - mae: 0.5530 - val_loss: 1.1667 - val_mse: 1.1667 - val_mae: 0.8601\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 443us/step - loss: 0.6506 - mse: 0.6506 - mae: 0.5518 - val_loss: 1.1640 - val_mse: 1.1640 - val_mae: 0.8591\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 874us/step - loss: 0.6494 - mse: 0.6494 - mae: 0.5512 - val_loss: 1.1606 - val_mse: 1.1606 - val_mae: 0.8584\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 668us/step - loss: 0.6479 - mse: 0.6479 - mae: 0.5507 - val_loss: 1.1577 - val_mse: 1.1577 - val_mae: 0.8575\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 458us/step - loss: 0.6467 - mse: 0.6467 - mae: 0.5500 - val_loss: 1.1549 - val_mse: 1.1549 - val_mae: 0.8570\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 548us/step - loss: 0.6455 - mse: 0.6455 - mae: 0.5502 - val_loss: 1.1518 - val_mse: 1.1518 - val_mae: 0.8567\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 838us/step - loss: 0.6443 - mse: 0.6443 - mae: 0.5502 - val_loss: 1.1491 - val_mse: 1.1491 - val_mae: 0.8561\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 552us/step - loss: 0.6433 - mse: 0.6433 - mae: 0.5494 - val_loss: 1.1463 - val_mse: 1.1463 - val_mae: 0.8555\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 507us/step - loss: 0.6425 - mse: 0.6425 - mae: 0.5494 - val_loss: 1.1419 - val_mse: 1.1419 - val_mae: 0.8551\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 524us/step - loss: 0.6415 - mse: 0.6415 - mae: 0.5502 - val_loss: 1.1375 - val_mse: 1.1375 - val_mae: 0.8545\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 685us/step - loss: 0.6404 - mse: 0.6404 - mae: 0.5502 - val_loss: 1.1347 - val_mse: 1.1347 - val_mae: 0.8539\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 530us/step - loss: 0.6393 - mse: 0.6393 - mae: 0.5495 - val_loss: 1.1324 - val_mse: 1.1324 - val_mae: 0.8533\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 510us/step - loss: 0.6385 - mse: 0.6385 - mae: 0.5494 - val_loss: 1.1298 - val_mse: 1.1298 - val_mae: 0.8529\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 441us/step - loss: 0.6375 - mse: 0.6375 - mae: 0.5487 - val_loss: 1.1269 - val_mse: 1.1269 - val_mae: 0.8522\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6366 - mse: 0.6366 - mae: 0.5484 - val_loss: 1.1227 - val_mse: 1.1227 - val_mae: 0.8518\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 877us/step - loss: 0.6359 - mse: 0.6359 - mae: 0.5493 - val_loss: 1.1189 - val_mse: 1.1189 - val_mae: 0.8518\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 0.6349 - mse: 0.6349 - mae: 0.5498 - val_loss: 1.1167 - val_mse: 1.1167 - val_mae: 0.8515\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 797us/step - loss: 0.6338 - mse: 0.6338 - mae: 0.5492 - val_loss: 1.1156 - val_mse: 1.1156 - val_mae: 0.8509\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 738us/step - loss: 0.6330 - mse: 0.6330 - mae: 0.5481 - val_loss: 1.1143 - val_mse: 1.1143 - val_mae: 0.8505\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 653us/step - loss: 0.6322 - mse: 0.6322 - mae: 0.5476 - val_loss: 1.1109 - val_mse: 1.1109 - val_mae: 0.8504\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 741us/step - loss: 0.6315 - mse: 0.6315 - mae: 0.5481 - val_loss: 1.1071 - val_mse: 1.1071 - val_mae: 0.8502\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 500us/step - loss: 0.6305 - mse: 0.6305 - mae: 0.5484 - val_loss: 1.1044 - val_mse: 1.1044 - val_mae: 0.8498\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 399us/step - loss: 0.6295 - mse: 0.6295 - mae: 0.5481 - val_loss: 1.1033 - val_mse: 1.1033 - val_mae: 0.8495\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 705us/step - loss: 0.6286 - mse: 0.6286 - mae: 0.5475 - val_loss: 1.1019 - val_mse: 1.1019 - val_mae: 0.8498\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 614us/step - loss: 0.6277 - mse: 0.6277 - mae: 0.5480 - val_loss: 1.1004 - val_mse: 1.1004 - val_mae: 0.8508\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 479us/step - loss: 0.6264 - mse: 0.6264 - mae: 0.5482 - val_loss: 1.0996 - val_mse: 1.0996 - val_mae: 0.8515\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 695us/step - loss: 0.6251 - mse: 0.6251 - mae: 0.5475 - val_loss: 1.0993 - val_mse: 1.0993 - val_mae: 0.8520\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 855us/step - loss: 0.6241 - mse: 0.6241 - mae: 0.5464 - val_loss: 1.0994 - val_mse: 1.0994 - val_mae: 0.8533\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 441us/step - loss: 0.6232 - mse: 0.6232 - mae: 0.5466 - val_loss: 1.0990 - val_mse: 1.0990 - val_mae: 0.8551\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 602us/step - loss: 0.6221 - mse: 0.6221 - mae: 0.5472 - val_loss: 1.0984 - val_mse: 1.0984 - val_mae: 0.8563\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 522us/step - loss: 0.6211 - mse: 0.6211 - mae: 0.5472 - val_loss: 1.0967 - val_mse: 1.0967 - val_mae: 0.8571\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 550us/step - loss: 0.6203 - mse: 0.6203 - mae: 0.5477 - val_loss: 1.0935 - val_mse: 1.0935 - val_mae: 0.8575\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 618us/step - loss: 0.6194 - mse: 0.6194 - mae: 0.5483 - val_loss: 1.0920 - val_mse: 1.0920 - val_mae: 0.8582\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 450us/step - loss: 0.6183 - mse: 0.6183 - mae: 0.5483 - val_loss: 1.0925 - val_mse: 1.0925 - val_mae: 0.8592\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 473us/step - loss: 0.6174 - mse: 0.6174 - mae: 0.5479 - val_loss: 1.0918 - val_mse: 1.0918 - val_mae: 0.8599\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 588us/step - loss: 0.6165 - mse: 0.6165 - mae: 0.5484 - val_loss: 1.0896 - val_mse: 1.0896 - val_mae: 0.8604\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 432us/step - loss: 0.6154 - mse: 0.6154 - mae: 0.5486 - val_loss: 1.0874 - val_mse: 1.0874 - val_mae: 0.8605\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 466us/step - loss: 0.6145 - mse: 0.6145 - mae: 0.5487 - val_loss: 1.0862 - val_mse: 1.0862 - val_mae: 0.8611\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 629us/step - loss: 0.6134 - mse: 0.6134 - mae: 0.5480 - val_loss: 1.0834 - val_mse: 1.0834 - val_mae: 0.8602\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 0.6127 - mse: 0.6127 - mae: 0.5476 - val_loss: 1.0800 - val_mse: 1.0800 - val_mae: 0.8591\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 492us/step - loss: 0.6116 - mse: 0.6116 - mae: 0.5471 - val_loss: 1.0774 - val_mse: 1.0774 - val_mae: 0.8588\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 439us/step - loss: 0.6109 - mse: 0.6109 - mae: 0.5476 - val_loss: 1.0747 - val_mse: 1.0747 - val_mae: 0.8588\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 350us/step - loss: 0.6097 - mse: 0.6097 - mae: 0.5475 - val_loss: 1.0735 - val_mse: 1.0735 - val_mae: 0.8583\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 410us/step - loss: 0.6086 - mse: 0.6086 - mae: 0.5462 - val_loss: 1.0724 - val_mse: 1.0724 - val_mae: 0.8582\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 652us/step - loss: 0.6076 - mse: 0.6076 - mae: 0.5461 - val_loss: 1.0703 - val_mse: 1.0703 - val_mae: 0.8584\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 613us/step - loss: 0.6065 - mse: 0.6065 - mae: 0.5464 - val_loss: 1.0673 - val_mse: 1.0673 - val_mae: 0.8576\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 505us/step - loss: 0.6057 - mse: 0.6057 - mae: 0.5464 - val_loss: 1.0641 - val_mse: 1.0641 - val_mae: 0.8568\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 474us/step - loss: 0.6045 - mse: 0.6045 - mae: 0.5454 - val_loss: 1.0626 - val_mse: 1.0626 - val_mae: 0.8564\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 615us/step - loss: 0.6038 - mse: 0.6038 - mae: 0.5459 - val_loss: 1.0597 - val_mse: 1.0597 - val_mae: 0.8562\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 479us/step - loss: 0.6027 - mse: 0.6027 - mae: 0.5462 - val_loss: 1.0607 - val_mse: 1.0607 - val_mae: 0.8565\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 492us/step - loss: 0.6015 - mse: 0.6015 - mae: 0.5451 - val_loss: 1.0637 - val_mse: 1.0637 - val_mae: 0.8574\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 406us/step - loss: 0.6009 - mse: 0.6009 - mae: 0.5450 - val_loss: 1.0651 - val_mse: 1.0651 - val_mae: 0.8588\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 680us/step - loss: 0.5999 - mse: 0.5999 - mae: 0.5450 - val_loss: 1.0611 - val_mse: 1.0611 - val_mae: 0.8581\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 370us/step - loss: 0.5992 - mse: 0.5992 - mae: 0.5458 - val_loss: 1.0555 - val_mse: 1.0555 - val_mae: 0.8566\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 569us/step - loss: 0.5980 - mse: 0.5980 - mae: 0.5457 - val_loss: 1.0549 - val_mse: 1.0549 - val_mae: 0.8560\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 434us/step - loss: 0.5967 - mse: 0.5967 - mae: 0.5443 - val_loss: 1.0582 - val_mse: 1.0582 - val_mae: 0.8572\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 508us/step - loss: 0.5956 - mse: 0.5956 - mae: 0.5441 - val_loss: 1.0602 - val_mse: 1.0602 - val_mae: 0.8584\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 731us/step - loss: 0.5948 - mse: 0.5948 - mae: 0.5442 - val_loss: 1.0592 - val_mse: 1.0592 - val_mae: 0.8583\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 714us/step - loss: 0.5938 - mse: 0.5938 - mae: 0.5442 - val_loss: 1.0571 - val_mse: 1.0571 - val_mae: 0.8582\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 667us/step - loss: 0.5929 - mse: 0.5929 - mae: 0.5440 - val_loss: 1.0552 - val_mse: 1.0552 - val_mae: 0.8572\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 543us/step - loss: 0.5921 - mse: 0.5921 - mae: 0.5428 - val_loss: 1.0552 - val_mse: 1.0552 - val_mae: 0.8574\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 473us/step - loss: 0.5912 - mse: 0.5912 - mae: 0.5436 - val_loss: 1.0547 - val_mse: 1.0547 - val_mae: 0.8582\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 475us/step - loss: 0.5900 - mse: 0.5900 - mae: 0.5445 - val_loss: 1.0543 - val_mse: 1.0543 - val_mae: 0.8583\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 480us/step - loss: 0.5892 - mse: 0.5892 - mae: 0.5453 - val_loss: 1.0530 - val_mse: 1.0530 - val_mae: 0.8580\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 575us/step - loss: 0.5880 - mse: 0.5880 - mae: 0.5445 - val_loss: 1.0520 - val_mse: 1.0520 - val_mae: 0.8574\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 789us/step - loss: 0.5871 - mse: 0.5871 - mae: 0.5440 - val_loss: 1.0508 - val_mse: 1.0508 - val_mae: 0.8570\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 384us/step - loss: 0.5861 - mse: 0.5861 - mae: 0.5433 - val_loss: 1.0513 - val_mse: 1.0513 - val_mae: 0.8565\n",
      "95\n",
      "[95]\n",
      "Train on 101 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 5.9789 - mse: 5.9789 - mae: 2.0570 - val_loss: 6.7590 - val_mse: 6.7590 - val_mae: 2.1574\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 420us/step - loss: 5.1664 - mse: 5.1664 - mae: 1.8484 - val_loss: 6.0064 - val_mse: 6.0064 - val_mae: 1.9292\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 367us/step - loss: 4.4280 - mse: 4.4280 - mae: 1.6319 - val_loss: 5.2841 - val_mse: 5.2841 - val_mae: 1.7323\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 387us/step - loss: 3.6686 - mse: 3.6686 - mae: 1.4227 - val_loss: 4.4019 - val_mse: 4.4019 - val_mae: 1.5745\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 442us/step - loss: 2.9931 - mse: 2.9931 - mae: 1.2882 - val_loss: 3.6505 - val_mse: 3.6505 - val_mae: 1.4325\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 635us/step - loss: 2.5001 - mse: 2.5001 - mae: 1.2116 - val_loss: 3.1980 - val_mse: 3.1980 - val_mae: 1.3594\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 411us/step - loss: 2.2620 - mse: 2.2620 - mae: 1.1883 - val_loss: 2.9959 - val_mse: 2.9959 - val_mae: 1.3425\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 444us/step - loss: 2.2054 - mse: 2.2054 - mae: 1.1930 - val_loss: 2.9399 - val_mse: 2.9399 - val_mae: 1.3640\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 376us/step - loss: 2.2194 - mse: 2.2194 - mae: 1.1995 - val_loss: 2.9284 - val_mse: 2.9284 - val_mae: 1.3732\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 646us/step - loss: 2.2165 - mse: 2.2165 - mae: 1.1973 - val_loss: 2.9091 - val_mse: 2.9091 - val_mae: 1.3683\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 483us/step - loss: 2.1713 - mse: 2.1713 - mae: 1.1834 - val_loss: 2.8791 - val_mse: 2.8791 - val_mae: 1.3550\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 463us/step - loss: 2.1053 - mse: 2.1053 - mae: 1.1622 - val_loss: 2.8534 - val_mse: 2.8534 - val_mae: 1.3377\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 344us/step - loss: 2.0447 - mse: 2.0447 - mae: 1.1433 - val_loss: 2.8370 - val_mse: 2.8370 - val_mae: 1.3191\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 519us/step - loss: 1.9994 - mse: 1.9994 - mae: 1.1275 - val_loss: 2.8281 - val_mse: 2.8281 - val_mae: 1.3021\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 375us/step - loss: 1.9680 - mse: 1.9680 - mae: 1.1160 - val_loss: 2.8202 - val_mse: 2.8202 - val_mae: 1.2884\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 425us/step - loss: 1.9434 - mse: 1.9434 - mae: 1.1062 - val_loss: 2.8072 - val_mse: 2.8072 - val_mae: 1.2791\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 348us/step - loss: 1.9206 - mse: 1.9206 - mae: 1.0977 - val_loss: 2.7889 - val_mse: 2.7889 - val_mae: 1.2736\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 336us/step - loss: 1.8979 - mse: 1.8979 - mae: 1.0904 - val_loss: 2.7693 - val_mse: 2.7693 - val_mae: 1.2697\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 365us/step - loss: 1.8761 - mse: 1.8761 - mae: 1.0836 - val_loss: 2.7498 - val_mse: 2.7498 - val_mae: 1.2670\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 822us/step - loss: 1.8564 - mse: 1.8564 - mae: 1.0774 - val_loss: 2.7311 - val_mse: 2.7311 - val_mae: 1.2643\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 457us/step - loss: 1.8386 - mse: 1.8386 - mae: 1.0730 - val_loss: 2.7131 - val_mse: 2.7131 - val_mae: 1.2614\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 837us/step - loss: 1.8213 - mse: 1.8213 - mae: 1.0686 - val_loss: 2.6948 - val_mse: 2.6948 - val_mae: 1.2580\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 449us/step - loss: 1.8038 - mse: 1.8038 - mae: 1.0636 - val_loss: 2.6783 - val_mse: 2.6783 - val_mae: 1.2538\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 477us/step - loss: 1.7864 - mse: 1.7864 - mae: 1.0582 - val_loss: 2.6633 - val_mse: 2.6633 - val_mae: 1.2490\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 806us/step - loss: 1.7695 - mse: 1.7695 - mae: 1.0528 - val_loss: 2.6490 - val_mse: 2.6490 - val_mae: 1.2435\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 743us/step - loss: 1.7544 - mse: 1.7544 - mae: 1.0478 - val_loss: 2.6353 - val_mse: 2.6353 - val_mae: 1.2381\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 765us/step - loss: 1.7402 - mse: 1.7402 - mae: 1.0429 - val_loss: 2.6233 - val_mse: 2.6233 - val_mae: 1.2334\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 646us/step - loss: 1.7270 - mse: 1.7270 - mae: 1.0382 - val_loss: 2.6124 - val_mse: 2.6124 - val_mae: 1.2293\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 521us/step - loss: 1.7148 - mse: 1.7148 - mae: 1.0342 - val_loss: 2.6011 - val_mse: 2.6011 - val_mae: 1.2253\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 523us/step - loss: 1.7035 - mse: 1.7035 - mae: 1.0306 - val_loss: 2.5892 - val_mse: 2.5892 - val_mae: 1.2216\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 580us/step - loss: 1.6930 - mse: 1.6930 - mae: 1.0274 - val_loss: 2.5779 - val_mse: 2.5779 - val_mae: 1.2182\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 541us/step - loss: 1.6818 - mse: 1.6818 - mae: 1.0238 - val_loss: 2.5677 - val_mse: 2.5677 - val_mae: 1.2153\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 370us/step - loss: 1.6709 - mse: 1.6709 - mae: 1.0202 - val_loss: 2.5580 - val_mse: 2.5580 - val_mae: 1.2124\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 362us/step - loss: 1.6604 - mse: 1.6604 - mae: 1.0166 - val_loss: 2.5486 - val_mse: 2.5486 - val_mae: 1.2096\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 518us/step - loss: 1.6501 - mse: 1.6501 - mae: 1.0129 - val_loss: 2.5395 - val_mse: 2.5395 - val_mae: 1.2075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 656us/step - loss: 1.6404 - mse: 1.6404 - mae: 1.0095 - val_loss: 2.5300 - val_mse: 2.5300 - val_mae: 1.2058\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 358us/step - loss: 1.6314 - mse: 1.6314 - mae: 1.0063 - val_loss: 2.5204 - val_mse: 2.5204 - val_mae: 1.2042\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 437us/step - loss: 1.6233 - mse: 1.6233 - mae: 1.0034 - val_loss: 2.5102 - val_mse: 2.5102 - val_mae: 1.2025\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 698us/step - loss: 1.6150 - mse: 1.6150 - mae: 1.0004 - val_loss: 2.4998 - val_mse: 2.4998 - val_mae: 1.2007\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 872us/step - loss: 1.6069 - mse: 1.6069 - mae: 0.9973 - val_loss: 2.4897 - val_mse: 2.4897 - val_mae: 1.1987\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 408us/step - loss: 1.5989 - mse: 1.5989 - mae: 0.9941 - val_loss: 2.4809 - val_mse: 2.4809 - val_mae: 1.1969\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 442us/step - loss: 1.5909 - mse: 1.5909 - mae: 0.9908 - val_loss: 2.4727 - val_mse: 2.4727 - val_mae: 1.1951\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 420us/step - loss: 1.5831 - mse: 1.5831 - mae: 0.9876 - val_loss: 2.4646 - val_mse: 2.4646 - val_mae: 1.1932\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 677us/step - loss: 1.5752 - mse: 1.5752 - mae: 0.9845 - val_loss: 2.4565 - val_mse: 2.4565 - val_mae: 1.1911\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 691us/step - loss: 1.5676 - mse: 1.5676 - mae: 0.9817 - val_loss: 2.4483 - val_mse: 2.4483 - val_mae: 1.1891\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 428us/step - loss: 1.5599 - mse: 1.5599 - mae: 0.9789 - val_loss: 2.4412 - val_mse: 2.4412 - val_mae: 1.1874\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 416us/step - loss: 1.5520 - mse: 1.5520 - mae: 0.9756 - val_loss: 2.4348 - val_mse: 2.4348 - val_mae: 1.1862\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 405us/step - loss: 1.5441 - mse: 1.5441 - mae: 0.9722 - val_loss: 2.4287 - val_mse: 2.4287 - val_mae: 1.1852\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 419us/step - loss: 1.5365 - mse: 1.5365 - mae: 0.9691 - val_loss: 2.4229 - val_mse: 2.4229 - val_mae: 1.1841\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 387us/step - loss: 1.5292 - mse: 1.5292 - mae: 0.9662 - val_loss: 2.4174 - val_mse: 2.4174 - val_mae: 1.1830\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 521us/step - loss: 1.5221 - mse: 1.5221 - mae: 0.9635 - val_loss: 2.4119 - val_mse: 2.4119 - val_mae: 1.1820\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 484us/step - loss: 1.5150 - mse: 1.5150 - mae: 0.9608 - val_loss: 2.4067 - val_mse: 2.4067 - val_mae: 1.1813\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 943us/step - loss: 1.5076 - mse: 1.5076 - mae: 0.9579 - val_loss: 2.4023 - val_mse: 2.4023 - val_mae: 1.1805\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 389us/step - loss: 1.5001 - mse: 1.5001 - mae: 0.9547 - val_loss: 2.3982 - val_mse: 2.3982 - val_mae: 1.1795\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 396us/step - loss: 1.4930 - mse: 1.4930 - mae: 0.9517 - val_loss: 2.3930 - val_mse: 2.3930 - val_mae: 1.1780\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 406us/step - loss: 1.4861 - mse: 1.4861 - mae: 0.9488 - val_loss: 2.3877 - val_mse: 2.3877 - val_mae: 1.1767\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 732us/step - loss: 1.4791 - mse: 1.4791 - mae: 0.9460 - val_loss: 2.3826 - val_mse: 2.3826 - val_mae: 1.1759\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 453us/step - loss: 1.4725 - mse: 1.4725 - mae: 0.9434 - val_loss: 2.3781 - val_mse: 2.3781 - val_mae: 1.1753\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 569us/step - loss: 1.4659 - mse: 1.4659 - mae: 0.9410 - val_loss: 2.3745 - val_mse: 2.3745 - val_mae: 1.1747\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 0s 347us/step - loss: 1.4593 - mse: 1.4593 - mae: 0.9385 - val_loss: 2.3721 - val_mse: 2.3721 - val_mae: 1.1739\n",
      "Epoch 61/100\n",
      "101/101 [==============================] - 0s 446us/step - loss: 1.4526 - mse: 1.4526 - mae: 0.9358 - val_loss: 2.3700 - val_mse: 2.3700 - val_mae: 1.1731\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 0s 388us/step - loss: 1.4462 - mse: 1.4462 - mae: 0.9333 - val_loss: 2.3683 - val_mse: 2.3683 - val_mae: 1.1725\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 0s 498us/step - loss: 1.4400 - mse: 1.4400 - mae: 0.9308 - val_loss: 2.3678 - val_mse: 2.3678 - val_mae: 1.1722\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 0s 686us/step - loss: 1.4339 - mse: 1.4339 - mae: 0.9284 - val_loss: 2.3674 - val_mse: 2.3674 - val_mae: 1.1717\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 0s 559us/step - loss: 1.4281 - mse: 1.4281 - mae: 0.9259 - val_loss: 2.3664 - val_mse: 2.3664 - val_mae: 1.1712\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 0s 848us/step - loss: 1.4224 - mse: 1.4224 - mae: 0.9233 - val_loss: 2.3643 - val_mse: 2.3643 - val_mae: 1.1705\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 0s 375us/step - loss: 1.4169 - mse: 1.4169 - mae: 0.9211 - val_loss: 2.3622 - val_mse: 2.3622 - val_mae: 1.1698\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 0s 435us/step - loss: 1.4108 - mse: 1.4108 - mae: 0.9186 - val_loss: 2.3608 - val_mse: 2.3608 - val_mae: 1.1691\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 0s 433us/step - loss: 1.4053 - mse: 1.4053 - mae: 0.9162 - val_loss: 2.3594 - val_mse: 2.3594 - val_mae: 1.1701\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 0s 414us/step - loss: 1.3997 - mse: 1.3997 - mae: 0.9141 - val_loss: 2.3575 - val_mse: 2.3575 - val_mae: 1.1717\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 0s 399us/step - loss: 1.3941 - mse: 1.3941 - mae: 0.9121 - val_loss: 2.3549 - val_mse: 2.3549 - val_mae: 1.1729\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 0s 425us/step - loss: 1.3886 - mse: 1.3886 - mae: 0.9100 - val_loss: 2.3523 - val_mse: 2.3523 - val_mae: 1.1741\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 0s 426us/step - loss: 1.3829 - mse: 1.3829 - mae: 0.9079 - val_loss: 2.3501 - val_mse: 2.3501 - val_mae: 1.1757\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 0s 440us/step - loss: 1.3772 - mse: 1.3772 - mae: 0.9061 - val_loss: 2.3487 - val_mse: 2.3487 - val_mae: 1.1772\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 0s 398us/step - loss: 1.3715 - mse: 1.3715 - mae: 0.9041 - val_loss: 2.3471 - val_mse: 2.3471 - val_mae: 1.1789\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 0s 473us/step - loss: 1.3652 - mse: 1.3652 - mae: 0.9018 - val_loss: 2.3451 - val_mse: 2.3451 - val_mae: 1.1801\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 0s 484us/step - loss: 1.3596 - mse: 1.3596 - mae: 0.8997 - val_loss: 2.3437 - val_mse: 2.3437 - val_mae: 1.1822\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 0s 360us/step - loss: 1.3532 - mse: 1.3532 - mae: 0.8975 - val_loss: 2.3429 - val_mse: 2.3429 - val_mae: 1.1848\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 0s 533us/step - loss: 1.3471 - mse: 1.3471 - mae: 0.8954 - val_loss: 2.3427 - val_mse: 2.3427 - val_mae: 1.1864\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 0s 326us/step - loss: 1.3415 - mse: 1.3415 - mae: 0.8931 - val_loss: 2.3415 - val_mse: 2.3415 - val_mae: 1.1873\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 0s 783us/step - loss: 1.3356 - mse: 1.3356 - mae: 0.8905 - val_loss: 2.3402 - val_mse: 2.3402 - val_mae: 1.1886\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - 0s 851us/step - loss: 1.3294 - mse: 1.3294 - mae: 0.8880 - val_loss: 2.3396 - val_mse: 2.3396 - val_mae: 1.1907\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 0s 447us/step - loss: 1.3232 - mse: 1.3232 - mae: 0.8856 - val_loss: 2.3392 - val_mse: 2.3392 - val_mae: 1.1920\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 0s 456us/step - loss: 1.3170 - mse: 1.3170 - mae: 0.8831 - val_loss: 2.3387 - val_mse: 2.3387 - val_mae: 1.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "101/101 [==============================] - 0s 705us/step - loss: 1.3110 - mse: 1.3110 - mae: 0.8806 - val_loss: 2.3382 - val_mse: 2.3382 - val_mae: 1.1951\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 0s 610us/step - loss: 1.3050 - mse: 1.3050 - mae: 0.8782 - val_loss: 2.3377 - val_mse: 2.3377 - val_mae: 1.1970\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - 0s 597us/step - loss: 1.2994 - mse: 1.2994 - mae: 0.8759 - val_loss: 2.3374 - val_mse: 2.3374 - val_mae: 1.1988\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 0s 518us/step - loss: 1.2932 - mse: 1.2932 - mae: 0.8733 - val_loss: 2.3362 - val_mse: 2.3362 - val_mae: 1.2004\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 0s 562us/step - loss: 1.2864 - mse: 1.2864 - mae: 0.8703 - val_loss: 2.3346 - val_mse: 2.3346 - val_mae: 1.2024\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 0s 548us/step - loss: 1.2794 - mse: 1.2794 - mae: 0.8674 - val_loss: 2.3324 - val_mse: 2.3324 - val_mae: 1.2030\n",
      "Epoch 91/100\n",
      "101/101 [==============================] - 0s 372us/step - loss: 1.2718 - mse: 1.2718 - mae: 0.8636 - val_loss: 2.3297 - val_mse: 2.3297 - val_mae: 1.2030\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 0s 477us/step - loss: 1.2655 - mse: 1.2655 - mae: 0.8606 - val_loss: 2.3289 - val_mse: 2.3289 - val_mae: 1.2041\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 0s 441us/step - loss: 1.2586 - mse: 1.2586 - mae: 0.8572 - val_loss: 2.3287 - val_mse: 2.3287 - val_mae: 1.2060\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 0s 908us/step - loss: 1.2516 - mse: 1.2516 - mae: 0.8539 - val_loss: 2.3278 - val_mse: 2.3278 - val_mae: 1.2058\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 0s 336us/step - loss: 1.2453 - mse: 1.2453 - mae: 0.8509 - val_loss: 2.3281 - val_mse: 2.3281 - val_mae: 1.2070\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 0s 339us/step - loss: 1.2398 - mse: 1.2398 - mae: 0.8491 - val_loss: 2.3282 - val_mse: 2.3282 - val_mae: 1.2090\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 0s 196us/step - loss: 1.2331 - mse: 1.2331 - mae: 0.8464 - val_loss: 2.3263 - val_mse: 2.3263 - val_mae: 1.2083\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 0s 595us/step - loss: 1.2276 - mse: 1.2276 - mae: 0.8439 - val_loss: 2.3261 - val_mse: 2.3261 - val_mae: 1.2089\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 0s 638us/step - loss: 1.2223 - mse: 1.2223 - mae: 0.8422 - val_loss: 2.3258 - val_mse: 2.3258 - val_mae: 1.2098\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 0s 428us/step - loss: 1.2167 - mse: 1.2167 - mae: 0.8395 - val_loss: 2.3252 - val_mse: 2.3252 - val_mae: 1.2101\n",
      "96\n",
      "[96]\n",
      "Train on 94 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 9.2862 - mse: 9.2862 - mae: 2.6477 - val_loss: 6.0243 - val_mse: 6.0243 - val_mae: 1.9812\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 669us/step - loss: 7.6249 - mse: 7.6249 - mae: 2.3236 - val_loss: 4.9386 - val_mse: 4.9386 - val_mae: 1.6777\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 695us/step - loss: 6.3237 - mse: 6.3237 - mae: 2.0394 - val_loss: 4.1265 - val_mse: 4.1265 - val_mae: 1.4121\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 565us/step - loss: 5.3217 - mse: 5.3217 - mae: 1.7963 - val_loss: 3.5555 - val_mse: 3.5555 - val_mae: 1.2851\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 409us/step - loss: 4.5044 - mse: 4.5044 - mae: 1.5914 - val_loss: 3.1521 - val_mse: 3.1521 - val_mae: 1.2339\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 393us/step - loss: 3.7937 - mse: 3.7937 - mae: 1.4159 - val_loss: 2.8219 - val_mse: 2.8219 - val_mae: 1.2154\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 539us/step - loss: 3.2298 - mse: 3.2298 - mae: 1.2932 - val_loss: 2.6731 - val_mse: 2.6731 - val_mae: 1.2216\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 443us/step - loss: 2.8828 - mse: 2.8828 - mae: 1.2500 - val_loss: 2.6631 - val_mse: 2.6631 - val_mae: 1.2727\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 406us/step - loss: 2.7112 - mse: 2.7112 - mae: 1.2448 - val_loss: 2.7342 - val_mse: 2.7342 - val_mae: 1.3234\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 481us/step - loss: 2.6551 - mse: 2.6551 - mae: 1.2492 - val_loss: 2.7931 - val_mse: 2.7931 - val_mae: 1.3474\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 511us/step - loss: 2.6331 - mse: 2.6331 - mae: 1.2558 - val_loss: 2.7923 - val_mse: 2.7923 - val_mae: 1.3463\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 531us/step - loss: 2.5847 - mse: 2.5847 - mae: 1.2490 - val_loss: 2.7373 - val_mse: 2.7373 - val_mae: 1.3268\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 552us/step - loss: 2.5048 - mse: 2.5048 - mae: 1.2287 - val_loss: 2.6568 - val_mse: 2.6568 - val_mae: 1.2968\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 923us/step - loss: 2.4167 - mse: 2.4167 - mae: 1.2044 - val_loss: 2.5813 - val_mse: 2.5813 - val_mae: 1.2652\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 541us/step - loss: 2.3392 - mse: 2.3392 - mae: 1.1810 - val_loss: 2.5123 - val_mse: 2.5123 - val_mae: 1.2344\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 562us/step - loss: 2.2764 - mse: 2.2764 - mae: 1.1597 - val_loss: 2.4587 - val_mse: 2.4587 - val_mae: 1.2077\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 403us/step - loss: 2.2231 - mse: 2.2231 - mae: 1.1423 - val_loss: 2.4252 - val_mse: 2.4252 - val_mae: 1.1888\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 414us/step - loss: 2.1755 - mse: 2.1755 - mae: 1.1283 - val_loss: 2.4009 - val_mse: 2.4009 - val_mae: 1.1759\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 467us/step - loss: 2.1320 - mse: 2.1320 - mae: 1.1184 - val_loss: 2.3859 - val_mse: 2.3859 - val_mae: 1.1679\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 371us/step - loss: 2.0926 - mse: 2.0926 - mae: 1.1117 - val_loss: 2.3771 - val_mse: 2.3771 - val_mae: 1.1614\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 541us/step - loss: 2.0573 - mse: 2.0573 - mae: 1.1075 - val_loss: 2.3714 - val_mse: 2.3714 - val_mae: 1.1544\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 403us/step - loss: 2.0239 - mse: 2.0239 - mae: 1.1018 - val_loss: 2.3678 - val_mse: 2.3678 - val_mae: 1.1496\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 403us/step - loss: 1.9928 - mse: 1.9928 - mae: 1.0949 - val_loss: 2.3648 - val_mse: 2.3648 - val_mae: 1.1439\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 488us/step - loss: 1.9644 - mse: 1.9644 - mae: 1.0875 - val_loss: 2.3633 - val_mse: 2.3633 - val_mae: 1.1378\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 361us/step - loss: 1.9381 - mse: 1.9381 - mae: 1.0799 - val_loss: 2.3640 - val_mse: 2.3640 - val_mae: 1.1405\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 637us/step - loss: 1.9128 - mse: 1.9128 - mae: 1.0722 - val_loss: 2.3674 - val_mse: 2.3674 - val_mae: 1.1443\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 477us/step - loss: 1.8887 - mse: 1.8887 - mae: 1.0634 - val_loss: 2.3738 - val_mse: 2.3738 - val_mae: 1.1476\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 458us/step - loss: 1.8671 - mse: 1.8671 - mae: 1.0551 - val_loss: 2.3803 - val_mse: 2.3803 - val_mae: 1.1507\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 375us/step - loss: 1.8474 - mse: 1.8474 - mae: 1.0493 - val_loss: 2.3881 - val_mse: 2.3881 - val_mae: 1.1538\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 502us/step - loss: 1.8305 - mse: 1.8305 - mae: 1.0445 - val_loss: 2.3949 - val_mse: 2.3949 - val_mae: 1.1560\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 491us/step - loss: 1.8143 - mse: 1.8143 - mae: 1.0402 - val_loss: 2.4028 - val_mse: 2.4028 - val_mae: 1.1582\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 627us/step - loss: 1.7990 - mse: 1.7990 - mae: 1.0359 - val_loss: 2.4139 - val_mse: 2.4139 - val_mae: 1.1598\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 630us/step - loss: 1.7837 - mse: 1.7837 - mae: 1.0310 - val_loss: 2.4266 - val_mse: 2.4266 - val_mae: 1.1616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 381us/step - loss: 1.7692 - mse: 1.7692 - mae: 1.0263 - val_loss: 2.4392 - val_mse: 2.4392 - val_mae: 1.1631\n",
      "97\n",
      "[97]\n",
      "Train on 80 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 2.6018 - mse: 2.6018 - mae: 1.2000 - val_loss: 1.5814 - val_mse: 1.5814 - val_mae: 0.9347\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 510us/step - loss: 2.2404 - mse: 2.2404 - mae: 1.1254 - val_loss: 1.4568 - val_mse: 1.4568 - val_mae: 0.9616\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 411us/step - loss: 2.0790 - mse: 2.0790 - mae: 1.1069 - val_loss: 1.4266 - val_mse: 1.4266 - val_mae: 1.0319\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 716us/step - loss: 2.0446 - mse: 2.0446 - mae: 1.1140 - val_loss: 1.4370 - val_mse: 1.4370 - val_mae: 1.0747\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 503us/step - loss: 2.0482 - mse: 2.0482 - mae: 1.1228 - val_loss: 1.4326 - val_mse: 1.4326 - val_mae: 1.0854\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0361 - mse: 2.0361 - mae: 1.1213 - val_loss: 1.4110 - val_mse: 1.4110 - val_mae: 1.0745\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9994 - mse: 1.9994 - mae: 1.1086 - val_loss: 1.3800 - val_mse: 1.3800 - val_mae: 1.0496\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 638us/step - loss: 1.9552 - mse: 1.9552 - mae: 1.0906 - val_loss: 1.3493 - val_mse: 1.3493 - val_mae: 1.0177\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 1.9189 - mse: 1.9189 - mae: 1.0723 - val_loss: 1.3258 - val_mse: 1.3258 - val_mae: 0.9855\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 700us/step - loss: 1.8966 - mse: 1.8966 - mae: 1.0564 - val_loss: 1.3101 - val_mse: 1.3101 - val_mae: 0.9583\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 423us/step - loss: 1.8850 - mse: 1.8850 - mae: 1.0461 - val_loss: 1.3007 - val_mse: 1.3007 - val_mae: 0.9397\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 469us/step - loss: 1.8757 - mse: 1.8757 - mae: 1.0391 - val_loss: 1.2951 - val_mse: 1.2951 - val_mae: 0.9319\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 513us/step - loss: 1.8641 - mse: 1.8641 - mae: 1.0347 - val_loss: 1.2915 - val_mse: 1.2915 - val_mae: 0.9344\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 516us/step - loss: 1.8485 - mse: 1.8485 - mae: 1.0321 - val_loss: 1.2906 - val_mse: 1.2906 - val_mae: 0.9434\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 565us/step - loss: 1.8317 - mse: 1.8317 - mae: 1.0306 - val_loss: 1.2932 - val_mse: 1.2932 - val_mae: 0.9554\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 448us/step - loss: 1.8161 - mse: 1.8161 - mae: 1.0308 - val_loss: 1.2988 - val_mse: 1.2988 - val_mae: 0.9670\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 278us/step - loss: 1.8016 - mse: 1.8016 - mae: 1.0314 - val_loss: 1.3071 - val_mse: 1.3071 - val_mae: 0.9769\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 871us/step - loss: 1.7881 - mse: 1.7881 - mae: 1.0305 - val_loss: 1.3147 - val_mse: 1.3147 - val_mae: 0.9832\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 685us/step - loss: 1.7752 - mse: 1.7752 - mae: 1.0282 - val_loss: 1.3191 - val_mse: 1.3191 - val_mae: 0.9849\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 493us/step - loss: 1.7632 - mse: 1.7632 - mae: 1.0249 - val_loss: 1.3200 - val_mse: 1.3200 - val_mae: 0.9829\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 416us/step - loss: 1.7509 - mse: 1.7509 - mae: 1.0206 - val_loss: 1.3193 - val_mse: 1.3193 - val_mae: 0.9789\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 687us/step - loss: 1.7389 - mse: 1.7389 - mae: 1.0160 - val_loss: 1.3177 - val_mse: 1.3177 - val_mae: 0.9746\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 436us/step - loss: 1.7273 - mse: 1.7273 - mae: 1.0114 - val_loss: 1.3154 - val_mse: 1.3154 - val_mae: 0.9713\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 499us/step - loss: 1.7166 - mse: 1.7166 - mae: 1.0074 - val_loss: 1.3122 - val_mse: 1.3122 - val_mae: 0.9691\n",
      "98\n",
      "[98]\n",
      "Train on 86 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 1.7033 - mse: 1.7033 - mae: 1.0500 - val_loss: 0.8273 - val_mse: 0.8273 - val_mae: 0.7015\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 397us/step - loss: 1.6012 - mse: 1.6012 - mae: 1.0228 - val_loss: 0.8049 - val_mse: 0.8049 - val_mae: 0.7013\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 668us/step - loss: 1.5241 - mse: 1.5241 - mae: 0.9974 - val_loss: 0.7891 - val_mse: 0.7891 - val_mae: 0.7081\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 397us/step - loss: 1.4559 - mse: 1.4559 - mae: 0.9751 - val_loss: 0.7743 - val_mse: 0.7743 - val_mae: 0.7149\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 314us/step - loss: 1.4033 - mse: 1.4033 - mae: 0.9544 - val_loss: 0.7621 - val_mse: 0.7621 - val_mae: 0.7193\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 597us/step - loss: 1.3668 - mse: 1.3668 - mae: 0.9379 - val_loss: 0.7571 - val_mse: 0.7571 - val_mae: 0.7235\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 619us/step - loss: 1.3390 - mse: 1.3390 - mae: 0.9247 - val_loss: 0.7545 - val_mse: 0.7545 - val_mae: 0.7271\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 545us/step - loss: 1.3151 - mse: 1.3151 - mae: 0.9140 - val_loss: 0.7507 - val_mse: 0.7507 - val_mae: 0.7289\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 447us/step - loss: 1.2932 - mse: 1.2932 - mae: 0.9050 - val_loss: 0.7464 - val_mse: 0.7464 - val_mae: 0.7299\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1.2743 - mse: 1.2743 - mae: 0.8980 - val_loss: 0.7404 - val_mse: 0.7404 - val_mae: 0.7296\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1.2585 - mse: 1.2585 - mae: 0.8929 - val_loss: 0.7351 - val_mse: 0.7351 - val_mae: 0.7292\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 400us/step - loss: 1.2439 - mse: 1.2439 - mae: 0.8885 - val_loss: 0.7298 - val_mse: 0.7298 - val_mae: 0.7289\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 618us/step - loss: 1.2315 - mse: 1.2315 - mae: 0.8845 - val_loss: 0.7245 - val_mse: 0.7245 - val_mae: 0.7279\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 497us/step - loss: 1.2210 - mse: 1.2210 - mae: 0.8805 - val_loss: 0.7196 - val_mse: 0.7196 - val_mae: 0.7264\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 570us/step - loss: 1.2112 - mse: 1.2112 - mae: 0.8768 - val_loss: 0.7144 - val_mse: 0.7144 - val_mae: 0.7239\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 651us/step - loss: 1.2023 - mse: 1.2023 - mae: 0.8734 - val_loss: 0.7103 - val_mse: 0.7103 - val_mae: 0.7214\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 400us/step - loss: 1.1941 - mse: 1.1941 - mae: 0.8704 - val_loss: 0.7072 - val_mse: 0.7072 - val_mae: 0.7190\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 374us/step - loss: 1.1863 - mse: 1.1863 - mae: 0.8676 - val_loss: 0.7047 - val_mse: 0.7047 - val_mae: 0.7168\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 507us/step - loss: 1.1783 - mse: 1.1783 - mae: 0.8647 - val_loss: 0.7029 - val_mse: 0.7029 - val_mae: 0.7149\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 441us/step - loss: 1.1711 - mse: 1.1711 - mae: 0.8623 - val_loss: 0.7021 - val_mse: 0.7021 - val_mae: 0.7133\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 480us/step - loss: 1.1643 - mse: 1.1643 - mae: 0.8601 - val_loss: 0.7014 - val_mse: 0.7014 - val_mae: 0.7127\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 351us/step - loss: 1.1577 - mse: 1.1577 - mae: 0.8578 - val_loss: 0.7007 - val_mse: 0.7007 - val_mae: 0.7121\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 396us/step - loss: 1.1513 - mse: 1.1513 - mae: 0.8553 - val_loss: 0.6999 - val_mse: 0.6999 - val_mae: 0.7115\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 394us/step - loss: 1.1448 - mse: 1.1448 - mae: 0.8529 - val_loss: 0.6992 - val_mse: 0.6992 - val_mae: 0.7111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 580us/step - loss: 1.1388 - mse: 1.1388 - mae: 0.8507 - val_loss: 0.6985 - val_mse: 0.6985 - val_mae: 0.7108\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 397us/step - loss: 1.1328 - mse: 1.1328 - mae: 0.8484 - val_loss: 0.6980 - val_mse: 0.6980 - val_mae: 0.7106\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 982us/step - loss: 1.1271 - mse: 1.1271 - mae: 0.8462 - val_loss: 0.6977 - val_mse: 0.6977 - val_mae: 0.7105\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 563us/step - loss: 1.1212 - mse: 1.1212 - mae: 0.8437 - val_loss: 0.6973 - val_mse: 0.6973 - val_mae: 0.7105\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 610us/step - loss: 1.1152 - mse: 1.1152 - mae: 0.8413 - val_loss: 0.6971 - val_mse: 0.6971 - val_mae: 0.7105\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 454us/step - loss: 1.1093 - mse: 1.1093 - mae: 0.8387 - val_loss: 0.6969 - val_mse: 0.6969 - val_mae: 0.7105\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 600us/step - loss: 1.1035 - mse: 1.1035 - mae: 0.8361 - val_loss: 0.6968 - val_mse: 0.6968 - val_mae: 0.7105\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 311us/step - loss: 1.0975 - mse: 1.0975 - mae: 0.8337 - val_loss: 0.6971 - val_mse: 0.6971 - val_mae: 0.7107\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 397us/step - loss: 1.0916 - mse: 1.0916 - mae: 0.8312 - val_loss: 0.6978 - val_mse: 0.6978 - val_mae: 0.7109\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1.0856 - mse: 1.0856 - mae: 0.8287 - val_loss: 0.6978 - val_mse: 0.6978 - val_mae: 0.7111\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 916us/step - loss: 1.0799 - mse: 1.0799 - mae: 0.8262 - val_loss: 0.6974 - val_mse: 0.6974 - val_mae: 0.7113\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 577us/step - loss: 1.0743 - mse: 1.0743 - mae: 0.8237 - val_loss: 0.6973 - val_mse: 0.6973 - val_mae: 0.7116\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 497us/step - loss: 1.0684 - mse: 1.0684 - mae: 0.8208 - val_loss: 0.6976 - val_mse: 0.6976 - val_mae: 0.7119\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 753us/step - loss: 1.0624 - mse: 1.0624 - mae: 0.8178 - val_loss: 0.6984 - val_mse: 0.6984 - val_mae: 0.7123\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 406us/step - loss: 1.0566 - mse: 1.0566 - mae: 0.8148 - val_loss: 0.6991 - val_mse: 0.6991 - val_mae: 0.7127\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 340us/step - loss: 1.0509 - mse: 1.0509 - mae: 0.8121 - val_loss: 0.6997 - val_mse: 0.6997 - val_mae: 0.7128\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 659us/step - loss: 1.0453 - mse: 1.0453 - mae: 0.8096 - val_loss: 0.7009 - val_mse: 0.7009 - val_mae: 0.7131\n",
      "99\n",
      "[99]\n",
      "Train on 101 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 5.5333 - mse: 5.5333 - mae: 1.9799 - val_loss: 5.0757 - val_mse: 5.0757 - val_mae: 1.9661\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 462us/step - loss: 4.3047 - mse: 4.3047 - mae: 1.6468 - val_loss: 3.8766 - val_mse: 3.8766 - val_mae: 1.6256\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 374us/step - loss: 3.2504 - mse: 3.2504 - mae: 1.3199 - val_loss: 2.9126 - val_mse: 2.9126 - val_mae: 1.3214\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 526us/step - loss: 2.4829 - mse: 2.4829 - mae: 1.0793 - val_loss: 2.2609 - val_mse: 2.2609 - val_mae: 1.1644\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 627us/step - loss: 1.9924 - mse: 1.9924 - mae: 0.9738 - val_loss: 1.8647 - val_mse: 1.8647 - val_mae: 1.0836\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 781us/step - loss: 1.7293 - mse: 1.7293 - mae: 0.9445 - val_loss: 1.6631 - val_mse: 1.6631 - val_mae: 1.0174\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 336us/step - loss: 1.6290 - mse: 1.6290 - mae: 0.9686 - val_loss: 1.5935 - val_mse: 1.5935 - val_mae: 1.0089\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 403us/step - loss: 1.6157 - mse: 1.6157 - mae: 0.9996 - val_loss: 1.5878 - val_mse: 1.5878 - val_mae: 1.0385\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 587us/step - loss: 1.6278 - mse: 1.6278 - mae: 1.0209 - val_loss: 1.6010 - val_mse: 1.6010 - val_mae: 1.0599\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 482us/step - loss: 1.6295 - mse: 1.6295 - mae: 1.0263 - val_loss: 1.6072 - val_mse: 1.6072 - val_mae: 1.0656\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 910us/step - loss: 1.6117 - mse: 1.6117 - mae: 1.0174 - val_loss: 1.6073 - val_mse: 1.6073 - val_mae: 1.0631\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 577us/step - loss: 1.5818 - mse: 1.5818 - mae: 0.9993 - val_loss: 1.6083 - val_mse: 1.6083 - val_mae: 1.0576\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 489us/step - loss: 1.5504 - mse: 1.5504 - mae: 0.9784 - val_loss: 1.6146 - val_mse: 1.6146 - val_mae: 1.0506\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.5244 - mse: 1.5244 - mae: 0.9584 - val_loss: 1.6240 - val_mse: 1.6240 - val_mae: 1.0435\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 690us/step - loss: 1.5056 - mse: 1.5056 - mae: 0.9414 - val_loss: 1.6347 - val_mse: 1.6347 - val_mae: 1.0387\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 656us/step - loss: 1.4913 - mse: 1.4913 - mae: 0.9279 - val_loss: 1.6418 - val_mse: 1.6418 - val_mae: 1.0362\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 377us/step - loss: 1.4785 - mse: 1.4785 - mae: 0.9186 - val_loss: 1.6445 - val_mse: 1.6445 - val_mae: 1.0361\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 759us/step - loss: 1.4661 - mse: 1.4661 - mae: 0.9121 - val_loss: 1.6431 - val_mse: 1.6431 - val_mae: 1.0380\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "from math import sqrt\n",
    "paths_to_folders = ['C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Splited Data s-1 to s-5/STORE__1']\n",
    "x=0\n",
    "for folder in paths_to_folders:\n",
    "   for csv_file in os.listdir(folder):\n",
    "        if  any(dff.File_name ==\"\"+csv_file)==True:\n",
    "       #if len(df.index)>=100:\n",
    "            select_indices=list(np.where(dff[\"File_name\"] == ''+csv_file)[0])\n",
    "            print(select_indices)\n",
    "            df=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Splited Data s-1 to s-5/STORE__1/\"+csv_file,parse_dates=['date'],index_col='date')\n",
    "            df.drop(['id','store_nbr','item_nbr','onpromotion'], axis=1,inplace=True)\n",
    "            k = int(len(df) * 0.8)\n",
    "            train,test = df.values[0:k,:], df.values[k:len(df.values),:]\n",
    "            look_back = 10\n",
    "#convert dataset into right shape in order to input into the DNN\n",
    "            trainX, trainY = convert2matrix(train, look_back)\n",
    "            testX, testY = convert2matrix(test, look_back)\n",
    "            model=model_dnn(look_back)\n",
    "            history=model.fit(trainX,trainY, epochs=100, batch_size=30, verbose=1, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)\n",
    "            test_predict = model.predict(testX)\n",
    "            rmse = np.sqrt(mean_squared_error(testY,test_predict))\n",
    "            error.loc[x, ['File_name']]=csv_file\n",
    "            error.loc[x, ['RMSE_ERROR_DNN']]=rmse\n",
    "            if len(select_indices)==1:\n",
    "                b=dff.iloc[select_indices[0]]['RMSE_ERROR_LSTM']\n",
    "                d=dff.iloc[select_indices[0]]['RMSE_ERROR_CNN']\n",
    "                c=dff.iloc[select_indices[0]]['RMSE_ERROR_CNN+LSTM']\n",
    "                error.loc[x, ['RMSE_ERROR_LSTM']]=b\n",
    "                error.loc[x, ['RMSE_ERROR_CNN']]=d\n",
    "                error.loc[x, ['RMSE_ERROR_CNN+LSTM']]=c\n",
    "            error.loc[x, ['MSE']]=mean_squared_error(testY,test_predict)\n",
    "            error.loc[x, ['MAPE']]=mean_absolute_percentage_error(testY,test_predict)\n",
    "            x=x+1\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>RMSE_ERROR_CNN</th>\n",
       "      <th>RMSE_ERROR_LSTM</th>\n",
       "      <th>RMSE_ERROR_CNN+LSTM</th>\n",
       "      <th>RMSE_ERROR_DNN</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S_1__I_1001305.csv</td>\n",
       "      <td>1.35458</td>\n",
       "      <td>1.10799</td>\n",
       "      <td>1.28191</td>\n",
       "      <td>1.05042</td>\n",
       "      <td>1.10339</td>\n",
       "      <td>49.2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S_1__I_1009998.csv</td>\n",
       "      <td>1.47389</td>\n",
       "      <td>1.35859</td>\n",
       "      <td>0.874792</td>\n",
       "      <td>1.34762</td>\n",
       "      <td>1.81609</td>\n",
       "      <td>64.4642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S_1__I_1010752.csv</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>1.00519</td>\n",
       "      <td>1.00439</td>\n",
       "      <td>0.68879</td>\n",
       "      <td>0.474432</td>\n",
       "      <td>30.7853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S_1__I_1018617.csv</td>\n",
       "      <td>1.0624</td>\n",
       "      <td>1.35548</td>\n",
       "      <td>1.42294</td>\n",
       "      <td>1.39926</td>\n",
       "      <td>1.95792</td>\n",
       "      <td>60.8592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S_1__I_1040170.csv</td>\n",
       "      <td>1.32738</td>\n",
       "      <td>1.19962</td>\n",
       "      <td>0.95653</td>\n",
       "      <td>0.99901</td>\n",
       "      <td>0.99802</td>\n",
       "      <td>64.548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            File_name RMSE_ERROR_CNN RMSE_ERROR_LSTM RMSE_ERROR_CNN+LSTM  \\\n",
       "0  S_1__I_1001305.csv        1.35458         1.10799             1.28191   \n",
       "1  S_1__I_1009998.csv        1.47389         1.35859            0.874792   \n",
       "2  S_1__I_1010752.csv       0.967724         1.00519             1.00439   \n",
       "3  S_1__I_1018617.csv         1.0624         1.35548             1.42294   \n",
       "4  S_1__I_1040170.csv        1.32738         1.19962             0.95653   \n",
       "\n",
       "  RMSE_ERROR_DNN       MSE     MAPE  \n",
       "0        1.05042   1.10339  49.2153  \n",
       "1        1.34762   1.81609  64.4642  \n",
       "2        0.68879  0.474432  30.7853  \n",
       "3        1.39926   1.95792  60.8592  \n",
       "4        0.99901   0.99802   64.548  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('FORECAST_Error_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
