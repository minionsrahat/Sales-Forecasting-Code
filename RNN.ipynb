{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2matrix(data_arr, look_back):\n",
    "   X, Y =[], []\n",
    "   for i in range(len(data_arr)-look_back):\n",
    "       d=i+look_back  \n",
    "       X.append(data_arr[i:d,])\n",
    "       Y.append(data_arr[d,])\n",
    "   return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Splited Data s-1 to s-5/STEST/S_1__I_582865.csv\",parse_dates=['date'],index_col='date')\n",
    "\n",
    "#convert date field from string to datetime\n",
    "#df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','store_nbr','item_nbr','onpromotion'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(len(df) * 0.8)\n",
    "train,test = df.values[0:k,:], df.values[k:len(df.values),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 20 #create window size as look_back=30\n",
    "test = np.append(test,np.repeat(test[-1,], look_back))\n",
    "train = np.append(train,np.repeat(train[-1,],look_back))\n",
    "trainX,trainY =convert2matrix(train,look_back)\n",
    "testX,testY =convert2matrix(test, look_back)\n",
    "# reshape input to be [samples, window size, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn(look_back):\n",
    "  model=Sequential()\n",
    "  model.add(SimpleRNN(units=32, input_shape=(1,look_back), activation=\"relu\"))\n",
    "  model.add(Dense(8, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 38.5370 - mse: 38.5370 - mae: 4.9188 - val_loss: 34.6855 - val_mse: 34.6855 - val_mae: 4.3750\n",
      "Epoch 2/200\n",
      "240/240 [==============================] - 0s 119us/step - loss: 34.1273 - mse: 34.1273 - mae: 4.5836 - val_loss: 29.6901 - val_mse: 29.6901 - val_mae: 3.9031\n",
      "Epoch 3/200\n",
      "240/240 [==============================] - 0s 126us/step - loss: 29.7464 - mse: 29.7465 - mae: 4.2623 - val_loss: 26.4654 - val_mse: 26.4654 - val_mae: 3.6488\n",
      "Epoch 4/200\n",
      "240/240 [==============================] - 0s 137us/step - loss: 27.5892 - mse: 27.5892 - mae: 4.0557 - val_loss: 24.1655 - val_mse: 24.1655 - val_mae: 3.4611\n",
      "Epoch 5/200\n",
      "240/240 [==============================] - 0s 196us/step - loss: 25.9768 - mse: 25.9768 - mae: 3.9564 - val_loss: 23.1975 - val_mse: 23.1975 - val_mae: 3.4284\n",
      "Epoch 6/200\n",
      "240/240 [==============================] - 0s 117us/step - loss: 24.9400 - mse: 24.9400 - mae: 3.9095 - val_loss: 21.8953 - val_mse: 21.8953 - val_mae: 3.2556\n",
      "Epoch 7/200\n",
      "240/240 [==============================] - 0s 131us/step - loss: 24.0365 - mse: 24.0365 - mae: 3.8284 - val_loss: 21.0147 - val_mse: 21.0147 - val_mae: 3.1703\n",
      "Epoch 8/200\n",
      "240/240 [==============================] - 0s 139us/step - loss: 23.3069 - mse: 23.3069 - mae: 3.7574 - val_loss: 20.3939 - val_mse: 20.3939 - val_mae: 3.1483\n",
      "Epoch 9/200\n",
      "240/240 [==============================] - 0s 136us/step - loss: 22.7365 - mse: 22.7365 - mae: 3.7123 - val_loss: 19.7716 - val_mse: 19.7716 - val_mae: 3.0856\n",
      "Epoch 10/200\n",
      "240/240 [==============================] - 0s 157us/step - loss: 22.2129 - mse: 22.2129 - mae: 3.6632 - val_loss: 19.1657 - val_mse: 19.1657 - val_mae: 3.0197\n",
      "Epoch 11/200\n",
      "240/240 [==============================] - 0s 149us/step - loss: 21.7547 - mse: 21.7547 - mae: 3.6201 - val_loss: 18.7064 - val_mse: 18.7064 - val_mae: 2.9769\n",
      "Epoch 12/200\n",
      "240/240 [==============================] - 0s 90us/step - loss: 21.3809 - mse: 21.3809 - mae: 3.5914 - val_loss: 18.2335 - val_mse: 18.2335 - val_mae: 2.9230\n",
      "Epoch 13/200\n",
      "240/240 [==============================] - 0s 208us/step - loss: 21.0340 - mse: 21.0340 - mae: 3.5627 - val_loss: 17.8836 - val_mse: 17.8836 - val_mae: 2.8881\n",
      "Epoch 14/200\n",
      "240/240 [==============================] - 0s 104us/step - loss: 20.7538 - mse: 20.7538 - mae: 3.5442 - val_loss: 17.5233 - val_mse: 17.5233 - val_mae: 2.8517\n",
      "Epoch 15/200\n",
      "240/240 [==============================] - 0s 178us/step - loss: 20.4894 - mse: 20.4894 - mae: 3.5242 - val_loss: 17.2312 - val_mse: 17.2312 - val_mae: 2.8266\n",
      "Epoch 16/200\n",
      "240/240 [==============================] - 0s 120us/step - loss: 20.2421 - mse: 20.2421 - mae: 3.5046 - val_loss: 16.9968 - val_mse: 16.9968 - val_mae: 2.8111\n",
      "Epoch 17/200\n",
      "240/240 [==============================] - 0s 153us/step - loss: 20.0204 - mse: 20.0204 - mae: 3.4880 - val_loss: 16.7920 - val_mse: 16.7920 - val_mae: 2.7978\n",
      "Epoch 18/200\n",
      "240/240 [==============================] - 0s 127us/step - loss: 19.8211 - mse: 19.8211 - mae: 3.4759 - val_loss: 16.5748 - val_mse: 16.5748 - val_mae: 2.7786\n",
      "Epoch 19/200\n",
      "240/240 [==============================] - 0s 184us/step - loss: 19.6120 - mse: 19.6120 - mae: 3.4597 - val_loss: 16.3914 - val_mse: 16.3914 - val_mae: 2.7649\n",
      "Epoch 20/200\n",
      "240/240 [==============================] - 0s 178us/step - loss: 19.4277 - mse: 19.4277 - mae: 3.4456 - val_loss: 16.2369 - val_mse: 16.2369 - val_mae: 2.7539\n",
      "Epoch 21/200\n",
      "240/240 [==============================] - 0s 176us/step - loss: 19.2782 - mse: 19.2782 - mae: 3.4365 - val_loss: 16.0667 - val_mse: 16.0667 - val_mae: 2.7374\n",
      "Epoch 22/200\n",
      "240/240 [==============================] - 0s 141us/step - loss: 19.1136 - mse: 19.1136 - mae: 3.4257 - val_loss: 15.9388 - val_mse: 15.9388 - val_mae: 2.7291\n",
      "Epoch 23/200\n",
      "240/240 [==============================] - 0s 111us/step - loss: 18.9747 - mse: 18.9747 - mae: 3.4168 - val_loss: 15.8647 - val_mse: 15.8647 - val_mae: 2.7215\n",
      "Epoch 24/200\n",
      "240/240 [==============================] - 0s 120us/step - loss: 18.8389 - mse: 18.8389 - mae: 3.4068 - val_loss: 15.8147 - val_mse: 15.8147 - val_mae: 2.7225\n",
      "Epoch 25/200\n",
      "240/240 [==============================] - 0s 170us/step - loss: 18.7206 - mse: 18.7206 - mae: 3.4010 - val_loss: 15.6922 - val_mse: 15.6922 - val_mae: 2.7106\n",
      "Epoch 26/200\n",
      "240/240 [==============================] - 0s 146us/step - loss: 18.5908 - mse: 18.5908 - mae: 3.3918 - val_loss: 15.6249 - val_mse: 15.6249 - val_mae: 2.7084\n",
      "Epoch 27/200\n",
      "240/240 [==============================] - 0s 145us/step - loss: 18.4889 - mse: 18.4889 - mae: 3.3816 - val_loss: 15.4996 - val_mse: 15.4996 - val_mae: 2.6991\n",
      "Epoch 28/200\n",
      "240/240 [==============================] - 0s 141us/step - loss: 18.3730 - mse: 18.3730 - mae: 3.3723 - val_loss: 15.4383 - val_mse: 15.4383 - val_mae: 2.6996\n",
      "Epoch 29/200\n",
      "240/240 [==============================] - 0s 226us/step - loss: 18.2755 - mse: 18.2755 - mae: 3.3668 - val_loss: 15.3972 - val_mse: 15.3972 - val_mae: 2.6967\n",
      "Epoch 30/200\n",
      "240/240 [==============================] - 0s 112us/step - loss: 18.1619 - mse: 18.1619 - mae: 3.3571 - val_loss: 15.2936 - val_mse: 15.2936 - val_mae: 2.6884\n",
      "Epoch 31/200\n",
      "240/240 [==============================] - 0s 124us/step - loss: 18.0744 - mse: 18.0744 - mae: 3.3516 - val_loss: 15.2706 - val_mse: 15.2706 - val_mae: 2.6906\n",
      "Epoch 32/200\n",
      "240/240 [==============================] - 0s 163us/step - loss: 17.9751 - mse: 17.9751 - mae: 3.3429 - val_loss: 15.1670 - val_mse: 15.1670 - val_mae: 2.6805\n",
      "Epoch 33/200\n",
      "240/240 [==============================] - 0s 159us/step - loss: 17.8813 - mse: 17.8813 - mae: 3.3352 - val_loss: 15.1557 - val_mse: 15.1557 - val_mae: 2.6829\n",
      "Epoch 34/200\n",
      "240/240 [==============================] - 0s 161us/step - loss: 17.8054 - mse: 17.8054 - mae: 3.3308 - val_loss: 15.0891 - val_mse: 15.0891 - val_mae: 2.6736\n",
      "Epoch 35/200\n",
      "240/240 [==============================] - 0s 153us/step - loss: 17.7006 - mse: 17.7006 - mae: 3.3245 - val_loss: 14.9853 - val_mse: 14.9853 - val_mae: 2.6628\n",
      "Epoch 36/200\n",
      "240/240 [==============================] - 0s 159us/step - loss: 17.6284 - mse: 17.6284 - mae: 3.3172 - val_loss: 14.9682 - val_mse: 14.9682 - val_mae: 2.6637\n",
      "Epoch 37/200\n",
      "240/240 [==============================] - 0s 165us/step - loss: 17.5448 - mse: 17.5448 - mae: 3.3113 - val_loss: 14.9450 - val_mse: 14.9450 - val_mae: 2.6593\n",
      "Epoch 38/200\n",
      "240/240 [==============================] - 0s 123us/step - loss: 17.4529 - mse: 17.4529 - mae: 3.3034 - val_loss: 14.8387 - val_mse: 14.8387 - val_mae: 2.6485\n",
      "Epoch 39/200\n",
      "240/240 [==============================] - 0s 136us/step - loss: 17.3908 - mse: 17.3908 - mae: 3.3002 - val_loss: 14.7917 - val_mse: 14.7917 - val_mae: 2.6434\n",
      "Epoch 40/200\n",
      "240/240 [==============================] - 0s 150us/step - loss: 17.3010 - mse: 17.3010 - mae: 3.2924 - val_loss: 14.8027 - val_mse: 14.8027 - val_mae: 2.6452\n",
      "Epoch 41/200\n",
      "240/240 [==============================] - 0s 177us/step - loss: 17.2292 - mse: 17.2292 - mae: 3.2872 - val_loss: 14.7025 - val_mse: 14.7025 - val_mae: 2.6331\n",
      "Epoch 42/200\n",
      "240/240 [==============================] - 0s 196us/step - loss: 17.1542 - mse: 17.1542 - mae: 3.2806 - val_loss: 14.7132 - val_mse: 14.7132 - val_mae: 2.6334\n",
      "Epoch 43/200\n",
      "240/240 [==============================] - 0s 163us/step - loss: 17.0791 - mse: 17.0791 - mae: 3.2716 - val_loss: 14.6828 - val_mse: 14.6828 - val_mae: 2.6321\n",
      "Epoch 44/200\n",
      "240/240 [==============================] - 0s 169us/step - loss: 17.0067 - mse: 17.0067 - mae: 3.2653 - val_loss: 14.6319 - val_mse: 14.6319 - val_mae: 2.6280\n",
      "Epoch 45/200\n",
      "240/240 [==============================] - 0s 139us/step - loss: 16.9217 - mse: 16.9217 - mae: 3.2596 - val_loss: 14.5541 - val_mse: 14.5541 - val_mae: 2.6194\n",
      "Epoch 46/200\n",
      "240/240 [==============================] - 0s 140us/step - loss: 16.8490 - mse: 16.8490 - mae: 3.2529 - val_loss: 14.5520 - val_mse: 14.5520 - val_mae: 2.6199\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 142us/step - loss: 16.7737 - mse: 16.7737 - mae: 3.2435 - val_loss: 14.5239 - val_mse: 14.5239 - val_mae: 2.6198\n",
      "Epoch 48/200\n",
      "240/240 [==============================] - 0s 134us/step - loss: 16.7102 - mse: 16.7102 - mae: 3.2402 - val_loss: 14.4651 - val_mse: 14.4651 - val_mae: 2.6119\n",
      "Epoch 49/200\n",
      "240/240 [==============================] - 0s 153us/step - loss: 16.6286 - mse: 16.6286 - mae: 3.2339 - val_loss: 14.4325 - val_mse: 14.4325 - val_mae: 2.6106\n",
      "Epoch 50/200\n",
      "240/240 [==============================] - 0s 197us/step - loss: 16.5563 - mse: 16.5563 - mae: 3.2219 - val_loss: 14.3975 - val_mse: 14.3975 - val_mae: 2.6079\n",
      "Epoch 51/200\n",
      "240/240 [==============================] - 0s 177us/step - loss: 16.5051 - mse: 16.5051 - mae: 3.2186 - val_loss: 14.3563 - val_mse: 14.3563 - val_mae: 2.5986\n",
      "Epoch 52/200\n",
      "240/240 [==============================] - 0s 146us/step - loss: 16.4143 - mse: 16.4143 - mae: 3.2134 - val_loss: 14.3841 - val_mse: 14.3841 - val_mae: 2.6066\n",
      "Epoch 53/200\n",
      "240/240 [==============================] - 0s 129us/step - loss: 16.3608 - mse: 16.3608 - mae: 3.2019 - val_loss: 14.3384 - val_mse: 14.3384 - val_mae: 2.6033\n",
      "Epoch 54/200\n",
      "240/240 [==============================] - 0s 128us/step - loss: 16.2909 - mse: 16.2909 - mae: 3.1952 - val_loss: 14.3292 - val_mse: 14.3292 - val_mae: 2.6034\n",
      "Epoch 55/200\n",
      "240/240 [==============================] - 0s 122us/step - loss: 16.2369 - mse: 16.2369 - mae: 3.1914 - val_loss: 14.2929 - val_mse: 14.2929 - val_mae: 2.5966\n",
      "Epoch 56/200\n",
      "240/240 [==============================] - 0s 207us/step - loss: 16.1470 - mse: 16.1470 - mae: 3.1843 - val_loss: 14.3255 - val_mse: 14.3255 - val_mae: 2.6001\n",
      "Epoch 57/200\n",
      "240/240 [==============================] - 0s 184us/step - loss: 16.0881 - mse: 16.0881 - mae: 3.1737 - val_loss: 14.2883 - val_mse: 14.2883 - val_mae: 2.5953\n",
      "Epoch 58/200\n",
      "240/240 [==============================] - 0s 145us/step - loss: 16.0198 - mse: 16.0198 - mae: 3.1696 - val_loss: 14.2705 - val_mse: 14.2705 - val_mae: 2.5916\n",
      "Epoch 59/200\n",
      "240/240 [==============================] - 0s 151us/step - loss: 15.9505 - mse: 15.9505 - mae: 3.1599 - val_loss: 14.2286 - val_mse: 14.2286 - val_mae: 2.5885\n",
      "Epoch 60/200\n",
      "240/240 [==============================] - 0s 145us/step - loss: 15.8964 - mse: 15.8964 - mae: 3.1548 - val_loss: 14.2445 - val_mse: 14.2445 - val_mae: 2.5887\n",
      "Epoch 61/200\n",
      "240/240 [==============================] - 0s 132us/step - loss: 15.8262 - mse: 15.8262 - mae: 3.1465 - val_loss: 14.1872 - val_mse: 14.1872 - val_mae: 2.5777\n",
      "Epoch 62/200\n",
      "240/240 [==============================] - 0s 215us/step - loss: 15.7830 - mse: 15.7830 - mae: 3.1394 - val_loss: 14.2470 - val_mse: 14.2470 - val_mae: 2.5877\n",
      "Epoch 63/200\n",
      "240/240 [==============================] - 0s 212us/step - loss: 15.7115 - mse: 15.7115 - mae: 3.1336 - val_loss: 14.1545 - val_mse: 14.1545 - val_mae: 2.5738\n",
      "Epoch 64/200\n",
      "240/240 [==============================] - 0s 160us/step - loss: 15.6398 - mse: 15.6398 - mae: 3.1238 - val_loss: 14.1944 - val_mse: 14.1944 - val_mae: 2.5800\n",
      "Epoch 65/200\n",
      "240/240 [==============================] - 0s 164us/step - loss: 15.5894 - mse: 15.5894 - mae: 3.1192 - val_loss: 14.1399 - val_mse: 14.1399 - val_mae: 2.5687\n",
      "Epoch 66/200\n",
      "240/240 [==============================] - 0s 203us/step - loss: 15.5310 - mse: 15.5310 - mae: 3.1108 - val_loss: 14.1053 - val_mse: 14.1053 - val_mae: 2.5647\n",
      "Epoch 67/200\n",
      "240/240 [==============================] - 0s 246us/step - loss: 15.4608 - mse: 15.4608 - mae: 3.1045 - val_loss: 14.0779 - val_mse: 14.0779 - val_mae: 2.5642\n",
      "Epoch 68/200\n",
      "240/240 [==============================] - 0s 239us/step - loss: 15.4019 - mse: 15.4019 - mae: 3.0962 - val_loss: 14.1242 - val_mse: 14.1242 - val_mae: 2.5689\n",
      "Epoch 69/200\n",
      "240/240 [==============================] - 0s 189us/step - loss: 15.3614 - mse: 15.3614 - mae: 3.0919 - val_loss: 14.0571 - val_mse: 14.0571 - val_mae: 2.5611\n",
      "Epoch 70/200\n",
      "240/240 [==============================] - 0s 143us/step - loss: 15.3002 - mse: 15.3002 - mae: 3.0787 - val_loss: 14.0587 - val_mse: 14.0587 - val_mae: 2.5591\n",
      "Epoch 71/200\n",
      "240/240 [==============================] - 0s 145us/step - loss: 15.2394 - mse: 15.2394 - mae: 3.0744 - val_loss: 14.0601 - val_mse: 14.0601 - val_mae: 2.5604\n",
      "Epoch 72/200\n",
      "240/240 [==============================] - 0s 180us/step - loss: 15.1815 - mse: 15.1815 - mae: 3.0648 - val_loss: 14.0333 - val_mse: 14.0332 - val_mae: 2.5569\n",
      "Epoch 73/200\n",
      "240/240 [==============================] - 0s 188us/step - loss: 15.1133 - mse: 15.1133 - mae: 3.0562 - val_loss: 14.0770 - val_mse: 14.0770 - val_mae: 2.5607\n",
      "Epoch 74/200\n",
      "240/240 [==============================] - 0s 176us/step - loss: 15.0745 - mse: 15.0745 - mae: 3.0504 - val_loss: 14.1002 - val_mse: 14.1002 - val_mae: 2.5629\n",
      "Epoch 75/200\n",
      "240/240 [==============================] - 0s 189us/step - loss: 14.9981 - mse: 14.9981 - mae: 3.0396 - val_loss: 14.0343 - val_mse: 14.0343 - val_mae: 2.5537\n",
      "Epoch 76/200\n",
      "240/240 [==============================] - 0s 146us/step - loss: 14.9674 - mse: 14.9674 - mae: 3.0362 - val_loss: 14.0932 - val_mse: 14.0932 - val_mae: 2.5629\n",
      "Epoch 77/200\n",
      "240/240 [==============================] - 0s 159us/step - loss: 14.8803 - mse: 14.8803 - mae: 3.0223 - val_loss: 14.0474 - val_mse: 14.0474 - val_mae: 2.5525\n",
      "Epoch 78/200\n",
      "240/240 [==============================] - 0s 155us/step - loss: 14.8472 - mse: 14.8472 - mae: 3.0216 - val_loss: 14.0580 - val_mse: 14.0580 - val_mae: 2.5546\n",
      "Epoch 79/200\n",
      "240/240 [==============================] - 0s 174us/step - loss: 14.7739 - mse: 14.7739 - mae: 3.0054 - val_loss: 14.0685 - val_mse: 14.0685 - val_mae: 2.5524\n",
      "Epoch 80/200\n",
      "240/240 [==============================] - 0s 126us/step - loss: 14.7384 - mse: 14.7384 - mae: 3.0080 - val_loss: 14.1011 - val_mse: 14.1011 - val_mae: 2.5624\n",
      "Epoch 81/200\n",
      "240/240 [==============================] - 0s 142us/step - loss: 14.6544 - mse: 14.6544 - mae: 2.9874 - val_loss: 14.0940 - val_mse: 14.0940 - val_mae: 2.5539\n",
      "Epoch 82/200\n",
      "240/240 [==============================] - 0s 202us/step - loss: 14.6216 - mse: 14.6216 - mae: 2.9903 - val_loss: 14.1113 - val_mse: 14.1113 - val_mae: 2.5578\n"
     ]
    }
   ],
   "source": [
    "model=model_rnn(look_back)\n",
    "history=model.fit(trainX,trainY, epochs=200, batch_size=30, verbose=1, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(trainX)\n",
    "test_predict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e2336e89f6de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mYtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ytest' is not defined"
     ]
    }
   ],
   "source": [
    "test=np.asanyarray(Ytest)  \n",
    "Ytest=Ytest.reshape(-1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.575339243322186"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(testY,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast1=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/ML_FORECAST_70%.csv\",parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>date</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>LSTM_1</th>\n",
       "      <th>ANN</th>\n",
       "      <th>CNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>15.910</td>\n",
       "      <td>12.966378</td>\n",
       "      <td>12.579720</td>\n",
       "      <td>16.562193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>10.261</td>\n",
       "      <td>12.850510</td>\n",
       "      <td>12.747951</td>\n",
       "      <td>14.999523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-22</td>\n",
       "      <td>15.035</td>\n",
       "      <td>13.017899</td>\n",
       "      <td>12.972117</td>\n",
       "      <td>16.905703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>12.190</td>\n",
       "      <td>12.846584</td>\n",
       "      <td>12.491053</td>\n",
       "      <td>13.831470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>11.514</td>\n",
       "      <td>12.917412</td>\n",
       "      <td>12.801822</td>\n",
       "      <td>7.564637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>2013-10-24</td>\n",
       "      <td>13.996</td>\n",
       "      <td>12.674856</td>\n",
       "      <td>12.599476</td>\n",
       "      <td>6.641022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>15.341</td>\n",
       "      <td>12.811443</td>\n",
       "      <td>12.186004</td>\n",
       "      <td>12.548703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>9.206</td>\n",
       "      <td>12.779969</td>\n",
       "      <td>12.580894</td>\n",
       "      <td>15.209799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>12.771</td>\n",
       "      <td>13.015878</td>\n",
       "      <td>13.101615</td>\n",
       "      <td>14.770230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>2013-10-28</td>\n",
       "      <td>11.808</td>\n",
       "      <td>12.906087</td>\n",
       "      <td>12.750529</td>\n",
       "      <td>15.710668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1       date  actual_value  \\\n",
       "0            0             0               0 2013-08-20        15.910   \n",
       "1            1             1               1 2013-08-21        10.261   \n",
       "2            2             2               2 2013-08-22        15.035   \n",
       "3            3             3               3 2013-08-23        12.190   \n",
       "4            4             4               4 2013-08-24        11.514   \n",
       "..         ...           ...             ...        ...           ...   \n",
       "65          65            65              65 2013-10-24        13.996   \n",
       "66          66            66              66 2013-10-25        15.341   \n",
       "67          67            67              67 2013-10-26         9.206   \n",
       "68          68            68              68 2013-10-27        12.771   \n",
       "69          69            69              69 2013-10-28        11.808   \n",
       "\n",
       "       LSTM_1        ANN        CNN  \n",
       "0   12.966378  12.579720  16.562193  \n",
       "1   12.850510  12.747951  14.999523  \n",
       "2   13.017899  12.972117  16.905703  \n",
       "3   12.846584  12.491053  13.831470  \n",
       "4   12.917412  12.801822   7.564637  \n",
       "..        ...        ...        ...  \n",
       "65  12.674856  12.599476   6.641022  \n",
       "66  12.811443  12.186004  12.548703  \n",
       "67  12.779969  12.580894  15.209799  \n",
       "68  13.015878  13.101615  14.770230  \n",
       "69  12.906087  12.750529  15.710668  \n",
       "\n",
       "[70 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast1['RNN_2']=np.array(test_predict[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>date</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>LSTM_1</th>\n",
       "      <th>ANN</th>\n",
       "      <th>CNN</th>\n",
       "      <th>RNN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>15.910</td>\n",
       "      <td>12.966378</td>\n",
       "      <td>12.579720</td>\n",
       "      <td>16.562193</td>\n",
       "      <td>12.276929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>10.261</td>\n",
       "      <td>12.850510</td>\n",
       "      <td>12.747951</td>\n",
       "      <td>14.999523</td>\n",
       "      <td>13.190181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-22</td>\n",
       "      <td>15.035</td>\n",
       "      <td>13.017899</td>\n",
       "      <td>12.972117</td>\n",
       "      <td>16.905703</td>\n",
       "      <td>11.340872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>12.190</td>\n",
       "      <td>12.846584</td>\n",
       "      <td>12.491053</td>\n",
       "      <td>13.831470</td>\n",
       "      <td>14.544037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>11.514</td>\n",
       "      <td>12.917412</td>\n",
       "      <td>12.801822</td>\n",
       "      <td>7.564637</td>\n",
       "      <td>12.094693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>2013-10-24</td>\n",
       "      <td>13.996</td>\n",
       "      <td>12.674856</td>\n",
       "      <td>12.599476</td>\n",
       "      <td>6.641022</td>\n",
       "      <td>12.206569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>15.341</td>\n",
       "      <td>12.811443</td>\n",
       "      <td>12.186004</td>\n",
       "      <td>12.548703</td>\n",
       "      <td>11.763103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>9.206</td>\n",
       "      <td>12.779969</td>\n",
       "      <td>12.580894</td>\n",
       "      <td>15.209799</td>\n",
       "      <td>11.140363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>12.771</td>\n",
       "      <td>13.015878</td>\n",
       "      <td>13.101615</td>\n",
       "      <td>14.770230</td>\n",
       "      <td>11.462310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>2013-10-28</td>\n",
       "      <td>11.808</td>\n",
       "      <td>12.906087</td>\n",
       "      <td>12.750529</td>\n",
       "      <td>15.710668</td>\n",
       "      <td>11.323783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1       date  actual_value  \\\n",
       "0            0             0               0 2013-08-20        15.910   \n",
       "1            1             1               1 2013-08-21        10.261   \n",
       "2            2             2               2 2013-08-22        15.035   \n",
       "3            3             3               3 2013-08-23        12.190   \n",
       "4            4             4               4 2013-08-24        11.514   \n",
       "..         ...           ...             ...        ...           ...   \n",
       "65          65            65              65 2013-10-24        13.996   \n",
       "66          66            66              66 2013-10-25        15.341   \n",
       "67          67            67              67 2013-10-26         9.206   \n",
       "68          68            68              68 2013-10-27        12.771   \n",
       "69          69            69              69 2013-10-28        11.808   \n",
       "\n",
       "       LSTM_1        ANN        CNN      RNN_2  \n",
       "0   12.966378  12.579720  16.562193  12.276929  \n",
       "1   12.850510  12.747951  14.999523  13.190181  \n",
       "2   13.017899  12.972117  16.905703  11.340872  \n",
       "3   12.846584  12.491053  13.831470  14.544037  \n",
       "4   12.917412  12.801822   7.564637  12.094693  \n",
       "..        ...        ...        ...        ...  \n",
       "65  12.674856  12.599476   6.641022  12.206569  \n",
       "66  12.811443  12.186004  12.548703  11.763103  \n",
       "67  12.779969  12.580894  15.209799  11.140363  \n",
       "68  13.015878  13.101615  14.770230  11.462310  \n",
       "69  12.906087  12.750529  15.710668  11.323783  \n",
       "\n",
       "[70 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast1.to_csv('ML_FORECAST_70%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/CNN+LSTM_forecast_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Train on 101 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 9.1832 - mse: 9.1832 - mae: 2.6297 - val_loss: 4.0485 - val_mse: 4.0485 - val_mae: 1.9021\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 355us/step - loss: 8.5442 - mse: 8.5442 - mae: 2.5111 - val_loss: 3.6906 - val_mse: 3.6906 - val_mae: 1.8051\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 278us/step - loss: 7.9181 - mse: 7.9181 - mae: 2.3891 - val_loss: 3.3440 - val_mse: 3.3440 - val_mae: 1.7053\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 220us/step - loss: 7.3124 - mse: 7.3124 - mae: 2.2644 - val_loss: 3.0125 - val_mse: 3.0125 - val_mae: 1.6035\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 410us/step - loss: 6.7360 - mse: 6.7360 - mae: 2.1386 - val_loss: 2.6907 - val_mse: 2.6907 - val_mae: 1.4981\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 291us/step - loss: 6.1801 - mse: 6.1801 - mae: 2.0126 - val_loss: 2.3844 - val_mse: 2.3844 - val_mae: 1.3902\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 344us/step - loss: 5.6435 - mse: 5.6435 - mae: 1.8902 - val_loss: 2.0840 - val_mse: 2.0840 - val_mae: 1.2765\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 263us/step - loss: 5.1256 - mse: 5.1256 - mae: 1.7760 - val_loss: 1.7976 - val_mse: 1.7976 - val_mae: 1.1588\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 317us/step - loss: 4.6230 - mse: 4.6230 - mae: 1.6644 - val_loss: 1.5214 - val_mse: 1.5214 - val_mae: 1.0567\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 284us/step - loss: 4.1319 - mse: 4.1319 - mae: 1.5613 - val_loss: 1.2631 - val_mse: 1.2631 - val_mae: 0.9518\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 240us/step - loss: 3.6643 - mse: 3.6643 - mae: 1.4666 - val_loss: 1.0238 - val_mse: 1.0238 - val_mae: 0.8366\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 341us/step - loss: 3.2271 - mse: 3.2271 - mae: 1.3839 - val_loss: 0.8219 - val_mse: 0.8219 - val_mae: 0.7175\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 253us/step - loss: 2.8427 - mse: 2.8427 - mae: 1.3077 - val_loss: 0.6664 - val_mse: 0.6664 - val_mae: 0.5946\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 166us/step - loss: 2.5204 - mse: 2.5204 - mae: 1.2455 - val_loss: 0.5620 - val_mse: 0.5620 - val_mae: 0.4997\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 339us/step - loss: 2.2728 - mse: 2.2728 - mae: 1.1963 - val_loss: 0.5090 - val_mse: 0.5090 - val_mae: 0.4902\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 248us/step - loss: 2.1029 - mse: 2.1029 - mae: 1.1500 - val_loss: 0.5049 - val_mse: 0.5049 - val_mae: 0.5163\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 265us/step - loss: 2.0125 - mse: 2.0125 - mae: 1.1282 - val_loss: 0.5379 - val_mse: 0.5379 - val_mae: 0.5725\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 433us/step - loss: 1.9859 - mse: 1.9859 - mae: 1.1273 - val_loss: 0.5901 - val_mse: 0.5901 - val_mae: 0.6308\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 288us/step - loss: 1.9975 - mse: 1.9975 - mae: 1.1405 - val_loss: 0.6445 - val_mse: 0.6445 - val_mae: 0.6749\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 373us/step - loss: 2.0235 - mse: 2.0235 - mae: 1.1563 - val_loss: 0.6874 - val_mse: 0.6874 - val_mae: 0.7039\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 356us/step - loss: 2.0464 - mse: 2.0464 - mae: 1.1672 - val_loss: 0.7128 - val_mse: 0.7128 - val_mae: 0.7195\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 191us/step - loss: 2.0580 - mse: 2.0580 - mae: 1.1720 - val_loss: 0.7208 - val_mse: 0.7208 - val_mae: 0.7240\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 299us/step - loss: 2.0573 - mse: 2.0573 - mae: 1.1721 - val_loss: 0.7156 - val_mse: 0.7156 - val_mae: 0.7208\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 291us/step - loss: 2.0483 - mse: 2.0483 - mae: 1.1690 - val_loss: 0.7030 - val_mse: 0.7030 - val_mae: 0.7130\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 208us/step - loss: 2.0347 - mse: 2.0347 - mae: 1.1640 - val_loss: 0.6872 - val_mse: 0.6872 - val_mae: 0.7028\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 438us/step - loss: 2.0203 - mse: 2.0203 - mae: 1.1582 - val_loss: 0.6716 - val_mse: 0.6716 - val_mae: 0.6922\n",
      "1\n",
      "[1]\n",
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.3873 - mse: 5.3873 - mae: 1.9720 - val_loss: 2.5649 - val_mse: 2.5649 - val_mae: 1.2407\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 199us/step - loss: 4.7233 - mse: 4.7233 - mae: 1.7969 - val_loss: 2.2536 - val_mse: 2.2536 - val_mae: 1.1153\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 306us/step - loss: 4.1476 - mse: 4.1476 - mae: 1.6394 - val_loss: 1.9936 - val_mse: 1.9936 - val_mae: 1.0115\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 265us/step - loss: 3.6415 - mse: 3.6415 - mae: 1.5031 - val_loss: 1.7707 - val_mse: 1.7707 - val_mae: 0.9064\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 328us/step - loss: 3.1951 - mse: 3.1951 - mae: 1.3895 - val_loss: 1.5950 - val_mse: 1.5950 - val_mae: 0.8445\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 343us/step - loss: 2.8032 - mse: 2.8032 - mae: 1.2988 - val_loss: 1.4747 - val_mse: 1.4747 - val_mae: 0.8151\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 231us/step - loss: 2.4702 - mse: 2.4702 - mae: 1.2311 - val_loss: 1.4134 - val_mse: 1.4134 - val_mae: 0.8021\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 177us/step - loss: 2.2102 - mse: 2.2102 - mae: 1.1723 - val_loss: 1.3920 - val_mse: 1.3920 - val_mae: 0.8186\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 313us/step - loss: 2.0212 - mse: 2.0212 - mae: 1.1257 - val_loss: 1.4088 - val_mse: 1.4088 - val_mae: 0.8405\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 255us/step - loss: 1.9014 - mse: 1.9014 - mae: 1.0966 - val_loss: 1.4476 - val_mse: 1.4476 - val_mae: 0.8642\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 304us/step - loss: 1.8394 - mse: 1.8394 - mae: 1.0747 - val_loss: 1.4933 - val_mse: 1.4933 - val_mae: 0.8946\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 245us/step - loss: 1.8135 - mse: 1.8135 - mae: 1.0637 - val_loss: 1.5289 - val_mse: 1.5289 - val_mae: 0.9198\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 242us/step - loss: 1.7947 - mse: 1.7947 - mae: 1.0554 - val_loss: 1.5380 - val_mse: 1.5380 - val_mae: 0.9317\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 184us/step - loss: 1.7677 - mse: 1.7677 - mae: 1.0483 - val_loss: 1.5148 - val_mse: 1.5148 - val_mae: 0.9294\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 241us/step - loss: 1.7302 - mse: 1.7302 - mae: 1.0391 - val_loss: 1.4762 - val_mse: 1.4762 - val_mae: 0.9190\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 221us/step - loss: 1.6875 - mse: 1.6875 - mae: 1.0277 - val_loss: 1.4388 - val_mse: 1.4388 - val_mae: 0.9060\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 261us/step - loss: 1.6460 - mse: 1.6460 - mae: 1.0162 - val_loss: 1.4032 - val_mse: 1.4032 - val_mae: 0.8917\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 203us/step - loss: 1.6086 - mse: 1.6086 - mae: 1.0060 - val_loss: 1.3715 - val_mse: 1.3715 - val_mae: 0.8778\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 280us/step - loss: 1.5770 - mse: 1.5770 - mae: 0.9975 - val_loss: 1.3455 - val_mse: 1.3455 - val_mae: 0.8665\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 263us/step - loss: 1.5485 - mse: 1.5485 - mae: 0.9890 - val_loss: 1.3253 - val_mse: 1.3253 - val_mae: 0.8585\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 155us/step - loss: 1.5240 - mse: 1.5240 - mae: 0.9814 - val_loss: 1.3078 - val_mse: 1.3078 - val_mae: 0.8523\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 200us/step - loss: 1.5021 - mse: 1.5021 - mae: 0.9748 - val_loss: 1.2946 - val_mse: 1.2946 - val_mae: 0.8481\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 264us/step - loss: 1.4832 - mse: 1.4832 - mae: 0.9697 - val_loss: 1.2837 - val_mse: 1.2837 - val_mae: 0.8455\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 239us/step - loss: 1.4663 - mse: 1.4663 - mae: 0.9651 - val_loss: 1.2759 - val_mse: 1.2759 - val_mae: 0.8462\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 280us/step - loss: 1.4515 - mse: 1.4515 - mae: 0.9614 - val_loss: 1.2686 - val_mse: 1.2686 - val_mae: 0.8464\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 232us/step - loss: 1.4377 - mse: 1.4377 - mae: 0.9577 - val_loss: 1.2588 - val_mse: 1.2588 - val_mae: 0.8447\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 168us/step - loss: 1.4239 - mse: 1.4239 - mae: 0.9536 - val_loss: 1.2477 - val_mse: 1.2477 - val_mae: 0.8415\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 250us/step - loss: 1.4098 - mse: 1.4098 - mae: 0.9490 - val_loss: 1.2373 - val_mse: 1.2373 - val_mae: 0.8378\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 217us/step - loss: 1.3954 - mse: 1.3954 - mae: 0.9439 - val_loss: 1.2270 - val_mse: 1.2270 - val_mae: 0.8340\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 157us/step - loss: 1.3814 - mse: 1.3814 - mae: 0.9389 - val_loss: 1.2185 - val_mse: 1.2185 - val_mae: 0.8306\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 312us/step - loss: 1.3682 - mse: 1.3682 - mae: 0.9341 - val_loss: 1.2100 - val_mse: 1.2100 - val_mae: 0.8273\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 253us/step - loss: 1.3557 - mse: 1.3557 - mae: 0.9294 - val_loss: 1.2022 - val_mse: 1.2022 - val_mae: 0.8243\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 302us/step - loss: 1.3441 - mse: 1.3441 - mae: 0.9247 - val_loss: 1.1977 - val_mse: 1.1977 - val_mae: 0.8225\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 247us/step - loss: 1.3335 - mse: 1.3335 - mae: 0.9203 - val_loss: 1.1938 - val_mse: 1.1938 - val_mae: 0.8210\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 156us/step - loss: 1.3237 - mse: 1.3237 - mae: 0.9159 - val_loss: 1.1904 - val_mse: 1.1904 - val_mae: 0.8197\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 194us/step - loss: 1.3144 - mse: 1.3144 - mae: 0.9120 - val_loss: 1.1870 - val_mse: 1.1870 - val_mae: 0.8187\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 181us/step - loss: 1.3056 - mse: 1.3056 - mae: 0.9084 - val_loss: 1.1843 - val_mse: 1.1843 - val_mae: 0.8180\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 230us/step - loss: 1.2971 - mse: 1.2971 - mae: 0.9050 - val_loss: 1.1821 - val_mse: 1.1821 - val_mae: 0.8176\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 228us/step - loss: 1.2889 - mse: 1.2889 - mae: 0.9016 - val_loss: 1.1803 - val_mse: 1.1803 - val_mae: 0.8173\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 220us/step - loss: 1.2809 - mse: 1.2809 - mae: 0.8983 - val_loss: 1.1796 - val_mse: 1.1796 - val_mae: 0.8171\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 285us/step - loss: 1.2729 - mse: 1.2729 - mae: 0.8951 - val_loss: 1.1781 - val_mse: 1.1781 - val_mae: 0.8166\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 179us/step - loss: 1.2651 - mse: 1.2651 - mae: 0.8925 - val_loss: 1.1755 - val_mse: 1.1755 - val_mae: 0.8154\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 208us/step - loss: 1.2573 - mse: 1.2573 - mae: 0.8896 - val_loss: 1.1717 - val_mse: 1.1717 - val_mae: 0.8137\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 266us/step - loss: 1.2496 - mse: 1.2496 - mae: 0.8866 - val_loss: 1.1679 - val_mse: 1.1679 - val_mae: 0.8119\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 167us/step - loss: 1.2420 - mse: 1.2420 - mae: 0.8835 - val_loss: 1.1650 - val_mse: 1.1650 - val_mae: 0.8103\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 185us/step - loss: 1.2346 - mse: 1.2346 - mae: 0.8806 - val_loss: 1.1625 - val_mse: 1.1625 - val_mae: 0.8086\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 257us/step - loss: 1.2275 - mse: 1.2275 - mae: 0.8778 - val_loss: 1.1622 - val_mse: 1.1622 - val_mae: 0.8075\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 153us/step - loss: 1.2204 - mse: 1.2204 - mae: 0.8751 - val_loss: 1.1630 - val_mse: 1.1630 - val_mae: 0.8078\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 302us/step - loss: 1.2137 - mse: 1.2137 - mae: 0.8727 - val_loss: 1.1634 - val_mse: 1.1634 - val_mae: 0.8080\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 223us/step - loss: 1.2068 - mse: 1.2068 - mae: 0.8701 - val_loss: 1.1631 - val_mse: 1.1631 - val_mae: 0.8079\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 135us/step - loss: 1.2000 - mse: 1.2000 - mae: 0.8672 - val_loss: 1.1628 - val_mse: 1.1628 - val_mae: 0.8087\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 356us/step - loss: 1.1934 - mse: 1.1934 - mae: 0.8645 - val_loss: 1.1626 - val_mse: 1.1626 - val_mae: 0.8099\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 258us/step - loss: 1.1869 - mse: 1.1869 - mae: 0.8620 - val_loss: 1.1631 - val_mse: 1.1631 - val_mae: 0.8110\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 168us/step - loss: 1.1803 - mse: 1.1803 - mae: 0.8594 - val_loss: 1.1640 - val_mse: 1.1640 - val_mae: 0.8120\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 199us/step - loss: 1.1740 - mse: 1.1740 - mae: 0.8569 - val_loss: 1.1643 - val_mse: 1.1643 - val_mae: 0.8126\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 369us/step - loss: 1.1675 - mse: 1.1675 - mae: 0.8541 - val_loss: 1.1660 - val_mse: 1.1660 - val_mae: 0.8136\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 274us/step - loss: 1.1611 - mse: 1.1611 - mae: 0.8514 - val_loss: 1.1690 - val_mse: 1.1690 - val_mae: 0.8148\n",
      "2\n",
      "[2]\n",
      "Train on 80 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 13.3618 - mse: 13.3618 - mae: 3.4123 - val_loss: 13.3357 - val_mse: 13.3357 - val_mae: 3.6126\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 10.8217 - mse: 10.8217 - mae: 3.0381 - val_loss: 10.5807 - val_mse: 10.5807 - val_mae: 3.2110\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 203us/step - loss: 8.7232 - mse: 8.7232 - mae: 2.6880 - val_loss: 8.2245 - val_mse: 8.2245 - val_mae: 2.8223\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 151us/step - loss: 6.9718 - mse: 6.9718 - mae: 2.3567 - val_loss: 6.2562 - val_mse: 6.2562 - val_mae: 2.4499\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 152us/step - loss: 5.5593 - mse: 5.5593 - mae: 2.0524 - val_loss: 4.6333 - val_mse: 4.6333 - val_mae: 2.0936\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 198us/step - loss: 4.4433 - mse: 4.4433 - mae: 1.7774 - val_loss: 3.3694 - val_mse: 3.3694 - val_mae: 1.7672\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 182us/step - loss: 3.5869 - mse: 3.5869 - mae: 1.5349 - val_loss: 2.4217 - val_mse: 2.4217 - val_mae: 1.4759\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 182us/step - loss: 2.9501 - mse: 2.9501 - mae: 1.3331 - val_loss: 1.7879 - val_mse: 1.7879 - val_mae: 1.2435\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 224us/step - loss: 2.4999 - mse: 2.4999 - mae: 1.1769 - val_loss: 1.4069 - val_mse: 1.4069 - val_mae: 1.0830\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 225us/step - loss: 2.1749 - mse: 2.1749 - mae: 1.0516 - val_loss: 1.1535 - val_mse: 1.1535 - val_mae: 0.9676\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 205us/step - loss: 1.9406 - mse: 1.9406 - mae: 0.9574 - val_loss: 0.9624 - val_mse: 0.9624 - val_mae: 0.8798\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 170us/step - loss: 1.7666 - mse: 1.7666 - mae: 0.8894 - val_loss: 0.8126 - val_mse: 0.8126 - val_mae: 0.8087\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 225us/step - loss: 1.6322 - mse: 1.6322 - mae: 0.8459 - val_loss: 0.6955 - val_mse: 0.6955 - val_mae: 0.7454\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 333us/step - loss: 1.5241 - mse: 1.5241 - mae: 0.8202 - val_loss: 0.6031 - val_mse: 0.6031 - val_mae: 0.6888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 271us/step - loss: 1.4373 - mse: 1.4373 - mae: 0.7999 - val_loss: 0.5254 - val_mse: 0.5254 - val_mae: 0.6347\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 221us/step - loss: 1.3670 - mse: 1.3670 - mae: 0.7828 - val_loss: 0.4610 - val_mse: 0.4610 - val_mae: 0.5836\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 171us/step - loss: 1.3095 - mse: 1.3095 - mae: 0.7695 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.5363\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 285us/step - loss: 1.2636 - mse: 1.2636 - mae: 0.7577 - val_loss: 0.3664 - val_mse: 0.3664 - val_mae: 0.4925\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 314us/step - loss: 1.2290 - mse: 1.2290 - mae: 0.7479 - val_loss: 0.3335 - val_mse: 0.3335 - val_mae: 0.4570\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 366us/step - loss: 1.2022 - mse: 1.2022 - mae: 0.7425 - val_loss: 0.3086 - val_mse: 0.3086 - val_mae: 0.4254\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 228us/step - loss: 1.1817 - mse: 1.1817 - mae: 0.7394 - val_loss: 0.2899 - val_mse: 0.2899 - val_mae: 0.4025\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 204us/step - loss: 1.1659 - mse: 1.1659 - mae: 0.7384 - val_loss: 0.2762 - val_mse: 0.2762 - val_mae: 0.3884\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 139us/step - loss: 1.1538 - mse: 1.1538 - mae: 0.7384 - val_loss: 0.2666 - val_mse: 0.2666 - val_mae: 0.3763\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 201us/step - loss: 1.1445 - mse: 1.1445 - mae: 0.7386 - val_loss: 0.2595 - val_mse: 0.2595 - val_mae: 0.3659\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 220us/step - loss: 1.1371 - mse: 1.1371 - mae: 0.7413 - val_loss: 0.2546 - val_mse: 0.2546 - val_mae: 0.3572\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 215us/step - loss: 1.1315 - mse: 1.1315 - mae: 0.7434 - val_loss: 0.2515 - val_mse: 0.2515 - val_mae: 0.3503\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 328us/step - loss: 1.1267 - mse: 1.1267 - mae: 0.7447 - val_loss: 0.2495 - val_mse: 0.2495 - val_mae: 0.3447\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 238us/step - loss: 1.1217 - mse: 1.1217 - mae: 0.7451 - val_loss: 0.2477 - val_mse: 0.2477 - val_mae: 0.3413\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 314us/step - loss: 1.1170 - mse: 1.1170 - mae: 0.7449 - val_loss: 0.2456 - val_mse: 0.2456 - val_mae: 0.3384\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 197us/step - loss: 1.1125 - mse: 1.1125 - mae: 0.7442 - val_loss: 0.2440 - val_mse: 0.2440 - val_mae: 0.3363\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 241us/step - loss: 1.1081 - mse: 1.1081 - mae: 0.7432 - val_loss: 0.2433 - val_mse: 0.2433 - val_mae: 0.3351\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 314us/step - loss: 1.1036 - mse: 1.1036 - mae: 0.7418 - val_loss: 0.2416 - val_mse: 0.2416 - val_mae: 0.3343\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 203us/step - loss: 1.0991 - mse: 1.0991 - mae: 0.7402 - val_loss: 0.2402 - val_mse: 0.2402 - val_mae: 0.3339\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 307us/step - loss: 1.0947 - mse: 1.0947 - mae: 0.7386 - val_loss: 0.2389 - val_mse: 0.2389 - val_mae: 0.3337\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 304us/step - loss: 1.0906 - mse: 1.0906 - mae: 0.7367 - val_loss: 0.2381 - val_mse: 0.2381 - val_mae: 0.3349\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 292us/step - loss: 1.0861 - mse: 1.0861 - mae: 0.7341 - val_loss: 0.2374 - val_mse: 0.2374 - val_mae: 0.3363\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 249us/step - loss: 1.0815 - mse: 1.0815 - mae: 0.7314 - val_loss: 0.2369 - val_mse: 0.2369 - val_mae: 0.3378\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 366us/step - loss: 1.0769 - mse: 1.0769 - mae: 0.7286 - val_loss: 0.2364 - val_mse: 0.2364 - val_mae: 0.3392\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 372us/step - loss: 1.0727 - mse: 1.0727 - mae: 0.7261 - val_loss: 0.2361 - val_mse: 0.2361 - val_mae: 0.3405\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 333us/step - loss: 1.0685 - mse: 1.0685 - mae: 0.7235 - val_loss: 0.2357 - val_mse: 0.2357 - val_mae: 0.3413\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 374us/step - loss: 1.0649 - mse: 1.0649 - mae: 0.7212 - val_loss: 0.2355 - val_mse: 0.2355 - val_mae: 0.3426\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 286us/step - loss: 1.0618 - mse: 1.0618 - mae: 0.7195 - val_loss: 0.2353 - val_mse: 0.2353 - val_mae: 0.3433\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 280us/step - loss: 1.0589 - mse: 1.0589 - mae: 0.7182 - val_loss: 0.2350 - val_mse: 0.2350 - val_mae: 0.3435\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 313us/step - loss: 1.0561 - mse: 1.0561 - mae: 0.7172 - val_loss: 0.2348 - val_mse: 0.2348 - val_mae: 0.3439\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 278us/step - loss: 1.0532 - mse: 1.0532 - mae: 0.7163 - val_loss: 0.2343 - val_mse: 0.2343 - val_mae: 0.3444\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 335us/step - loss: 1.0500 - mse: 1.0500 - mae: 0.7155 - val_loss: 0.2338 - val_mse: 0.2338 - val_mae: 0.3450\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 247us/step - loss: 1.0467 - mse: 1.0467 - mae: 0.7146 - val_loss: 0.2333 - val_mse: 0.2333 - val_mae: 0.3456\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 253us/step - loss: 1.0435 - mse: 1.0435 - mae: 0.7137 - val_loss: 0.2329 - val_mse: 0.2329 - val_mae: 0.3462\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 242us/step - loss: 1.0403 - mse: 1.0403 - mae: 0.7129 - val_loss: 0.2324 - val_mse: 0.2324 - val_mae: 0.3469\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 281us/step - loss: 1.0375 - mse: 1.0375 - mae: 0.7124 - val_loss: 0.2318 - val_mse: 0.2318 - val_mae: 0.3470\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 248us/step - loss: 1.0347 - mse: 1.0347 - mae: 0.7120 - val_loss: 0.2313 - val_mse: 0.2313 - val_mae: 0.3469\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 291us/step - loss: 1.0318 - mse: 1.0318 - mae: 0.7117 - val_loss: 0.2307 - val_mse: 0.2307 - val_mae: 0.3466\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 327us/step - loss: 1.0288 - mse: 1.0288 - mae: 0.7114 - val_loss: 0.2303 - val_mse: 0.2303 - val_mae: 0.3463\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 497us/step - loss: 1.0254 - mse: 1.0254 - mae: 0.7109 - val_loss: 0.2303 - val_mse: 0.2303 - val_mae: 0.3462\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 251us/step - loss: 1.0216 - mse: 1.0216 - mae: 0.7102 - val_loss: 0.2300 - val_mse: 0.2300 - val_mae: 0.3460\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 294us/step - loss: 1.0178 - mse: 1.0178 - mae: 0.7094 - val_loss: 0.2298 - val_mse: 0.2298 - val_mae: 0.3459\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 324us/step - loss: 1.0140 - mse: 1.0140 - mae: 0.7086 - val_loss: 0.2296 - val_mse: 0.2296 - val_mae: 0.3460\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 348us/step - loss: 1.0103 - mse: 1.0103 - mae: 0.7080 - val_loss: 0.2293 - val_mse: 0.2293 - val_mae: 0.3460\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 421us/step - loss: 1.0068 - mse: 1.0068 - mae: 0.7072 - val_loss: 0.2286 - val_mse: 0.2286 - val_mae: 0.3461\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 173us/step - loss: 1.0031 - mse: 1.0031 - mae: 0.7058 - val_loss: 0.2285 - val_mse: 0.2285 - val_mae: 0.3469\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 357us/step - loss: 0.9997 - mse: 0.9997 - mae: 0.7044 - val_loss: 0.2287 - val_mse: 0.2287 - val_mae: 0.3480\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 138us/step - loss: 0.9961 - mse: 0.9961 - mae: 0.7027 - val_loss: 0.2289 - val_mse: 0.2289 - val_mae: 0.3492\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 156us/step - loss: 0.9923 - mse: 0.9923 - mae: 0.7010 - val_loss: 0.2292 - val_mse: 0.2292 - val_mae: 0.3502\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.9885 - mse: 0.9885 - mae: 0.6992 - val_loss: 0.2294 - val_mse: 0.2294 - val_mae: 0.3512\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 286us/step - loss: 0.9848 - mse: 0.9848 - mae: 0.6974 - val_loss: 0.2296 - val_mse: 0.2296 - val_mae: 0.3518\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 259us/step - loss: 0.9813 - mse: 0.9813 - mae: 0.6957 - val_loss: 0.2296 - val_mse: 0.2296 - val_mae: 0.3519\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 328us/step - loss: 0.9776 - mse: 0.9776 - mae: 0.6940 - val_loss: 0.2297 - val_mse: 0.2297 - val_mae: 0.3520\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 393us/step - loss: 0.9739 - mse: 0.9739 - mae: 0.6923 - val_loss: 0.2297 - val_mse: 0.2297 - val_mae: 0.3527\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 297us/step - loss: 0.9707 - mse: 0.9707 - mae: 0.6908 - val_loss: 0.2298 - val_mse: 0.2298 - val_mae: 0.3538\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 265us/step - loss: 0.9679 - mse: 0.9679 - mae: 0.6896 - val_loss: 0.2295 - val_mse: 0.2295 - val_mae: 0.3547\n",
      "3\n",
      "[3]\n",
      "Train on 97 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.7757 - mse: 4.7757 - mae: 1.6062 - val_loss: 2.0957 - val_mse: 2.0957 - val_mae: 0.9964\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 211us/step - loss: 4.1054 - mse: 4.1054 - mae: 1.4555 - val_loss: 1.8455 - val_mse: 1.8455 - val_mae: 0.9392\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 214us/step - loss: 3.7395 - mse: 3.7395 - mae: 1.3830 - val_loss: 1.6963 - val_mse: 1.6963 - val_mae: 0.9193\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 172us/step - loss: 3.5213 - mse: 3.5213 - mae: 1.3401 - val_loss: 1.6121 - val_mse: 1.6121 - val_mae: 0.9239\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 260us/step - loss: 3.3392 - mse: 3.3392 - mae: 1.3057 - val_loss: 1.5556 - val_mse: 1.5556 - val_mae: 0.9174\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 233us/step - loss: 3.1768 - mse: 3.1768 - mae: 1.2772 - val_loss: 1.5029 - val_mse: 1.5029 - val_mae: 0.8997\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 206us/step - loss: 3.0304 - mse: 3.0304 - mae: 1.2470 - val_loss: 1.4561 - val_mse: 1.4561 - val_mae: 0.8751\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 384us/step - loss: 2.9113 - mse: 2.9113 - mae: 1.2182 - val_loss: 1.4147 - val_mse: 1.4147 - val_mae: 0.8514\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 321us/step - loss: 2.8115 - mse: 2.8115 - mae: 1.1926 - val_loss: 1.3761 - val_mse: 1.3761 - val_mae: 0.8278\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 196us/step - loss: 2.7322 - mse: 2.7322 - mae: 1.1710 - val_loss: 1.3499 - val_mse: 1.3499 - val_mae: 0.8116\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 137us/step - loss: 2.6637 - mse: 2.6637 - mae: 1.1519 - val_loss: 1.3337 - val_mse: 1.3337 - val_mae: 0.7995\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 135us/step - loss: 2.6026 - mse: 2.6026 - mae: 1.1341 - val_loss: 1.3155 - val_mse: 1.3155 - val_mae: 0.7881\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 280us/step - loss: 2.5495 - mse: 2.5495 - mae: 1.1199 - val_loss: 1.3018 - val_mse: 1.3018 - val_mae: 0.7816\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 144us/step - loss: 2.5002 - mse: 2.5002 - mae: 1.1074 - val_loss: 1.2891 - val_mse: 1.2891 - val_mae: 0.7780\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 324us/step - loss: 2.4528 - mse: 2.4528 - mae: 1.0961 - val_loss: 1.2763 - val_mse: 1.2763 - val_mae: 0.7732\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 377us/step - loss: 2.4058 - mse: 2.4058 - mae: 1.0857 - val_loss: 1.2662 - val_mse: 1.2662 - val_mae: 0.7678\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 286us/step - loss: 2.3629 - mse: 2.3629 - mae: 1.0748 - val_loss: 1.2582 - val_mse: 1.2582 - val_mae: 0.7632\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 201us/step - loss: 2.3241 - mse: 2.3241 - mae: 1.0642 - val_loss: 1.2512 - val_mse: 1.2512 - val_mae: 0.7587\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 222us/step - loss: 2.2864 - mse: 2.2864 - mae: 1.0550 - val_loss: 1.2428 - val_mse: 1.2428 - val_mae: 0.7545\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 269us/step - loss: 2.2550 - mse: 2.2550 - mae: 1.0456 - val_loss: 1.2336 - val_mse: 1.2336 - val_mae: 0.7513\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 223us/step - loss: 2.2254 - mse: 2.2254 - mae: 1.0382 - val_loss: 1.2249 - val_mse: 1.2249 - val_mae: 0.7473\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 252us/step - loss: 2.1959 - mse: 2.1959 - mae: 1.0317 - val_loss: 1.2171 - val_mse: 1.2171 - val_mae: 0.7432\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 150us/step - loss: 2.1674 - mse: 2.1674 - mae: 1.0256 - val_loss: 1.2103 - val_mse: 1.2103 - val_mae: 0.7385\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 139us/step - loss: 2.1394 - mse: 2.1394 - mae: 1.0186 - val_loss: 1.2029 - val_mse: 1.2029 - val_mae: 0.7345\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 157us/step - loss: 2.1160 - mse: 2.1160 - mae: 1.0126 - val_loss: 1.2002 - val_mse: 1.2002 - val_mae: 0.7336\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 347us/step - loss: 2.0931 - mse: 2.0931 - mae: 1.0075 - val_loss: 1.1961 - val_mse: 1.1961 - val_mae: 0.7346\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 369us/step - loss: 2.0713 - mse: 2.0713 - mae: 1.0031 - val_loss: 1.1906 - val_mse: 1.1906 - val_mae: 0.7358\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 320us/step - loss: 2.0502 - mse: 2.0502 - mae: 0.9991 - val_loss: 1.1886 - val_mse: 1.1886 - val_mae: 0.7363\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 527us/step - loss: 2.0329 - mse: 2.0329 - mae: 0.9948 - val_loss: 1.1857 - val_mse: 1.1857 - val_mae: 0.7370\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 435us/step - loss: 2.0125 - mse: 2.0125 - mae: 0.9908 - val_loss: 1.1810 - val_mse: 1.1810 - val_mae: 0.7365\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 310us/step - loss: 1.9929 - mse: 1.9929 - mae: 0.9857 - val_loss: 1.1799 - val_mse: 1.1799 - val_mae: 0.7368\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 145us/step - loss: 1.9758 - mse: 1.9758 - mae: 0.9814 - val_loss: 1.1732 - val_mse: 1.1732 - val_mae: 0.7357\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 186us/step - loss: 1.9587 - mse: 1.9587 - mae: 0.9780 - val_loss: 1.1686 - val_mse: 1.1686 - val_mae: 0.7346\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 144us/step - loss: 1.9412 - mse: 1.9412 - mae: 0.9738 - val_loss: 1.1677 - val_mse: 1.1677 - val_mae: 0.7344\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 217us/step - loss: 1.9240 - mse: 1.9240 - mae: 0.9682 - val_loss: 1.1699 - val_mse: 1.1699 - val_mae: 0.7354\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 271us/step - loss: 1.9073 - mse: 1.9073 - mae: 0.9629 - val_loss: 1.1676 - val_mse: 1.1676 - val_mae: 0.7358\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 139us/step - loss: 1.8901 - mse: 1.8901 - mae: 0.9595 - val_loss: 1.1638 - val_mse: 1.1638 - val_mae: 0.7357\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 235us/step - loss: 1.8769 - mse: 1.8769 - mae: 0.9562 - val_loss: 1.1654 - val_mse: 1.1654 - val_mae: 0.7360\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 165us/step - loss: 1.8611 - mse: 1.8611 - mae: 0.9510 - val_loss: 1.1686 - val_mse: 1.1686 - val_mae: 0.7387\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 252us/step - loss: 1.8456 - mse: 1.8456 - mae: 0.9467 - val_loss: 1.1686 - val_mse: 1.1686 - val_mae: 0.7411\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 131us/step - loss: 1.8299 - mse: 1.8299 - mae: 0.9436 - val_loss: 1.1642 - val_mse: 1.1642 - val_mae: 0.7426\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 304us/step - loss: 1.8150 - mse: 1.8150 - mae: 0.9402 - val_loss: 1.1610 - val_mse: 1.1610 - val_mae: 0.7424\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 229us/step - loss: 1.8022 - mse: 1.8022 - mae: 0.9360 - val_loss: 1.1612 - val_mse: 1.1612 - val_mae: 0.7425\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 155us/step - loss: 1.7856 - mse: 1.7856 - mae: 0.9315 - val_loss: 1.1617 - val_mse: 1.1617 - val_mae: 0.7436\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 286us/step - loss: 1.7694 - mse: 1.7694 - mae: 0.9281 - val_loss: 1.1602 - val_mse: 1.1602 - val_mae: 0.7433\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 253us/step - loss: 1.7553 - mse: 1.7553 - mae: 0.9234 - val_loss: 1.1580 - val_mse: 1.1580 - val_mae: 0.7421\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 353us/step - loss: 1.7415 - mse: 1.7415 - mae: 0.9186 - val_loss: 1.1549 - val_mse: 1.1549 - val_mae: 0.7414\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 287us/step - loss: 1.7285 - mse: 1.7285 - mae: 0.9161 - val_loss: 1.1518 - val_mse: 1.1518 - val_mae: 0.7440\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 138us/step - loss: 1.7127 - mse: 1.7127 - mae: 0.9154 - val_loss: 1.1516 - val_mse: 1.1516 - val_mae: 0.7469\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 179us/step - loss: 1.6947 - mse: 1.6947 - mae: 0.9122 - val_loss: 1.1437 - val_mse: 1.1437 - val_mae: 0.7448\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 260us/step - loss: 1.6703 - mse: 1.6703 - mae: 0.9066 - val_loss: 1.1340 - val_mse: 1.1340 - val_mae: 0.7406\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 0s 297us/step - loss: 1.6429 - mse: 1.6429 - mae: 0.9006 - val_loss: 1.1295 - val_mse: 1.1295 - val_mae: 0.7336\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 0s 240us/step - loss: 1.6161 - mse: 1.6161 - mae: 0.8931 - val_loss: 1.1261 - val_mse: 1.1261 - val_mae: 0.7276\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 0s 304us/step - loss: 1.5888 - mse: 1.5888 - mae: 0.8860 - val_loss: 1.1248 - val_mse: 1.1248 - val_mae: 0.7245\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 0s 283us/step - loss: 1.5671 - mse: 1.5671 - mae: 0.8819 - val_loss: 1.1300 - val_mse: 1.1300 - val_mae: 0.7247\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 0s 167us/step - loss: 1.5391 - mse: 1.5391 - mae: 0.8736 - val_loss: 1.1379 - val_mse: 1.1379 - val_mae: 0.7246\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 0s 403us/step - loss: 1.5113 - mse: 1.5113 - mae: 0.8645 - val_loss: 1.1469 - val_mse: 1.1469 - val_mae: 0.7273\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 0s 536us/step - loss: 1.4847 - mse: 1.4847 - mae: 0.8562 - val_loss: 1.1564 - val_mse: 1.1564 - val_mae: 0.7305\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 0s 205us/step - loss: 1.4639 - mse: 1.4639 - mae: 0.8507 - val_loss: 1.1646 - val_mse: 1.1646 - val_mae: 0.7352\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 0s 337us/step - loss: 1.4404 - mse: 1.4404 - mae: 0.8473 - val_loss: 1.1702 - val_mse: 1.1702 - val_mae: 0.7399\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 0s 319us/step - loss: 1.4173 - mse: 1.4173 - mae: 0.8430 - val_loss: 1.1738 - val_mse: 1.1738 - val_mae: 0.7410\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 0s 443us/step - loss: 1.3971 - mse: 1.3971 - mae: 0.8375 - val_loss: 1.1759 - val_mse: 1.1759 - val_mae: 0.7436\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 0s 200us/step - loss: 1.3776 - mse: 1.3776 - mae: 0.8326 - val_loss: 1.1791 - val_mse: 1.1791 - val_mae: 0.7435\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 0s 299us/step - loss: 1.3589 - mse: 1.3589 - mae: 0.8272 - val_loss: 1.1854 - val_mse: 1.1854 - val_mae: 0.7482\n",
      "4\n",
      "[4]\n",
      "Train on 103 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 6.2523 - mse: 6.2523 - mae: 2.2224 - val_loss: 6.1190 - val_mse: 6.1190 - val_mae: 2.3093\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 159us/step - loss: 5.0215 - mse: 5.0215 - mae: 1.9254 - val_loss: 4.7251 - val_mse: 4.7251 - val_mae: 2.0022\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 220us/step - loss: 4.0685 - mse: 4.0685 - mae: 1.6598 - val_loss: 3.6755 - val_mse: 3.6755 - val_mae: 1.7321\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 347us/step - loss: 3.3673 - mse: 3.3673 - mae: 1.4381 - val_loss: 2.9259 - val_mse: 2.9259 - val_mae: 1.5074\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 156us/step - loss: 2.8546 - mse: 2.8546 - mae: 1.2580 - val_loss: 2.3734 - val_mse: 2.3734 - val_mae: 1.3231\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 344us/step - loss: 2.4512 - mse: 2.4512 - mae: 1.1223 - val_loss: 1.9343 - val_mse: 1.9343 - val_mae: 1.1672\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 230us/step - loss: 2.1337 - mse: 2.1337 - mae: 1.0233 - val_loss: 1.5785 - val_mse: 1.5785 - val_mae: 1.0315\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 145us/step - loss: 1.8915 - mse: 1.8915 - mae: 0.9476 - val_loss: 1.2935 - val_mse: 1.2935 - val_mae: 0.9311\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 163us/step - loss: 1.7112 - mse: 1.7112 - mae: 0.9065 - val_loss: 1.0672 - val_mse: 1.0672 - val_mae: 0.8441\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 123us/step - loss: 1.5851 - mse: 1.5851 - mae: 0.8825 - val_loss: 0.9051 - val_mse: 0.9051 - val_mae: 0.7932\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 243us/step - loss: 1.5042 - mse: 1.5042 - mae: 0.8711 - val_loss: 0.8010 - val_mse: 0.8010 - val_mae: 0.7531\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 338us/step - loss: 1.4593 - mse: 1.4593 - mae: 0.8730 - val_loss: 0.7410 - val_mse: 0.7410 - val_mae: 0.7287\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 222us/step - loss: 1.4375 - mse: 1.4375 - mae: 0.8805 - val_loss: 0.7131 - val_mse: 0.7131 - val_mae: 0.7143\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 259us/step - loss: 1.4284 - mse: 1.4284 - mae: 0.8883 - val_loss: 0.7018 - val_mse: 0.7018 - val_mae: 0.7052\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 204us/step - loss: 1.4210 - mse: 1.4210 - mae: 0.8913 - val_loss: 0.6964 - val_mse: 0.6964 - val_mae: 0.7010\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 173us/step - loss: 1.4101 - mse: 1.4101 - mae: 0.8897 - val_loss: 0.6935 - val_mse: 0.6935 - val_mae: 0.7013\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 301us/step - loss: 1.3948 - mse: 1.3948 - mae: 0.8841 - val_loss: 0.6924 - val_mse: 0.6924 - val_mae: 0.7049\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 314us/step - loss: 1.3769 - mse: 1.3769 - mae: 0.8761 - val_loss: 0.6947 - val_mse: 0.6947 - val_mae: 0.7103\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 178us/step - loss: 1.3591 - mse: 1.3591 - mae: 0.8674 - val_loss: 0.6991 - val_mse: 0.6991 - val_mae: 0.7161\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 318us/step - loss: 1.3422 - mse: 1.3422 - mae: 0.8588 - val_loss: 0.7047 - val_mse: 0.7047 - val_mae: 0.7212\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 166us/step - loss: 1.3276 - mse: 1.3276 - mae: 0.8509 - val_loss: 0.7089 - val_mse: 0.7089 - val_mae: 0.7244\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 523us/step - loss: 1.3130 - mse: 1.3130 - mae: 0.8440 - val_loss: 0.7121 - val_mse: 0.7121 - val_mae: 0.7267\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 130us/step - loss: 1.2984 - mse: 1.2984 - mae: 0.8374 - val_loss: 0.7140 - val_mse: 0.7140 - val_mae: 0.7283\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 148us/step - loss: 1.2847 - mse: 1.2847 - mae: 0.8324 - val_loss: 0.7141 - val_mse: 0.7141 - val_mae: 0.7287\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 144us/step - loss: 1.2719 - mse: 1.2719 - mae: 0.8281 - val_loss: 0.7123 - val_mse: 0.7123 - val_mae: 0.7281\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 191us/step - loss: 1.2587 - mse: 1.2587 - mae: 0.8239 - val_loss: 0.7108 - val_mse: 0.7108 - val_mae: 0.7272\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 266us/step - loss: 1.2463 - mse: 1.2463 - mae: 0.8201 - val_loss: 0.7086 - val_mse: 0.7086 - val_mae: 0.7258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[5]\n",
      "Train on 80 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.5984 - mse: 19.5984 - mae: 4.1237 - val_loss: 20.2351 - val_mse: 20.2351 - val_mae: 4.4275\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 266us/step - loss: 17.0640 - mse: 17.0640 - mae: 3.8230 - val_loss: 17.7287 - val_mse: 17.7287 - val_mae: 4.1387\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 401us/step - loss: 14.9965 - mse: 14.9965 - mae: 3.5554 - val_loss: 15.6491 - val_mse: 15.6491 - val_mae: 3.8818\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 13.2962 - mse: 13.2962 - mae: 3.3185 - val_loss: 13.9563 - val_mse: 13.9563 - val_mae: 3.6579\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 307us/step - loss: 11.8731 - mse: 11.8731 - mae: 3.1067 - val_loss: 12.5558 - val_mse: 12.5558 - val_mae: 3.4624\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 204us/step - loss: 10.7083 - mse: 10.7083 - mae: 2.9226 - val_loss: 11.3770 - val_mse: 11.3770 - val_mae: 3.2890\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 185us/step - loss: 9.7520 - mse: 9.7520 - mae: 2.7623 - val_loss: 10.4111 - val_mse: 10.4111 - val_mae: 3.1396\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 461us/step - loss: 8.9593 - mse: 8.9593 - mae: 2.6239 - val_loss: 9.6464 - val_mse: 9.6464 - val_mae: 3.0158\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 573us/step - loss: 8.3005 - mse: 8.3005 - mae: 2.5049 - val_loss: 9.0661 - val_mse: 9.0661 - val_mae: 2.9171\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 254us/step - loss: 7.7841 - mse: 7.7841 - mae: 2.4076 - val_loss: 8.6001 - val_mse: 8.6001 - val_mae: 2.8344\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 484us/step - loss: 7.3623 - mse: 7.3623 - mae: 2.3260 - val_loss: 8.2232 - val_mse: 8.2232 - val_mae: 2.7663\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 270us/step - loss: 7.0155 - mse: 7.0155 - mae: 2.2569 - val_loss: 7.9207 - val_mse: 7.9207 - val_mae: 2.7120\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 304us/step - loss: 6.7388 - mse: 6.7388 - mae: 2.2006 - val_loss: 7.6956 - val_mse: 7.6956 - val_mae: 2.6689\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 316us/step - loss: 6.5176 - mse: 6.5176 - mae: 2.1544 - val_loss: 7.5144 - val_mse: 7.5144 - val_mae: 2.6330\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 152us/step - loss: 6.3298 - mse: 6.3298 - mae: 2.1149 - val_loss: 7.4029 - val_mse: 7.4029 - val_mae: 2.6112\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 383us/step - loss: 6.1769 - mse: 6.1769 - mae: 2.0827 - val_loss: 7.3162 - val_mse: 7.3162 - val_mae: 2.5954\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 330us/step - loss: 6.0483 - mse: 6.0483 - mae: 2.0554 - val_loss: 7.2451 - val_mse: 7.2451 - val_mae: 2.5829\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 304us/step - loss: 5.9471 - mse: 5.9471 - mae: 2.0340 - val_loss: 7.1948 - val_mse: 7.1948 - val_mae: 2.5738\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 339us/step - loss: 5.8669 - mse: 5.8669 - mae: 2.0173 - val_loss: 7.1541 - val_mse: 7.1541 - val_mae: 2.5661\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 164us/step - loss: 5.7966 - mse: 5.7966 - mae: 2.0028 - val_loss: 7.1199 - val_mse: 7.1199 - val_mae: 2.5598\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 352us/step - loss: 5.7392 - mse: 5.7392 - mae: 1.9907 - val_loss: 7.0886 - val_mse: 7.0886 - val_mae: 2.5542\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 528us/step - loss: 5.6903 - mse: 5.6903 - mae: 1.9805 - val_loss: 7.0599 - val_mse: 7.0599 - val_mae: 2.5490\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 325us/step - loss: 5.6482 - mse: 5.6482 - mae: 1.9713 - val_loss: 7.0332 - val_mse: 7.0332 - val_mae: 2.5442\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 390us/step - loss: 5.6124 - mse: 5.6124 - mae: 1.9634 - val_loss: 7.0079 - val_mse: 7.0079 - val_mae: 2.5396\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 223us/step - loss: 5.5793 - mse: 5.5793 - mae: 1.9562 - val_loss: 6.9842 - val_mse: 6.9842 - val_mae: 2.5353\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 266us/step - loss: 5.5481 - mse: 5.5481 - mae: 1.9492 - val_loss: 6.9624 - val_mse: 6.9624 - val_mae: 2.5313\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 211us/step - loss: 5.5182 - mse: 5.5182 - mae: 1.9426 - val_loss: 6.9408 - val_mse: 6.9408 - val_mae: 2.5275\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 223us/step - loss: 5.4919 - mse: 5.4919 - mae: 1.9369 - val_loss: 6.9189 - val_mse: 6.9189 - val_mae: 2.5236\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 245us/step - loss: 5.4673 - mse: 5.4673 - mae: 1.9314 - val_loss: 6.8975 - val_mse: 6.8975 - val_mae: 2.5197\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 180us/step - loss: 5.4447 - mse: 5.4447 - mae: 1.9263 - val_loss: 6.8766 - val_mse: 6.8766 - val_mae: 2.5159\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 5.4235 - mse: 5.4235 - mae: 1.9216 - val_loss: 6.8561 - val_mse: 6.8561 - val_mae: 2.5122\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 293us/step - loss: 5.4029 - mse: 5.4029 - mae: 1.9170 - val_loss: 6.8359 - val_mse: 6.8359 - val_mae: 2.5084\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 224us/step - loss: 5.3826 - mse: 5.3826 - mae: 1.9125 - val_loss: 6.8160 - val_mse: 6.8160 - val_mae: 2.5048\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 335us/step - loss: 5.3631 - mse: 5.3631 - mae: 1.9082 - val_loss: 6.7972 - val_mse: 6.7972 - val_mae: 2.5013\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 291us/step - loss: 5.3448 - mse: 5.3448 - mae: 1.9043 - val_loss: 6.7789 - val_mse: 6.7789 - val_mae: 2.4979\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 168us/step - loss: 5.3273 - mse: 5.3273 - mae: 1.9006 - val_loss: 6.7610 - val_mse: 6.7610 - val_mae: 2.4945\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 405us/step - loss: 5.3098 - mse: 5.3098 - mae: 1.8970 - val_loss: 6.7434 - val_mse: 6.7434 - val_mae: 2.4912\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 223us/step - loss: 5.2924 - mse: 5.2924 - mae: 1.8933 - val_loss: 6.7262 - val_mse: 6.7262 - val_mae: 2.4879\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 388us/step - loss: 5.2758 - mse: 5.2758 - mae: 1.8898 - val_loss: 6.7094 - val_mse: 6.7094 - val_mae: 2.4847\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 168us/step - loss: 5.2611 - mse: 5.2611 - mae: 1.8865 - val_loss: 6.6934 - val_mse: 6.6934 - val_mae: 2.4817\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 339us/step - loss: 5.2466 - mse: 5.2466 - mae: 1.8832 - val_loss: 6.6785 - val_mse: 6.6785 - val_mae: 2.4788\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 583us/step - loss: 5.2322 - mse: 5.2322 - mae: 1.8800 - val_loss: 6.6635 - val_mse: 6.6635 - val_mae: 2.4758\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 446us/step - loss: 5.2178 - mse: 5.2178 - mae: 1.8767 - val_loss: 6.6484 - val_mse: 6.6484 - val_mae: 2.4729\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 153us/step - loss: 5.2034 - mse: 5.2034 - mae: 1.8734 - val_loss: 6.6331 - val_mse: 6.6331 - val_mae: 2.4699\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 223us/step - loss: 5.1891 - mse: 5.1891 - mae: 1.8702 - val_loss: 6.6178 - val_mse: 6.6178 - val_mae: 2.4669\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 132us/step - loss: 5.1747 - mse: 5.1747 - mae: 1.8669 - val_loss: 6.6040 - val_mse: 6.6040 - val_mae: 2.4641\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 242us/step - loss: 5.1605 - mse: 5.1605 - mae: 1.8636 - val_loss: 6.5903 - val_mse: 6.5903 - val_mae: 2.4613\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 453us/step - loss: 5.1461 - mse: 5.1461 - mae: 1.8603 - val_loss: 6.5762 - val_mse: 6.5762 - val_mae: 2.4585\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 267us/step - loss: 5.1318 - mse: 5.1318 - mae: 1.8571 - val_loss: 6.5620 - val_mse: 6.5620 - val_mae: 2.4556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 164us/step - loss: 5.1176 - mse: 5.1176 - mae: 1.8538 - val_loss: 6.5483 - val_mse: 6.5483 - val_mae: 2.4528\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 442us/step - loss: 5.1033 - mse: 5.1033 - mae: 1.8504 - val_loss: 6.5349 - val_mse: 6.5349 - val_mae: 2.4501\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 148us/step - loss: 5.0890 - mse: 5.0890 - mae: 1.8471 - val_loss: 6.5216 - val_mse: 6.5216 - val_mae: 2.4474\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 536us/step - loss: 5.0747 - mse: 5.0747 - mae: 1.8438 - val_loss: 6.5082 - val_mse: 6.5082 - val_mae: 2.4448\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 276us/step - loss: 5.0606 - mse: 5.0606 - mae: 1.8405 - val_loss: 6.4950 - val_mse: 6.4950 - val_mae: 2.4421\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 193us/step - loss: 5.0468 - mse: 5.0468 - mae: 1.8373 - val_loss: 6.4819 - val_mse: 6.4819 - val_mae: 2.4395\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 149us/step - loss: 5.0341 - mse: 5.0341 - mae: 1.8343 - val_loss: 6.4689 - val_mse: 6.4689 - val_mae: 2.4368\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 141us/step - loss: 5.0230 - mse: 5.0230 - mae: 1.8315 - val_loss: 6.4560 - val_mse: 6.4560 - val_mae: 2.4342\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 299us/step - loss: 5.0129 - mse: 5.0129 - mae: 1.8288 - val_loss: 6.4441 - val_mse: 6.4441 - val_mae: 2.4318\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 398us/step - loss: 5.0031 - mse: 5.0031 - mae: 1.8261 - val_loss: 6.4322 - val_mse: 6.4322 - val_mae: 2.4293\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 251us/step - loss: 4.9935 - mse: 4.9935 - mae: 1.8235 - val_loss: 6.4204 - val_mse: 6.4204 - val_mae: 2.4269\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 378us/step - loss: 4.9839 - mse: 4.9839 - mae: 1.8210 - val_loss: 6.4086 - val_mse: 6.4086 - val_mae: 2.4244\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 350us/step - loss: 4.9744 - mse: 4.9744 - mae: 1.8184 - val_loss: 6.3967 - val_mse: 6.3967 - val_mae: 2.4220\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 189us/step - loss: 4.9649 - mse: 4.9649 - mae: 1.8158 - val_loss: 6.3849 - val_mse: 6.3849 - val_mae: 2.4196\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 145us/step - loss: 4.9554 - mse: 4.9554 - mae: 1.8133 - val_loss: 6.3730 - val_mse: 6.3730 - val_mae: 2.4171\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 346us/step - loss: 4.9459 - mse: 4.9459 - mae: 1.8107 - val_loss: 6.3612 - val_mse: 6.3612 - val_mae: 2.4147\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 270us/step - loss: 4.9365 - mse: 4.9365 - mae: 1.8082 - val_loss: 6.3494 - val_mse: 6.3494 - val_mae: 2.4122\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 336us/step - loss: 4.9270 - mse: 4.9270 - mae: 1.8056 - val_loss: 6.3375 - val_mse: 6.3375 - val_mae: 2.4098\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 268us/step - loss: 4.9176 - mse: 4.9176 - mae: 1.8030 - val_loss: 6.3257 - val_mse: 6.3257 - val_mae: 2.4073\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 250us/step - loss: 4.9082 - mse: 4.9082 - mae: 1.8005 - val_loss: 6.3139 - val_mse: 6.3139 - val_mae: 2.4048\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 289us/step - loss: 4.8988 - mse: 4.8988 - mae: 1.7979 - val_loss: 6.3021 - val_mse: 6.3021 - val_mae: 2.4024\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 229us/step - loss: 4.8894 - mse: 4.8894 - mae: 1.7954 - val_loss: 6.2902 - val_mse: 6.2902 - val_mae: 2.3999\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 194us/step - loss: 4.8800 - mse: 4.8800 - mae: 1.7928 - val_loss: 6.2784 - val_mse: 6.2784 - val_mae: 2.3975\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 304us/step - loss: 4.8706 - mse: 4.8706 - mae: 1.7902 - val_loss: 6.2666 - val_mse: 6.2666 - val_mae: 2.3950\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 271us/step - loss: 4.8613 - mse: 4.8613 - mae: 1.7877 - val_loss: 6.2548 - val_mse: 6.2548 - val_mae: 2.3925\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 353us/step - loss: 4.8519 - mse: 4.8519 - mae: 1.7851 - val_loss: 6.2430 - val_mse: 6.2430 - val_mae: 2.3901\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 235us/step - loss: 4.8425 - mse: 4.8425 - mae: 1.7825 - val_loss: 6.2312 - val_mse: 6.2312 - val_mae: 2.3876\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 248us/step - loss: 4.8332 - mse: 4.8332 - mae: 1.7800 - val_loss: 6.2194 - val_mse: 6.2194 - val_mae: 2.3851\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 278us/step - loss: 4.8238 - mse: 4.8238 - mae: 1.7774 - val_loss: 6.2076 - val_mse: 6.2076 - val_mae: 2.3826\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 206us/step - loss: 4.8145 - mse: 4.8145 - mae: 1.7748 - val_loss: 6.1958 - val_mse: 6.1958 - val_mae: 2.3802\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 305us/step - loss: 4.8051 - mse: 4.8051 - mae: 1.7722 - val_loss: 6.1841 - val_mse: 6.1841 - val_mae: 2.3777\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 185us/step - loss: 4.7958 - mse: 4.7958 - mae: 1.7697 - val_loss: 6.1723 - val_mse: 6.1723 - val_mae: 2.3752\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 206us/step - loss: 4.7865 - mse: 4.7865 - mae: 1.7671 - val_loss: 6.1605 - val_mse: 6.1605 - val_mae: 2.3727\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 258us/step - loss: 4.7772 - mse: 4.7772 - mae: 1.7645 - val_loss: 6.1488 - val_mse: 6.1488 - val_mae: 2.3703\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 266us/step - loss: 4.7679 - mse: 4.7679 - mae: 1.7619 - val_loss: 6.1371 - val_mse: 6.1371 - val_mae: 2.3678\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 320us/step - loss: 4.7586 - mse: 4.7586 - mae: 1.7593 - val_loss: 6.1253 - val_mse: 6.1253 - val_mae: 2.3653\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 205us/step - loss: 4.7494 - mse: 4.7494 - mae: 1.7568 - val_loss: 6.1136 - val_mse: 6.1136 - val_mae: 2.3628\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 151us/step - loss: 4.7401 - mse: 4.7401 - mae: 1.7542 - val_loss: 6.1019 - val_mse: 6.1019 - val_mae: 2.3604\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 155us/step - loss: 4.7308 - mse: 4.7308 - mae: 1.7516 - val_loss: 6.0902 - val_mse: 6.0902 - val_mae: 2.3579\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - ETA: 0s - loss: 6.2588 - mse: 6.2588 - mae: 1.888 - 0s 193us/step - loss: 4.7216 - mse: 4.7216 - mae: 1.7490 - val_loss: 6.0785 - val_mse: 6.0785 - val_mae: 2.3554\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 299us/step - loss: 4.7124 - mse: 4.7124 - mae: 1.7464 - val_loss: 6.0668 - val_mse: 6.0668 - val_mae: 2.3529\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 487us/step - loss: 4.7031 - mse: 4.7031 - mae: 1.7438 - val_loss: 6.0552 - val_mse: 6.0552 - val_mae: 2.3504\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 219us/step - loss: 4.6939 - mse: 4.6939 - mae: 1.7412 - val_loss: 6.0435 - val_mse: 6.0435 - val_mae: 2.3480\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 142us/step - loss: 4.6847 - mse: 4.6847 - mae: 1.7387 - val_loss: 6.0319 - val_mse: 6.0319 - val_mae: 2.3455\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 374us/step - loss: 4.6755 - mse: 4.6755 - mae: 1.7361 - val_loss: 6.0202 - val_mse: 6.0202 - val_mae: 2.3430\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 430us/step - loss: 4.6666 - mse: 4.6666 - mae: 1.7335 - val_loss: 6.0086 - val_mse: 6.0086 - val_mae: 2.3405\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 645us/step - loss: 4.6579 - mse: 4.6579 - mae: 1.7310 - val_loss: 5.9970 - val_mse: 5.9970 - val_mae: 2.3380\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 246us/step - loss: 4.6493 - mse: 4.6493 - mae: 1.7285 - val_loss: 5.9854 - val_mse: 5.9854 - val_mae: 2.3356\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 229us/step - loss: 4.6406 - mse: 4.6406 - mae: 1.7260 - val_loss: 5.9738 - val_mse: 5.9738 - val_mae: 2.3331\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 151us/step - loss: 4.6320 - mse: 4.6320 - mae: 1.7235 - val_loss: 5.9623 - val_mse: 5.9623 - val_mae: 2.3306\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 278us/step - loss: 4.6233 - mse: 4.6233 - mae: 1.7210 - val_loss: 5.9507 - val_mse: 5.9507 - val_mae: 2.3281\n",
      "6\n",
      "[6]\n",
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 6.9470 - mse: 6.9470 - mae: 2.4830 - val_loss: 3.9476 - val_mse: 3.9476 - val_mae: 1.8470\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 0s 530us/step - loss: 5.4945 - mse: 5.4945 - mae: 2.1771 - val_loss: 2.9535 - val_mse: 2.9535 - val_mae: 1.5590\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 0s 174us/step - loss: 4.2419 - mse: 4.2419 - mae: 1.8760 - val_loss: 2.2235 - val_mse: 2.2235 - val_mae: 1.3106\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 0s 235us/step - loss: 3.2539 - mse: 3.2539 - mae: 1.6031 - val_loss: 1.6985 - val_mse: 1.6985 - val_mae: 1.0919\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 0s 196us/step - loss: 2.5050 - mse: 2.5050 - mae: 1.3642 - val_loss: 1.3287 - val_mse: 1.3287 - val_mae: 0.9024\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 0s 239us/step - loss: 1.9702 - mse: 1.9702 - mae: 1.1690 - val_loss: 1.0855 - val_mse: 1.0855 - val_mae: 0.7490\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 0s 350us/step - loss: 1.6142 - mse: 1.6142 - mae: 1.0211 - val_loss: 0.9209 - val_mse: 0.9209 - val_mae: 0.6293\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 0s 434us/step - loss: 1.3686 - mse: 1.3686 - mae: 0.9105 - val_loss: 0.8058 - val_mse: 0.8058 - val_mae: 0.5436\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 0s 328us/step - loss: 1.1806 - mse: 1.1806 - mae: 0.8216 - val_loss: 0.7323 - val_mse: 0.7323 - val_mae: 0.4969\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 0s 282us/step - loss: 1.0291 - mse: 1.0291 - mae: 0.7481 - val_loss: 0.6796 - val_mse: 0.6796 - val_mae: 0.4646\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 0s 392us/step - loss: 0.9095 - mse: 0.9095 - mae: 0.6965 - val_loss: 0.6427 - val_mse: 0.6427 - val_mae: 0.4475\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 0s 187us/step - loss: 0.8083 - mse: 0.8083 - mae: 0.6524 - val_loss: 0.6221 - val_mse: 0.6221 - val_mae: 0.4505\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 0s 404us/step - loss: 0.7211 - mse: 0.7211 - mae: 0.6164 - val_loss: 0.6211 - val_mse: 0.6211 - val_mae: 0.4587\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 0s 232us/step - loss: 0.6552 - mse: 0.6552 - mae: 0.5997 - val_loss: 0.6376 - val_mse: 0.6376 - val_mae: 0.4838\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 0s 316us/step - loss: 0.6140 - mse: 0.6140 - mae: 0.6010 - val_loss: 0.6658 - val_mse: 0.6658 - val_mae: 0.5191\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 0s 258us/step - loss: 0.5903 - mse: 0.5903 - mae: 0.6058 - val_loss: 0.6934 - val_mse: 0.6934 - val_mae: 0.5549\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 0s 262us/step - loss: 0.5802 - mse: 0.5802 - mae: 0.6102 - val_loss: 0.7165 - val_mse: 0.7165 - val_mae: 0.5800\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 0s 280us/step - loss: 0.5777 - mse: 0.5777 - mae: 0.6126 - val_loss: 0.7308 - val_mse: 0.7308 - val_mae: 0.5951\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 0s 256us/step - loss: 0.5754 - mse: 0.5754 - mae: 0.6134 - val_loss: 0.7350 - val_mse: 0.7350 - val_mae: 0.5995\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 0s 241us/step - loss: 0.5709 - mse: 0.5709 - mae: 0.6114 - val_loss: 0.7316 - val_mse: 0.7316 - val_mae: 0.5947\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 0s 325us/step - loss: 0.5653 - mse: 0.5653 - mae: 0.6076 - val_loss: 0.7239 - val_mse: 0.7239 - val_mae: 0.5866\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 0s 287us/step - loss: 0.5606 - mse: 0.5606 - mae: 0.6039 - val_loss: 0.7162 - val_mse: 0.7162 - val_mae: 0.5776\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 0s 136us/step - loss: 0.5563 - mse: 0.5563 - mae: 0.6000 - val_loss: 0.7086 - val_mse: 0.7086 - val_mae: 0.5697\n",
      "7\n",
      "[7]\n",
      "Train on 98 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 15.3897 - mse: 15.3897 - mae: 3.3105 - val_loss: 7.6022 - val_mse: 7.6022 - val_mae: 2.3148\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 304us/step - loss: 12.5683 - mse: 12.5683 - mae: 2.8771 - val_loss: 5.9609 - val_mse: 5.9609 - val_mae: 1.9456\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 337us/step - loss: 10.2582 - mse: 10.2582 - mae: 2.4948 - val_loss: 4.6044 - val_mse: 4.6044 - val_mae: 1.6276\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 359us/step - loss: 8.4009 - mse: 8.4009 - mae: 2.1675 - val_loss: 3.5534 - val_mse: 3.5534 - val_mae: 1.3354\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 430us/step - loss: 7.0068 - mse: 7.0068 - mae: 1.9065 - val_loss: 2.7951 - val_mse: 2.7951 - val_mae: 1.0817\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 330us/step - loss: 6.0371 - mse: 6.0371 - mae: 1.7348 - val_loss: 2.3071 - val_mse: 2.3071 - val_mae: 0.9459\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 331us/step - loss: 5.4024 - mse: 5.4024 - mae: 1.6327 - val_loss: 2.0236 - val_mse: 2.0236 - val_mae: 0.8856\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 314us/step - loss: 4.9940 - mse: 4.9940 - mae: 1.5677 - val_loss: 1.8770 - val_mse: 1.8770 - val_mae: 0.9047\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 361us/step - loss: 4.7273 - mse: 4.7273 - mae: 1.5457 - val_loss: 1.8254 - val_mse: 1.8254 - val_mae: 0.9283\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 369us/step - loss: 4.5423 - mse: 4.5423 - mae: 1.5316 - val_loss: 1.8112 - val_mse: 1.8112 - val_mae: 0.9424\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 204us/step - loss: 4.3948 - mse: 4.3948 - mae: 1.5169 - val_loss: 1.8091 - val_mse: 1.8091 - val_mae: 0.9504\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 360us/step - loss: 4.2536 - mse: 4.2536 - mae: 1.4972 - val_loss: 1.8069 - val_mse: 1.8069 - val_mae: 0.9582\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 345us/step - loss: 4.1095 - mse: 4.1095 - mae: 1.4742 - val_loss: 1.7977 - val_mse: 1.7977 - val_mae: 0.9578\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 184us/step - loss: 3.9643 - mse: 3.9643 - mae: 1.4485 - val_loss: 1.7860 - val_mse: 1.7860 - val_mae: 0.9533\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 412us/step - loss: 3.8218 - mse: 3.8218 - mae: 1.4208 - val_loss: 1.7744 - val_mse: 1.7744 - val_mae: 0.9488\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 486us/step - loss: 3.6888 - mse: 3.6888 - mae: 1.3960 - val_loss: 1.7637 - val_mse: 1.7637 - val_mae: 0.9426\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 283us/step - loss: 3.5652 - mse: 3.5652 - mae: 1.3716 - val_loss: 1.7539 - val_mse: 1.7539 - val_mae: 0.9348\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 256us/step - loss: 3.4523 - mse: 3.4523 - mae: 1.3479 - val_loss: 1.7441 - val_mse: 1.7441 - val_mae: 0.9262\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 379us/step - loss: 3.3530 - mse: 3.3530 - mae: 1.3269 - val_loss: 1.7328 - val_mse: 1.7328 - val_mae: 0.9167\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 628us/step - loss: 3.2705 - mse: 3.2705 - mae: 1.3091 - val_loss: 1.7225 - val_mse: 1.7225 - val_mae: 0.9097\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 300us/step - loss: 3.1957 - mse: 3.1957 - mae: 1.2952 - val_loss: 1.7138 - val_mse: 1.7138 - val_mae: 0.9047\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 531us/step - loss: 3.1256 - mse: 3.1256 - mae: 1.2830 - val_loss: 1.7062 - val_mse: 1.7062 - val_mae: 0.9012\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 603us/step - loss: 3.0600 - mse: 3.0600 - mae: 1.2722 - val_loss: 1.6997 - val_mse: 1.6997 - val_mae: 0.8988\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 498us/step - loss: 2.9978 - mse: 2.9978 - mae: 1.2619 - val_loss: 1.6956 - val_mse: 1.6956 - val_mae: 0.8977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 140us/step - loss: 2.9356 - mse: 2.9356 - mae: 1.2514 - val_loss: 1.6930 - val_mse: 1.6930 - val_mae: 0.8967\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 157us/step - loss: 2.8757 - mse: 2.8757 - mae: 1.2407 - val_loss: 1.6919 - val_mse: 1.6919 - val_mae: 0.8955\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 159us/step - loss: 2.8189 - mse: 2.8189 - mae: 1.2314 - val_loss: 1.6928 - val_mse: 1.6928 - val_mae: 0.8942\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 250us/step - loss: 2.7646 - mse: 2.7646 - mae: 1.2220 - val_loss: 1.6949 - val_mse: 1.6949 - val_mae: 0.8937\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 162us/step - loss: 2.7132 - mse: 2.7132 - mae: 1.2127 - val_loss: 1.6984 - val_mse: 1.6984 - val_mae: 0.8931\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 336us/step - loss: 2.6652 - mse: 2.6652 - mae: 1.2041 - val_loss: 1.7025 - val_mse: 1.7025 - val_mae: 0.8926\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 282us/step - loss: 2.6181 - mse: 2.6181 - mae: 1.1951 - val_loss: 1.7070 - val_mse: 1.7070 - val_mae: 0.8929\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 199us/step - loss: 2.5766 - mse: 2.5766 - mae: 1.1862 - val_loss: 1.7120 - val_mse: 1.7120 - val_mae: 0.8932\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 325us/step - loss: 2.5348 - mse: 2.5348 - mae: 1.1774 - val_loss: 1.7235 - val_mse: 1.7235 - val_mae: 0.8945\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 363us/step - loss: 2.4945 - mse: 2.4945 - mae: 1.1694 - val_loss: 1.7344 - val_mse: 1.7344 - val_mae: 0.8973\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 280us/step - loss: 2.4576 - mse: 2.4576 - mae: 1.1622 - val_loss: 1.7416 - val_mse: 1.7416 - val_mae: 0.8999\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 150us/step - loss: 2.4181 - mse: 2.4181 - mae: 1.1538 - val_loss: 1.7472 - val_mse: 1.7472 - val_mae: 0.9024\n",
      "8\n",
      "[8]\n",
      "Train on 81 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 3.7085 - mse: 3.7085 - mae: 1.5628 - val_loss: 5.1726 - val_mse: 5.1726 - val_mae: 1.9142\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 0s 475us/step - loss: 3.1131 - mse: 3.1131 - mae: 1.3756 - val_loss: 4.2645 - val_mse: 4.2645 - val_mae: 1.7119\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 0s 387us/step - loss: 2.5827 - mse: 2.5827 - mae: 1.2028 - val_loss: 3.5311 - val_mse: 3.5311 - val_mae: 1.5658\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 0s 163us/step - loss: 2.1608 - mse: 2.1608 - mae: 1.0675 - val_loss: 2.9281 - val_mse: 2.9281 - val_mae: 1.4296\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 0s 147us/step - loss: 1.8550 - mse: 1.8550 - mae: 0.9734 - val_loss: 2.4391 - val_mse: 2.4391 - val_mae: 1.3003\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 0s 158us/step - loss: 1.6394 - mse: 1.6394 - mae: 0.9105 - val_loss: 2.0420 - val_mse: 2.0420 - val_mae: 1.1926\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 0s 222us/step - loss: 1.4972 - mse: 1.4972 - mae: 0.8687 - val_loss: 1.7716 - val_mse: 1.7716 - val_mae: 1.1166\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 0s 172us/step - loss: 1.4160 - mse: 1.4160 - mae: 0.8462 - val_loss: 1.5894 - val_mse: 1.5894 - val_mae: 1.0658\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 0s 269us/step - loss: 1.3615 - mse: 1.3615 - mae: 0.8320 - val_loss: 1.4692 - val_mse: 1.4692 - val_mae: 1.0269\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 0s 282us/step - loss: 1.3176 - mse: 1.3176 - mae: 0.8189 - val_loss: 1.3903 - val_mse: 1.3903 - val_mae: 0.9974\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 0s 345us/step - loss: 1.2734 - mse: 1.2734 - mae: 0.8069 - val_loss: 1.3452 - val_mse: 1.3452 - val_mae: 0.9776\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 0s 150us/step - loss: 1.2303 - mse: 1.2303 - mae: 0.7940 - val_loss: 1.3220 - val_mse: 1.3220 - val_mae: 0.9676\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 0s 297us/step - loss: 1.1888 - mse: 1.1888 - mae: 0.7806 - val_loss: 1.3162 - val_mse: 1.3162 - val_mae: 0.9630\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 0s 338us/step - loss: 1.1490 - mse: 1.1490 - mae: 0.7671 - val_loss: 1.3195 - val_mse: 1.3195 - val_mae: 0.9620\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 0s 412us/step - loss: 1.1144 - mse: 1.1144 - mae: 0.7547 - val_loss: 1.3206 - val_mse: 1.3206 - val_mae: 0.9586\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 0s 190us/step - loss: 1.0857 - mse: 1.0857 - mae: 0.7424 - val_loss: 1.3172 - val_mse: 1.3172 - val_mae: 0.9524\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 0s 226us/step - loss: 1.0619 - mse: 1.0619 - mae: 0.7309 - val_loss: 1.3110 - val_mse: 1.3110 - val_mae: 0.9461\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 0s 378us/step - loss: 1.0426 - mse: 1.0426 - mae: 0.7218 - val_loss: 1.3012 - val_mse: 1.3012 - val_mae: 0.9388\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 0s 256us/step - loss: 1.0248 - mse: 1.0248 - mae: 0.7134 - val_loss: 1.2871 - val_mse: 1.2871 - val_mae: 0.9303\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 0s 237us/step - loss: 1.0076 - mse: 1.0076 - mae: 0.7057 - val_loss: 1.2693 - val_mse: 1.2693 - val_mae: 0.9214\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 0s 610us/step - loss: 0.9912 - mse: 0.9912 - mae: 0.6987 - val_loss: 1.2485 - val_mse: 1.2485 - val_mae: 0.9111\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - 0s 295us/step - loss: 0.9769 - mse: 0.9769 - mae: 0.6927 - val_loss: 1.2263 - val_mse: 1.2263 - val_mae: 0.9002\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - 0s 210us/step - loss: 0.9635 - mse: 0.9635 - mae: 0.6866 - val_loss: 1.2021 - val_mse: 1.2021 - val_mae: 0.8885\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.9510 - mse: 0.9510 - mae: 0.6805 - val_loss: 1.1769 - val_mse: 1.1769 - val_mae: 0.8765\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - 0s 230us/step - loss: 0.9398 - mse: 0.9398 - mae: 0.6749 - val_loss: 1.1532 - val_mse: 1.1532 - val_mae: 0.8646\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - 0s 213us/step - loss: 0.9283 - mse: 0.9283 - mae: 0.6700 - val_loss: 1.1316 - val_mse: 1.1316 - val_mae: 0.8532\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - 0s 310us/step - loss: 0.9180 - mse: 0.9180 - mae: 0.6656 - val_loss: 1.1120 - val_mse: 1.1120 - val_mae: 0.8426\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - 0s 411us/step - loss: 0.9086 - mse: 0.9086 - mae: 0.6613 - val_loss: 1.0933 - val_mse: 1.0933 - val_mae: 0.8331\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - 0s 317us/step - loss: 0.9005 - mse: 0.9005 - mae: 0.6574 - val_loss: 1.0778 - val_mse: 1.0778 - val_mae: 0.8249\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - 0s 199us/step - loss: 0.8931 - mse: 0.8931 - mae: 0.6538 - val_loss: 1.0642 - val_mse: 1.0642 - val_mae: 0.8173\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - 0s 399us/step - loss: 0.8864 - mse: 0.8864 - mae: 0.6504 - val_loss: 1.0523 - val_mse: 1.0523 - val_mae: 0.8108\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.8802 - mse: 0.8802 - mae: 0.6476 - val_loss: 1.0424 - val_mse: 1.0424 - val_mae: 0.8057\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - 0s 245us/step - loss: 0.8746 - mse: 0.8746 - mae: 0.6451 - val_loss: 1.0335 - val_mse: 1.0335 - val_mae: 0.8008\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - 0s 319us/step - loss: 0.8689 - mse: 0.8689 - mae: 0.6425 - val_loss: 1.0268 - val_mse: 1.0268 - val_mae: 0.7970\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - 0s 285us/step - loss: 0.8643 - mse: 0.8643 - mae: 0.6399 - val_loss: 1.0215 - val_mse: 1.0215 - val_mae: 0.7938\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - 0s 332us/step - loss: 0.8601 - mse: 0.8601 - mae: 0.6374 - val_loss: 1.0167 - val_mse: 1.0167 - val_mae: 0.7909\n",
      "Epoch 37/100\n",
      "81/81 [==============================] - 0s 296us/step - loss: 0.8559 - mse: 0.8559 - mae: 0.6350 - val_loss: 1.0121 - val_mse: 1.0121 - val_mae: 0.7883\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - 0s 375us/step - loss: 0.8518 - mse: 0.8518 - mae: 0.6329 - val_loss: 1.0074 - val_mse: 1.0074 - val_mae: 0.7856\n",
      "Epoch 39/100\n",
      "81/81 [==============================] - 0s 260us/step - loss: 0.8479 - mse: 0.8479 - mae: 0.6308 - val_loss: 1.0022 - val_mse: 1.0022 - val_mae: 0.7827\n",
      "Epoch 40/100\n",
      "81/81 [==============================] - 0s 290us/step - loss: 0.8438 - mse: 0.8438 - mae: 0.6287 - val_loss: 0.9965 - val_mse: 0.9965 - val_mae: 0.7796\n",
      "Epoch 41/100\n",
      "81/81 [==============================] - 0s 266us/step - loss: 0.8397 - mse: 0.8397 - mae: 0.6265 - val_loss: 0.9903 - val_mse: 0.9903 - val_mae: 0.7761\n",
      "Epoch 42/100\n",
      "81/81 [==============================] - 0s 380us/step - loss: 0.8355 - mse: 0.8355 - mae: 0.6245 - val_loss: 0.9837 - val_mse: 0.9837 - val_mae: 0.7725\n",
      "Epoch 43/100\n",
      "81/81 [==============================] - 0s 468us/step - loss: 0.8313 - mse: 0.8313 - mae: 0.6226 - val_loss: 0.9769 - val_mse: 0.9769 - val_mae: 0.7687\n",
      "Epoch 44/100\n",
      "81/81 [==============================] - 0s 294us/step - loss: 0.8272 - mse: 0.8272 - mae: 0.6209 - val_loss: 0.9700 - val_mse: 0.9700 - val_mae: 0.7649\n",
      "Epoch 45/100\n",
      "81/81 [==============================] - 0s 380us/step - loss: 0.8232 - mse: 0.8232 - mae: 0.6194 - val_loss: 0.9632 - val_mse: 0.9632 - val_mae: 0.7612\n",
      "Epoch 46/100\n",
      "81/81 [==============================] - 0s 253us/step - loss: 0.8191 - mse: 0.8191 - mae: 0.6180 - val_loss: 0.9566 - val_mse: 0.9566 - val_mae: 0.7575\n",
      "Epoch 47/100\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.8153 - mse: 0.8153 - mae: 0.6166 - val_loss: 0.9499 - val_mse: 0.9499 - val_mae: 0.7538\n",
      "Epoch 48/100\n",
      "81/81 [==============================] - 0s 342us/step - loss: 0.8115 - mse: 0.8115 - mae: 0.6151 - val_loss: 0.9432 - val_mse: 0.9432 - val_mae: 0.7500\n",
      "Epoch 49/100\n",
      "81/81 [==============================] - 0s 317us/step - loss: 0.8078 - mse: 0.8078 - mae: 0.6139 - val_loss: 0.9364 - val_mse: 0.9364 - val_mae: 0.7462\n",
      "Epoch 50/100\n",
      "81/81 [==============================] - 0s 552us/step - loss: 0.8042 - mse: 0.8042 - mae: 0.6127 - val_loss: 0.9298 - val_mse: 0.9298 - val_mae: 0.7422\n",
      "Epoch 51/100\n",
      "81/81 [==============================] - 0s 304us/step - loss: 0.8006 - mse: 0.8006 - mae: 0.6113 - val_loss: 0.9231 - val_mse: 0.9231 - val_mae: 0.7381\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - 0s 204us/step - loss: 0.7971 - mse: 0.7971 - mae: 0.6099 - val_loss: 0.9170 - val_mse: 0.9170 - val_mae: 0.7342\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - 0s 382us/step - loss: 0.7938 - mse: 0.7938 - mae: 0.6087 - val_loss: 0.9112 - val_mse: 0.9112 - val_mae: 0.7305\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - 0s 294us/step - loss: 0.7906 - mse: 0.7906 - mae: 0.6077 - val_loss: 0.9059 - val_mse: 0.9059 - val_mae: 0.7272\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - 0s 375us/step - loss: 0.7875 - mse: 0.7875 - mae: 0.6069 - val_loss: 0.9001 - val_mse: 0.9001 - val_mae: 0.7238\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - 0s 375us/step - loss: 0.7846 - mse: 0.7846 - mae: 0.6061 - val_loss: 0.8951 - val_mse: 0.8951 - val_mae: 0.7212\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - 0s 386us/step - loss: 0.7818 - mse: 0.7818 - mae: 0.6052 - val_loss: 0.8900 - val_mse: 0.8900 - val_mae: 0.7189\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - 0s 352us/step - loss: 0.7790 - mse: 0.7790 - mae: 0.6043 - val_loss: 0.8856 - val_mse: 0.8856 - val_mae: 0.7169\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - 0s 307us/step - loss: 0.7763 - mse: 0.7763 - mae: 0.6034 - val_loss: 0.8819 - val_mse: 0.8819 - val_mae: 0.7151\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - 0s 244us/step - loss: 0.7736 - mse: 0.7736 - mae: 0.6026 - val_loss: 0.8788 - val_mse: 0.8788 - val_mae: 0.7138\n",
      "Epoch 61/100\n",
      "81/81 [==============================] - 0s 289us/step - loss: 0.7713 - mse: 0.7713 - mae: 0.6020 - val_loss: 0.8754 - val_mse: 0.8754 - val_mae: 0.7124\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - 0s 367us/step - loss: 0.7688 - mse: 0.7688 - mae: 0.6013 - val_loss: 0.8716 - val_mse: 0.8716 - val_mae: 0.7110\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - 0s 248us/step - loss: 0.7662 - mse: 0.7662 - mae: 0.6006 - val_loss: 0.8689 - val_mse: 0.8689 - val_mae: 0.7101\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.7637 - mse: 0.7637 - mae: 0.6000 - val_loss: 0.8664 - val_mse: 0.8664 - val_mae: 0.7092\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - 0s 569us/step - loss: 0.7612 - mse: 0.7612 - mae: 0.5993 - val_loss: 0.8640 - val_mse: 0.8640 - val_mae: 0.7082\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - 0s 280us/step - loss: 0.7589 - mse: 0.7589 - mae: 0.5987 - val_loss: 0.8613 - val_mse: 0.8613 - val_mae: 0.7072\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - 0s 343us/step - loss: 0.7565 - mse: 0.7565 - mae: 0.5982 - val_loss: 0.8589 - val_mse: 0.8589 - val_mae: 0.7063\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - 0s 465us/step - loss: 0.7540 - mse: 0.7540 - mae: 0.5977 - val_loss: 0.8566 - val_mse: 0.8566 - val_mae: 0.7054\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - 0s 375us/step - loss: 0.7517 - mse: 0.7517 - mae: 0.5969 - val_loss: 0.8546 - val_mse: 0.8546 - val_mae: 0.7047\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - 0s 466us/step - loss: 0.7496 - mse: 0.7496 - mae: 0.5961 - val_loss: 0.8535 - val_mse: 0.8535 - val_mae: 0.7043\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.7473 - mse: 0.7473 - mae: 0.5954 - val_loss: 0.8533 - val_mse: 0.8533 - val_mae: 0.7046\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - 0s 371us/step - loss: 0.7450 - mse: 0.7450 - mae: 0.5948 - val_loss: 0.8532 - val_mse: 0.8532 - val_mae: 0.7048\n",
      "Epoch 73/100\n",
      "81/81 [==============================] - 0s 474us/step - loss: 0.7428 - mse: 0.7428 - mae: 0.5941 - val_loss: 0.8527 - val_mse: 0.8527 - val_mae: 0.7048\n",
      "Epoch 74/100\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.7408 - mse: 0.7408 - mae: 0.5935 - val_loss: 0.8524 - val_mse: 0.8524 - val_mae: 0.7051\n",
      "Epoch 75/100\n",
      "81/81 [==============================] - 0s 324us/step - loss: 0.7385 - mse: 0.7385 - mae: 0.5928 - val_loss: 0.8520 - val_mse: 0.8520 - val_mae: 0.7051\n",
      "Epoch 76/100\n",
      "81/81 [==============================] - 0s 498us/step - loss: 0.7364 - mse: 0.7364 - mae: 0.5920 - val_loss: 0.8524 - val_mse: 0.8524 - val_mae: 0.7056\n",
      "Epoch 77/100\n",
      "81/81 [==============================] - 0s 337us/step - loss: 0.7346 - mse: 0.7346 - mae: 0.5915 - val_loss: 0.8517 - val_mse: 0.8517 - val_mae: 0.7055\n",
      "Epoch 78/100\n",
      "81/81 [==============================] - 0s 299us/step - loss: 0.7328 - mse: 0.7328 - mae: 0.5909 - val_loss: 0.8507 - val_mse: 0.8507 - val_mae: 0.7053\n",
      "Epoch 79/100\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.7309 - mse: 0.7309 - mae: 0.5901 - val_loss: 0.8500 - val_mse: 0.8500 - val_mae: 0.7054\n",
      "Epoch 80/100\n",
      "81/81 [==============================] - 0s 200us/step - loss: 0.7292 - mse: 0.7292 - mae: 0.5895 - val_loss: 0.8509 - val_mse: 0.8509 - val_mae: 0.7065\n",
      "Epoch 81/100\n",
      "81/81 [==============================] - 0s 326us/step - loss: 0.7273 - mse: 0.7273 - mae: 0.5890 - val_loss: 0.8518 - val_mse: 0.8518 - val_mae: 0.7076\n",
      "Epoch 82/100\n",
      "81/81 [==============================] - 0s 420us/step - loss: 0.7253 - mse: 0.7253 - mae: 0.5883 - val_loss: 0.8520 - val_mse: 0.8520 - val_mae: 0.7083\n",
      "Epoch 83/100\n",
      "81/81 [==============================] - 0s 274us/step - loss: 0.7236 - mse: 0.7236 - mae: 0.5876 - val_loss: 0.8528 - val_mse: 0.8528 - val_mae: 0.7096\n",
      "Epoch 84/100\n",
      "81/81 [==============================] - 0s 178us/step - loss: 0.7217 - mse: 0.7217 - mae: 0.5871 - val_loss: 0.8540 - val_mse: 0.8540 - val_mae: 0.7110\n",
      "Epoch 85/100\n",
      "81/81 [==============================] - 0s 425us/step - loss: 0.7196 - mse: 0.7196 - mae: 0.5864 - val_loss: 0.8556 - val_mse: 0.8556 - val_mae: 0.7128\n",
      "Epoch 86/100\n",
      "81/81 [==============================] - 0s 406us/step - loss: 0.7180 - mse: 0.7180 - mae: 0.5859 - val_loss: 0.8575 - val_mse: 0.8575 - val_mae: 0.7147\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 212us/step - loss: 0.7161 - mse: 0.7161 - mae: 0.5853 - val_loss: 0.8595 - val_mse: 0.8595 - val_mae: 0.7163\n",
      "Epoch 88/100\n",
      "81/81 [==============================] - 0s 302us/step - loss: 0.7139 - mse: 0.7139 - mae: 0.5843 - val_loss: 0.8620 - val_mse: 0.8620 - val_mae: 0.7183\n",
      "Epoch 89/100\n",
      "81/81 [==============================] - 0s 299us/step - loss: 0.7121 - mse: 0.7121 - mae: 0.5836 - val_loss: 0.8648 - val_mse: 0.8648 - val_mae: 0.7205\n",
      "9\n",
      "[9]\n",
      "Train on 82 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 4.7781 - mse: 4.7781 - mae: 1.9082 - val_loss: 2.3339 - val_mse: 2.3339 - val_mae: 1.3951\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 575us/step - loss: 4.5650 - mse: 4.5650 - mae: 1.8554 - val_loss: 2.2449 - val_mse: 2.2449 - val_mae: 1.3622\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 403us/step - loss: 4.3908 - mse: 4.3908 - mae: 1.8121 - val_loss: 2.1669 - val_mse: 2.1669 - val_mae: 1.3333\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 390us/step - loss: 4.2387 - mse: 4.2387 - mae: 1.7732 - val_loss: 2.0889 - val_mse: 2.0889 - val_mae: 1.3041\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 353us/step - loss: 4.0961 - mse: 4.0961 - mae: 1.7354 - val_loss: 2.0109 - val_mse: 2.0109 - val_mae: 1.2741\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 301us/step - loss: 3.9578 - mse: 3.9578 - mae: 1.6979 - val_loss: 1.9332 - val_mse: 1.9332 - val_mae: 1.2437\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 259us/step - loss: 3.8234 - mse: 3.8234 - mae: 1.6602 - val_loss: 1.8551 - val_mse: 1.8551 - val_mae: 1.2123\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 228us/step - loss: 3.6890 - mse: 3.6890 - mae: 1.6216 - val_loss: 1.7757 - val_mse: 1.7757 - val_mae: 1.1795\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 199us/step - loss: 3.5556 - mse: 3.5556 - mae: 1.5822 - val_loss: 1.6959 - val_mse: 1.6959 - val_mae: 1.1454\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 231us/step - loss: 3.4227 - mse: 3.4227 - mae: 1.5419 - val_loss: 1.6160 - val_mse: 1.6160 - val_mae: 1.1103\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 134us/step - loss: 3.2902 - mse: 3.2902 - mae: 1.5003 - val_loss: 1.5363 - val_mse: 1.5363 - val_mae: 1.0740\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 275us/step - loss: 3.1567 - mse: 3.1567 - mae: 1.4571 - val_loss: 1.4565 - val_mse: 1.4565 - val_mae: 1.0363\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 165us/step - loss: 3.0221 - mse: 3.0221 - mae: 1.4116 - val_loss: 1.3737 - val_mse: 1.3737 - val_mae: 0.9959\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 217us/step - loss: 2.8865 - mse: 2.8865 - mae: 1.3637 - val_loss: 1.2897 - val_mse: 1.2897 - val_mae: 0.9531\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 387us/step - loss: 2.7478 - mse: 2.7478 - mae: 1.3126 - val_loss: 1.2048 - val_mse: 1.2048 - val_mae: 0.9077\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 308us/step - loss: 2.6067 - mse: 2.6067 - mae: 1.2583 - val_loss: 1.1187 - val_mse: 1.1187 - val_mae: 0.8593\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 324us/step - loss: 2.4623 - mse: 2.4623 - mae: 1.1997 - val_loss: 1.0323 - val_mse: 1.0323 - val_mae: 0.8078\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 443us/step - loss: 2.3169 - mse: 2.3169 - mae: 1.1383 - val_loss: 0.9478 - val_mse: 0.9478 - val_mae: 0.7537\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 356us/step - loss: 2.1723 - mse: 2.1723 - mae: 1.0746 - val_loss: 0.8641 - val_mse: 0.8641 - val_mae: 0.6949\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 204us/step - loss: 2.0291 - mse: 2.0291 - mae: 1.0078 - val_loss: 0.7829 - val_mse: 0.7829 - val_mae: 0.6304\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 163us/step - loss: 1.8878 - mse: 1.8878 - mae: 0.9413 - val_loss: 0.7066 - val_mse: 0.7066 - val_mae: 0.5618\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 553us/step - loss: 1.7484 - mse: 1.7484 - mae: 0.8796 - val_loss: 0.6396 - val_mse: 0.6396 - val_mae: 0.4958\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 370us/step - loss: 1.6116 - mse: 1.6116 - mae: 0.8256 - val_loss: 0.5836 - val_mse: 0.5836 - val_mae: 0.4541\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 185us/step - loss: 1.4713 - mse: 1.4713 - mae: 0.7699 - val_loss: 0.5434 - val_mse: 0.5434 - val_mae: 0.4433\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 318us/step - loss: 1.3447 - mse: 1.3447 - mae: 0.7357 - val_loss: 0.5128 - val_mse: 0.5128 - val_mae: 0.4507\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 324us/step - loss: 1.2252 - mse: 1.2252 - mae: 0.7187 - val_loss: 0.5060 - val_mse: 0.5060 - val_mae: 0.4680\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 231us/step - loss: 1.1451 - mse: 1.1451 - mae: 0.7260 - val_loss: 0.5102 - val_mse: 0.5102 - val_mae: 0.5044\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 261us/step - loss: 1.1069 - mse: 1.1069 - mae: 0.7521 - val_loss: 0.5335 - val_mse: 0.5335 - val_mae: 0.5576\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 257us/step - loss: 1.0974 - mse: 1.0974 - mae: 0.7794 - val_loss: 0.5572 - val_mse: 0.5572 - val_mae: 0.5996\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 295us/step - loss: 1.0979 - mse: 1.0979 - mae: 0.7972 - val_loss: 0.5678 - val_mse: 0.5678 - val_mae: 0.6193\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 150us/step - loss: 1.0937 - mse: 1.0937 - mae: 0.8016 - val_loss: 0.5614 - val_mse: 0.5614 - val_mae: 0.6180\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 241us/step - loss: 1.0803 - mse: 1.0803 - mae: 0.7951 - val_loss: 0.5431 - val_mse: 0.5431 - val_mae: 0.6022\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 275us/step - loss: 1.0626 - mse: 1.0626 - mae: 0.7819 - val_loss: 0.5201 - val_mse: 0.5201 - val_mae: 0.5786\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 176us/step - loss: 1.0456 - mse: 1.0456 - mae: 0.7664 - val_loss: 0.4982 - val_mse: 0.4982 - val_mae: 0.5532\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 302us/step - loss: 1.0331 - mse: 1.0331 - mae: 0.7511 - val_loss: 0.4800 - val_mse: 0.4800 - val_mae: 0.5300\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 401us/step - loss: 1.0244 - mse: 1.0244 - mae: 0.7381 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.5116\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 487us/step - loss: 1.0178 - mse: 1.0178 - mae: 0.7281 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4990\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 470us/step - loss: 1.0118 - mse: 1.0118 - mae: 0.7212 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4914\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 231us/step - loss: 1.0052 - mse: 1.0052 - mae: 0.7173 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.4888\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 171us/step - loss: 0.9976 - mse: 0.9976 - mae: 0.7150 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4882\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 256us/step - loss: 0.9893 - mse: 0.9893 - mae: 0.7137 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4891\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 626us/step - loss: 0.9816 - mse: 0.9816 - mae: 0.7136 - val_loss: 0.4277 - val_mse: 0.4277 - val_mae: 0.4915\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 334us/step - loss: 0.9740 - mse: 0.9740 - mae: 0.7141 - val_loss: 0.4247 - val_mse: 0.4247 - val_mae: 0.4942\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 187us/step - loss: 0.9669 - mse: 0.9669 - mae: 0.7143 - val_loss: 0.4213 - val_mse: 0.4213 - val_mae: 0.4957\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 280us/step - loss: 0.9600 - mse: 0.9600 - mae: 0.7139 - val_loss: 0.4159 - val_mse: 0.4159 - val_mae: 0.4948\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 359us/step - loss: 0.9536 - mse: 0.9536 - mae: 0.7128 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4922\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 385us/step - loss: 0.9479 - mse: 0.9479 - mae: 0.7116 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4879\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 469us/step - loss: 0.9412 - mse: 0.9412 - mae: 0.7091 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4807\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0083 - mse: 1.0083 - mae: 0.731 - 0s 218us/step - loss: 0.9340 - mse: 0.9340 - mae: 0.7042 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.4714\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 475us/step - loss: 0.9273 - mse: 0.9273 - mae: 0.6992 - val_loss: 0.3768 - val_mse: 0.3768 - val_mae: 0.4618\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 489us/step - loss: 0.9218 - mse: 0.9218 - mae: 0.6948 - val_loss: 0.3705 - val_mse: 0.3705 - val_mae: 0.4556\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 273us/step - loss: 0.9176 - mse: 0.9176 - mae: 0.6921 - val_loss: 0.3668 - val_mse: 0.3668 - val_mae: 0.4532\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9945 - mse: 0.9945 - mae: 0.720 - 0s 297us/step - loss: 0.9132 - mse: 0.9132 - mae: 0.6905 - val_loss: 0.3649 - val_mse: 0.3649 - val_mae: 0.4535\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 164us/step - loss: 0.9083 - mse: 0.9083 - mae: 0.6895 - val_loss: 0.3638 - val_mse: 0.3638 - val_mae: 0.4546\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 436us/step - loss: 0.9035 - mse: 0.9035 - mae: 0.6885 - val_loss: 0.3629 - val_mse: 0.3629 - val_mae: 0.4557\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 172us/step - loss: 0.8988 - mse: 0.8988 - mae: 0.6876 - val_loss: 0.3619 - val_mse: 0.3619 - val_mae: 0.4560\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 236us/step - loss: 0.8941 - mse: 0.8941 - mae: 0.6862 - val_loss: 0.3607 - val_mse: 0.3607 - val_mae: 0.4554\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 209us/step - loss: 0.8896 - mse: 0.8896 - mae: 0.6843 - val_loss: 0.3592 - val_mse: 0.3592 - val_mae: 0.4538\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 205us/step - loss: 0.8855 - mse: 0.8855 - mae: 0.6826 - val_loss: 0.3592 - val_mse: 0.3592 - val_mae: 0.4543\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 164us/step - loss: 0.8812 - mse: 0.8812 - mae: 0.6810 - val_loss: 0.3586 - val_mse: 0.3586 - val_mae: 0.4533\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 223us/step - loss: 0.8777 - mse: 0.8777 - mae: 0.6792 - val_loss: 0.3574 - val_mse: 0.3574 - val_mae: 0.4511\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 353us/step - loss: 0.8740 - mse: 0.8740 - mae: 0.6758 - val_loss: 0.3532 - val_mse: 0.3532 - val_mae: 0.4441\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 155us/step - loss: 0.8703 - mse: 0.8703 - mae: 0.6711 - val_loss: 0.3488 - val_mse: 0.3488 - val_mae: 0.4366\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 171us/step - loss: 0.8672 - mse: 0.8672 - mae: 0.6664 - val_loss: 0.3461 - val_mse: 0.3461 - val_mae: 0.4321\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 293us/step - loss: 0.8643 - mse: 0.8643 - mae: 0.6642 - val_loss: 0.3457 - val_mse: 0.3457 - val_mae: 0.4318\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 243us/step - loss: 0.8608 - mse: 0.8608 - mae: 0.6636 - val_loss: 0.3470 - val_mse: 0.3470 - val_mae: 0.4341\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 502us/step - loss: 0.8572 - mse: 0.8572 - mae: 0.6634 - val_loss: 0.3471 - val_mse: 0.3471 - val_mae: 0.4346\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 203us/step - loss: 0.8536 - mse: 0.8536 - mae: 0.6620 - val_loss: 0.3455 - val_mse: 0.3455 - val_mae: 0.4323\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 423us/step - loss: 0.8504 - mse: 0.8504 - mae: 0.6599 - val_loss: 0.3444 - val_mse: 0.3444 - val_mae: 0.4307\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 275us/step - loss: 0.8474 - mse: 0.8474 - mae: 0.6587 - val_loss: 0.3446 - val_mse: 0.3446 - val_mae: 0.4311\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 161us/step - loss: 0.8440 - mse: 0.8440 - mae: 0.6576 - val_loss: 0.3437 - val_mse: 0.3437 - val_mae: 0.4295\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 177us/step - loss: 0.8409 - mse: 0.8409 - mae: 0.6556 - val_loss: 0.3430 - val_mse: 0.3430 - val_mae: 0.4285\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 165us/step - loss: 0.8378 - mse: 0.8378 - mae: 0.6541 - val_loss: 0.3430 - val_mse: 0.3430 - val_mae: 0.4290\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 194us/step - loss: 0.8345 - mse: 0.8345 - mae: 0.6529 - val_loss: 0.3435 - val_mse: 0.3435 - val_mae: 0.4302\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 196us/step - loss: 0.8314 - mse: 0.8314 - mae: 0.6515 - val_loss: 0.3428 - val_mse: 0.3428 - val_mae: 0.4304\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 509us/step - loss: 0.8279 - mse: 0.8279 - mae: 0.6489 - val_loss: 0.3405 - val_mse: 0.3405 - val_mae: 0.4303\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 160us/step - loss: 0.8253 - mse: 0.8253 - mae: 0.6461 - val_loss: 0.3398 - val_mse: 0.3398 - val_mae: 0.4314\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 436us/step - loss: 0.8228 - mse: 0.8228 - mae: 0.6450 - val_loss: 0.3413 - val_mse: 0.3413 - val_mae: 0.4343\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 530us/step - loss: 0.8196 - mse: 0.8196 - mae: 0.6446 - val_loss: 0.3427 - val_mse: 0.3427 - val_mae: 0.4368\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 484us/step - loss: 0.8169 - mse: 0.8169 - mae: 0.6435 - val_loss: 0.3429 - val_mse: 0.3429 - val_mae: 0.4384\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 586us/step - loss: 0.8146 - mse: 0.8146 - mae: 0.6421 - val_loss: 0.3437 - val_mse: 0.3437 - val_mae: 0.4403\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 161us/step - loss: 0.8123 - mse: 0.8123 - mae: 0.6417 - val_loss: 0.3455 - val_mse: 0.3455 - val_mae: 0.4427\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 172us/step - loss: 0.8096 - mse: 0.8096 - mae: 0.6415 - val_loss: 0.3465 - val_mse: 0.3465 - val_mae: 0.4444\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 199us/step - loss: 0.8071 - mse: 0.8071 - mae: 0.6404 - val_loss: 0.3472 - val_mse: 0.3472 - val_mae: 0.4457\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 431us/step - loss: 0.8050 - mse: 0.8050 - mae: 0.6393 - val_loss: 0.3470 - val_mse: 0.3470 - val_mae: 0.4464\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 355us/step - loss: 0.8028 - mse: 0.8028 - mae: 0.6374 - val_loss: 0.3472 - val_mse: 0.3472 - val_mae: 0.4473\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 162us/step - loss: 0.8009 - mse: 0.8009 - mae: 0.6362 - val_loss: 0.3474 - val_mse: 0.3474 - val_mae: 0.4482\n",
      "10\n",
      "[10]\n",
      "Train on 107 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 18.6840 - mse: 18.6840 - mae: 3.8388 - val_loss: 7.2824 - val_mse: 7.2824 - val_mae: 2.4534\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 352us/step - loss: 13.5345 - mse: 13.5345 - mae: 3.1681 - val_loss: 5.0295 - val_mse: 5.0295 - val_mae: 1.9892\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 193us/step - loss: 9.5181 - mse: 9.5181 - mae: 2.5294 - val_loss: 3.4270 - val_mse: 3.4270 - val_mae: 1.5866\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 362us/step - loss: 6.6023 - mse: 6.6023 - mae: 1.9789 - val_loss: 2.4172 - val_mse: 2.4172 - val_mae: 1.2879\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 131us/step - loss: 4.6951 - mse: 4.6951 - mae: 1.5939 - val_loss: 1.9288 - val_mse: 1.9288 - val_mae: 1.1089\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 134us/step - loss: 3.6326 - mse: 3.6326 - mae: 1.3837 - val_loss: 1.8201 - val_mse: 1.8201 - val_mae: 1.0354\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 333us/step - loss: 3.1586 - mse: 3.1586 - mae: 1.3042 - val_loss: 1.8835 - val_mse: 1.8835 - val_mae: 1.0437\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 258us/step - loss: 3.0170 - mse: 3.0170 - mae: 1.3003 - val_loss: 1.9976 - val_mse: 1.9976 - val_mae: 1.0666\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 157us/step - loss: 2.9990 - mse: 2.9990 - mae: 1.3102 - val_loss: 2.0723 - val_mse: 2.0723 - val_mae: 1.0862\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 564us/step - loss: 2.9903 - mse: 2.9903 - mae: 1.3162 - val_loss: 2.0998 - val_mse: 2.0998 - val_mae: 1.0892\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 299us/step - loss: 2.9459 - mse: 2.9459 - mae: 1.3057 - val_loss: 2.0847 - val_mse: 2.0847 - val_mae: 1.0802\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 208us/step - loss: 2.8702 - mse: 2.8702 - mae: 1.2868 - val_loss: 2.0471 - val_mse: 2.0471 - val_mae: 1.0688\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 170us/step - loss: 2.7846 - mse: 2.7846 - mae: 1.2632 - val_loss: 2.0072 - val_mse: 2.0072 - val_mae: 1.0628\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 356us/step - loss: 2.7113 - mse: 2.7113 - mae: 1.2446 - val_loss: 1.9744 - val_mse: 1.9744 - val_mae: 1.0596\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 237us/step - loss: 2.6557 - mse: 2.6557 - mae: 1.2298 - val_loss: 1.9488 - val_mse: 1.9488 - val_mae: 1.0598\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 237us/step - loss: 2.6161 - mse: 2.6161 - mae: 1.2190 - val_loss: 1.9339 - val_mse: 1.9339 - val_mae: 1.0615\n",
      "11\n",
      "[11]\n",
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 7.7033 - mse: 7.7033 - mae: 1.9900 - val_loss: 3.1980 - val_mse: 3.1980 - val_mae: 1.5461\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 234us/step - loss: 6.7489 - mse: 6.7489 - mae: 1.8379 - val_loss: 2.6932 - val_mse: 2.6932 - val_mae: 1.4022\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 305us/step - loss: 6.0552 - mse: 6.0552 - mae: 1.7388 - val_loss: 2.2942 - val_mse: 2.2942 - val_mae: 1.2904\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 185us/step - loss: 5.5213 - mse: 5.5213 - mae: 1.6658 - val_loss: 1.9824 - val_mse: 1.9824 - val_mae: 1.1937\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 201us/step - loss: 5.0925 - mse: 5.0925 - mae: 1.5983 - val_loss: 1.7510 - val_mse: 1.7510 - val_mae: 1.1179\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 373us/step - loss: 4.7510 - mse: 4.7510 - mae: 1.5414 - val_loss: 1.5901 - val_mse: 1.5901 - val_mae: 1.0727\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 4.4614 - mse: 4.4614 - mae: 1.4909 - val_loss: 1.4786 - val_mse: 1.4786 - val_mae: 1.0398\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 341us/step - loss: 4.2017 - mse: 4.2017 - mae: 1.4521 - val_loss: 1.4036 - val_mse: 1.4036 - val_mae: 1.0154\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 281us/step - loss: 3.9639 - mse: 3.9639 - mae: 1.4192 - val_loss: 1.3528 - val_mse: 1.3528 - val_mae: 0.9978\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 263us/step - loss: 3.7481 - mse: 3.7481 - mae: 1.3892 - val_loss: 1.3183 - val_mse: 1.3183 - val_mae: 0.9849\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 338us/step - loss: 3.5521 - mse: 3.5521 - mae: 1.3610 - val_loss: 1.2935 - val_mse: 1.2935 - val_mae: 0.9750\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 357us/step - loss: 3.3760 - mse: 3.3760 - mae: 1.3346 - val_loss: 1.2753 - val_mse: 1.2753 - val_mae: 0.9672\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 323us/step - loss: 3.2184 - mse: 3.2184 - mae: 1.3092 - val_loss: 1.2564 - val_mse: 1.2564 - val_mae: 0.9591\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 238us/step - loss: 3.0805 - mse: 3.0805 - mae: 1.2854 - val_loss: 1.2352 - val_mse: 1.2352 - val_mae: 0.9497\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 317us/step - loss: 2.9579 - mse: 2.9579 - mae: 1.2631 - val_loss: 1.2181 - val_mse: 1.2181 - val_mae: 0.9414\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 297us/step - loss: 2.8495 - mse: 2.8495 - mae: 1.2425 - val_loss: 1.2022 - val_mse: 1.2022 - val_mae: 0.9342\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 306us/step - loss: 2.7537 - mse: 2.7537 - mae: 1.2236 - val_loss: 1.1868 - val_mse: 1.1868 - val_mae: 0.9287\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 274us/step - loss: 2.6694 - mse: 2.6694 - mae: 1.2062 - val_loss: 1.1708 - val_mse: 1.1708 - val_mae: 0.9229\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - ETA: 0s - loss: 4.7013 - mse: 4.7013 - mae: 1.593 - 0s 412us/step - loss: 2.5954 - mse: 2.5954 - mae: 1.1905 - val_loss: 1.1534 - val_mse: 1.1534 - val_mae: 0.9165\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 311us/step - loss: 2.5295 - mse: 2.5295 - mae: 1.1765 - val_loss: 1.1367 - val_mse: 1.1367 - val_mae: 0.9108\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 364us/step - loss: 2.4712 - mse: 2.4712 - mae: 1.1650 - val_loss: 1.1213 - val_mse: 1.1213 - val_mae: 0.9058\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 278us/step - loss: 2.4194 - mse: 2.4194 - mae: 1.1552 - val_loss: 1.1077 - val_mse: 1.1077 - val_mae: 0.9018\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 208us/step - loss: 2.3730 - mse: 2.3730 - mae: 1.1460 - val_loss: 1.0968 - val_mse: 1.0968 - val_mae: 0.8988\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 172us/step - loss: 2.3314 - mse: 2.3314 - mae: 1.1367 - val_loss: 1.0892 - val_mse: 1.0892 - val_mae: 0.8970\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 299us/step - loss: 2.2924 - mse: 2.2924 - mae: 1.1274 - val_loss: 1.0827 - val_mse: 1.0827 - val_mae: 0.8954\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 153us/step - loss: 2.2556 - mse: 2.2556 - mae: 1.1190 - val_loss: 1.0770 - val_mse: 1.0770 - val_mae: 0.8941\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 434us/step - loss: 2.2218 - mse: 2.2218 - mae: 1.1109 - val_loss: 1.0716 - val_mse: 1.0716 - val_mae: 0.8928\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 312us/step - loss: 2.1907 - mse: 2.1907 - mae: 1.1036 - val_loss: 1.0655 - val_mse: 1.0655 - val_mae: 0.8911\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 439us/step - loss: 2.1624 - mse: 2.1624 - mae: 1.0971 - val_loss: 1.0590 - val_mse: 1.0590 - val_mae: 0.8889\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 363us/step - loss: 2.1362 - mse: 2.1362 - mae: 1.0909 - val_loss: 1.0526 - val_mse: 1.0526 - val_mae: 0.8865\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 376us/step - loss: 2.1111 - mse: 2.1111 - mae: 1.0847 - val_loss: 1.0469 - val_mse: 1.0469 - val_mae: 0.8840\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 151us/step - loss: 2.0877 - mse: 2.0877 - mae: 1.0787 - val_loss: 1.0415 - val_mse: 1.0415 - val_mae: 0.8815\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 241us/step - loss: 2.0657 - mse: 2.0657 - mae: 1.0740 - val_loss: 1.0361 - val_mse: 1.0361 - val_mae: 0.8788\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 218us/step - loss: 2.0453 - mse: 2.0453 - mae: 1.0707 - val_loss: 1.0319 - val_mse: 1.0319 - val_mae: 0.8766\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 162us/step - loss: 2.0261 - mse: 2.0261 - mae: 1.0672 - val_loss: 1.0288 - val_mse: 1.0288 - val_mae: 0.8749\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 322us/step - loss: 2.0080 - mse: 2.0080 - mae: 1.0638 - val_loss: 1.0261 - val_mse: 1.0261 - val_mae: 0.8730\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 389us/step - loss: 1.9907 - mse: 1.9907 - mae: 1.0603 - val_loss: 1.0237 - val_mse: 1.0237 - val_mae: 0.8711\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 422us/step - loss: 1.9742 - mse: 1.9742 - mae: 1.0566 - val_loss: 1.0212 - val_mse: 1.0212 - val_mae: 0.8692\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 159us/step - loss: 1.9578 - mse: 1.9578 - mae: 1.0527 - val_loss: 1.0188 - val_mse: 1.0188 - val_mae: 0.8676\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 202us/step - loss: 1.9422 - mse: 1.9422 - mae: 1.0489 - val_loss: 1.0166 - val_mse: 1.0166 - val_mae: 0.8660\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 308us/step - loss: 1.9277 - mse: 1.9277 - mae: 1.0455 - val_loss: 1.0141 - val_mse: 1.0141 - val_mae: 0.8642\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 0s 138us/step - loss: 1.9134 - mse: 1.9134 - mae: 1.0421 - val_loss: 1.0114 - val_mse: 1.0114 - val_mae: 0.8622\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 0s 146us/step - loss: 1.9003 - mse: 1.9003 - mae: 1.0391 - val_loss: 1.0085 - val_mse: 1.0085 - val_mae: 0.8604\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 0s 151us/step - loss: 1.8876 - mse: 1.8876 - mae: 1.0364 - val_loss: 1.0061 - val_mse: 1.0061 - val_mae: 0.8589\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 0s 332us/step - loss: 1.8754 - mse: 1.8754 - mae: 1.0337 - val_loss: 1.0037 - val_mse: 1.0037 - val_mae: 0.8576\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 0s 135us/step - loss: 1.8636 - mse: 1.8636 - mae: 1.0308 - val_loss: 1.0024 - val_mse: 1.0024 - val_mae: 0.8571\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 0s 167us/step - loss: 1.8523 - mse: 1.8523 - mae: 1.0274 - val_loss: 1.0007 - val_mse: 1.0007 - val_mae: 0.8566\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 0s 170us/step - loss: 1.8411 - mse: 1.8411 - mae: 1.0240 - val_loss: 0.9997 - val_mse: 0.9997 - val_mae: 0.8563\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 0s 258us/step - loss: 1.8301 - mse: 1.8301 - mae: 1.0205 - val_loss: 0.9980 - val_mse: 0.9980 - val_mae: 0.8557\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 0s 150us/step - loss: 1.8193 - mse: 1.8193 - mae: 1.0171 - val_loss: 0.9961 - val_mse: 0.9961 - val_mae: 0.8549\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 0s 247us/step - loss: 1.8082 - mse: 1.8082 - mae: 1.0138 - val_loss: 0.9946 - val_mse: 0.9946 - val_mae: 0.8539\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 0s 325us/step - loss: 1.7976 - mse: 1.7976 - mae: 1.0106 - val_loss: 0.9936 - val_mse: 0.9936 - val_mae: 0.8533\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 0s 392us/step - loss: 1.7864 - mse: 1.7864 - mae: 1.0068 - val_loss: 0.9936 - val_mse: 0.9936 - val_mae: 0.8536\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 0s 175us/step - loss: 1.7746 - mse: 1.7746 - mae: 1.0019 - val_loss: 0.9938 - val_mse: 0.9938 - val_mae: 0.8539\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 0s 368us/step - loss: 1.7629 - mse: 1.7629 - mae: 0.9978 - val_loss: 0.9931 - val_mse: 0.9931 - val_mae: 0.8536\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 0s 342us/step - loss: 1.7522 - mse: 1.7522 - mae: 0.9942 - val_loss: 0.9929 - val_mse: 0.9929 - val_mae: 0.8531\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 0s 225us/step - loss: 1.7409 - mse: 1.7409 - mae: 0.9910 - val_loss: 0.9931 - val_mse: 0.9931 - val_mae: 0.8526\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 0s 160us/step - loss: 1.7306 - mse: 1.7306 - mae: 0.9886 - val_loss: 0.9921 - val_mse: 0.9921 - val_mae: 0.8518\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 0s 275us/step - loss: 1.7204 - mse: 1.7204 - mae: 0.9860 - val_loss: 0.9897 - val_mse: 0.9897 - val_mae: 0.8510\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 0s 340us/step - loss: 1.7106 - mse: 1.7106 - mae: 0.9828 - val_loss: 0.9867 - val_mse: 0.9867 - val_mae: 0.8501\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 0s 183us/step - loss: 1.7009 - mse: 1.7009 - mae: 0.9795 - val_loss: 0.9846 - val_mse: 0.9846 - val_mae: 0.8495\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 0s 442us/step - loss: 1.6929 - mse: 1.6929 - mae: 0.9766 - val_loss: 0.9837 - val_mse: 0.9837 - val_mae: 0.8487\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 0s 271us/step - loss: 1.6849 - mse: 1.6849 - mae: 0.9743 - val_loss: 0.9828 - val_mse: 0.9828 - val_mae: 0.8478\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 0s 154us/step - loss: 1.6772 - mse: 1.6772 - mae: 0.9720 - val_loss: 0.9816 - val_mse: 0.9816 - val_mae: 0.8474\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 0s 222us/step - loss: 1.6697 - mse: 1.6697 - mae: 0.9690 - val_loss: 0.9797 - val_mse: 0.9797 - val_mae: 0.8470\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 0s 155us/step - loss: 1.6627 - mse: 1.6627 - mae: 0.9662 - val_loss: 0.9782 - val_mse: 0.9782 - val_mae: 0.8465\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 0s 252us/step - loss: 1.6560 - mse: 1.6560 - mae: 0.9636 - val_loss: 0.9770 - val_mse: 0.9770 - val_mae: 0.8461\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 0s 209us/step - loss: 1.6491 - mse: 1.6491 - mae: 0.9610 - val_loss: 0.9767 - val_mse: 0.9767 - val_mae: 0.8471\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 0s 338us/step - loss: 1.6433 - mse: 1.6433 - mae: 0.9580 - val_loss: 0.9767 - val_mse: 0.9767 - val_mae: 0.8478\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 0s 263us/step - loss: 1.6376 - mse: 1.6376 - mae: 0.9555 - val_loss: 0.9753 - val_mse: 0.9753 - val_mae: 0.8468\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - 0s 336us/step - loss: 1.6315 - mse: 1.6315 - mae: 0.9535 - val_loss: 0.9747 - val_mse: 0.9747 - val_mae: 0.8472\n",
      "Epoch 72/100\n",
      "108/108 [==============================] - 0s 386us/step - loss: 1.6255 - mse: 1.6255 - mae: 0.9501 - val_loss: 0.9736 - val_mse: 0.9736 - val_mae: 0.8478\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 0s 219us/step - loss: 1.6210 - mse: 1.6210 - mae: 0.9472 - val_loss: 0.9703 - val_mse: 0.9703 - val_mae: 0.8462\n",
      "Epoch 74/100\n",
      "108/108 [==============================] - 0s 252us/step - loss: 1.6156 - mse: 1.6156 - mae: 0.9457 - val_loss: 0.9682 - val_mse: 0.9682 - val_mae: 0.8450\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 0s 266us/step - loss: 1.6098 - mse: 1.6098 - mae: 0.9442 - val_loss: 0.9676 - val_mse: 0.9676 - val_mae: 0.8454\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 0s 396us/step - loss: 1.6051 - mse: 1.6051 - mae: 0.9416 - val_loss: 0.9653 - val_mse: 0.9653 - val_mae: 0.8446\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 0s 253us/step - loss: 1.6004 - mse: 1.6004 - mae: 0.9399 - val_loss: 0.9624 - val_mse: 0.9624 - val_mae: 0.8435\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 0s 240us/step - loss: 1.5953 - mse: 1.5953 - mae: 0.9386 - val_loss: 0.9610 - val_mse: 0.9610 - val_mae: 0.8428\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 0s 259us/step - loss: 1.5908 - mse: 1.5908 - mae: 0.9364 - val_loss: 0.9599 - val_mse: 0.9599 - val_mae: 0.8433\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 0s 225us/step - loss: 1.5864 - mse: 1.5864 - mae: 0.9342 - val_loss: 0.9589 - val_mse: 0.9589 - val_mae: 0.8440\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 0s 238us/step - loss: 1.5814 - mse: 1.5814 - mae: 0.9328 - val_loss: 0.9568 - val_mse: 0.9568 - val_mae: 0.8429\n",
      "Epoch 82/100\n",
      "108/108 [==============================] - 0s 161us/step - loss: 1.5783 - mse: 1.5783 - mae: 0.9309 - val_loss: 0.9549 - val_mse: 0.9549 - val_mae: 0.8420\n",
      "Epoch 83/100\n",
      "108/108 [==============================] - 0s 148us/step - loss: 1.5744 - mse: 1.5744 - mae: 0.9300 - val_loss: 0.9533 - val_mse: 0.9533 - val_mae: 0.8410\n",
      "Epoch 84/100\n",
      "108/108 [==============================] - 0s 273us/step - loss: 1.5691 - mse: 1.5691 - mae: 0.9301 - val_loss: 0.9529 - val_mse: 0.9529 - val_mae: 0.8415\n",
      "Epoch 85/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.5658 - mse: 1.5658 - mae: 0.9282 - val_loss: 0.9510 - val_mse: 0.9510 - val_mae: 0.8406\n",
      "Epoch 86/100\n",
      "108/108 [==============================] - 0s 232us/step - loss: 1.5612 - mse: 1.5612 - mae: 0.9275 - val_loss: 0.9497 - val_mse: 0.9497 - val_mae: 0.8397\n",
      "Epoch 87/100\n",
      "108/108 [==============================] - 0s 320us/step - loss: 1.5581 - mse: 1.5581 - mae: 0.9254 - val_loss: 0.9493 - val_mse: 0.9493 - val_mae: 0.8412\n",
      "Epoch 88/100\n",
      "108/108 [==============================] - 0s 345us/step - loss: 1.5538 - mse: 1.5538 - mae: 0.9234 - val_loss: 0.9476 - val_mse: 0.9476 - val_mae: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "108/108 [==============================] - 0s 360us/step - loss: 1.5499 - mse: 1.5499 - mae: 0.9220 - val_loss: 0.9475 - val_mse: 0.9475 - val_mae: 0.8424\n",
      "Epoch 90/100\n",
      "108/108 [==============================] - 0s 360us/step - loss: 1.5441 - mse: 1.5441 - mae: 0.9198 - val_loss: 0.9465 - val_mse: 0.9465 - val_mae: 0.8420\n",
      "Epoch 91/100\n",
      "108/108 [==============================] - 0s 185us/step - loss: 1.5396 - mse: 1.5396 - mae: 0.9187 - val_loss: 0.9456 - val_mse: 0.9456 - val_mae: 0.8423\n",
      "Epoch 92/100\n",
      "108/108 [==============================] - 0s 326us/step - loss: 1.5352 - mse: 1.5352 - mae: 0.9185 - val_loss: 0.9457 - val_mse: 0.9457 - val_mae: 0.8438\n",
      "Epoch 93/100\n",
      "108/108 [==============================] - 0s 331us/step - loss: 1.5295 - mse: 1.5295 - mae: 0.9158 - val_loss: 0.9459 - val_mse: 0.9459 - val_mae: 0.8445\n",
      "Epoch 94/100\n",
      "108/108 [==============================] - 0s 310us/step - loss: 1.5262 - mse: 1.5262 - mae: 0.9154 - val_loss: 0.9444 - val_mse: 0.9444 - val_mae: 0.8436\n",
      "Epoch 95/100\n",
      "108/108 [==============================] - 0s 465us/step - loss: 1.5216 - mse: 1.5216 - mae: 0.9141 - val_loss: 0.9462 - val_mse: 0.9462 - val_mae: 0.8454\n",
      "Epoch 96/100\n",
      "108/108 [==============================] - 0s 389us/step - loss: 1.5177 - mse: 1.5177 - mae: 0.9128 - val_loss: 0.9458 - val_mse: 0.9458 - val_mae: 0.8467\n",
      "Epoch 97/100\n",
      "108/108 [==============================] - 0s 443us/step - loss: 1.5128 - mse: 1.5128 - mae: 0.9107 - val_loss: 0.9438 - val_mse: 0.9438 - val_mae: 0.8465\n",
      "Epoch 98/100\n",
      "108/108 [==============================] - 0s 176us/step - loss: 1.5079 - mse: 1.5079 - mae: 0.9089 - val_loss: 0.9414 - val_mse: 0.9414 - val_mae: 0.8464\n",
      "Epoch 99/100\n",
      "108/108 [==============================] - 0s 185us/step - loss: 1.5033 - mse: 1.5033 - mae: 0.9072 - val_loss: 0.9394 - val_mse: 0.9394 - val_mae: 0.8454\n",
      "Epoch 100/100\n",
      "108/108 [==============================] - 0s 294us/step - loss: 1.4996 - mse: 1.4996 - mae: 0.9063 - val_loss: 0.9399 - val_mse: 0.9399 - val_mae: 0.8470\n",
      "12\n",
      "[12]\n",
      "Train on 84 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 0.6763 - mse: 0.6763 - mae: 0.5785 - val_loss: 0.4900 - val_mse: 0.4900 - val_mae: 0.4420\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 384us/step - loss: 0.6230 - mse: 0.6230 - mae: 0.5694 - val_loss: 0.4884 - val_mse: 0.4884 - val_mae: 0.4572\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 350us/step - loss: 0.5967 - mse: 0.5967 - mae: 0.5718 - val_loss: 0.4996 - val_mse: 0.4996 - val_mae: 0.4671\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 338us/step - loss: 0.5817 - mse: 0.5817 - mae: 0.5755 - val_loss: 0.5100 - val_mse: 0.5100 - val_mae: 0.4813\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 335us/step - loss: 0.5664 - mse: 0.5664 - mae: 0.5712 - val_loss: 0.5138 - val_mse: 0.5138 - val_mae: 0.4853\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 346us/step - loss: 0.5504 - mse: 0.5504 - mae: 0.5630 - val_loss: 0.5124 - val_mse: 0.5124 - val_mae: 0.4831\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 328us/step - loss: 0.5365 - mse: 0.5365 - mae: 0.5535 - val_loss: 0.5081 - val_mse: 0.5081 - val_mae: 0.4770\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 196us/step - loss: 0.5249 - mse: 0.5249 - mae: 0.5448 - val_loss: 0.5046 - val_mse: 0.5046 - val_mae: 0.4737\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 174us/step - loss: 0.5144 - mse: 0.5144 - mae: 0.5371 - val_loss: 0.5018 - val_mse: 0.5018 - val_mae: 0.4707\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 181us/step - loss: 0.5051 - mse: 0.5051 - mae: 0.5311 - val_loss: 0.4992 - val_mse: 0.4992 - val_mae: 0.4709\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 317us/step - loss: 0.4986 - mse: 0.4986 - mae: 0.5273 - val_loss: 0.4980 - val_mse: 0.4980 - val_mae: 0.4736\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 347us/step - loss: 0.4931 - mse: 0.4931 - mae: 0.5246 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.4754\n",
      "13\n",
      "[13]\n",
      "Train on 96 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.6304 - mse: 4.6304 - mae: 1.6549 - val_loss: 2.4213 - val_mse: 2.4213 - val_mae: 1.2658\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 356us/step - loss: 3.3907 - mse: 3.3907 - mae: 1.3391 - val_loss: 1.6302 - val_mse: 1.6302 - val_mae: 0.9692\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 300us/step - loss: 2.6292 - mse: 2.6292 - mae: 1.1553 - val_loss: 1.1785 - val_mse: 1.1785 - val_mae: 0.7633\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 262us/step - loss: 2.2861 - mse: 2.2861 - mae: 1.1136 - val_loss: 0.9585 - val_mse: 0.9585 - val_mae: 0.6465\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 194us/step - loss: 2.1973 - mse: 2.1973 - mae: 1.1463 - val_loss: 0.8775 - val_mse: 0.8775 - val_mae: 0.6204\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 241us/step - loss: 2.1912 - mse: 2.1912 - mae: 1.1785 - val_loss: 0.8392 - val_mse: 0.8392 - val_mae: 0.6225\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 175us/step - loss: 2.1557 - mse: 2.1557 - mae: 1.1783 - val_loss: 0.7993 - val_mse: 0.7993 - val_mae: 0.6048\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 594us/step - loss: 2.0890 - mse: 2.0890 - mae: 1.1530 - val_loss: 0.7620 - val_mse: 0.7620 - val_mae: 0.5733\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 260us/step - loss: 2.0010 - mse: 2.0010 - mae: 1.1169 - val_loss: 0.7369 - val_mse: 0.7369 - val_mae: 0.5654\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 397us/step - loss: 1.9336 - mse: 1.9336 - mae: 1.0821 - val_loss: 0.7293 - val_mse: 0.7293 - val_mae: 0.5782\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 240us/step - loss: 1.8893 - mse: 1.8893 - mae: 1.0571 - val_loss: 0.7252 - val_mse: 0.7252 - val_mae: 0.5881\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 270us/step - loss: 1.8532 - mse: 1.8532 - mae: 1.0428 - val_loss: 0.7137 - val_mse: 0.7137 - val_mae: 0.5951\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 656us/step - loss: 1.8187 - mse: 1.8187 - mae: 1.0325 - val_loss: 0.6956 - val_mse: 0.6956 - val_mae: 0.5884\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 495us/step - loss: 1.7898 - mse: 1.7898 - mae: 1.0245 - val_loss: 0.6736 - val_mse: 0.6736 - val_mae: 0.5728\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 408us/step - loss: 1.7659 - mse: 1.7659 - mae: 1.0181 - val_loss: 0.6532 - val_mse: 0.6532 - val_mae: 0.5569\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 367us/step - loss: 1.7480 - mse: 1.7480 - mae: 1.0130 - val_loss: 0.6365 - val_mse: 0.6365 - val_mae: 0.5471\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 334us/step - loss: 1.7323 - mse: 1.7323 - mae: 1.0110 - val_loss: 0.6240 - val_mse: 0.6240 - val_mae: 0.5418\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 340us/step - loss: 1.7158 - mse: 1.7158 - mae: 1.0075 - val_loss: 0.6139 - val_mse: 0.6139 - val_mae: 0.5392\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 277us/step - loss: 1.6989 - mse: 1.6989 - mae: 1.0028 - val_loss: 0.6073 - val_mse: 0.6073 - val_mae: 0.5394\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 380us/step - loss: 1.6819 - mse: 1.6819 - mae: 0.9974 - val_loss: 0.6028 - val_mse: 0.6028 - val_mae: 0.5421\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 325us/step - loss: 1.6655 - mse: 1.6655 - mae: 0.9915 - val_loss: 0.5992 - val_mse: 0.5992 - val_mae: 0.5442\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 295us/step - loss: 1.6517 - mse: 1.6517 - mae: 0.9865 - val_loss: 0.5957 - val_mse: 0.5957 - val_mae: 0.5439\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 312us/step - loss: 1.6373 - mse: 1.6373 - mae: 0.9811 - val_loss: 0.5918 - val_mse: 0.5918 - val_mae: 0.5427\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 470us/step - loss: 1.6235 - mse: 1.6235 - mae: 0.9758 - val_loss: 0.5885 - val_mse: 0.5885 - val_mae: 0.5421\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 296us/step - loss: 1.6099 - mse: 1.6099 - mae: 0.9705 - val_loss: 0.5850 - val_mse: 0.5850 - val_mae: 0.5429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 413us/step - loss: 1.5961 - mse: 1.5961 - mae: 0.9649 - val_loss: 0.5809 - val_mse: 0.5809 - val_mae: 0.5433\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 337us/step - loss: 1.5848 - mse: 1.5848 - mae: 0.9600 - val_loss: 0.5755 - val_mse: 0.5755 - val_mae: 0.5407\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 308us/step - loss: 1.5748 - mse: 1.5748 - mae: 0.9562 - val_loss: 0.5712 - val_mse: 0.5712 - val_mae: 0.5369\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 232us/step - loss: 1.5662 - mse: 1.5662 - mae: 0.9532 - val_loss: 0.5673 - val_mse: 0.5673 - val_mae: 0.5336\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 367us/step - loss: 1.5573 - mse: 1.5573 - mae: 0.9502 - val_loss: 0.5638 - val_mse: 0.5638 - val_mae: 0.5323\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 430us/step - loss: 1.5476 - mse: 1.5476 - mae: 0.9469 - val_loss: 0.5606 - val_mse: 0.5606 - val_mae: 0.5326\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 388us/step - loss: 1.5380 - mse: 1.5380 - mae: 0.9434 - val_loss: 0.5578 - val_mse: 0.5578 - val_mae: 0.5330\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 354us/step - loss: 1.5284 - mse: 1.5284 - mae: 0.9394 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.5323\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 410us/step - loss: 1.5196 - mse: 1.5196 - mae: 0.9354 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5306\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 278us/step - loss: 1.5102 - mse: 1.5102 - mae: 0.9323 - val_loss: 0.5500 - val_mse: 0.5500 - val_mae: 0.5309\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 418us/step - loss: 1.5005 - mse: 1.5005 - mae: 0.9289 - val_loss: 0.5453 - val_mse: 0.5453 - val_mae: 0.5311\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 254us/step - loss: 1.4909 - mse: 1.4909 - mae: 0.9253 - val_loss: 0.5408 - val_mse: 0.5408 - val_mae: 0.5290\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.6643 - mse: 1.6643 - mae: 0.957 - 0s 445us/step - loss: 1.4821 - mse: 1.4821 - mae: 0.9224 - val_loss: 0.5366 - val_mse: 0.5366 - val_mae: 0.5258\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 273us/step - loss: 1.4741 - mse: 1.4741 - mae: 0.9200 - val_loss: 0.5317 - val_mse: 0.5317 - val_mae: 0.5243\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 185us/step - loss: 1.4654 - mse: 1.4654 - mae: 0.9170 - val_loss: 0.5278 - val_mse: 0.5278 - val_mae: 0.5227\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 430us/step - loss: 1.4577 - mse: 1.4577 - mae: 0.9145 - val_loss: 0.5245 - val_mse: 0.5245 - val_mae: 0.5220\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 243us/step - loss: 1.4498 - mse: 1.4498 - mae: 0.9114 - val_loss: 0.5220 - val_mse: 0.5220 - val_mae: 0.5196\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 245us/step - loss: 1.4422 - mse: 1.4422 - mae: 0.9088 - val_loss: 0.5199 - val_mse: 0.5199 - val_mae: 0.5184\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 346us/step - loss: 1.4352 - mse: 1.4352 - mae: 0.9072 - val_loss: 0.5175 - val_mse: 0.5175 - val_mae: 0.5182\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 343us/step - loss: 1.4273 - mse: 1.4273 - mae: 0.9047 - val_loss: 0.5152 - val_mse: 0.5152 - val_mae: 0.5181\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 476us/step - loss: 1.4194 - mse: 1.4194 - mae: 0.9013 - val_loss: 0.5145 - val_mse: 0.5145 - val_mae: 0.5176\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 320us/step - loss: 1.4127 - mse: 1.4127 - mae: 0.8993 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5166\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 387us/step - loss: 1.4059 - mse: 1.4059 - mae: 0.8975 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.5153\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 290us/step - loss: 1.3996 - mse: 1.3996 - mae: 0.8959 - val_loss: 0.5090 - val_mse: 0.5090 - val_mae: 0.5147\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 317us/step - loss: 1.3927 - mse: 1.3927 - mae: 0.8933 - val_loss: 0.5081 - val_mse: 0.5081 - val_mae: 0.5145\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 512us/step - loss: 1.3863 - mse: 1.3863 - mae: 0.8909 - val_loss: 0.5080 - val_mse: 0.5080 - val_mae: 0.5140\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 413us/step - loss: 1.3806 - mse: 1.3806 - mae: 0.8896 - val_loss: 0.5066 - val_mse: 0.5066 - val_mae: 0.5135\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 549us/step - loss: 1.3739 - mse: 1.3739 - mae: 0.8876 - val_loss: 0.5043 - val_mse: 0.5043 - val_mae: 0.5136\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 390us/step - loss: 1.3664 - mse: 1.3664 - mae: 0.8847 - val_loss: 0.5023 - val_mse: 0.5023 - val_mae: 0.5138\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 269us/step - loss: 1.3598 - mse: 1.3598 - mae: 0.8824 - val_loss: 0.5009 - val_mse: 0.5009 - val_mae: 0.5131\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 252us/step - loss: 1.3530 - mse: 1.3530 - mae: 0.8809 - val_loss: 0.4986 - val_mse: 0.4986 - val_mae: 0.5124\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 357us/step - loss: 1.3464 - mse: 1.3464 - mae: 0.8793 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5125\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 294us/step - loss: 1.3395 - mse: 1.3395 - mae: 0.8768 - val_loss: 0.4958 - val_mse: 0.4958 - val_mae: 0.5130\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 162us/step - loss: 1.3331 - mse: 1.3331 - mae: 0.8749 - val_loss: 0.4959 - val_mse: 0.4959 - val_mae: 0.5141\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 289us/step - loss: 1.3260 - mse: 1.3260 - mae: 0.8736 - val_loss: 0.4935 - val_mse: 0.4935 - val_mae: 0.5149\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 325us/step - loss: 1.3172 - mse: 1.3172 - mae: 0.8703 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.5148\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 456us/step - loss: 1.3097 - mse: 1.3097 - mae: 0.8672 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.5149\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 456us/step - loss: 1.3024 - mse: 1.3024 - mae: 0.8648 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5151\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 171us/step - loss: 1.2945 - mse: 1.2945 - mae: 0.8627 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.5152\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 231us/step - loss: 1.2865 - mse: 1.2865 - mae: 0.8593 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.5151\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 530us/step - loss: 1.2794 - mse: 1.2794 - mae: 0.8567 - val_loss: 0.4841 - val_mse: 0.4841 - val_mae: 0.5143\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 610us/step - loss: 1.2723 - mse: 1.2723 - mae: 0.8546 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.5139\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 223us/step - loss: 1.2668 - mse: 1.2668 - mae: 0.8537 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.5137\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 274us/step - loss: 1.2591 - mse: 1.2591 - mae: 0.8510 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5142\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 226us/step - loss: 1.2505 - mse: 1.2505 - mae: 0.8469 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.5137\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 328us/step - loss: 1.2435 - mse: 1.2435 - mae: 0.8457 - val_loss: 0.4789 - val_mse: 0.4789 - val_mae: 0.5143\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 458us/step - loss: 1.2354 - mse: 1.2354 - mae: 0.8428 - val_loss: 0.4785 - val_mse: 0.4785 - val_mae: 0.5147\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 318us/step - loss: 1.2283 - mse: 1.2283 - mae: 0.8406 - val_loss: 0.4783 - val_mse: 0.4783 - val_mae: 0.5145\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 324us/step - loss: 1.2204 - mse: 1.2204 - mae: 0.8380 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5143\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 320us/step - loss: 1.2121 - mse: 1.2121 - mae: 0.8342 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.5140\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 429us/step - loss: 1.2054 - mse: 1.2054 - mae: 0.8321 - val_loss: 0.4755 - val_mse: 0.4755 - val_mae: 0.5138\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 277us/step - loss: 1.1977 - mse: 1.1977 - mae: 0.8293 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5131\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 291us/step - loss: 1.1901 - mse: 1.1901 - mae: 0.8261 - val_loss: 0.4753 - val_mse: 0.4753 - val_mae: 0.5141\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 390us/step - loss: 1.1840 - mse: 1.1840 - mae: 0.8250 - val_loss: 0.4743 - val_mse: 0.4743 - val_mae: 0.5143\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 459us/step - loss: 1.1766 - mse: 1.1766 - mae: 0.8220 - val_loss: 0.4731 - val_mse: 0.4731 - val_mae: 0.5137\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 262us/step - loss: 1.1680 - mse: 1.1680 - mae: 0.8174 - val_loss: 0.4741 - val_mse: 0.4741 - val_mae: 0.5135\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 344us/step - loss: 1.1599 - mse: 1.1599 - mae: 0.8141 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.5137\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 324us/step - loss: 1.1538 - mse: 1.1538 - mae: 0.8119 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.5131\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 431us/step - loss: 1.1463 - mse: 1.1463 - mae: 0.8073 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5131\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 347us/step - loss: 1.1394 - mse: 1.1394 - mae: 0.8047 - val_loss: 0.4779 - val_mse: 0.4779 - val_mae: 0.5126\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 328us/step - loss: 1.1328 - mse: 1.1328 - mae: 0.8018 - val_loss: 0.4773 - val_mse: 0.4773 - val_mae: 0.5120\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 481us/step - loss: 1.1252 - mse: 1.1252 - mae: 0.7984 - val_loss: 0.4798 - val_mse: 0.4798 - val_mae: 0.5135\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 307us/step - loss: 1.1195 - mse: 1.1195 - mae: 0.7967 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5131\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 322us/step - loss: 1.1123 - mse: 1.1123 - mae: 0.7923 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.5135\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 502us/step - loss: 1.1052 - mse: 1.1052 - mae: 0.7890 - val_loss: 0.4832 - val_mse: 0.4832 - val_mae: 0.5151\n",
      "14\n",
      "[14]\n",
      "Train on 86 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 3.4832 - mse: 3.4832 - mae: 1.4456 - val_loss: 7.4027 - val_mse: 7.4027 - val_mae: 2.4522\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 209us/step - loss: 3.2923 - mse: 3.2923 - mae: 1.3838 - val_loss: 7.0134 - val_mse: 7.0134 - val_mae: 2.3688\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 297us/step - loss: 3.0938 - mse: 3.0938 - mae: 1.3209 - val_loss: 6.5799 - val_mse: 6.5799 - val_mae: 2.2689\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 412us/step - loss: 2.8772 - mse: 2.8772 - mae: 1.2536 - val_loss: 6.1059 - val_mse: 6.1059 - val_mae: 2.1525\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 270us/step - loss: 2.6422 - mse: 2.6422 - mae: 1.1730 - val_loss: 5.5398 - val_mse: 5.5398 - val_mae: 2.0098\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 285us/step - loss: 2.3949 - mse: 2.3949 - mae: 1.0851 - val_loss: 4.8499 - val_mse: 4.8499 - val_mae: 1.8286\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 322us/step - loss: 2.1214 - mse: 2.1214 - mae: 0.9997 - val_loss: 4.1491 - val_mse: 4.1491 - val_mae: 1.6624\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 199us/step - loss: 1.8702 - mse: 1.8702 - mae: 0.9310 - val_loss: 3.4822 - val_mse: 3.4822 - val_mae: 1.5161\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 260us/step - loss: 1.6670 - mse: 1.6670 - mae: 0.8878 - val_loss: 2.8836 - val_mse: 2.8836 - val_mae: 1.4334\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 144us/step - loss: 1.5320 - mse: 1.5320 - mae: 0.8765 - val_loss: 2.4226 - val_mse: 2.4226 - val_mae: 1.3486\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 191us/step - loss: 1.4709 - mse: 1.4709 - mae: 0.8836 - val_loss: 2.1527 - val_mse: 2.1527 - val_mae: 1.2758\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 428us/step - loss: 1.4580 - mse: 1.4580 - mae: 0.8980 - val_loss: 2.0183 - val_mse: 2.0183 - val_mae: 1.2442\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 336us/step - loss: 1.4575 - mse: 1.4575 - mae: 0.9100 - val_loss: 1.9545 - val_mse: 1.9545 - val_mae: 1.2314\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 173us/step - loss: 1.4417 - mse: 1.4417 - mae: 0.9086 - val_loss: 1.9245 - val_mse: 1.9245 - val_mae: 1.2211\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 512us/step - loss: 1.4112 - mse: 1.4112 - mae: 0.8940 - val_loss: 1.9208 - val_mse: 1.9208 - val_mae: 1.2138\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 167us/step - loss: 1.3807 - mse: 1.3807 - mae: 0.8746 - val_loss: 1.9406 - val_mse: 1.9406 - val_mae: 1.2097\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 159us/step - loss: 1.3562 - mse: 1.3562 - mae: 0.8564 - val_loss: 1.9776 - val_mse: 1.9776 - val_mae: 1.2203\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 173us/step - loss: 1.3396 - mse: 1.3396 - mae: 0.8407 - val_loss: 2.0099 - val_mse: 2.0099 - val_mae: 1.2303\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 157us/step - loss: 1.3291 - mse: 1.3291 - mae: 0.8291 - val_loss: 2.0308 - val_mse: 2.0308 - val_mae: 1.2357\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 527us/step - loss: 1.3205 - mse: 1.3205 - mae: 0.8214 - val_loss: 2.0326 - val_mse: 2.0326 - val_mae: 1.2355\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 181us/step - loss: 1.3112 - mse: 1.3112 - mae: 0.8165 - val_loss: 2.0142 - val_mse: 2.0142 - val_mae: 1.2299\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 365us/step - loss: 1.3003 - mse: 1.3003 - mae: 0.8136 - val_loss: 1.9806 - val_mse: 1.9806 - val_mae: 1.2200\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 253us/step - loss: 1.2886 - mse: 1.2886 - mae: 0.8127 - val_loss: 1.9419 - val_mse: 1.9419 - val_mae: 1.2084\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 389us/step - loss: 1.2771 - mse: 1.2771 - mae: 0.8128 - val_loss: 1.9038 - val_mse: 1.9038 - val_mae: 1.1965\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 228us/step - loss: 1.2667 - mse: 1.2667 - mae: 0.8136 - val_loss: 1.8705 - val_mse: 1.8705 - val_mae: 1.1858\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 455us/step - loss: 1.2573 - mse: 1.2573 - mae: 0.8141 - val_loss: 1.8453 - val_mse: 1.8453 - val_mae: 1.1788\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 368us/step - loss: 1.2485 - mse: 1.2485 - mae: 0.8136 - val_loss: 1.8287 - val_mse: 1.8287 - val_mae: 1.1750\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 472us/step - loss: 1.2398 - mse: 1.2398 - mae: 0.8117 - val_loss: 1.8197 - val_mse: 1.8197 - val_mae: 1.1729\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 176us/step - loss: 1.2310 - mse: 1.2310 - mae: 0.8086 - val_loss: 1.8168 - val_mse: 1.8168 - val_mae: 1.1724\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 294us/step - loss: 1.2223 - mse: 1.2223 - mae: 0.8045 - val_loss: 1.8181 - val_mse: 1.8181 - val_mae: 1.1724\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 144us/step - loss: 1.2142 - mse: 1.2142 - mae: 0.8003 - val_loss: 1.8203 - val_mse: 1.8203 - val_mae: 1.1735\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 170us/step - loss: 1.2064 - mse: 1.2064 - mae: 0.7968 - val_loss: 1.8193 - val_mse: 1.8193 - val_mae: 1.1737\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 350us/step - loss: 1.1987 - mse: 1.1987 - mae: 0.7940 - val_loss: 1.8137 - val_mse: 1.8137 - val_mae: 1.1721\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 167us/step - loss: 1.1910 - mse: 1.1910 - mae: 0.7922 - val_loss: 1.8044 - val_mse: 1.8044 - val_mae: 1.1692\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 270us/step - loss: 1.1833 - mse: 1.1833 - mae: 0.7909 - val_loss: 1.7935 - val_mse: 1.7935 - val_mae: 1.1655\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 306us/step - loss: 1.1757 - mse: 1.1757 - mae: 0.7899 - val_loss: 1.7824 - val_mse: 1.7824 - val_mae: 1.1618\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 171us/step - loss: 1.1686 - mse: 1.1686 - mae: 0.7887 - val_loss: 1.7735 - val_mse: 1.7735 - val_mae: 1.1594\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 235us/step - loss: 1.1617 - mse: 1.1617 - mae: 0.7870 - val_loss: 1.7667 - val_mse: 1.7667 - val_mae: 1.1574\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 208us/step - loss: 1.1550 - mse: 1.1550 - mae: 0.7850 - val_loss: 1.7601 - val_mse: 1.7601 - val_mae: 1.1555\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 260us/step - loss: 1.1483 - mse: 1.1483 - mae: 0.7828 - val_loss: 1.7532 - val_mse: 1.7532 - val_mae: 1.1536\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 169us/step - loss: 1.1420 - mse: 1.1420 - mae: 0.7808 - val_loss: 1.7452 - val_mse: 1.7452 - val_mae: 1.1525\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 230us/step - loss: 1.1357 - mse: 1.1357 - mae: 0.7790 - val_loss: 1.7380 - val_mse: 1.7380 - val_mae: 1.1517\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 277us/step - loss: 1.1293 - mse: 1.1293 - mae: 0.7769 - val_loss: 1.7334 - val_mse: 1.7334 - val_mae: 1.1516\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 502us/step - loss: 1.1236 - mse: 1.1236 - mae: 0.7746 - val_loss: 1.7309 - val_mse: 1.7309 - val_mae: 1.1519\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 210us/step - loss: 1.1183 - mse: 1.1183 - mae: 0.7720 - val_loss: 1.7285 - val_mse: 1.7285 - val_mae: 1.1521\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 511us/step - loss: 1.1134 - mse: 1.1134 - mae: 0.7696 - val_loss: 1.7266 - val_mse: 1.7266 - val_mae: 1.1525\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 433us/step - loss: 1.1084 - mse: 1.1084 - mae: 0.7675 - val_loss: 1.7267 - val_mse: 1.7267 - val_mae: 1.1536\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 182us/step - loss: 1.1034 - mse: 1.1034 - mae: 0.7649 - val_loss: 1.7276 - val_mse: 1.7276 - val_mae: 1.1551\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 389us/step - loss: 1.0985 - mse: 1.0985 - mae: 0.7624 - val_loss: 1.7275 - val_mse: 1.7275 - val_mae: 1.1562\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 255us/step - loss: 1.0939 - mse: 1.0939 - mae: 0.7603 - val_loss: 1.7244 - val_mse: 1.7244 - val_mae: 1.1560\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 159us/step - loss: 1.0893 - mse: 1.0893 - mae: 0.7588 - val_loss: 1.7180 - val_mse: 1.7180 - val_mae: 1.1547\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 387us/step - loss: 1.0848 - mse: 1.0848 - mae: 0.7579 - val_loss: 1.7109 - val_mse: 1.7109 - val_mae: 1.1531\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 477us/step - loss: 1.0805 - mse: 1.0805 - mae: 0.7571 - val_loss: 1.7045 - val_mse: 1.7045 - val_mae: 1.1517\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 284us/step - loss: 1.0762 - mse: 1.0762 - mae: 0.7562 - val_loss: 1.7001 - val_mse: 1.7001 - val_mae: 1.1510\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 213us/step - loss: 1.0719 - mse: 1.0719 - mae: 0.7548 - val_loss: 1.6984 - val_mse: 1.6984 - val_mae: 1.1514\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 168us/step - loss: 1.0685 - mse: 1.0685 - mae: 0.7532 - val_loss: 1.6937 - val_mse: 1.6937 - val_mae: 1.1507\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 165us/step - loss: 1.0650 - mse: 1.0650 - mae: 0.7524 - val_loss: 1.6856 - val_mse: 1.6856 - val_mae: 1.1485\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 181us/step - loss: 1.0610 - mse: 1.0610 - mae: 0.7520 - val_loss: 1.6775 - val_mse: 1.6775 - val_mae: 1.1463\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 163us/step - loss: 1.0572 - mse: 1.0572 - mae: 0.7514 - val_loss: 1.6724 - val_mse: 1.6724 - val_mae: 1.1451\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 515us/step - loss: 1.0531 - mse: 1.0531 - mae: 0.7502 - val_loss: 1.6722 - val_mse: 1.6722 - val_mae: 1.1457\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 575us/step - loss: 1.0497 - mse: 1.0497 - mae: 0.7483 - val_loss: 1.6742 - val_mse: 1.6742 - val_mae: 1.1471\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 218us/step - loss: 1.0465 - mse: 1.0465 - mae: 0.7462 - val_loss: 1.6744 - val_mse: 1.6744 - val_mae: 1.1477\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 293us/step - loss: 1.0430 - mse: 1.0430 - mae: 0.7446 - val_loss: 1.6730 - val_mse: 1.6730 - val_mae: 1.1475\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 177us/step - loss: 1.0394 - mse: 1.0394 - mae: 0.7430 - val_loss: 1.6729 - val_mse: 1.6729 - val_mae: 1.1478\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 403us/step - loss: 1.0363 - mse: 1.0363 - mae: 0.7414 - val_loss: 1.6733 - val_mse: 1.6733 - val_mae: 1.1484\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 337us/step - loss: 1.0335 - mse: 1.0335 - mae: 0.7401 - val_loss: 1.6705 - val_mse: 1.6705 - val_mae: 1.1478\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 375us/step - loss: 1.0303 - mse: 1.0303 - mae: 0.7394 - val_loss: 1.6651 - val_mse: 1.6651 - val_mae: 1.1462\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 436us/step - loss: 1.0273 - mse: 1.0273 - mae: 0.7389 - val_loss: 1.6616 - val_mse: 1.6616 - val_mae: 1.1452\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 310us/step - loss: 1.0242 - mse: 1.0242 - mae: 0.7378 - val_loss: 1.6619 - val_mse: 1.6619 - val_mae: 1.1455\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 229us/step - loss: 1.0212 - mse: 1.0212 - mae: 0.7361 - val_loss: 1.6631 - val_mse: 1.6631 - val_mae: 1.1463\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 388us/step - loss: 1.0184 - mse: 1.0184 - mae: 0.7344 - val_loss: 1.6615 - val_mse: 1.6615 - val_mae: 1.1463\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 174us/step - loss: 1.0155 - mse: 1.0155 - mae: 0.7329 - val_loss: 1.6559 - val_mse: 1.6559 - val_mae: 1.1448\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 160us/step - loss: 1.0124 - mse: 1.0124 - mae: 0.7318 - val_loss: 1.6500 - val_mse: 1.6500 - val_mae: 1.1430\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 225us/step - loss: 1.0091 - mse: 1.0091 - mae: 0.7305 - val_loss: 1.6480 - val_mse: 1.6480 - val_mae: 1.1426\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 207us/step - loss: 1.0061 - mse: 1.0061 - mae: 0.7289 - val_loss: 1.6466 - val_mse: 1.6466 - val_mae: 1.1427\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 170us/step - loss: 1.0036 - mse: 1.0036 - mae: 0.7273 - val_loss: 1.6436 - val_mse: 1.6436 - val_mae: 1.1417\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 175us/step - loss: 1.0007 - mse: 1.0007 - mae: 0.7261 - val_loss: 1.6428 - val_mse: 1.6428 - val_mae: 1.1412\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.9977 - mse: 0.9977 - mae: 0.7249 - val_loss: 1.6450 - val_mse: 1.6450 - val_mae: 1.1418\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 447us/step - loss: 0.9950 - mse: 0.9950 - mae: 0.7234 - val_loss: 1.6461 - val_mse: 1.6461 - val_mae: 1.1420\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.9924 - mse: 0.9924 - mae: 0.7221 - val_loss: 1.6460 - val_mse: 1.6460 - val_mae: 1.1420\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 361us/step - loss: 0.9894 - mse: 0.9894 - mae: 0.7206 - val_loss: 1.6474 - val_mse: 1.6474 - val_mae: 1.1425\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.9867 - mse: 0.9867 - mae: 0.7189 - val_loss: 1.6484 - val_mse: 1.6484 - val_mae: 1.1427\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 593us/step - loss: 0.9841 - mse: 0.9841 - mae: 0.7176 - val_loss: 1.6485 - val_mse: 1.6485 - val_mae: 1.1428\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 192us/step - loss: 0.9815 - mse: 0.9815 - mae: 0.7163 - val_loss: 1.6467 - val_mse: 1.6467 - val_mae: 1.1421\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 174us/step - loss: 0.9789 - mse: 0.9789 - mae: 0.7154 - val_loss: 1.6438 - val_mse: 1.6438 - val_mae: 1.1408\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.9760 - mse: 0.9760 - mae: 0.7141 - val_loss: 1.6446 - val_mse: 1.6446 - val_mae: 1.1409\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 219us/step - loss: 0.9735 - mse: 0.9735 - mae: 0.7126 - val_loss: 1.6453 - val_mse: 1.6453 - val_mae: 1.1411\n",
      "15\n",
      "[15]\n",
      "Train on 111 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "111/111 [==============================] - 1s 8ms/step - loss: 12.7740 - mse: 12.7740 - mae: 3.1062 - val_loss: 3.6631 - val_mse: 3.6631 - val_mae: 1.5951\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 0s 474us/step - loss: 10.1571 - mse: 10.1571 - mae: 2.6787 - val_loss: 2.7652 - val_mse: 2.7652 - val_mae: 1.3342\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 0s 470us/step - loss: 8.1546 - mse: 8.1546 - mae: 2.3186 - val_loss: 2.0977 - val_mse: 2.0977 - val_mae: 1.1273\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 0s 274us/step - loss: 6.5881 - mse: 6.5881 - mae: 2.0041 - val_loss: 1.5956 - val_mse: 1.5956 - val_mae: 0.9318\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 0s 506us/step - loss: 5.3862 - mse: 5.3862 - mae: 1.7391 - val_loss: 1.2607 - val_mse: 1.2607 - val_mae: 0.7779\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 0s 238us/step - loss: 4.4924 - mse: 4.4924 - mae: 1.5297 - val_loss: 1.0670 - val_mse: 1.0670 - val_mae: 0.6686\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 0s 219us/step - loss: 3.8701 - mse: 3.8701 - mae: 1.3981 - val_loss: 0.9736 - val_mse: 0.9736 - val_mae: 0.5995\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 0s 341us/step - loss: 3.4699 - mse: 3.4699 - mae: 1.3163 - val_loss: 0.9540 - val_mse: 0.9540 - val_mae: 0.6225\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 3.2289 - mse: 3.2289 - mae: 1.2719 - val_loss: 0.9745 - val_mse: 0.9745 - val_mae: 0.6612\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 0s 382us/step - loss: 3.0917 - mse: 3.0917 - mae: 1.2614 - val_loss: 1.0016 - val_mse: 1.0016 - val_mae: 0.6919\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 0s 185us/step - loss: 3.0111 - mse: 3.0111 - mae: 1.2585 - val_loss: 1.0197 - val_mse: 1.0197 - val_mae: 0.7090\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 0s 499us/step - loss: 2.9483 - mse: 2.9483 - mae: 1.2493 - val_loss: 1.0146 - val_mse: 1.0146 - val_mae: 0.7104\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 0s 479us/step - loss: 2.8928 - mse: 2.8928 - mae: 1.2358 - val_loss: 0.9910 - val_mse: 0.9910 - val_mae: 0.7001\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 0s 345us/step - loss: 2.8272 - mse: 2.8272 - mae: 1.2167 - val_loss: 0.9591 - val_mse: 0.9591 - val_mae: 0.6825\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 0s 359us/step - loss: 2.7663 - mse: 2.7663 - mae: 1.1980 - val_loss: 0.9304 - val_mse: 0.9304 - val_mae: 0.6646\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 0s 381us/step - loss: 2.7122 - mse: 2.7122 - mae: 1.1824 - val_loss: 0.9090 - val_mse: 0.9090 - val_mae: 0.6491\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 0s 178us/step - loss: 2.6636 - mse: 2.6636 - mae: 1.1679 - val_loss: 0.8963 - val_mse: 0.8963 - val_mae: 0.6384\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 0s 257us/step - loss: 2.6192 - mse: 2.6192 - mae: 1.1564 - val_loss: 0.8901 - val_mse: 0.8901 - val_mae: 0.6336\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 0s 148us/step - loss: 2.5782 - mse: 2.5782 - mae: 1.1485 - val_loss: 0.8906 - val_mse: 0.8906 - val_mae: 0.6331\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 0s 152us/step - loss: 2.5388 - mse: 2.5388 - mae: 1.1424 - val_loss: 0.8949 - val_mse: 0.8949 - val_mae: 0.6356\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 0s 147us/step - loss: 2.5024 - mse: 2.5024 - mae: 1.1389 - val_loss: 0.8991 - val_mse: 0.8991 - val_mae: 0.6390\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 0s 155us/step - loss: 2.4691 - mse: 2.4691 - mae: 1.1358 - val_loss: 0.9004 - val_mse: 0.9004 - val_mae: 0.6405\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 0s 343us/step - loss: 2.4392 - mse: 2.4392 - mae: 1.1322 - val_loss: 0.8993 - val_mse: 0.8993 - val_mae: 0.6404\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 0s 524us/step - loss: 2.4110 - mse: 2.4110 - mae: 1.1277 - val_loss: 0.8967 - val_mse: 0.8967 - val_mae: 0.6395\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 0s 317us/step - loss: 2.3848 - mse: 2.3848 - mae: 1.1229 - val_loss: 0.8947 - val_mse: 0.8947 - val_mae: 0.6404\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 0s 166us/step - loss: 2.3598 - mse: 2.3598 - mae: 1.1180 - val_loss: 0.8924 - val_mse: 0.8924 - val_mae: 0.6411\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 0s 142us/step - loss: 2.3358 - mse: 2.3358 - mae: 1.1130 - val_loss: 0.8880 - val_mse: 0.8880 - val_mae: 0.6405\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 0s 171us/step - loss: 2.3122 - mse: 2.3122 - mae: 1.1083 - val_loss: 0.8836 - val_mse: 0.8836 - val_mae: 0.6397\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 0s 527us/step - loss: 2.2895 - mse: 2.2895 - mae: 1.1039 - val_loss: 0.8804 - val_mse: 0.8804 - val_mae: 0.6395\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 0s 174us/step - loss: 2.2675 - mse: 2.2675 - mae: 1.0996 - val_loss: 0.8778 - val_mse: 0.8778 - val_mae: 0.6396\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 0s 202us/step - loss: 2.2465 - mse: 2.2465 - mae: 1.0953 - val_loss: 0.8736 - val_mse: 0.8736 - val_mae: 0.6385\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 0s 181us/step - loss: 2.2254 - mse: 2.2254 - mae: 1.0908 - val_loss: 0.8693 - val_mse: 0.8693 - val_mae: 0.6373\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 0s 260us/step - loss: 2.2061 - mse: 2.2061 - mae: 1.0866 - val_loss: 0.8683 - val_mse: 0.8683 - val_mae: 0.6385\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 0s 156us/step - loss: 2.1880 - mse: 2.1880 - mae: 1.0833 - val_loss: 0.8695 - val_mse: 0.8695 - val_mae: 0.6408\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 0s 335us/step - loss: 2.1709 - mse: 2.1709 - mae: 1.0804 - val_loss: 0.8712 - val_mse: 0.8712 - val_mae: 0.6433\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 0s 272us/step - loss: 2.1548 - mse: 2.1548 - mae: 1.0775 - val_loss: 0.8698 - val_mse: 0.8698 - val_mae: 0.6435\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 0s 154us/step - loss: 2.1386 - mse: 2.1386 - mae: 1.0740 - val_loss: 0.8680 - val_mse: 0.8680 - val_mae: 0.6429\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 0s 431us/step - loss: 2.1238 - mse: 2.1238 - mae: 1.0705 - val_loss: 0.8682 - val_mse: 0.8682 - val_mae: 0.6434\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 0s 176us/step - loss: 2.1104 - mse: 2.1104 - mae: 1.0678 - val_loss: 0.8718 - val_mse: 0.8718 - val_mae: 0.6463\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 0s 395us/step - loss: 2.0968 - mse: 2.0968 - mae: 1.0654 - val_loss: 0.8770 - val_mse: 0.8770 - val_mae: 0.6502\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 0s 212us/step - loss: 2.0842 - mse: 2.0842 - mae: 1.0624 - val_loss: 0.8792 - val_mse: 0.8792 - val_mae: 0.6517\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 0s 307us/step - loss: 2.0718 - mse: 2.0718 - mae: 1.0586 - val_loss: 0.8800 - val_mse: 0.8800 - val_mae: 0.6516\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 0s 529us/step - loss: 2.0592 - mse: 2.0592 - mae: 1.0552 - val_loss: 0.8854 - val_mse: 0.8854 - val_mae: 0.6547\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 0s 306us/step - loss: 2.0464 - mse: 2.0464 - mae: 1.0521 - val_loss: 0.8912 - val_mse: 0.8912 - val_mae: 0.6580\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 0s 485us/step - loss: 2.0343 - mse: 2.0343 - mae: 1.0488 - val_loss: 0.8937 - val_mse: 0.8937 - val_mae: 0.6589\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 0s 369us/step - loss: 2.0220 - mse: 2.0220 - mae: 1.0448 - val_loss: 0.8953 - val_mse: 0.8953 - val_mae: 0.6592\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 0s 363us/step - loss: 2.0099 - mse: 2.0099 - mae: 1.0409 - val_loss: 0.8975 - val_mse: 0.8975 - val_mae: 0.6600\n",
      "16\n",
      "[16]\n",
      "Train on 83 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.7624 - mse: 2.7624 - mae: 1.1824 - val_loss: 3.2921 - val_mse: 3.2921 - val_mae: 1.6119\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 457us/step - loss: 2.4142 - mse: 2.4142 - mae: 1.0413 - val_loss: 2.5108 - val_mse: 2.5108 - val_mae: 1.3642\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 451us/step - loss: 2.1404 - mse: 2.1404 - mae: 0.9324 - val_loss: 1.9760 - val_mse: 1.9760 - val_mae: 1.1985\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 184us/step - loss: 1.9660 - mse: 1.9660 - mae: 0.8633 - val_loss: 1.5490 - val_mse: 1.5490 - val_mae: 1.0448\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 241us/step - loss: 1.8601 - mse: 1.8601 - mae: 0.8257 - val_loss: 1.2195 - val_mse: 1.2195 - val_mae: 0.9167\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 219us/step - loss: 1.7973 - mse: 1.7973 - mae: 0.8325 - val_loss: 0.9750 - val_mse: 0.9750 - val_mae: 0.8087\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 427us/step - loss: 1.7588 - mse: 1.7588 - mae: 0.8551 - val_loss: 0.8200 - val_mse: 0.8200 - val_mae: 0.7363\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 334us/step - loss: 1.7323 - mse: 1.7323 - mae: 0.8746 - val_loss: 0.7324 - val_mse: 0.7324 - val_mae: 0.6887\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 215us/step - loss: 1.7048 - mse: 1.7048 - mae: 0.8807 - val_loss: 0.6945 - val_mse: 0.6945 - val_mae: 0.6666\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 181us/step - loss: 1.6684 - mse: 1.6684 - mae: 0.8719 - val_loss: 0.6823 - val_mse: 0.6823 - val_mae: 0.6609\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 422us/step - loss: 1.6240 - mse: 1.6240 - mae: 0.8541 - val_loss: 0.6847 - val_mse: 0.6847 - val_mae: 0.6658\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 276us/step - loss: 1.5811 - mse: 1.5811 - mae: 0.8340 - val_loss: 0.6909 - val_mse: 0.6909 - val_mae: 0.6766\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 648us/step - loss: 1.5408 - mse: 1.5408 - mae: 0.8138 - val_loss: 0.6939 - val_mse: 0.6939 - val_mae: 0.6842\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 190us/step - loss: 1.5034 - mse: 1.5034 - mae: 0.7957 - val_loss: 0.6887 - val_mse: 0.6887 - val_mae: 0.6849\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 237us/step - loss: 1.4718 - mse: 1.4718 - mae: 0.7817 - val_loss: 0.6785 - val_mse: 0.6785 - val_mae: 0.6804\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 237us/step - loss: 1.4450 - mse: 1.4450 - mae: 0.7721 - val_loss: 0.6626 - val_mse: 0.6626 - val_mae: 0.6704\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 329us/step - loss: 1.4188 - mse: 1.4188 - mae: 0.7645 - val_loss: 0.6394 - val_mse: 0.6394 - val_mae: 0.6532\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 424us/step - loss: 1.3934 - mse: 1.3934 - mae: 0.7589 - val_loss: 0.6121 - val_mse: 0.6121 - val_mae: 0.6313\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 523us/step - loss: 1.3690 - mse: 1.3690 - mae: 0.7578 - val_loss: 0.5837 - val_mse: 0.5837 - val_mae: 0.6061\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 233us/step - loss: 1.3453 - mse: 1.3453 - mae: 0.7571 - val_loss: 0.5584 - val_mse: 0.5584 - val_mae: 0.5812\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 214us/step - loss: 1.3224 - mse: 1.3224 - mae: 0.7554 - val_loss: 0.5380 - val_mse: 0.5380 - val_mae: 0.5600\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 527us/step - loss: 1.3024 - mse: 1.3024 - mae: 0.7530 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5459\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 461us/step - loss: 1.2848 - mse: 1.2848 - mae: 0.7498 - val_loss: 0.5098 - val_mse: 0.5098 - val_mae: 0.5357\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 492us/step - loss: 1.2678 - mse: 1.2678 - mae: 0.7455 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.5305\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 535us/step - loss: 1.2526 - mse: 1.2526 - mae: 0.7405 - val_loss: 0.4968 - val_mse: 0.4968 - val_mae: 0.5276\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 366us/step - loss: 1.2391 - mse: 1.2391 - mae: 0.7356 - val_loss: 0.4921 - val_mse: 0.4921 - val_mae: 0.5249\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 185us/step - loss: 1.2273 - mse: 1.2273 - mae: 0.7326 - val_loss: 0.4862 - val_mse: 0.4862 - val_mae: 0.5222\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 193us/step - loss: 1.2157 - mse: 1.2157 - mae: 0.7308 - val_loss: 0.4798 - val_mse: 0.4798 - val_mae: 0.5187\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 249us/step - loss: 1.2036 - mse: 1.2036 - mae: 0.7291 - val_loss: 0.4744 - val_mse: 0.4744 - val_mae: 0.5150\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 222us/step - loss: 1.1933 - mse: 1.1933 - mae: 0.7284 - val_loss: 0.4685 - val_mse: 0.4685 - val_mae: 0.5109\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 534us/step - loss: 1.1829 - mse: 1.1829 - mae: 0.7282 - val_loss: 0.4640 - val_mse: 0.4640 - val_mae: 0.5071\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 510us/step - loss: 1.1718 - mse: 1.1718 - mae: 0.7264 - val_loss: 0.4622 - val_mse: 0.4622 - val_mae: 0.5045\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 206us/step - loss: 1.1618 - mse: 1.1618 - mae: 0.7223 - val_loss: 0.4600 - val_mse: 0.4600 - val_mae: 0.5016\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 170us/step - loss: 1.1534 - mse: 1.1534 - mae: 0.7199 - val_loss: 0.4571 - val_mse: 0.4571 - val_mae: 0.4984\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 276us/step - loss: 1.1452 - mse: 1.1452 - mae: 0.7184 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4951\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 233us/step - loss: 1.1367 - mse: 1.1367 - mae: 0.7179 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.4906\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 377us/step - loss: 1.1281 - mse: 1.1281 - mae: 0.7168 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4882\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 475us/step - loss: 1.1188 - mse: 1.1188 - mae: 0.7128 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.4884\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 331us/step - loss: 1.1117 - mse: 1.1117 - mae: 0.7086 - val_loss: 0.4471 - val_mse: 0.4471 - val_mae: 0.4874\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 189us/step - loss: 1.1046 - mse: 1.1046 - mae: 0.7081 - val_loss: 0.4436 - val_mse: 0.4436 - val_mae: 0.4848\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 173us/step - loss: 1.0972 - mse: 1.0972 - mae: 0.7091 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4849\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 178us/step - loss: 1.0894 - mse: 1.0894 - mae: 0.7090 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4852\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 255us/step - loss: 1.0818 - mse: 1.0818 - mae: 0.7052 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4854\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 316us/step - loss: 1.0741 - mse: 1.0741 - mae: 0.6988 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4869\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 564us/step - loss: 1.0686 - mse: 1.0686 - mae: 0.6952 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4880\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 284us/step - loss: 1.0616 - mse: 1.0616 - mae: 0.6955 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4900\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 259us/step - loss: 1.0538 - mse: 1.0538 - mae: 0.6978 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4913\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 209us/step - loss: 1.0461 - mse: 1.0461 - mae: 0.7010 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.4950\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 283us/step - loss: 1.0381 - mse: 1.0381 - mae: 0.6998 - val_loss: 0.4520 - val_mse: 0.4520 - val_mae: 0.4962\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 214us/step - loss: 1.0301 - mse: 1.0301 - mae: 0.6945 - val_loss: 0.4550 - val_mse: 0.4550 - val_mae: 0.4970\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 464us/step - loss: 1.0232 - mse: 1.0232 - mae: 0.6900 - val_loss: 0.4580 - val_mse: 0.4580 - val_mae: 0.4985\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 681us/step - loss: 1.0165 - mse: 1.0165 - mae: 0.6872 - val_loss: 0.4599 - val_mse: 0.4599 - val_mae: 0.5013\n",
      "17\n",
      "[17]\n",
      "Train on 100 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 4.1039 - mse: 4.1039 - mae: 1.5676 - val_loss: 1.8144 - val_mse: 1.8144 - val_mae: 1.0200\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 578us/step - loss: 3.5443 - mse: 3.5443 - mae: 1.3949 - val_loss: 1.5328 - val_mse: 1.5328 - val_mae: 0.8942\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 592us/step - loss: 3.0065 - mse: 3.0065 - mae: 1.2554 - val_loss: 1.2897 - val_mse: 1.2897 - val_mae: 0.7704\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 431us/step - loss: 2.5245 - mse: 2.5245 - mae: 1.1450 - val_loss: 1.0957 - val_mse: 1.0957 - val_mae: 0.7176\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 359us/step - loss: 2.1700 - mse: 2.1700 - mae: 1.0722 - val_loss: 0.9882 - val_mse: 0.9882 - val_mae: 0.6974\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 395us/step - loss: 1.9496 - mse: 1.9496 - mae: 1.0314 - val_loss: 0.9478 - val_mse: 0.9478 - val_mae: 0.7037\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 447us/step - loss: 1.8505 - mse: 1.8505 - mae: 1.0410 - val_loss: 0.9563 - val_mse: 0.9563 - val_mae: 0.7413\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 204us/step - loss: 1.8205 - mse: 1.8205 - mae: 1.0657 - val_loss: 0.9641 - val_mse: 0.9641 - val_mae: 0.7670\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 355us/step - loss: 1.8000 - mse: 1.8000 - mae: 1.0736 - val_loss: 0.9497 - val_mse: 0.9497 - val_mae: 0.7694\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 596us/step - loss: 1.7605 - mse: 1.7605 - mae: 1.0607 - val_loss: 0.9111 - val_mse: 0.9111 - val_mae: 0.7499\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 498us/step - loss: 1.7076 - mse: 1.7076 - mae: 1.0340 - val_loss: 0.8639 - val_mse: 0.8639 - val_mae: 0.7205\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 192us/step - loss: 1.6568 - mse: 1.6568 - mae: 1.0035 - val_loss: 0.8209 - val_mse: 0.8209 - val_mae: 0.6920\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 531us/step - loss: 1.6170 - mse: 1.6170 - mae: 0.9747 - val_loss: 0.7876 - val_mse: 0.7876 - val_mae: 0.6690\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 409us/step - loss: 1.5867 - mse: 1.5867 - mae: 0.9534 - val_loss: 0.7632 - val_mse: 0.7632 - val_mae: 0.6559\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 523us/step - loss: 1.5633 - mse: 1.5633 - mae: 0.9376 - val_loss: 0.7455 - val_mse: 0.7455 - val_mae: 0.6479\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 347us/step - loss: 1.5413 - mse: 1.5413 - mae: 0.9258 - val_loss: 0.7329 - val_mse: 0.7329 - val_mae: 0.6443\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 258us/step - loss: 1.5199 - mse: 1.5199 - mae: 0.9173 - val_loss: 0.7243 - val_mse: 0.7243 - val_mae: 0.6435\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 471us/step - loss: 1.4995 - mse: 1.4995 - mae: 0.9112 - val_loss: 0.7187 - val_mse: 0.7187 - val_mae: 0.6450\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 222us/step - loss: 1.4803 - mse: 1.4803 - mae: 0.9057 - val_loss: 0.7148 - val_mse: 0.7148 - val_mae: 0.6480\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 551us/step - loss: 1.4629 - mse: 1.4629 - mae: 0.9004 - val_loss: 0.7111 - val_mse: 0.7111 - val_mae: 0.6492\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 371us/step - loss: 1.4468 - mse: 1.4468 - mae: 0.8943 - val_loss: 0.7065 - val_mse: 0.7065 - val_mae: 0.6493\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 289us/step - loss: 1.4310 - mse: 1.4310 - mae: 0.8865 - val_loss: 0.7016 - val_mse: 0.7016 - val_mae: 0.6484\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 402us/step - loss: 1.4139 - mse: 1.4139 - mae: 0.8777 - val_loss: 0.6965 - val_mse: 0.6965 - val_mae: 0.6469\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 378us/step - loss: 1.3962 - mse: 1.3962 - mae: 0.8680 - val_loss: 0.6926 - val_mse: 0.6926 - val_mae: 0.6455\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 1.3773 - mse: 1.3773 - mae: 0.8588 - val_loss: 0.6895 - val_mse: 0.6895 - val_mae: 0.6445\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 462us/step - loss: 1.3596 - mse: 1.3596 - mae: 0.8511 - val_loss: 0.6883 - val_mse: 0.6883 - val_mae: 0.6447\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 205us/step - loss: 1.3433 - mse: 1.3433 - mae: 0.8441 - val_loss: 0.6904 - val_mse: 0.6904 - val_mae: 0.6462\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 358us/step - loss: 1.3280 - mse: 1.3280 - mae: 0.8373 - val_loss: 0.6924 - val_mse: 0.6924 - val_mae: 0.6471\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 397us/step - loss: 1.3135 - mse: 1.3135 - mae: 0.8306 - val_loss: 0.6940 - val_mse: 0.6940 - val_mae: 0.6477\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 204us/step - loss: 1.3004 - mse: 1.3004 - mae: 0.8240 - val_loss: 0.6956 - val_mse: 0.6956 - val_mae: 0.6485\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 408us/step - loss: 1.2879 - mse: 1.2879 - mae: 0.8176 - val_loss: 0.6970 - val_mse: 0.6970 - val_mae: 0.6501\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 478us/step - loss: 1.2761 - mse: 1.2761 - mae: 0.8117 - val_loss: 0.6984 - val_mse: 0.6984 - val_mae: 0.6525\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 424us/step - loss: 1.2646 - mse: 1.2646 - mae: 0.8061 - val_loss: 0.7005 - val_mse: 0.7005 - val_mae: 0.6554\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 440us/step - loss: 1.2536 - mse: 1.2536 - mae: 0.8008 - val_loss: 0.7023 - val_mse: 0.7023 - val_mae: 0.6586\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 356us/step - loss: 1.2429 - mse: 1.2429 - mae: 0.7963 - val_loss: 0.7044 - val_mse: 0.7044 - val_mae: 0.6617\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 278us/step - loss: 1.2329 - mse: 1.2329 - mae: 0.7923 - val_loss: 0.7058 - val_mse: 0.7058 - val_mae: 0.6644\n",
      "18\n",
      "[18]\n",
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.7534 - mse: 2.7534 - mae: 1.3704 - val_loss: 1.1527 - val_mse: 1.1527 - val_mae: 0.8285\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 234us/step - loss: 2.2982 - mse: 2.2982 - mae: 1.2083 - val_loss: 0.8830 - val_mse: 0.8830 - val_mae: 0.6616\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 182us/step - loss: 1.8753 - mse: 1.8753 - mae: 1.0432 - val_loss: 0.6618 - val_mse: 0.6618 - val_mae: 0.5437\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 199us/step - loss: 1.5129 - mse: 1.5129 - mae: 0.9078 - val_loss: 0.5117 - val_mse: 0.5117 - val_mae: 0.4916\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 444us/step - loss: 1.2314 - mse: 1.2314 - mae: 0.7963 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.5098\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 572us/step - loss: 1.0311 - mse: 1.0311 - mae: 0.7247 - val_loss: 0.4303 - val_mse: 0.4303 - val_mae: 0.5469\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 388us/step - loss: 0.9102 - mse: 0.9102 - mae: 0.6911 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.6069\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.8546 - mse: 0.8546 - mae: 0.7018 - val_loss: 0.5666 - val_mse: 0.5666 - val_mae: 0.6683\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 736us/step - loss: 0.8451 - mse: 0.8451 - mae: 0.7269 - val_loss: 0.6593 - val_mse: 0.6593 - val_mae: 0.7160\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 189us/step - loss: 0.8591 - mse: 0.8591 - mae: 0.7501 - val_loss: 0.7317 - val_mse: 0.7317 - val_mae: 0.7464\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 177us/step - loss: 0.8731 - mse: 0.8731 - mae: 0.7662 - val_loss: 0.7682 - val_mse: 0.7682 - val_mae: 0.7593\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 196us/step - loss: 0.8744 - mse: 0.8744 - mae: 0.7713 - val_loss: 0.7651 - val_mse: 0.7651 - val_mae: 0.7566\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 448us/step - loss: 0.8618 - mse: 0.8618 - mae: 0.7675 - val_loss: 0.7330 - val_mse: 0.7330 - val_mae: 0.7429\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 676us/step - loss: 0.8407 - mse: 0.8407 - mae: 0.7570 - val_loss: 0.6852 - val_mse: 0.6852 - val_mae: 0.7219\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 224us/step - loss: 0.8181 - mse: 0.8181 - mae: 0.7434 - val_loss: 0.6342 - val_mse: 0.6342 - val_mae: 0.6980\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 403us/step - loss: 0.7987 - mse: 0.7987 - mae: 0.7291 - val_loss: 0.5884 - val_mse: 0.5884 - val_mae: 0.6742\n",
      "19\n",
      "[19]\n",
      "Train on 97 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 14.7802 - mse: 14.7802 - mae: 3.6401 - val_loss: 7.5857 - val_mse: 7.5857 - val_mae: 2.7039\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 301us/step - loss: 12.8296 - mse: 12.8296 - mae: 3.3686 - val_loss: 6.5138 - val_mse: 6.5138 - val_mae: 2.4999\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 188us/step - loss: 11.2474 - mse: 11.2474 - mae: 3.1330 - val_loss: 5.5917 - val_mse: 5.5917 - val_mae: 2.3096\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 438us/step - loss: 9.8880 - mse: 9.8880 - mae: 2.9149 - val_loss: 4.8059 - val_mse: 4.8059 - val_mae: 2.1343\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 450us/step - loss: 8.7148 - mse: 8.7148 - mae: 2.7122 - val_loss: 4.1310 - val_mse: 4.1310 - val_mae: 1.9715\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 547us/step - loss: 7.6936 - mse: 7.6936 - mae: 2.5220 - val_loss: 3.5357 - val_mse: 3.5357 - val_mae: 1.8160\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 321us/step - loss: 6.8062 - mse: 6.8062 - mae: 2.3434 - val_loss: 3.0163 - val_mse: 3.0163 - val_mae: 1.6684\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 259us/step - loss: 6.0119 - mse: 6.0119 - mae: 2.1720 - val_loss: 2.5609 - val_mse: 2.5609 - val_mae: 1.5263\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 245us/step - loss: 5.3017 - mse: 5.3017 - mae: 2.0068 - val_loss: 2.1655 - val_mse: 2.1655 - val_mae: 1.3912\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 177us/step - loss: 4.6783 - mse: 4.6783 - mae: 1.8489 - val_loss: 1.8169 - val_mse: 1.8169 - val_mae: 1.2607\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 337us/step - loss: 4.1203 - mse: 4.1203 - mae: 1.6949 - val_loss: 1.5108 - val_mse: 1.5108 - val_mae: 1.1331\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 446us/step - loss: 3.6141 - mse: 3.6141 - mae: 1.5446 - val_loss: 1.2430 - val_mse: 1.2430 - val_mae: 1.0072\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 646us/step - loss: 3.1490 - mse: 3.1490 - mae: 1.4019 - val_loss: 1.0082 - val_mse: 1.0082 - val_mae: 0.8819\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 482us/step - loss: 2.7306 - mse: 2.7306 - mae: 1.2826 - val_loss: 0.8071 - val_mse: 0.8071 - val_mae: 0.7679\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 269us/step - loss: 2.3657 - mse: 2.3657 - mae: 1.1821 - val_loss: 0.6432 - val_mse: 0.6432 - val_mae: 0.6718\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 415us/step - loss: 2.0562 - mse: 2.0562 - mae: 1.0914 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5978\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 367us/step - loss: 1.7985 - mse: 1.7985 - mae: 1.0191 - val_loss: 0.4132 - val_mse: 0.4132 - val_mae: 0.5452\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 445us/step - loss: 1.5922 - mse: 1.5922 - mae: 0.9734 - val_loss: 0.3430 - val_mse: 0.3430 - val_mae: 0.4961\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 445us/step - loss: 1.4378 - mse: 1.4378 - mae: 0.9404 - val_loss: 0.2980 - val_mse: 0.2980 - val_mae: 0.4515\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 330us/step - loss: 1.3292 - mse: 1.3292 - mae: 0.9141 - val_loss: 0.2733 - val_mse: 0.2733 - val_mae: 0.4268\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 672us/step - loss: 1.2582 - mse: 1.2582 - mae: 0.8987 - val_loss: 0.2694 - val_mse: 0.2694 - val_mae: 0.4224\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 303us/step - loss: 1.2215 - mse: 1.2215 - mae: 0.8963 - val_loss: 0.2798 - val_mse: 0.2798 - val_mae: 0.4333\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 250us/step - loss: 1.2074 - mse: 1.2074 - mae: 0.9012 - val_loss: 0.2972 - val_mse: 0.2972 - val_mae: 0.4452\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 448us/step - loss: 1.2056 - mse: 1.2056 - mae: 0.9110 - val_loss: 0.3151 - val_mse: 0.3151 - val_mae: 0.4578\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 224us/step - loss: 1.2087 - mse: 1.2087 - mae: 0.9197 - val_loss: 0.3302 - val_mse: 0.3302 - val_mae: 0.4689\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 436us/step - loss: 1.2111 - mse: 1.2111 - mae: 0.9257 - val_loss: 0.3403 - val_mse: 0.3403 - val_mae: 0.4749\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 431us/step - loss: 1.2113 - mse: 1.2113 - mae: 0.9285 - val_loss: 0.3445 - val_mse: 0.3445 - val_mae: 0.4769\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 552us/step - loss: 1.2081 - mse: 1.2081 - mae: 0.9283 - val_loss: 0.3440 - val_mse: 0.3440 - val_mae: 0.4756\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 256us/step - loss: 1.2023 - mse: 1.2023 - mae: 0.9263 - val_loss: 0.3402 - val_mse: 0.3402 - val_mae: 0.4721\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 488us/step - loss: 1.1949 - mse: 1.1949 - mae: 0.9231 - val_loss: 0.3348 - val_mse: 0.3348 - val_mae: 0.4675\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 451us/step - loss: 1.1869 - mse: 1.1869 - mae: 0.9192 - val_loss: 0.3289 - val_mse: 0.3289 - val_mae: 0.4625\n",
      "20\n",
      "[20]\n",
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 11ms/step - loss: 1.9765 - mse: 1.9765 - mae: 1.0385 - val_loss: 1.0981 - val_mse: 1.0981 - val_mae: 0.9105\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 232us/step - loss: 1.8559 - mse: 1.8559 - mae: 0.9896 - val_loss: 1.1766 - val_mse: 1.1766 - val_mae: 0.9743\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 368us/step - loss: 1.8047 - mse: 1.8047 - mae: 0.9631 - val_loss: 1.2185 - val_mse: 1.2185 - val_mae: 0.9993\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 380us/step - loss: 1.7583 - mse: 1.7583 - mae: 0.9460 - val_loss: 1.2066 - val_mse: 1.2066 - val_mae: 0.9983\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 266us/step - loss: 1.7094 - mse: 1.7094 - mae: 0.9345 - val_loss: 1.1659 - val_mse: 1.1659 - val_mae: 0.9817\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.6659 - mse: 1.6659 - mae: 0.9252 - val_loss: 1.1294 - val_mse: 1.1294 - val_mae: 0.9671\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 276us/step - loss: 1.6314 - mse: 1.6314 - mae: 0.9206 - val_loss: 1.1091 - val_mse: 1.1091 - val_mae: 0.9591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 488us/step - loss: 1.6023 - mse: 1.6023 - mae: 0.9164 - val_loss: 1.1055 - val_mse: 1.1055 - val_mae: 0.9585\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 313us/step - loss: 1.5756 - mse: 1.5756 - mae: 0.9107 - val_loss: 1.1133 - val_mse: 1.1133 - val_mae: 0.9635\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 340us/step - loss: 1.5525 - mse: 1.5525 - mae: 0.9044 - val_loss: 1.1253 - val_mse: 1.1253 - val_mae: 0.9699\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 337us/step - loss: 1.5320 - mse: 1.5320 - mae: 0.8981 - val_loss: 1.1392 - val_mse: 1.1392 - val_mae: 0.9763\n",
      "21\n",
      "[21]\n",
      "Train on 89 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 11.3504 - mse: 11.3504 - mae: 3.2082 - val_loss: 4.4224 - val_mse: 4.4224 - val_mae: 1.9694\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 365us/step - loss: 9.1738 - mse: 9.1738 - mae: 2.8525 - val_loss: 3.5180 - val_mse: 3.5180 - val_mae: 1.7364\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 290us/step - loss: 7.3321 - mse: 7.3321 - mae: 2.5128 - val_loss: 2.7351 - val_mse: 2.7351 - val_mae: 1.5097\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 196us/step - loss: 5.7941 - mse: 5.7941 - mae: 2.1912 - val_loss: 2.0909 - val_mse: 2.0909 - val_mae: 1.2926\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 238us/step - loss: 4.5571 - mse: 4.5571 - mae: 1.8961 - val_loss: 1.5793 - val_mse: 1.5793 - val_mae: 1.0880\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 278us/step - loss: 3.5791 - mse: 3.5791 - mae: 1.6288 - val_loss: 1.1883 - val_mse: 1.1883 - val_mae: 0.9051\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 228us/step - loss: 2.8068 - mse: 2.8068 - mae: 1.3956 - val_loss: 0.8910 - val_mse: 0.8910 - val_mae: 0.7720\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 351us/step - loss: 2.2169 - mse: 2.2169 - mae: 1.2065 - val_loss: 0.6758 - val_mse: 0.6758 - val_mae: 0.6577\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 377us/step - loss: 1.7853 - mse: 1.7853 - mae: 1.0478 - val_loss: 0.5268 - val_mse: 0.5268 - val_mae: 0.5537\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 261us/step - loss: 1.4832 - mse: 1.4832 - mae: 0.9307 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4661\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 386us/step - loss: 1.2801 - mse: 1.2801 - mae: 0.8456 - val_loss: 0.3719 - val_mse: 0.3719 - val_mae: 0.4070\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 564us/step - loss: 1.1537 - mse: 1.1537 - mae: 0.8077 - val_loss: 0.3453 - val_mse: 0.3453 - val_mae: 0.3778\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 428us/step - loss: 1.0881 - mse: 1.0881 - mae: 0.7878 - val_loss: 0.3406 - val_mse: 0.3406 - val_mae: 0.3694\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 269us/step - loss: 1.0617 - mse: 1.0617 - mae: 0.7830 - val_loss: 0.3479 - val_mse: 0.3479 - val_mae: 0.3945\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 346us/step - loss: 1.0562 - mse: 1.0562 - mae: 0.7915 - val_loss: 0.3592 - val_mse: 0.3592 - val_mae: 0.4222\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 340us/step - loss: 1.0599 - mse: 1.0599 - mae: 0.8072 - val_loss: 0.3681 - val_mse: 0.3681 - val_mae: 0.4398\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 362us/step - loss: 1.0637 - mse: 1.0637 - mae: 0.8185 - val_loss: 0.3722 - val_mse: 0.3722 - val_mae: 0.4479\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 314us/step - loss: 1.0634 - mse: 1.0634 - mae: 0.8234 - val_loss: 0.3713 - val_mse: 0.3713 - val_mae: 0.4491\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 419us/step - loss: 1.0578 - mse: 1.0578 - mae: 0.8219 - val_loss: 0.3657 - val_mse: 0.3657 - val_mae: 0.4444\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 224us/step - loss: 1.0485 - mse: 1.0485 - mae: 0.8159 - val_loss: 0.3570 - val_mse: 0.3570 - val_mae: 0.4359\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 402us/step - loss: 1.0372 - mse: 1.0372 - mae: 0.8070 - val_loss: 0.3469 - val_mse: 0.3469 - val_mae: 0.4250\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 376us/step - loss: 1.0259 - mse: 1.0259 - mae: 0.7976 - val_loss: 0.3366 - val_mse: 0.3366 - val_mae: 0.4130\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 285us/step - loss: 1.0162 - mse: 1.0162 - mae: 0.7888 - val_loss: 0.3274 - val_mse: 0.3274 - val_mae: 0.4011\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 275us/step - loss: 1.0081 - mse: 1.0081 - mae: 0.7814 - val_loss: 0.3194 - val_mse: 0.3194 - val_mae: 0.3903\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 260us/step - loss: 1.0025 - mse: 1.0025 - mae: 0.7780 - val_loss: 0.3131 - val_mse: 0.3131 - val_mae: 0.3814\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 341us/step - loss: 0.9984 - mse: 0.9984 - mae: 0.7753 - val_loss: 0.3081 - val_mse: 0.3081 - val_mae: 0.3744\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.9098 - mse: 0.9098 - mae: 0.787 - 0s 405us/step - loss: 0.9951 - mse: 0.9951 - mae: 0.7730 - val_loss: 0.3043 - val_mse: 0.3043 - val_mae: 0.3695\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 345us/step - loss: 0.9919 - mse: 0.9919 - mae: 0.7711 - val_loss: 0.3017 - val_mse: 0.3017 - val_mae: 0.3666\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 393us/step - loss: 0.9886 - mse: 0.9886 - mae: 0.7695 - val_loss: 0.2998 - val_mse: 0.2998 - val_mae: 0.3654\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 569us/step - loss: 0.9852 - mse: 0.9852 - mae: 0.7683 - val_loss: 0.2987 - val_mse: 0.2987 - val_mae: 0.3657\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 349us/step - loss: 0.9815 - mse: 0.9815 - mae: 0.7675 - val_loss: 0.2982 - val_mse: 0.2982 - val_mae: 0.3670\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 432us/step - loss: 0.9781 - mse: 0.9781 - mae: 0.7669 - val_loss: 0.2979 - val_mse: 0.2979 - val_mae: 0.3686\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 322us/step - loss: 0.9745 - mse: 0.9745 - mae: 0.7664 - val_loss: 0.2974 - val_mse: 0.2974 - val_mae: 0.3701\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 408us/step - loss: 0.9708 - mse: 0.9708 - mae: 0.7660 - val_loss: 0.2969 - val_mse: 0.2969 - val_mae: 0.3712\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 284us/step - loss: 0.9673 - mse: 0.9673 - mae: 0.7658 - val_loss: 0.2963 - val_mse: 0.2963 - val_mae: 0.3720\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 318us/step - loss: 0.9642 - mse: 0.9642 - mae: 0.7656 - val_loss: 0.2959 - val_mse: 0.2959 - val_mae: 0.3730\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 281us/step - loss: 0.9614 - mse: 0.9614 - mae: 0.7654 - val_loss: 0.2959 - val_mse: 0.2959 - val_mae: 0.3742\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 470us/step - loss: 0.9587 - mse: 0.9587 - mae: 0.7650 - val_loss: 0.2956 - val_mse: 0.2956 - val_mae: 0.3752\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 290us/step - loss: 0.9558 - mse: 0.9558 - mae: 0.7645 - val_loss: 0.2952 - val_mse: 0.2952 - val_mae: 0.3760\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 290us/step - loss: 0.9529 - mse: 0.9529 - mae: 0.7638 - val_loss: 0.2944 - val_mse: 0.2944 - val_mae: 0.3761\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 287us/step - loss: 0.9500 - mse: 0.9500 - mae: 0.7629 - val_loss: 0.2934 - val_mse: 0.2934 - val_mae: 0.3760\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 344us/step - loss: 0.9470 - mse: 0.9470 - mae: 0.7619 - val_loss: 0.2926 - val_mse: 0.2926 - val_mae: 0.3763\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 337us/step - loss: 0.9441 - mse: 0.9441 - mae: 0.7608 - val_loss: 0.2919 - val_mse: 0.2919 - val_mae: 0.3768\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 266us/step - loss: 0.9412 - mse: 0.9412 - mae: 0.7598 - val_loss: 0.2913 - val_mse: 0.2913 - val_mae: 0.3772\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 414us/step - loss: 0.9383 - mse: 0.9383 - mae: 0.7586 - val_loss: 0.2906 - val_mse: 0.2906 - val_mae: 0.3775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 391us/step - loss: 0.9355 - mse: 0.9355 - mae: 0.7574 - val_loss: 0.2901 - val_mse: 0.2901 - val_mae: 0.3779\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 292us/step - loss: 0.9327 - mse: 0.9327 - mae: 0.7564 - val_loss: 0.2896 - val_mse: 0.2896 - val_mae: 0.3785\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 336us/step - loss: 0.9299 - mse: 0.9299 - mae: 0.7554 - val_loss: 0.2892 - val_mse: 0.2892 - val_mae: 0.3792\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 487us/step - loss: 0.9272 - mse: 0.9272 - mae: 0.7544 - val_loss: 0.2887 - val_mse: 0.2887 - val_mae: 0.3799\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 362us/step - loss: 0.9246 - mse: 0.9246 - mae: 0.7537 - val_loss: 0.2883 - val_mse: 0.2883 - val_mae: 0.3809\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 244us/step - loss: 0.9220 - mse: 0.9220 - mae: 0.7529 - val_loss: 0.2881 - val_mse: 0.2881 - val_mae: 0.3820\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 328us/step - loss: 0.9195 - mse: 0.9195 - mae: 0.7522 - val_loss: 0.2878 - val_mse: 0.2878 - val_mae: 0.3829\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 344us/step - loss: 0.9171 - mse: 0.9171 - mae: 0.7513 - val_loss: 0.2871 - val_mse: 0.2871 - val_mae: 0.3835\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 288us/step - loss: 0.9148 - mse: 0.9148 - mae: 0.7503 - val_loss: 0.2866 - val_mse: 0.2866 - val_mae: 0.3840\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 268us/step - loss: 0.9123 - mse: 0.9123 - mae: 0.7493 - val_loss: 0.2860 - val_mse: 0.2860 - val_mae: 0.3845\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 239us/step - loss: 0.9099 - mse: 0.9099 - mae: 0.7483 - val_loss: 0.2855 - val_mse: 0.2855 - val_mae: 0.3849\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 313us/step - loss: 0.9075 - mse: 0.9075 - mae: 0.7474 - val_loss: 0.2851 - val_mse: 0.2851 - val_mae: 0.3856\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 264us/step - loss: 0.9051 - mse: 0.9051 - mae: 0.7465 - val_loss: 0.2849 - val_mse: 0.2849 - val_mae: 0.3864\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 253us/step - loss: 0.9028 - mse: 0.9028 - mae: 0.7457 - val_loss: 0.2847 - val_mse: 0.2847 - val_mae: 0.3873\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 310us/step - loss: 0.9005 - mse: 0.9005 - mae: 0.7449 - val_loss: 0.2845 - val_mse: 0.2845 - val_mae: 0.3880\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 0s 239us/step - loss: 0.8981 - mse: 0.8981 - mae: 0.7441 - val_loss: 0.2842 - val_mse: 0.2842 - val_mae: 0.3885\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 445us/step - loss: 0.8958 - mse: 0.8958 - mae: 0.7432 - val_loss: 0.2839 - val_mse: 0.2839 - val_mae: 0.3892\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 606us/step - loss: 0.8936 - mse: 0.8936 - mae: 0.7423 - val_loss: 0.2838 - val_mse: 0.2838 - val_mae: 0.3902\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 0s 285us/step - loss: 0.8913 - mse: 0.8913 - mae: 0.7414 - val_loss: 0.2839 - val_mse: 0.2839 - val_mae: 0.3915\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 348us/step - loss: 0.8890 - mse: 0.8890 - mae: 0.7407 - val_loss: 0.2840 - val_mse: 0.2840 - val_mae: 0.3925\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 288us/step - loss: 0.8866 - mse: 0.8866 - mae: 0.7399 - val_loss: 0.2841 - val_mse: 0.2841 - val_mae: 0.3932\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 230us/step - loss: 0.8844 - mse: 0.8844 - mae: 0.7391 - val_loss: 0.2842 - val_mse: 0.2842 - val_mae: 0.3941\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 404us/step - loss: 0.8819 - mse: 0.8819 - mae: 0.7381 - val_loss: 0.2840 - val_mse: 0.2840 - val_mae: 0.3945\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 0s 310us/step - loss: 0.8797 - mse: 0.8797 - mae: 0.7373 - val_loss: 0.2836 - val_mse: 0.2836 - val_mae: 0.3948\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 346us/step - loss: 0.8775 - mse: 0.8775 - mae: 0.7363 - val_loss: 0.2834 - val_mse: 0.2834 - val_mae: 0.3956\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 200us/step - loss: 0.8752 - mse: 0.8752 - mae: 0.7354 - val_loss: 0.2833 - val_mse: 0.2833 - val_mae: 0.3961\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 0.8729 - mse: 0.8729 - mae: 0.7344 - val_loss: 0.2831 - val_mse: 0.2831 - val_mae: 0.3965\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 0s 497us/step - loss: 0.8707 - mse: 0.8707 - mae: 0.7335 - val_loss: 0.2831 - val_mse: 0.2831 - val_mae: 0.3975\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 201us/step - loss: 0.8683 - mse: 0.8683 - mae: 0.7326 - val_loss: 0.2829 - val_mse: 0.2829 - val_mae: 0.3983\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 213us/step - loss: 0.8660 - mse: 0.8660 - mae: 0.7318 - val_loss: 0.2831 - val_mse: 0.2831 - val_mae: 0.3992\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 264us/step - loss: 0.8639 - mse: 0.8639 - mae: 0.7311 - val_loss: 0.2833 - val_mse: 0.2833 - val_mae: 0.3999\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 0s 257us/step - loss: 0.8617 - mse: 0.8617 - mae: 0.7303 - val_loss: 0.2834 - val_mse: 0.2834 - val_mae: 0.4006\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 438us/step - loss: 0.8594 - mse: 0.8594 - mae: 0.7294 - val_loss: 0.2835 - val_mse: 0.2835 - val_mae: 0.4012\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 528us/step - loss: 0.8573 - mse: 0.8573 - mae: 0.7286 - val_loss: 0.2836 - val_mse: 0.2836 - val_mae: 0.4018\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 233us/step - loss: 0.8551 - mse: 0.8551 - mae: 0.7278 - val_loss: 0.2836 - val_mse: 0.2836 - val_mae: 0.4026\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 415us/step - loss: 0.8530 - mse: 0.8530 - mae: 0.7271 - val_loss: 0.2841 - val_mse: 0.2841 - val_mae: 0.4038\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 213us/step - loss: 0.8509 - mse: 0.8509 - mae: 0.7263 - val_loss: 0.2848 - val_mse: 0.2848 - val_mae: 0.4052\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 312us/step - loss: 0.8488 - mse: 0.8488 - mae: 0.7254 - val_loss: 0.2853 - val_mse: 0.2853 - val_mae: 0.4060\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 301us/step - loss: 0.8466 - mse: 0.8466 - mae: 0.7244 - val_loss: 0.2857 - val_mse: 0.2857 - val_mae: 0.4067\n",
      "22\n",
      "[22]\n",
      "Train on 112 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 3.0433 - mse: 3.0433 - mae: 1.3096 - val_loss: 4.0954 - val_mse: 4.0954 - val_mae: 1.7716\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 194us/step - loss: 2.7646 - mse: 2.7646 - mae: 1.2365 - val_loss: 3.4835 - val_mse: 3.4835 - val_mae: 1.6391\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 225us/step - loss: 2.5702 - mse: 2.5702 - mae: 1.1939 - val_loss: 3.0536 - val_mse: 3.0536 - val_mae: 1.5203\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 303us/step - loss: 2.4569 - mse: 2.4569 - mae: 1.1751 - val_loss: 2.7675 - val_mse: 2.7675 - val_mae: 1.4324\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 196us/step - loss: 2.3972 - mse: 2.3972 - mae: 1.1763 - val_loss: 2.5984 - val_mse: 2.5984 - val_mae: 1.3802\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 323us/step - loss: 2.3608 - mse: 2.3608 - mae: 1.1786 - val_loss: 2.5177 - val_mse: 2.5177 - val_mae: 1.3587\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 227us/step - loss: 2.3267 - mse: 2.3267 - mae: 1.1760 - val_loss: 2.4882 - val_mse: 2.4882 - val_mae: 1.3558\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 296us/step - loss: 2.2888 - mse: 2.2888 - mae: 1.1692 - val_loss: 2.4919 - val_mse: 2.4919 - val_mae: 1.3640\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 280us/step - loss: 2.2514 - mse: 2.2514 - mae: 1.1609 - val_loss: 2.5072 - val_mse: 2.5072 - val_mae: 1.3736\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 196us/step - loss: 2.2205 - mse: 2.2205 - mae: 1.1528 - val_loss: 2.5278 - val_mse: 2.5278 - val_mae: 1.3839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 261us/step - loss: 2.1965 - mse: 2.1965 - mae: 1.1462 - val_loss: 2.5400 - val_mse: 2.5400 - val_mae: 1.3905\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 234us/step - loss: 2.1759 - mse: 2.1759 - mae: 1.1410 - val_loss: 2.5325 - val_mse: 2.5325 - val_mae: 1.3907\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 247us/step - loss: 2.1568 - mse: 2.1568 - mae: 1.1373 - val_loss: 2.5136 - val_mse: 2.5136 - val_mae: 1.3865\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 248us/step - loss: 2.1386 - mse: 2.1386 - mae: 1.1343 - val_loss: 2.4904 - val_mse: 2.4904 - val_mae: 1.3803\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 277us/step - loss: 2.1207 - mse: 2.1207 - mae: 1.1316 - val_loss: 2.4659 - val_mse: 2.4659 - val_mae: 1.3732\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 261us/step - loss: 2.1045 - mse: 2.1045 - mae: 1.1293 - val_loss: 2.4437 - val_mse: 2.4437 - val_mae: 1.3668\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 222us/step - loss: 2.0902 - mse: 2.0902 - mae: 1.1275 - val_loss: 2.4274 - val_mse: 2.4274 - val_mae: 1.3624\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 201us/step - loss: 2.0771 - mse: 2.0771 - mae: 1.1253 - val_loss: 2.4193 - val_mse: 2.4193 - val_mae: 1.3604\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 222us/step - loss: 2.0645 - mse: 2.0645 - mae: 1.1224 - val_loss: 2.4205 - val_mse: 2.4205 - val_mae: 1.3612\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 520us/step - loss: 2.0522 - mse: 2.0522 - mae: 1.1190 - val_loss: 2.4257 - val_mse: 2.4257 - val_mae: 1.3632\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 243us/step - loss: 2.0405 - mse: 2.0405 - mae: 1.1156 - val_loss: 2.4326 - val_mse: 2.4326 - val_mae: 1.3661\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 328us/step - loss: 2.0299 - mse: 2.0299 - mae: 1.1123 - val_loss: 2.4355 - val_mse: 2.4355 - val_mae: 1.3679\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 280us/step - loss: 2.0196 - mse: 2.0196 - mae: 1.1095 - val_loss: 2.4363 - val_mse: 2.4363 - val_mae: 1.3689\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 181us/step - loss: 2.0094 - mse: 2.0094 - mae: 1.1070 - val_loss: 2.4360 - val_mse: 2.4360 - val_mae: 1.3689\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 264us/step - loss: 1.9993 - mse: 1.9993 - mae: 1.1045 - val_loss: 2.4324 - val_mse: 2.4324 - val_mae: 1.3680\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 279us/step - loss: 1.9896 - mse: 1.9896 - mae: 1.1024 - val_loss: 2.4286 - val_mse: 2.4286 - val_mae: 1.3671\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 287us/step - loss: 1.9802 - mse: 1.9802 - mae: 1.1004 - val_loss: 2.4288 - val_mse: 2.4288 - val_mae: 1.3674\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 220us/step - loss: 1.9706 - mse: 1.9706 - mae: 1.0978 - val_loss: 2.4344 - val_mse: 2.4344 - val_mae: 1.3696\n",
      "23\n",
      "[23]\n",
      "Train on 92 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 13.6083 - mse: 13.6083 - mae: 3.3457 - val_loss: 8.4260 - val_mse: 8.4260 - val_mae: 2.7260\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 0s 388us/step - loss: 10.4852 - mse: 10.4852 - mae: 2.8505 - val_loss: 6.2902 - val_mse: 6.2902 - val_mae: 2.3040\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 0s 292us/step - loss: 8.0689 - mse: 8.0689 - mae: 2.4038 - val_loss: 4.6040 - val_mse: 4.6040 - val_mae: 1.9100\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 0s 362us/step - loss: 6.2146 - mse: 6.2146 - mae: 2.0187 - val_loss: 3.3227 - val_mse: 3.3227 - val_mae: 1.5509\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 0s 480us/step - loss: 4.8219 - mse: 4.8219 - mae: 1.7018 - val_loss: 2.3996 - val_mse: 2.3996 - val_mae: 1.2520\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 0s 272us/step - loss: 3.7913 - mse: 3.7913 - mae: 1.4727 - val_loss: 1.7719 - val_mse: 1.7719 - val_mae: 1.0332\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 0s 284us/step - loss: 3.0490 - mse: 3.0490 - mae: 1.3210 - val_loss: 1.3504 - val_mse: 1.3504 - val_mae: 0.8715\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 0s 321us/step - loss: 2.5314 - mse: 2.5314 - mae: 1.2209 - val_loss: 1.0786 - val_mse: 1.0786 - val_mae: 0.7702\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 0s 304us/step - loss: 2.1957 - mse: 2.1957 - mae: 1.1615 - val_loss: 0.9106 - val_mse: 0.9106 - val_mae: 0.7079\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 0s 278us/step - loss: 1.9900 - mse: 1.9900 - mae: 1.1233 - val_loss: 0.8103 - val_mse: 0.8103 - val_mae: 0.6756\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 0s 397us/step - loss: 1.8657 - mse: 1.8657 - mae: 1.1005 - val_loss: 0.7518 - val_mse: 0.7518 - val_mae: 0.6568\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 0s 381us/step - loss: 1.7903 - mse: 1.7903 - mae: 1.0841 - val_loss: 0.7268 - val_mse: 0.7268 - val_mae: 0.6446\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 0s 442us/step - loss: 1.7473 - mse: 1.7473 - mae: 1.0773 - val_loss: 0.7223 - val_mse: 0.7223 - val_mae: 0.6410\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 0s 335us/step - loss: 1.7250 - mse: 1.7250 - mae: 1.0756 - val_loss: 0.7201 - val_mse: 0.7201 - val_mae: 0.6381\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 0s 319us/step - loss: 1.7058 - mse: 1.7058 - mae: 1.0732 - val_loss: 0.7159 - val_mse: 0.7159 - val_mae: 0.6370\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 0s 358us/step - loss: 1.6884 - mse: 1.6884 - mae: 1.0674 - val_loss: 0.7091 - val_mse: 0.7091 - val_mae: 0.6333\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 0s 361us/step - loss: 1.6721 - mse: 1.6721 - mae: 1.0603 - val_loss: 0.7028 - val_mse: 0.7028 - val_mae: 0.6288\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 0s 247us/step - loss: 1.6577 - mse: 1.6577 - mae: 1.0536 - val_loss: 0.6977 - val_mse: 0.6977 - val_mae: 0.6260\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 0s 212us/step - loss: 1.6451 - mse: 1.6451 - mae: 1.0470 - val_loss: 0.6938 - val_mse: 0.6938 - val_mae: 0.6252\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 0s 388us/step - loss: 1.6341 - mse: 1.6341 - mae: 1.0406 - val_loss: 0.6907 - val_mse: 0.6907 - val_mae: 0.6242\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 0s 513us/step - loss: 1.6242 - mse: 1.6242 - mae: 1.0348 - val_loss: 0.6881 - val_mse: 0.6881 - val_mae: 0.6229\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 0s 519us/step - loss: 1.6162 - mse: 1.6162 - mae: 1.0302 - val_loss: 0.6856 - val_mse: 0.6856 - val_mae: 0.6213\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 0s 503us/step - loss: 1.6080 - mse: 1.6080 - mae: 1.0262 - val_loss: 0.6830 - val_mse: 0.6830 - val_mae: 0.6193\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 0s 345us/step - loss: 1.5994 - mse: 1.5994 - mae: 1.0228 - val_loss: 0.6803 - val_mse: 0.6803 - val_mae: 0.6172\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 0s 276us/step - loss: 1.5906 - mse: 1.5906 - mae: 1.0198 - val_loss: 0.6778 - val_mse: 0.6778 - val_mae: 0.6149\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 0s 396us/step - loss: 1.5818 - mse: 1.5818 - mae: 1.0170 - val_loss: 0.6754 - val_mse: 0.6754 - val_mae: 0.6125\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 0s 419us/step - loss: 1.5732 - mse: 1.5732 - mae: 1.0144 - val_loss: 0.6732 - val_mse: 0.6732 - val_mae: 0.6102\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 0s 388us/step - loss: 1.5647 - mse: 1.5647 - mae: 1.0117 - val_loss: 0.6711 - val_mse: 0.6711 - val_mae: 0.6080\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 0s 381us/step - loss: 1.5567 - mse: 1.5567 - mae: 1.0091 - val_loss: 0.6692 - val_mse: 0.6692 - val_mae: 0.6059\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 0s 475us/step - loss: 1.5488 - mse: 1.5488 - mae: 1.0065 - val_loss: 0.6673 - val_mse: 0.6673 - val_mae: 0.6040\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 0s 393us/step - loss: 1.5412 - mse: 1.5412 - mae: 1.0039 - val_loss: 0.6657 - val_mse: 0.6657 - val_mae: 0.6022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "92/92 [==============================] - 0s 412us/step - loss: 1.5340 - mse: 1.5340 - mae: 1.0013 - val_loss: 0.6642 - val_mse: 0.6642 - val_mae: 0.6006\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 0s 387us/step - loss: 1.5270 - mse: 1.5270 - mae: 0.9986 - val_loss: 0.6628 - val_mse: 0.6628 - val_mae: 0.5989\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 0s 460us/step - loss: 1.5202 - mse: 1.5202 - mae: 0.9958 - val_loss: 0.6615 - val_mse: 0.6615 - val_mae: 0.5973\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 0s 377us/step - loss: 1.5137 - mse: 1.5137 - mae: 0.9931 - val_loss: 0.6603 - val_mse: 0.6603 - val_mae: 0.5956\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 0s 289us/step - loss: 1.5072 - mse: 1.5072 - mae: 0.9904 - val_loss: 0.6594 - val_mse: 0.6594 - val_mae: 0.5941\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 0s 390us/step - loss: 1.5007 - mse: 1.5007 - mae: 0.9879 - val_loss: 0.6585 - val_mse: 0.6585 - val_mae: 0.5930\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 0s 387us/step - loss: 1.4942 - mse: 1.4942 - mae: 0.9856 - val_loss: 0.6577 - val_mse: 0.6577 - val_mae: 0.5918\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 0s 368us/step - loss: 1.4878 - mse: 1.4878 - mae: 0.9833 - val_loss: 0.6569 - val_mse: 0.6569 - val_mae: 0.5907\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 0s 477us/step - loss: 1.4815 - mse: 1.4815 - mae: 0.9810 - val_loss: 0.6562 - val_mse: 0.6562 - val_mae: 0.5897\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 0s 357us/step - loss: 1.4754 - mse: 1.4754 - mae: 0.9787 - val_loss: 0.6556 - val_mse: 0.6556 - val_mae: 0.5888\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 0s 404us/step - loss: 1.4694 - mse: 1.4694 - mae: 0.9763 - val_loss: 0.6551 - val_mse: 0.6551 - val_mae: 0.5879\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 0s 348us/step - loss: 1.4636 - mse: 1.4636 - mae: 0.9740 - val_loss: 0.6547 - val_mse: 0.6547 - val_mae: 0.5870\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 0s 403us/step - loss: 1.4579 - mse: 1.4579 - mae: 0.9719 - val_loss: 0.6543 - val_mse: 0.6543 - val_mae: 0.5861\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 0s 325us/step - loss: 1.4523 - mse: 1.4523 - mae: 0.9698 - val_loss: 0.6541 - val_mse: 0.6541 - val_mae: 0.5852\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 0s 317us/step - loss: 1.4468 - mse: 1.4468 - mae: 0.9678 - val_loss: 0.6538 - val_mse: 0.6538 - val_mae: 0.5843\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 0s 500us/step - loss: 1.4413 - mse: 1.4413 - mae: 0.9658 - val_loss: 0.6536 - val_mse: 0.6536 - val_mae: 0.5833\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 0s 290us/step - loss: 1.4357 - mse: 1.4357 - mae: 0.9638 - val_loss: 0.6537 - val_mse: 0.6537 - val_mae: 0.5823\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 0s 683us/step - loss: 1.4301 - mse: 1.4301 - mae: 0.9617 - val_loss: 0.6538 - val_mse: 0.6538 - val_mae: 0.5812\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 0s 347us/step - loss: 1.4244 - mse: 1.4244 - mae: 0.9593 - val_loss: 0.6539 - val_mse: 0.6539 - val_mae: 0.5800\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 0s 437us/step - loss: 1.4191 - mse: 1.4191 - mae: 0.9570 - val_loss: 0.6535 - val_mse: 0.6535 - val_mae: 0.5786\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 0s 438us/step - loss: 1.4139 - mse: 1.4139 - mae: 0.9547 - val_loss: 0.6532 - val_mse: 0.6532 - val_mae: 0.5773\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 0s 444us/step - loss: 1.4090 - mse: 1.4090 - mae: 0.9524 - val_loss: 0.6529 - val_mse: 0.6529 - val_mae: 0.5761\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 0s 450us/step - loss: 1.4044 - mse: 1.4044 - mae: 0.9502 - val_loss: 0.6526 - val_mse: 0.6526 - val_mae: 0.5753\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 0s 418us/step - loss: 1.4001 - mse: 1.4001 - mae: 0.9481 - val_loss: 0.6524 - val_mse: 0.6524 - val_mae: 0.5745\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 0s 429us/step - loss: 1.3956 - mse: 1.3956 - mae: 0.9461 - val_loss: 0.6523 - val_mse: 0.6523 - val_mae: 0.5738\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 0s 488us/step - loss: 1.3913 - mse: 1.3913 - mae: 0.9441 - val_loss: 0.6523 - val_mse: 0.6523 - val_mae: 0.5728\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 0s 497us/step - loss: 1.3870 - mse: 1.3870 - mae: 0.9423 - val_loss: 0.6521 - val_mse: 0.6521 - val_mae: 0.5716\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 0s 268us/step - loss: 1.3826 - mse: 1.3826 - mae: 0.9406 - val_loss: 0.6519 - val_mse: 0.6519 - val_mae: 0.5707\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 0s 380us/step - loss: 1.3783 - mse: 1.3783 - mae: 0.9388 - val_loss: 0.6519 - val_mse: 0.6519 - val_mae: 0.5709\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 0s 390us/step - loss: 1.3740 - mse: 1.3740 - mae: 0.9368 - val_loss: 0.6520 - val_mse: 0.6520 - val_mae: 0.5714\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 0s 317us/step - loss: 1.3699 - mse: 1.3699 - mae: 0.9348 - val_loss: 0.6522 - val_mse: 0.6522 - val_mae: 0.5716\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 0s 470us/step - loss: 1.3658 - mse: 1.3658 - mae: 0.9330 - val_loss: 0.6526 - val_mse: 0.6526 - val_mae: 0.5715\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 0s 443us/step - loss: 1.3617 - mse: 1.3617 - mae: 0.9312 - val_loss: 0.6531 - val_mse: 0.6531 - val_mae: 0.5717\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 0s 389us/step - loss: 1.3579 - mse: 1.3579 - mae: 0.9291 - val_loss: 0.6533 - val_mse: 0.6533 - val_mae: 0.5723\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 0s 354us/step - loss: 1.3545 - mse: 1.3545 - mae: 0.9271 - val_loss: 0.6533 - val_mse: 0.6533 - val_mae: 0.5729\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 0s 384us/step - loss: 1.3511 - mse: 1.3511 - mae: 0.9253 - val_loss: 0.6532 - val_mse: 0.6532 - val_mae: 0.5733\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 0s 624us/step - loss: 1.3476 - mse: 1.3476 - mae: 0.9237 - val_loss: 0.6532 - val_mse: 0.6532 - val_mae: 0.5735\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 0s 387us/step - loss: 1.3442 - mse: 1.3442 - mae: 0.9221 - val_loss: 0.6535 - val_mse: 0.6535 - val_mae: 0.5739\n",
      "24\n",
      "[24]\n",
      "Train on 97 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 16.9974 - mse: 16.9974 - mae: 3.8482 - val_loss: 19.8809 - val_mse: 19.8809 - val_mae: 4.3524\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 323us/step - loss: 14.5817 - mse: 14.5817 - mae: 3.5331 - val_loss: 16.9501 - val_mse: 16.9501 - val_mae: 4.0141\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 302us/step - loss: 12.5419 - mse: 12.5419 - mae: 3.2433 - val_loss: 14.3405 - val_mse: 14.3405 - val_mae: 3.6871\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 259us/step - loss: 10.7631 - mse: 10.7631 - mae: 2.9686 - val_loss: 12.1102 - val_mse: 12.1102 - val_mae: 3.3813\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 289us/step - loss: 9.2537 - mse: 9.2537 - mae: 2.7165 - val_loss: 10.2932 - val_mse: 10.2932 - val_mae: 3.1109\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 376us/step - loss: 8.0214 - mse: 8.0214 - mae: 2.4980 - val_loss: 8.9064 - val_mse: 8.9064 - val_mae: 2.8851\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 427us/step - loss: 7.0297 - mse: 7.0297 - mae: 2.3080 - val_loss: 7.7948 - val_mse: 7.7948 - val_mae: 2.6898\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 297us/step - loss: 6.2298 - mse: 6.2298 - mae: 2.1441 - val_loss: 6.9309 - val_mse: 6.9309 - val_mae: 2.5285\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 311us/step - loss: 5.5933 - mse: 5.5933 - mae: 2.0051 - val_loss: 6.2546 - val_mse: 6.2546 - val_mae: 2.3934\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 438us/step - loss: 5.0841 - mse: 5.0841 - mae: 1.8877 - val_loss: 5.7235 - val_mse: 5.7235 - val_mae: 2.2808\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 360us/step - loss: 4.6671 - mse: 4.6671 - mae: 1.7848 - val_loss: 5.2833 - val_mse: 5.2833 - val_mae: 2.1834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 458us/step - loss: 4.3211 - mse: 4.3211 - mae: 1.6923 - val_loss: 4.9026 - val_mse: 4.9026 - val_mae: 2.0963\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 462us/step - loss: 4.0268 - mse: 4.0268 - mae: 1.6076 - val_loss: 4.5564 - val_mse: 4.5564 - val_mae: 2.0142\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 284us/step - loss: 3.7653 - mse: 3.7653 - mae: 1.5285 - val_loss: 4.2525 - val_mse: 4.2525 - val_mae: 1.9381\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 429us/step - loss: 3.5337 - mse: 3.5337 - mae: 1.4560 - val_loss: 3.9728 - val_mse: 3.9728 - val_mae: 1.8661\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 456us/step - loss: 3.3262 - mse: 3.3262 - mae: 1.3907 - val_loss: 3.7133 - val_mse: 3.7133 - val_mae: 1.7979\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 401us/step - loss: 3.1372 - mse: 3.1372 - mae: 1.3283 - val_loss: 3.4658 - val_mse: 3.4658 - val_mae: 1.7298\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 459us/step - loss: 2.9621 - mse: 2.9621 - mae: 1.2675 - val_loss: 3.2276 - val_mse: 3.2276 - val_mae: 1.6620\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 258us/step - loss: 2.7957 - mse: 2.7957 - mae: 1.2062 - val_loss: 2.9947 - val_mse: 2.9947 - val_mae: 1.5924\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 263us/step - loss: 2.6367 - mse: 2.6367 - mae: 1.1450 - val_loss: 2.7687 - val_mse: 2.7687 - val_mae: 1.5217\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 248us/step - loss: 2.4860 - mse: 2.4860 - mae: 1.0859 - val_loss: 2.5466 - val_mse: 2.5466 - val_mae: 1.4487\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 381us/step - loss: 2.3418 - mse: 2.3418 - mae: 1.0345 - val_loss: 2.3265 - val_mse: 2.3265 - val_mae: 1.3780\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 524us/step - loss: 2.2048 - mse: 2.2048 - mae: 0.9940 - val_loss: 2.1129 - val_mse: 2.1129 - val_mae: 1.3105\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 286us/step - loss: 2.0744 - mse: 2.0744 - mae: 0.9612 - val_loss: 1.9091 - val_mse: 1.9091 - val_mae: 1.2462\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 451us/step - loss: 1.9547 - mse: 1.9547 - mae: 0.9347 - val_loss: 1.7163 - val_mse: 1.7163 - val_mae: 1.1818\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 410us/step - loss: 1.8462 - mse: 1.8462 - mae: 0.9124 - val_loss: 1.5372 - val_mse: 1.5372 - val_mae: 1.1173\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 230us/step - loss: 1.7500 - mse: 1.7500 - mae: 0.8960 - val_loss: 1.3725 - val_mse: 1.3725 - val_mae: 1.0531\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 366us/step - loss: 1.6658 - mse: 1.6658 - mae: 0.8843 - val_loss: 1.2245 - val_mse: 1.2245 - val_mae: 0.9902\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 617us/step - loss: 1.5951 - mse: 1.5951 - mae: 0.8746 - val_loss: 1.0939 - val_mse: 1.0939 - val_mae: 0.9297\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 356us/step - loss: 1.5362 - mse: 1.5362 - mae: 0.8666 - val_loss: 0.9810 - val_mse: 0.9810 - val_mae: 0.8727\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 398us/step - loss: 1.4890 - mse: 1.4890 - mae: 0.8607 - val_loss: 0.8883 - val_mse: 0.8883 - val_mae: 0.8209\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 596us/step - loss: 1.4526 - mse: 1.4526 - mae: 0.8581 - val_loss: 0.8119 - val_mse: 0.8119 - val_mae: 0.7740\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 323us/step - loss: 1.4268 - mse: 1.4268 - mae: 0.8589 - val_loss: 0.7508 - val_mse: 0.7508 - val_mae: 0.7330\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 657us/step - loss: 1.4081 - mse: 1.4081 - mae: 0.8625 - val_loss: 0.7031 - val_mse: 0.7031 - val_mae: 0.6980\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 741us/step - loss: 1.3946 - mse: 1.3946 - mae: 0.8678 - val_loss: 0.6667 - val_mse: 0.6667 - val_mae: 0.6693\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 229us/step - loss: 1.3847 - mse: 1.3847 - mae: 0.8724 - val_loss: 0.6398 - val_mse: 0.6398 - val_mae: 0.6465\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 367us/step - loss: 1.3772 - mse: 1.3772 - mae: 0.8758 - val_loss: 0.6205 - val_mse: 0.6205 - val_mae: 0.6293\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 372us/step - loss: 1.3715 - mse: 1.3715 - mae: 0.8780 - val_loss: 0.6074 - val_mse: 0.6074 - val_mae: 0.6172\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 285us/step - loss: 1.3664 - mse: 1.3664 - mae: 0.8789 - val_loss: 0.5993 - val_mse: 0.5993 - val_mae: 0.6096\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 470us/step - loss: 1.3620 - mse: 1.3620 - mae: 0.8790 - val_loss: 0.5946 - val_mse: 0.5946 - val_mae: 0.6054\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 363us/step - loss: 1.3579 - mse: 1.3579 - mae: 0.8785 - val_loss: 0.5924 - val_mse: 0.5924 - val_mae: 0.6034\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 433us/step - loss: 1.3539 - mse: 1.3539 - mae: 0.8776 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.6032\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 421us/step - loss: 1.3499 - mse: 1.3499 - mae: 0.8762 - val_loss: 0.5925 - val_mse: 0.5925 - val_mae: 0.6040\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 794us/step - loss: 1.3461 - mse: 1.3461 - mae: 0.8745 - val_loss: 0.5937 - val_mse: 0.5937 - val_mae: 0.6054\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 288us/step - loss: 1.3422 - mse: 1.3422 - mae: 0.8727 - val_loss: 0.5952 - val_mse: 0.5952 - val_mae: 0.6071\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 330us/step - loss: 1.3385 - mse: 1.3385 - mae: 0.8708 - val_loss: 0.5969 - val_mse: 0.5969 - val_mae: 0.6090\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 516us/step - loss: 1.3347 - mse: 1.3347 - mae: 0.8689 - val_loss: 0.5985 - val_mse: 0.5985 - val_mae: 0.6108\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 423us/step - loss: 1.3310 - mse: 1.3310 - mae: 0.8670 - val_loss: 0.5996 - val_mse: 0.5996 - val_mae: 0.6121\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 485us/step - loss: 1.3273 - mse: 1.3273 - mae: 0.8654 - val_loss: 0.6004 - val_mse: 0.6004 - val_mae: 0.6131\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 289us/step - loss: 1.3236 - mse: 1.3236 - mae: 0.8637 - val_loss: 0.6011 - val_mse: 0.6011 - val_mae: 0.6139\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 589us/step - loss: 1.3195 - mse: 1.3195 - mae: 0.8620 - val_loss: 0.6012 - val_mse: 0.6012 - val_mae: 0.6143\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7191 - mse: 0.7191 - mae: 0.635 - 0s 492us/step - loss: 1.3154 - mse: 1.3154 - mae: 0.8604 - val_loss: 0.6009 - val_mse: 0.6009 - val_mae: 0.6142\n",
      "25\n",
      "[25]\n",
      "Train on 91 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 1s 14ms/step - loss: 2.5927 - mse: 2.5927 - mae: 1.3803 - val_loss: 2.9075 - val_mse: 2.9075 - val_mae: 1.6443\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 613us/step - loss: 1.8939 - mse: 1.8939 - mae: 1.0994 - val_loss: 1.8168 - val_mse: 1.8168 - val_mae: 1.2685\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 427us/step - loss: 1.3592 - mse: 1.3592 - mae: 0.8193 - val_loss: 1.0129 - val_mse: 1.0129 - val_mae: 0.9041\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 396us/step - loss: 1.0157 - mse: 1.0157 - mae: 0.6774 - val_loss: 0.5204 - val_mse: 0.5204 - val_mae: 0.6326\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 211us/step - loss: 0.8400 - mse: 0.8400 - mae: 0.6744 - val_loss: 0.2891 - val_mse: 0.2891 - val_mae: 0.4388\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 329us/step - loss: 0.7954 - mse: 0.7954 - mae: 0.7250 - val_loss: 0.2252 - val_mse: 0.2252 - val_mae: 0.3502\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 302us/step - loss: 0.8080 - mse: 0.8080 - mae: 0.7701 - val_loss: 0.2242 - val_mse: 0.2242 - val_mae: 0.3378\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 306us/step - loss: 0.8160 - mse: 0.8160 - mae: 0.7875 - val_loss: 0.2255 - val_mse: 0.2255 - val_mae: 0.3369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 417us/step - loss: 0.7973 - mse: 0.7973 - mae: 0.7792 - val_loss: 0.2224 - val_mse: 0.2224 - val_mae: 0.3365\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 401us/step - loss: 0.7638 - mse: 0.7638 - mae: 0.7548 - val_loss: 0.2287 - val_mse: 0.2287 - val_mae: 0.3446\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 533us/step - loss: 0.7337 - mse: 0.7337 - mae: 0.7244 - val_loss: 0.2498 - val_mse: 0.2498 - val_mae: 0.3830\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 192us/step - loss: 0.7148 - mse: 0.7148 - mae: 0.6963 - val_loss: 0.2765 - val_mse: 0.2765 - val_mae: 0.4153\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.7044 - mse: 0.7044 - mae: 0.6754 - val_loss: 0.2960 - val_mse: 0.2960 - val_mae: 0.4404\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 217us/step - loss: 0.6962 - mse: 0.6962 - mae: 0.6624 - val_loss: 0.3029 - val_mse: 0.3029 - val_mae: 0.4483\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 987us/step - loss: 0.6874 - mse: 0.6874 - mae: 0.6563 - val_loss: 0.2980 - val_mse: 0.2980 - val_mae: 0.4424\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.6774 - mse: 0.6774 - mae: 0.6555 - val_loss: 0.2865 - val_mse: 0.2865 - val_mae: 0.4278\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 486us/step - loss: 0.6670 - mse: 0.6670 - mae: 0.6577 - val_loss: 0.2736 - val_mse: 0.2736 - val_mae: 0.4096\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.6571 - mse: 0.6571 - mae: 0.6611 - val_loss: 0.2632 - val_mse: 0.2632 - val_mae: 0.3935\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 454us/step - loss: 0.6482 - mse: 0.6482 - mae: 0.6634 - val_loss: 0.2569 - val_mse: 0.2569 - val_mae: 0.3837\n",
      "26\n",
      "[26]\n",
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 10.0029 - mse: 10.0029 - mae: 2.7000 - val_loss: 6.1653 - val_mse: 6.1653 - val_mae: 2.2933\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 666us/step - loss: 9.2415 - mse: 9.2415 - mae: 2.5569 - val_loss: 5.8572 - val_mse: 5.8572 - val_mae: 2.2156\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 496us/step - loss: 8.4941 - mse: 8.4941 - mae: 2.4087 - val_loss: 5.3664 - val_mse: 5.3664 - val_mae: 2.1040\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 238us/step - loss: 7.6805 - mse: 7.6805 - mae: 2.2425 - val_loss: 4.7184 - val_mse: 4.7184 - val_mae: 1.9504\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 404us/step - loss: 6.8081 - mse: 6.8081 - mae: 2.0541 - val_loss: 4.0235 - val_mse: 4.0235 - val_mae: 1.7703\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 587us/step - loss: 5.8967 - mse: 5.8967 - mae: 1.8429 - val_loss: 3.3586 - val_mse: 3.3586 - val_mae: 1.5912\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 240us/step - loss: 5.0395 - mse: 5.0395 - mae: 1.6396 - val_loss: 2.7583 - val_mse: 2.7583 - val_mae: 1.4330\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 4.2609 - mse: 4.2609 - mae: 1.4548 - val_loss: 2.2450 - val_mse: 2.2450 - val_mae: 1.2923\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 376us/step - loss: 3.6336 - mse: 3.6336 - mae: 1.3070 - val_loss: 1.8305 - val_mse: 1.8305 - val_mae: 1.1600\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 3.1685 - mse: 3.1685 - mae: 1.2080 - val_loss: 1.5135 - val_mse: 1.5135 - val_mae: 1.0590\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 310us/step - loss: 2.8557 - mse: 2.8557 - mae: 1.1595 - val_loss: 1.3006 - val_mse: 1.3006 - val_mae: 1.0002\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 338us/step - loss: 2.6671 - mse: 2.6671 - mae: 1.1589 - val_loss: 1.1746 - val_mse: 1.1746 - val_mae: 0.9552\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 246us/step - loss: 2.5772 - mse: 2.5772 - mae: 1.1687 - val_loss: 1.1081 - val_mse: 1.1081 - val_mae: 0.9234\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 248us/step - loss: 2.5367 - mse: 2.5367 - mae: 1.1769 - val_loss: 1.0800 - val_mse: 1.0800 - val_mae: 0.9072\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 411us/step - loss: 2.5091 - mse: 2.5091 - mae: 1.1791 - val_loss: 1.0728 - val_mse: 1.0728 - val_mae: 0.9051\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 404us/step - loss: 2.4730 - mse: 2.4730 - mae: 1.1723 - val_loss: 1.0778 - val_mse: 1.0778 - val_mae: 0.9106\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 305us/step - loss: 2.4307 - mse: 2.4307 - mae: 1.1614 - val_loss: 1.0908 - val_mse: 1.0908 - val_mae: 0.9200\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 574us/step - loss: 2.3878 - mse: 2.3878 - mae: 1.1492 - val_loss: 1.1076 - val_mse: 1.1076 - val_mae: 0.9301\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 359us/step - loss: 2.3519 - mse: 2.3519 - mae: 1.1375 - val_loss: 1.1280 - val_mse: 1.1280 - val_mae: 0.9409\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 436us/step - loss: 2.3210 - mse: 2.3210 - mae: 1.1264 - val_loss: 1.1462 - val_mse: 1.1462 - val_mae: 0.9501\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 482us/step - loss: 2.2907 - mse: 2.2907 - mae: 1.1171 - val_loss: 1.1584 - val_mse: 1.1584 - val_mae: 0.9569\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 498us/step - loss: 2.2596 - mse: 2.2596 - mae: 1.1085 - val_loss: 1.1613 - val_mse: 1.1613 - val_mae: 0.9604\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 331us/step - loss: 2.2273 - mse: 2.2273 - mae: 1.1008 - val_loss: 1.1570 - val_mse: 1.1570 - val_mae: 0.9608\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 549us/step - loss: 2.1964 - mse: 2.1964 - mae: 1.0944 - val_loss: 1.1479 - val_mse: 1.1479 - val_mae: 0.9588\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 219us/step - loss: 2.1689 - mse: 2.1689 - mae: 1.0895 - val_loss: 1.1392 - val_mse: 1.1392 - val_mae: 0.9568\n",
      "27\n",
      "[27]\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 6.0993 - mse: 6.0993 - mae: 2.1527 - val_loss: 3.8027 - val_mse: 3.8027 - val_mae: 1.7912\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 252us/step - loss: 5.4827 - mse: 5.4827 - mae: 2.0023 - val_loss: 3.3516 - val_mse: 3.3516 - val_mae: 1.6752\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 381us/step - loss: 4.9618 - mse: 4.9618 - mae: 1.8650 - val_loss: 2.9613 - val_mse: 2.9613 - val_mae: 1.5685\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 411us/step - loss: 4.5314 - mse: 4.5314 - mae: 1.7436 - val_loss: 2.6072 - val_mse: 2.6072 - val_mae: 1.4608\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 473us/step - loss: 4.1590 - mse: 4.1590 - mae: 1.6317 - val_loss: 2.2679 - val_mse: 2.2679 - val_mae: 1.3433\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 625us/step - loss: 3.7845 - mse: 3.7845 - mae: 1.5120 - val_loss: 1.8771 - val_mse: 1.8771 - val_mae: 1.1907\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 400us/step - loss: 3.3941 - mse: 3.3941 - mae: 1.3810 - val_loss: 1.5046 - val_mse: 1.5046 - val_mae: 1.0161\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 833us/step - loss: 2.9358 - mse: 2.9358 - mae: 1.2124 - val_loss: 1.1344 - val_mse: 1.1344 - val_mae: 0.8128\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 928us/step - loss: 2.4838 - mse: 2.4838 - mae: 1.0391 - val_loss: 0.8384 - val_mse: 0.8384 - val_mae: 0.6416\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 544us/step - loss: 2.1177 - mse: 2.1177 - mae: 0.9109 - val_loss: 0.6335 - val_mse: 0.6335 - val_mae: 0.5507\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 292us/step - loss: 1.8631 - mse: 1.8631 - mae: 0.8449 - val_loss: 0.5170 - val_mse: 0.5170 - val_mae: 0.5330\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 440us/step - loss: 1.7121 - mse: 1.7121 - mae: 0.8137 - val_loss: 0.4750 - val_mse: 0.4750 - val_mae: 0.5446\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 567us/step - loss: 1.6418 - mse: 1.6418 - mae: 0.8289 - val_loss: 0.4807 - val_mse: 0.4807 - val_mae: 0.5821\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 258us/step - loss: 1.6230 - mse: 1.6230 - mae: 0.8575 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.6176\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 486us/step - loss: 1.6243 - mse: 1.6243 - mae: 0.8879 - val_loss: 0.5338 - val_mse: 0.5338 - val_mae: 0.6405\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 203us/step - loss: 1.6245 - mse: 1.6245 - mae: 0.9026 - val_loss: 0.5470 - val_mse: 0.5470 - val_mae: 0.6511\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 267us/step - loss: 1.6134 - mse: 1.6134 - mae: 0.9034 - val_loss: 0.5455 - val_mse: 0.5455 - val_mae: 0.6515\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 237us/step - loss: 1.5907 - mse: 1.5907 - mae: 0.8937 - val_loss: 0.5335 - val_mse: 0.5335 - val_mae: 0.6449\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 746us/step - loss: 1.5607 - mse: 1.5607 - mae: 0.8765 - val_loss: 0.5161 - val_mse: 0.5161 - val_mae: 0.6334\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 694us/step - loss: 1.5291 - mse: 1.5291 - mae: 0.8552 - val_loss: 0.4988 - val_mse: 0.4988 - val_mae: 0.6196\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 303us/step - loss: 1.5008 - mse: 1.5008 - mae: 0.8363 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.6059\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 442us/step - loss: 1.4769 - mse: 1.4769 - mae: 0.8201 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.5933\n",
      "28\n",
      "[28]\n",
      "Train on 99 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 6.0634 - mse: 6.0634 - mae: 2.1003 - val_loss: 2.3199 - val_mse: 2.3199 - val_mae: 1.2307\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 625us/step - loss: 3.9724 - mse: 3.9724 - mae: 1.6082 - val_loss: 1.5221 - val_mse: 1.5221 - val_mae: 0.9479\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 516us/step - loss: 2.7010 - mse: 2.7010 - mae: 1.2882 - val_loss: 1.1531 - val_mse: 1.1531 - val_mae: 0.8320\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 219us/step - loss: 2.0877 - mse: 2.0877 - mae: 1.1245 - val_loss: 1.1055 - val_mse: 1.1055 - val_mae: 0.8337\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 309us/step - loss: 1.9000 - mse: 1.9000 - mae: 1.0898 - val_loss: 1.2038 - val_mse: 1.2038 - val_mae: 0.9140\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 419us/step - loss: 1.9059 - mse: 1.9059 - mae: 1.1008 - val_loss: 1.3051 - val_mse: 1.3051 - val_mae: 0.9728\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.9505 - mse: 1.9505 - mae: 1.1295 - val_loss: 1.3193 - val_mse: 1.3193 - val_mae: 0.9869\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 305us/step - loss: 1.9478 - mse: 1.9478 - mae: 1.1344 - val_loss: 1.2705 - val_mse: 1.2705 - val_mae: 0.9736\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 211us/step - loss: 1.8894 - mse: 1.8894 - mae: 1.1191 - val_loss: 1.1948 - val_mse: 1.1948 - val_mae: 0.9414\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 199us/step - loss: 1.7997 - mse: 1.7997 - mae: 1.0916 - val_loss: 1.1157 - val_mse: 1.1157 - val_mae: 0.9024\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 328us/step - loss: 1.7125 - mse: 1.7125 - mae: 1.0609 - val_loss: 1.0500 - val_mse: 1.0500 - val_mae: 0.8672\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.8696 - mse: 1.8696 - mae: 1.102 - 0s 720us/step - loss: 1.6416 - mse: 1.6416 - mae: 1.0350 - val_loss: 1.0013 - val_mse: 1.0013 - val_mae: 0.8368\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 407us/step - loss: 1.5873 - mse: 1.5873 - mae: 1.0149 - val_loss: 0.9670 - val_mse: 0.9670 - val_mae: 0.8201\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 655us/step - loss: 1.5459 - mse: 1.5459 - mae: 0.9995 - val_loss: 0.9431 - val_mse: 0.9431 - val_mae: 0.8105\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 624us/step - loss: 1.5143 - mse: 1.5143 - mae: 0.9874 - val_loss: 0.9277 - val_mse: 0.9277 - val_mae: 0.8045\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 565us/step - loss: 1.4903 - mse: 1.4903 - mae: 0.9784 - val_loss: 0.9192 - val_mse: 0.9192 - val_mae: 0.8015\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 358us/step - loss: 1.4711 - mse: 1.4711 - mae: 0.9717 - val_loss: 0.9151 - val_mse: 0.9151 - val_mae: 0.8004\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 197us/step - loss: 1.4552 - mse: 1.4552 - mae: 0.9662 - val_loss: 0.9129 - val_mse: 0.9129 - val_mae: 0.7998\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 436us/step - loss: 1.4417 - mse: 1.4417 - mae: 0.9618 - val_loss: 0.9112 - val_mse: 0.9112 - val_mae: 0.8001\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 294us/step - loss: 1.4292 - mse: 1.4292 - mae: 0.9575 - val_loss: 0.9087 - val_mse: 0.9087 - val_mae: 0.8005\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 359us/step - loss: 1.4173 - mse: 1.4173 - mae: 0.9531 - val_loss: 0.9042 - val_mse: 0.9042 - val_mae: 0.7993\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 343us/step - loss: 1.4053 - mse: 1.4053 - mae: 0.9487 - val_loss: 0.8973 - val_mse: 0.8973 - val_mae: 0.7963\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 400us/step - loss: 1.3933 - mse: 1.3933 - mae: 0.9440 - val_loss: 0.8881 - val_mse: 0.8881 - val_mae: 0.7920\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 463us/step - loss: 1.3809 - mse: 1.3809 - mae: 0.9390 - val_loss: 0.8789 - val_mse: 0.8789 - val_mae: 0.7874\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 451us/step - loss: 1.3690 - mse: 1.3690 - mae: 0.9340 - val_loss: 0.8707 - val_mse: 0.8707 - val_mae: 0.7831\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 231us/step - loss: 1.3578 - mse: 1.3578 - mae: 0.9291 - val_loss: 0.8643 - val_mse: 0.8643 - val_mae: 0.7796\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 551us/step - loss: 1.3476 - mse: 1.3476 - mae: 0.9247 - val_loss: 0.8594 - val_mse: 0.8594 - val_mae: 0.7770\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 490us/step - loss: 1.3384 - mse: 1.3384 - mae: 0.9207 - val_loss: 0.8556 - val_mse: 0.8556 - val_mae: 0.7752\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 406us/step - loss: 1.3299 - mse: 1.3299 - mae: 0.9171 - val_loss: 0.8528 - val_mse: 0.8528 - val_mae: 0.7742\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 279us/step - loss: 1.3221 - mse: 1.3221 - mae: 0.9136 - val_loss: 0.8501 - val_mse: 0.8501 - val_mae: 0.7734\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 285us/step - loss: 1.3149 - mse: 1.3149 - mae: 0.9103 - val_loss: 0.8479 - val_mse: 0.8479 - val_mae: 0.7731\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 345us/step - loss: 1.3081 - mse: 1.3081 - mae: 0.9072 - val_loss: 0.8461 - val_mse: 0.8461 - val_mae: 0.7727\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 701us/step - loss: 1.3011 - mse: 1.3011 - mae: 0.9043 - val_loss: 0.8434 - val_mse: 0.8434 - val_mae: 0.7720\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 407us/step - loss: 1.2939 - mse: 1.2939 - mae: 0.9013 - val_loss: 0.8406 - val_mse: 0.8406 - val_mae: 0.7713\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 394us/step - loss: 1.2867 - mse: 1.2867 - mae: 0.8983 - val_loss: 0.8372 - val_mse: 0.8372 - val_mae: 0.7702\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 382us/step - loss: 1.2795 - mse: 1.2795 - mae: 0.8956 - val_loss: 0.8342 - val_mse: 0.8342 - val_mae: 0.7692\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 228us/step - loss: 1.2726 - mse: 1.2726 - mae: 0.8930 - val_loss: 0.8313 - val_mse: 0.8313 - val_mae: 0.7681\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 399us/step - loss: 1.2659 - mse: 1.2659 - mae: 0.8904 - val_loss: 0.8284 - val_mse: 0.8284 - val_mae: 0.7672\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.2593 - mse: 1.2593 - mae: 0.8877 - val_loss: 0.8252 - val_mse: 0.8252 - val_mae: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 217us/step - loss: 1.2530 - mse: 1.2530 - mae: 0.8851 - val_loss: 0.8229 - val_mse: 0.8229 - val_mae: 0.7654\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 654us/step - loss: 1.2469 - mse: 1.2469 - mae: 0.8827 - val_loss: 0.8211 - val_mse: 0.8211 - val_mae: 0.7651\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 376us/step - loss: 1.2413 - mse: 1.2413 - mae: 0.8804 - val_loss: 0.8193 - val_mse: 0.8193 - val_mae: 0.7646\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 438us/step - loss: 1.2353 - mse: 1.2353 - mae: 0.8781 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.7638\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 239us/step - loss: 1.2284 - mse: 1.2284 - mae: 0.8755 - val_loss: 0.8144 - val_mse: 0.8144 - val_mae: 0.7632\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 558us/step - loss: 1.2212 - mse: 1.2212 - mae: 0.8728 - val_loss: 0.8121 - val_mse: 0.8121 - val_mae: 0.7627\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 342us/step - loss: 1.2140 - mse: 1.2140 - mae: 0.8702 - val_loss: 0.8101 - val_mse: 0.8101 - val_mae: 0.7623\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 552us/step - loss: 1.2071 - mse: 1.2071 - mae: 0.8676 - val_loss: 0.8084 - val_mse: 0.8084 - val_mae: 0.7621\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.2004 - mse: 1.2004 - mae: 0.8650 - val_loss: 0.8069 - val_mse: 0.8069 - val_mae: 0.7618\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 438us/step - loss: 1.1932 - mse: 1.1932 - mae: 0.8622 - val_loss: 0.8055 - val_mse: 0.8055 - val_mae: 0.7617\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 464us/step - loss: 1.1849 - mse: 1.1849 - mae: 0.8592 - val_loss: 0.8044 - val_mse: 0.8044 - val_mae: 0.7618\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 362us/step - loss: 1.1757 - mse: 1.1757 - mae: 0.8560 - val_loss: 0.8023 - val_mse: 0.8023 - val_mae: 0.7617\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 602us/step - loss: 1.1667 - mse: 1.1667 - mae: 0.8529 - val_loss: 0.8010 - val_mse: 0.8010 - val_mae: 0.7621\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 400us/step - loss: 1.1582 - mse: 1.1581 - mae: 0.8500 - val_loss: 0.8006 - val_mse: 0.8006 - val_mae: 0.7630\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 458us/step - loss: 1.1502 - mse: 1.1502 - mae: 0.8471 - val_loss: 0.8007 - val_mse: 0.8007 - val_mae: 0.7642\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 456us/step - loss: 1.1428 - mse: 1.1428 - mae: 0.8444 - val_loss: 0.8012 - val_mse: 0.8012 - val_mae: 0.7652\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 314us/step - loss: 1.1358 - mse: 1.1358 - mae: 0.8417 - val_loss: 0.8011 - val_mse: 0.8011 - val_mae: 0.7656\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 351us/step - loss: 1.1291 - mse: 1.1291 - mae: 0.8389 - val_loss: 0.8011 - val_mse: 0.8011 - val_mae: 0.7659\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 459us/step - loss: 1.1227 - mse: 1.1227 - mae: 0.8362 - val_loss: 0.8017 - val_mse: 0.8017 - val_mae: 0.7665\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 400us/step - loss: 1.1167 - mse: 1.1167 - mae: 0.8335 - val_loss: 0.8010 - val_mse: 0.8010 - val_mae: 0.7663\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 425us/step - loss: 1.1111 - mse: 1.1111 - mae: 0.8309 - val_loss: 0.8007 - val_mse: 0.8007 - val_mae: 0.7661\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 378us/step - loss: 1.1062 - mse: 1.1062 - mae: 0.8284 - val_loss: 0.8020 - val_mse: 0.8020 - val_mae: 0.7663\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 357us/step - loss: 1.1014 - mse: 1.1014 - mae: 0.8257 - val_loss: 0.8027 - val_mse: 0.8027 - val_mae: 0.7664\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 476us/step - loss: 1.0968 - mse: 1.0968 - mae: 0.8232 - val_loss: 0.8045 - val_mse: 0.8045 - val_mae: 0.7671\n",
      "29\n",
      "[29]\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 7.4533 - mse: 7.4533 - mae: 2.0424 - val_loss: 0.8194 - val_mse: 0.8194 - val_mae: 0.7533\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 212us/step - loss: 6.2701 - mse: 6.2701 - mae: 1.8006 - val_loss: 0.5173 - val_mse: 0.5173 - val_mae: 0.5565\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 549us/step - loss: 5.6008 - mse: 5.6008 - mae: 1.6339 - val_loss: 0.4674 - val_mse: 0.4674 - val_mae: 0.4670\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 443us/step - loss: 5.2588 - mse: 5.2588 - mae: 1.5737 - val_loss: 0.5023 - val_mse: 0.5023 - val_mae: 0.5173\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 469us/step - loss: 5.0578 - mse: 5.0578 - mae: 1.5275 - val_loss: 0.5342 - val_mse: 0.5342 - val_mae: 0.5651\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 250us/step - loss: 4.8804 - mse: 4.8804 - mae: 1.4745 - val_loss: 0.5236 - val_mse: 0.5236 - val_mae: 0.5712\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 4.6917 - mse: 4.6917 - mae: 1.4164 - val_loss: 0.4749 - val_mse: 0.4749 - val_mae: 0.5422\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 421us/step - loss: 4.4945 - mse: 4.4945 - mae: 1.3593 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4891\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 434us/step - loss: 4.3167 - mse: 4.3167 - mae: 1.3140 - val_loss: 0.3547 - val_mse: 0.3547 - val_mae: 0.4408\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 443us/step - loss: 4.1863 - mse: 4.1863 - mae: 1.2821 - val_loss: 0.3171 - val_mse: 0.3171 - val_mae: 0.4142\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 305us/step - loss: 4.0839 - mse: 4.0839 - mae: 1.2626 - val_loss: 0.2953 - val_mse: 0.2953 - val_mae: 0.4102\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 227us/step - loss: 4.0006 - mse: 4.0006 - mae: 1.2464 - val_loss: 0.2828 - val_mse: 0.2828 - val_mae: 0.4148\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 428us/step - loss: 3.9280 - mse: 3.9280 - mae: 1.2294 - val_loss: 0.2761 - val_mse: 0.2761 - val_mae: 0.4172\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 461us/step - loss: 3.8581 - mse: 3.8581 - mae: 1.2115 - val_loss: 0.2722 - val_mse: 0.2722 - val_mae: 0.4185\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 320us/step - loss: 3.7951 - mse: 3.7951 - mae: 1.1913 - val_loss: 0.2699 - val_mse: 0.2699 - val_mae: 0.4204\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 231us/step - loss: 3.7420 - mse: 3.7420 - mae: 1.1710 - val_loss: 0.2685 - val_mse: 0.2685 - val_mae: 0.4225\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 328us/step - loss: 3.6951 - mse: 3.6951 - mae: 1.1520 - val_loss: 0.2669 - val_mse: 0.2669 - val_mae: 0.4239\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 576us/step - loss: 3.6545 - mse: 3.6545 - mae: 1.1351 - val_loss: 0.2646 - val_mse: 0.2646 - val_mae: 0.4243\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 559us/step - loss: 3.6170 - mse: 3.6170 - mae: 1.1209 - val_loss: 0.2615 - val_mse: 0.2615 - val_mae: 0.4240\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 481us/step - loss: 3.5825 - mse: 3.5825 - mae: 1.1095 - val_loss: 0.2583 - val_mse: 0.2583 - val_mae: 0.4231\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 552us/step - loss: 3.5498 - mse: 3.5498 - mae: 1.1010 - val_loss: 0.2561 - val_mse: 0.2561 - val_mae: 0.4242\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 228us/step - loss: 3.5189 - mse: 3.5189 - mae: 1.0946 - val_loss: 0.2553 - val_mse: 0.2553 - val_mae: 0.4265\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 240us/step - loss: 3.4901 - mse: 3.4901 - mae: 1.0892 - val_loss: 0.2560 - val_mse: 0.2560 - val_mae: 0.4293\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 393us/step - loss: 3.4625 - mse: 3.4625 - mae: 1.0843 - val_loss: 0.2577 - val_mse: 0.2577 - val_mae: 0.4332\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 440us/step - loss: 3.4361 - mse: 3.4361 - mae: 1.0793 - val_loss: 0.2599 - val_mse: 0.2599 - val_mae: 0.4366\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 323us/step - loss: 3.4104 - mse: 3.4104 - mae: 1.0729 - val_loss: 0.2622 - val_mse: 0.2622 - val_mae: 0.4394\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 371us/step - loss: 3.3861 - mse: 3.3861 - mae: 1.0658 - val_loss: 0.2641 - val_mse: 0.2641 - val_mae: 0.4413\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 412us/step - loss: 3.3626 - mse: 3.3626 - mae: 1.0589 - val_loss: 0.2666 - val_mse: 0.2666 - val_mae: 0.4434\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 397us/step - loss: 3.3411 - mse: 3.3411 - mae: 1.0522 - val_loss: 0.2696 - val_mse: 0.2696 - val_mae: 0.4454\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 277us/step - loss: 3.3203 - mse: 3.3203 - mae: 1.0462 - val_loss: 0.2735 - val_mse: 0.2735 - val_mae: 0.4481\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 315us/step - loss: 3.2999 - mse: 3.2999 - mae: 1.0402 - val_loss: 0.2776 - val_mse: 0.2776 - val_mae: 0.4507\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 864us/step - loss: 3.2797 - mse: 3.2797 - mae: 1.0338 - val_loss: 0.2821 - val_mse: 0.2821 - val_mae: 0.4534\n",
      "30\n",
      "[30]\n",
      "Train on 85 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 3.2725 - mse: 3.2725 - mae: 1.4174 - val_loss: 3.7924 - val_mse: 3.7924 - val_mae: 1.5510\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 472us/step - loss: 2.5977 - mse: 2.5977 - mae: 1.2170 - val_loss: 2.9909 - val_mse: 2.9909 - val_mae: 1.3289\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 397us/step - loss: 2.0832 - mse: 2.0832 - mae: 1.0511 - val_loss: 2.4049 - val_mse: 2.4049 - val_mae: 1.1424\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 825us/step - loss: 1.7106 - mse: 1.7106 - mae: 0.9283 - val_loss: 1.9847 - val_mse: 1.9847 - val_mae: 1.0034\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 391us/step - loss: 1.4613 - mse: 1.4613 - mae: 0.8605 - val_loss: 1.7004 - val_mse: 1.7004 - val_mae: 0.9276\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 232us/step - loss: 1.3032 - mse: 1.3032 - mae: 0.8233 - val_loss: 1.5139 - val_mse: 1.5139 - val_mae: 0.8873\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 1.2185 - mse: 1.2185 - mae: 0.8070 - val_loss: 1.4034 - val_mse: 1.4034 - val_mae: 0.8660\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 460us/step - loss: 1.1806 - mse: 1.1806 - mae: 0.8127 - val_loss: 1.3525 - val_mse: 1.3525 - val_mae: 0.8583\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 417us/step - loss: 1.1698 - mse: 1.1698 - mae: 0.8184 - val_loss: 1.3241 - val_mse: 1.3241 - val_mae: 0.8493\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 653us/step - loss: 1.1650 - mse: 1.1650 - mae: 0.8266 - val_loss: 1.3034 - val_mse: 1.3034 - val_mae: 0.8465\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 230us/step - loss: 1.1565 - mse: 1.1565 - mae: 0.8270 - val_loss: 1.2888 - val_mse: 1.2888 - val_mae: 0.8402\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 393us/step - loss: 1.1417 - mse: 1.1417 - mae: 0.8205 - val_loss: 1.2744 - val_mse: 1.2744 - val_mae: 0.8304\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 248us/step - loss: 1.1225 - mse: 1.1225 - mae: 0.8101 - val_loss: 1.2629 - val_mse: 1.2629 - val_mae: 0.8181\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 266us/step - loss: 1.1048 - mse: 1.1048 - mae: 0.7995 - val_loss: 1.2565 - val_mse: 1.2565 - val_mae: 0.8046\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 235us/step - loss: 1.0926 - mse: 1.0926 - mae: 0.7902 - val_loss: 1.2574 - val_mse: 1.2574 - val_mae: 0.7930\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 505us/step - loss: 1.0836 - mse: 1.0836 - mae: 0.7821 - val_loss: 1.2593 - val_mse: 1.2593 - val_mae: 0.7860\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 264us/step - loss: 1.0764 - mse: 1.0764 - mae: 0.7753 - val_loss: 1.2598 - val_mse: 1.2598 - val_mae: 0.7822\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 590us/step - loss: 1.0688 - mse: 1.0688 - mae: 0.7698 - val_loss: 1.2576 - val_mse: 1.2576 - val_mae: 0.7789\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 265us/step - loss: 1.0598 - mse: 1.0598 - mae: 0.7657 - val_loss: 1.2526 - val_mse: 1.2526 - val_mae: 0.7758\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 220us/step - loss: 1.0504 - mse: 1.0504 - mae: 0.7626 - val_loss: 1.2462 - val_mse: 1.2462 - val_mae: 0.7728\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 551us/step - loss: 1.0414 - mse: 1.0414 - mae: 0.7605 - val_loss: 1.2392 - val_mse: 1.2392 - val_mae: 0.7698\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 409us/step - loss: 1.0326 - mse: 1.0326 - mae: 0.7590 - val_loss: 1.2327 - val_mse: 1.2327 - val_mae: 0.7668\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 344us/step - loss: 1.0241 - mse: 1.0241 - mae: 0.7577 - val_loss: 1.2271 - val_mse: 1.2271 - val_mae: 0.7640\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 229us/step - loss: 1.0157 - mse: 1.0157 - mae: 0.7560 - val_loss: 1.2226 - val_mse: 1.2226 - val_mae: 0.7616\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 229us/step - loss: 1.0076 - mse: 1.0076 - mae: 0.7539 - val_loss: 1.2191 - val_mse: 1.2191 - val_mae: 0.7589\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 515us/step - loss: 0.9994 - mse: 0.9994 - mae: 0.7511 - val_loss: 1.2162 - val_mse: 1.2162 - val_mae: 0.7564\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 355us/step - loss: 0.9917 - mse: 0.9917 - mae: 0.7484 - val_loss: 1.2128 - val_mse: 1.2128 - val_mae: 0.7537\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 630us/step - loss: 0.9844 - mse: 0.9844 - mae: 0.7459 - val_loss: 1.2087 - val_mse: 1.2087 - val_mae: 0.7510\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 370us/step - loss: 0.9777 - mse: 0.9777 - mae: 0.7438 - val_loss: 1.2037 - val_mse: 1.2037 - val_mae: 0.7482\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 335us/step - loss: 0.9711 - mse: 0.9711 - mae: 0.7421 - val_loss: 1.1983 - val_mse: 1.1983 - val_mae: 0.7457\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 208us/step - loss: 0.9647 - mse: 0.9647 - mae: 0.7409 - val_loss: 1.1931 - val_mse: 1.1931 - val_mae: 0.7431\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 317us/step - loss: 0.9583 - mse: 0.9583 - mae: 0.7395 - val_loss: 1.1886 - val_mse: 1.1886 - val_mae: 0.7407\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 407us/step - loss: 0.9517 - mse: 0.9517 - mae: 0.7379 - val_loss: 1.1844 - val_mse: 1.1844 - val_mae: 0.7383\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 367us/step - loss: 0.9457 - mse: 0.9457 - mae: 0.7366 - val_loss: 1.1799 - val_mse: 1.1799 - val_mae: 0.7357\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 244us/step - loss: 0.9400 - mse: 0.9400 - mae: 0.7354 - val_loss: 1.1755 - val_mse: 1.1755 - val_mae: 0.7328\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 420us/step - loss: 0.9342 - mse: 0.9342 - mae: 0.7342 - val_loss: 1.1710 - val_mse: 1.1710 - val_mae: 0.7300\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 419us/step - loss: 0.9285 - mse: 0.9285 - mae: 0.7328 - val_loss: 1.1671 - val_mse: 1.1671 - val_mae: 0.7270\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 764us/step - loss: 0.9229 - mse: 0.9229 - mae: 0.7312 - val_loss: 1.1639 - val_mse: 1.1639 - val_mae: 0.7239\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 183us/step - loss: 0.9174 - mse: 0.9174 - mae: 0.7295 - val_loss: 1.1607 - val_mse: 1.1607 - val_mae: 0.7206\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 507us/step - loss: 0.9122 - mse: 0.9122 - mae: 0.7280 - val_loss: 1.1571 - val_mse: 1.1571 - val_mae: 0.7173\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 230us/step - loss: 0.9075 - mse: 0.9075 - mae: 0.7265 - val_loss: 1.1544 - val_mse: 1.1544 - val_mae: 0.7142\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 355us/step - loss: 0.9024 - mse: 0.9024 - mae: 0.7243 - val_loss: 1.1525 - val_mse: 1.1525 - val_mae: 0.7115\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 503us/step - loss: 0.8978 - mse: 0.8978 - mae: 0.7221 - val_loss: 1.1500 - val_mse: 1.1500 - val_mae: 0.7088\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 494us/step - loss: 0.8932 - mse: 0.8932 - mae: 0.7203 - val_loss: 1.1469 - val_mse: 1.1469 - val_mae: 0.7064\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 511us/step - loss: 0.8886 - mse: 0.8886 - mae: 0.7190 - val_loss: 1.1440 - val_mse: 1.1440 - val_mae: 0.7047\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 313us/step - loss: 0.8840 - mse: 0.8840 - mae: 0.7173 - val_loss: 1.1420 - val_mse: 1.1420 - val_mae: 0.7031\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 231us/step - loss: 0.8797 - mse: 0.8797 - mae: 0.7159 - val_loss: 1.1394 - val_mse: 1.1394 - val_mae: 0.7018\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 787us/step - loss: 0.8754 - mse: 0.8754 - mae: 0.7148 - val_loss: 1.1366 - val_mse: 1.1366 - val_mae: 0.7005\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 241us/step - loss: 0.8711 - mse: 0.8711 - mae: 0.7133 - val_loss: 1.1341 - val_mse: 1.1341 - val_mae: 0.6992\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 232us/step - loss: 0.8670 - mse: 0.8670 - mae: 0.7116 - val_loss: 1.1320 - val_mse: 1.1320 - val_mae: 0.6983\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 331us/step - loss: 0.8626 - mse: 0.8626 - mae: 0.7099 - val_loss: 1.1298 - val_mse: 1.1298 - val_mae: 0.6974\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 813us/step - loss: 0.8585 - mse: 0.8585 - mae: 0.7084 - val_loss: 1.1281 - val_mse: 1.1281 - val_mae: 0.6967\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 646us/step - loss: 0.8549 - mse: 0.8549 - mae: 0.7068 - val_loss: 1.1273 - val_mse: 1.1273 - val_mae: 0.6962\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 715us/step - loss: 0.8514 - mse: 0.8514 - mae: 0.7052 - val_loss: 1.1257 - val_mse: 1.1257 - val_mae: 0.6955\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 540us/step - loss: 0.8481 - mse: 0.8481 - mae: 0.7043 - val_loss: 1.1232 - val_mse: 1.1232 - val_mae: 0.6947\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 847us/step - loss: 0.8448 - mse: 0.8448 - mae: 0.7038 - val_loss: 1.1211 - val_mse: 1.1211 - val_mae: 0.6938\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 236us/step - loss: 0.8415 - mse: 0.8415 - mae: 0.7027 - val_loss: 1.1203 - val_mse: 1.1203 - val_mae: 0.6929\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 268us/step - loss: 0.8383 - mse: 0.8383 - mae: 0.7014 - val_loss: 1.1201 - val_mse: 1.1201 - val_mae: 0.6921\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 242us/step - loss: 0.8352 - mse: 0.8352 - mae: 0.7000 - val_loss: 1.1202 - val_mse: 1.1202 - val_mae: 0.6914\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 236us/step - loss: 0.8320 - mse: 0.8320 - mae: 0.6987 - val_loss: 1.1211 - val_mse: 1.1211 - val_mae: 0.6911\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 385us/step - loss: 0.8286 - mse: 0.8286 - mae: 0.6972 - val_loss: 1.1218 - val_mse: 1.1218 - val_mae: 0.6909\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 434us/step - loss: 0.8251 - mse: 0.8251 - mae: 0.6955 - val_loss: 1.1224 - val_mse: 1.1224 - val_mae: 0.6907\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 572us/step - loss: 0.8212 - mse: 0.8212 - mae: 0.6933 - val_loss: 1.1228 - val_mse: 1.1228 - val_mae: 0.6905\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 428us/step - loss: 0.8180 - mse: 0.8180 - mae: 0.6919 - val_loss: 1.1239 - val_mse: 1.1239 - val_mae: 0.6912\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 401us/step - loss: 0.8143 - mse: 0.8143 - mae: 0.6912 - val_loss: 1.1259 - val_mse: 1.1259 - val_mae: 0.6918\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 422us/step - loss: 0.8105 - mse: 0.8105 - mae: 0.6897 - val_loss: 1.1293 - val_mse: 1.1293 - val_mae: 0.6925\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 594us/step - loss: 0.8056 - mse: 0.8056 - mae: 0.6873 - val_loss: 1.1328 - val_mse: 1.1328 - val_mae: 0.6928\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8254 - mse: 0.8254 - mae: 0.734 - 0s 349us/step - loss: 0.8009 - mse: 0.8009 - mae: 0.6847 - val_loss: 1.1358 - val_mse: 1.1358 - val_mae: 0.6932\n",
      "31\n",
      "[31]\n",
      "Train on 101 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 14.2502 - mse: 14.2502 - mae: 3.0414 - val_loss: 7.8705 - val_mse: 7.8705 - val_mae: 2.6264\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 442us/step - loss: 11.7617 - mse: 11.7617 - mae: 2.6853 - val_loss: 6.0849 - val_mse: 6.0849 - val_mae: 2.2643\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 504us/step - loss: 9.8064 - mse: 9.8064 - mae: 2.3629 - val_loss: 4.5894 - val_mse: 4.5894 - val_mae: 1.9101\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 268us/step - loss: 8.3462 - mse: 8.3462 - mae: 2.0991 - val_loss: 3.3737 - val_mse: 3.3737 - val_mae: 1.6021\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 475us/step - loss: 7.2496 - mse: 7.2496 - mae: 1.9163 - val_loss: 2.4709 - val_mse: 2.4709 - val_mae: 1.3564\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 453us/step - loss: 6.4698 - mse: 6.4698 - mae: 1.7961 - val_loss: 1.8469 - val_mse: 1.8469 - val_mae: 1.1549\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 390us/step - loss: 5.8944 - mse: 5.8944 - mae: 1.7452 - val_loss: 1.4378 - val_mse: 1.4378 - val_mae: 1.0096\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 276us/step - loss: 5.4970 - mse: 5.4970 - mae: 1.7191 - val_loss: 1.1798 - val_mse: 1.1798 - val_mae: 0.9072\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 247us/step - loss: 5.2841 - mse: 5.2841 - mae: 1.7199 - val_loss: 1.0473 - val_mse: 1.0473 - val_mae: 0.8539\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 503us/step - loss: 5.1753 - mse: 5.1753 - mae: 1.7349 - val_loss: 0.9907 - val_mse: 0.9907 - val_mae: 0.8358\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 269us/step - loss: 5.0968 - mse: 5.0968 - mae: 1.7430 - val_loss: 0.9758 - val_mse: 0.9758 - val_mae: 0.8345\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 224us/step - loss: 5.0057 - mse: 5.0057 - mae: 1.7328 - val_loss: 0.9890 - val_mse: 0.9890 - val_mae: 0.8467\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 244us/step - loss: 4.9086 - mse: 4.9086 - mae: 1.7123 - val_loss: 1.0170 - val_mse: 1.0170 - val_mae: 0.8650\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 435us/step - loss: 4.8136 - mse: 4.8136 - mae: 1.6876 - val_loss: 1.0556 - val_mse: 1.0556 - val_mae: 0.8850\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 702us/step - loss: 4.7242 - mse: 4.7242 - mae: 1.6617 - val_loss: 1.0976 - val_mse: 1.0976 - val_mae: 0.9032\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 230us/step - loss: 4.6440 - mse: 4.6441 - mae: 1.6402 - val_loss: 1.1380 - val_mse: 1.1380 - val_mae: 0.9192\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 710us/step - loss: 4.5716 - mse: 4.5716 - mae: 1.6224 - val_loss: 1.1719 - val_mse: 1.1719 - val_mae: 0.9320\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 231us/step - loss: 4.5070 - mse: 4.5070 - mae: 1.6079 - val_loss: 1.1967 - val_mse: 1.1967 - val_mae: 0.9418\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 388us/step - loss: 4.4442 - mse: 4.4442 - mae: 1.5949 - val_loss: 1.2119 - val_mse: 1.2119 - val_mae: 0.9486\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 378us/step - loss: 4.3849 - mse: 4.3849 - mae: 1.5840 - val_loss: 1.2182 - val_mse: 1.2182 - val_mae: 0.9529\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 638us/step - loss: 4.3273 - mse: 4.3273 - mae: 1.5757 - val_loss: 1.2201 - val_mse: 1.2201 - val_mae: 0.9557\n",
      "32\n",
      "[32]\n",
      "Train on 103 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "103/103 [==============================] - 1s 14ms/step - loss: 4.9956 - mse: 4.9956 - mae: 1.8746 - val_loss: 4.7313 - val_mse: 4.7313 - val_mae: 1.9857\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 341us/step - loss: 4.4951 - mse: 4.4951 - mae: 1.7355 - val_loss: 4.1701 - val_mse: 4.1701 - val_mae: 1.8330\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 391us/step - loss: 4.0168 - mse: 4.0168 - mae: 1.5988 - val_loss: 3.6490 - val_mse: 3.6490 - val_mae: 1.6790\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 746us/step - loss: 3.5734 - mse: 3.5734 - mae: 1.4739 - val_loss: 3.1481 - val_mse: 3.1481 - val_mae: 1.5273\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 407us/step - loss: 3.1892 - mse: 3.1892 - mae: 1.3697 - val_loss: 2.7100 - val_mse: 2.7100 - val_mae: 1.3894\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 383us/step - loss: 2.8395 - mse: 2.8395 - mae: 1.2764 - val_loss: 2.3147 - val_mse: 2.3147 - val_mae: 1.2563\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 329us/step - loss: 2.5310 - mse: 2.5310 - mae: 1.1922 - val_loss: 1.9699 - val_mse: 1.9699 - val_mae: 1.1378\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 294us/step - loss: 2.2683 - mse: 2.2683 - mae: 1.1284 - val_loss: 1.6771 - val_mse: 1.6771 - val_mae: 1.0199\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 285us/step - loss: 2.0571 - mse: 2.0571 - mae: 1.0828 - val_loss: 1.4441 - val_mse: 1.4441 - val_mae: 0.9338\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 1.8943 - mse: 1.8943 - mae: 1.0453 - val_loss: 1.2661 - val_mse: 1.2661 - val_mae: 0.8603\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 320us/step - loss: 1.7759 - mse: 1.7759 - mae: 1.0231 - val_loss: 1.1538 - val_mse: 1.1538 - val_mae: 0.7968\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 227us/step - loss: 1.7071 - mse: 1.7071 - mae: 1.0147 - val_loss: 1.0869 - val_mse: 1.0869 - val_mae: 0.7524\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 238us/step - loss: 1.6755 - mse: 1.6755 - mae: 1.0173 - val_loss: 1.0614 - val_mse: 1.0614 - val_mae: 0.7422\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 223us/step - loss: 1.6679 - mse: 1.6679 - mae: 1.0235 - val_loss: 1.0530 - val_mse: 1.0530 - val_mae: 0.7482\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 671us/step - loss: 1.6599 - mse: 1.6599 - mae: 1.0271 - val_loss: 1.0449 - val_mse: 1.0449 - val_mae: 0.7456\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 307us/step - loss: 1.6441 - mse: 1.6441 - mae: 1.0226 - val_loss: 1.0344 - val_mse: 1.0344 - val_mae: 0.7367\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 349us/step - loss: 1.6248 - mse: 1.6248 - mae: 1.0139 - val_loss: 1.0254 - val_mse: 1.0254 - val_mae: 0.7250\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 679us/step - loss: 1.6069 - mse: 1.6069 - mae: 1.0056 - val_loss: 1.0194 - val_mse: 1.0194 - val_mae: 0.7174\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 402us/step - loss: 1.5915 - mse: 1.5915 - mae: 0.9985 - val_loss: 1.0162 - val_mse: 1.0162 - val_mae: 0.7150\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.4617 - mse: 1.4617 - mae: 0.969 - 0s 317us/step - loss: 1.5791 - mse: 1.5791 - mae: 0.9922 - val_loss: 1.0129 - val_mse: 1.0129 - val_mae: 0.7141\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 330us/step - loss: 1.5675 - mse: 1.5675 - mae: 0.9870 - val_loss: 1.0091 - val_mse: 1.0091 - val_mae: 0.7124\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 493us/step - loss: 1.5558 - mse: 1.5558 - mae: 0.9828 - val_loss: 1.0041 - val_mse: 1.0041 - val_mae: 0.7095\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 362us/step - loss: 1.5442 - mse: 1.5442 - mae: 0.9793 - val_loss: 0.9985 - val_mse: 0.9985 - val_mae: 0.7064\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 371us/step - loss: 1.5331 - mse: 1.5331 - mae: 0.9761 - val_loss: 0.9927 - val_mse: 0.9927 - val_mae: 0.7031\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 519us/step - loss: 1.5220 - mse: 1.5220 - mae: 0.9730 - val_loss: 0.9869 - val_mse: 0.9869 - val_mae: 0.6999\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 349us/step - loss: 1.5110 - mse: 1.5110 - mae: 0.9697 - val_loss: 0.9817 - val_mse: 0.9817 - val_mae: 0.6969\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 562us/step - loss: 1.5001 - mse: 1.5001 - mae: 0.9662 - val_loss: 0.9771 - val_mse: 0.9771 - val_mae: 0.6945\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 338us/step - loss: 1.4897 - mse: 1.4897 - mae: 0.9628 - val_loss: 0.9728 - val_mse: 0.9728 - val_mae: 0.6925\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 309us/step - loss: 1.4795 - mse: 1.4795 - mae: 0.9592 - val_loss: 0.9689 - val_mse: 0.9689 - val_mae: 0.6904\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 334us/step - loss: 1.4698 - mse: 1.4698 - mae: 0.9557 - val_loss: 0.9655 - val_mse: 0.9655 - val_mae: 0.6884\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 516us/step - loss: 1.4604 - mse: 1.4604 - mae: 0.9522 - val_loss: 0.9625 - val_mse: 0.9625 - val_mae: 0.6867\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.3837 - mse: 1.3837 - mae: 0.947 - 0s 300us/step - loss: 1.4510 - mse: 1.4510 - mae: 0.9486 - val_loss: 0.9597 - val_mse: 0.9597 - val_mae: 0.6852\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 239us/step - loss: 1.4413 - mse: 1.4413 - mae: 0.9447 - val_loss: 0.9570 - val_mse: 0.9570 - val_mae: 0.6840\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 435us/step - loss: 1.4316 - mse: 1.4316 - mae: 0.9406 - val_loss: 0.9543 - val_mse: 0.9543 - val_mae: 0.6841\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 368us/step - loss: 1.4221 - mse: 1.4221 - mae: 0.9365 - val_loss: 0.9515 - val_mse: 0.9515 - val_mae: 0.6839\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 638us/step - loss: 1.4130 - mse: 1.4130 - mae: 0.9325 - val_loss: 0.9487 - val_mse: 0.9487 - val_mae: 0.6835\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 391us/step - loss: 1.4040 - mse: 1.4040 - mae: 0.9290 - val_loss: 0.9461 - val_mse: 0.9461 - val_mae: 0.6829\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 305us/step - loss: 1.3952 - mse: 1.3952 - mae: 0.9258 - val_loss: 0.9439 - val_mse: 0.9439 - val_mae: 0.6827\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 261us/step - loss: 1.3867 - mse: 1.3867 - mae: 0.9224 - val_loss: 0.9421 - val_mse: 0.9421 - val_mae: 0.6836\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 222us/step - loss: 1.3786 - mse: 1.3786 - mae: 0.9190 - val_loss: 0.9403 - val_mse: 0.9403 - val_mae: 0.6846\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 422us/step - loss: 1.3708 - mse: 1.3708 - mae: 0.9156 - val_loss: 0.9385 - val_mse: 0.9385 - val_mae: 0.6854\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 456us/step - loss: 1.3634 - mse: 1.3634 - mae: 0.9126 - val_loss: 0.9367 - val_mse: 0.9367 - val_mae: 0.6860\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 230us/step - loss: 1.3562 - mse: 1.3562 - mae: 0.9096 - val_loss: 0.9353 - val_mse: 0.9353 - val_mae: 0.6867\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 347us/step - loss: 1.3490 - mse: 1.3490 - mae: 0.9067 - val_loss: 0.9347 - val_mse: 0.9347 - val_mae: 0.6876\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 401us/step - loss: 1.3421 - mse: 1.3421 - mae: 0.9042 - val_loss: 0.9343 - val_mse: 0.9343 - val_mae: 0.6884\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 479us/step - loss: 1.3356 - mse: 1.3356 - mae: 0.9023 - val_loss: 0.9338 - val_mse: 0.9338 - val_mae: 0.6891\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 345us/step - loss: 1.3291 - mse: 1.3291 - mae: 0.9001 - val_loss: 0.9333 - val_mse: 0.9333 - val_mae: 0.6898\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 472us/step - loss: 1.3227 - mse: 1.3227 - mae: 0.8979 - val_loss: 0.9333 - val_mse: 0.9333 - val_mae: 0.6907\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 443us/step - loss: 1.3162 - mse: 1.3162 - mae: 0.8957 - val_loss: 0.9335 - val_mse: 0.9335 - val_mae: 0.6917\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 341us/step - loss: 1.3097 - mse: 1.3097 - mae: 0.8936 - val_loss: 0.9338 - val_mse: 0.9338 - val_mae: 0.6925\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 466us/step - loss: 1.3033 - mse: 1.3033 - mae: 0.8915 - val_loss: 0.9344 - val_mse: 0.9344 - val_mae: 0.6931\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 555us/step - loss: 1.2970 - mse: 1.2970 - mae: 0.8896 - val_loss: 0.9345 - val_mse: 0.9345 - val_mae: 0.6935\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 587us/step - loss: 1.2909 - mse: 1.2909 - mae: 0.8881 - val_loss: 0.9336 - val_mse: 0.9336 - val_mae: 0.6936\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 426us/step - loss: 1.2849 - mse: 1.2849 - mae: 0.8868 - val_loss: 0.9332 - val_mse: 0.9332 - val_mae: 0.6947\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 208us/step - loss: 1.2799 - mse: 1.2799 - mae: 0.8856 - val_loss: 0.9346 - val_mse: 0.9346 - val_mae: 0.6961\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 216us/step - loss: 1.2743 - mse: 1.2743 - mae: 0.8838 - val_loss: 0.9361 - val_mse: 0.9361 - val_mae: 0.6974\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 323us/step - loss: 1.2689 - mse: 1.2689 - mae: 0.8815 - val_loss: 0.9371 - val_mse: 0.9371 - val_mae: 0.6985\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 523us/step - loss: 1.2637 - mse: 1.2637 - mae: 0.8792 - val_loss: 0.9375 - val_mse: 0.9375 - val_mae: 0.6995\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 334us/step - loss: 1.2587 - mse: 1.2587 - mae: 0.8774 - val_loss: 0.9381 - val_mse: 0.9381 - val_mae: 0.7002\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 477us/step - loss: 1.2538 - mse: 1.2538 - mae: 0.8761 - val_loss: 0.9386 - val_mse: 0.9386 - val_mae: 0.7009\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 559us/step - loss: 1.2492 - mse: 1.2492 - mae: 0.8749 - val_loss: 0.9393 - val_mse: 0.9393 - val_mae: 0.7019\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 276us/step - loss: 1.2443 - mse: 1.2443 - mae: 0.8735 - val_loss: 0.9403 - val_mse: 0.9403 - val_mae: 0.7029\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 286us/step - loss: 1.2399 - mse: 1.2399 - mae: 0.8717 - val_loss: 0.9412 - val_mse: 0.9412 - val_mae: 0.7035\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 391us/step - loss: 1.2356 - mse: 1.2356 - mae: 0.8699 - val_loss: 0.9422 - val_mse: 0.9422 - val_mae: 0.7041\n",
      "33\n",
      "[33]\n",
      "Train on 109 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 7.4199 - mse: 7.4199 - mae: 2.5263 - val_loss: 3.6257 - val_mse: 3.6257 - val_mae: 1.7885\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 0s 453us/step - loss: 6.4089 - mse: 6.4089 - mae: 2.3362 - val_loss: 3.1773 - val_mse: 3.1773 - val_mae: 1.6647\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 0s 343us/step - loss: 5.7224 - mse: 5.7224 - mae: 2.1956 - val_loss: 2.8828 - val_mse: 2.8828 - val_mae: 1.5781\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 0s 312us/step - loss: 5.2502 - mse: 5.2502 - mae: 2.0894 - val_loss: 2.6677 - val_mse: 2.6677 - val_mae: 1.5087\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 302us/step - loss: 4.8805 - mse: 4.8805 - mae: 2.0012 - val_loss: 2.4871 - val_mse: 2.4871 - val_mae: 1.4480\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 392us/step - loss: 4.5446 - mse: 4.5446 - mae: 1.9167 - val_loss: 2.3016 - val_mse: 2.3016 - val_mae: 1.3828\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 3.5032 - mse: 3.5032 - mae: 1.709 - 0s 694us/step - loss: 4.1651 - mse: 4.1651 - mae: 1.8165 - val_loss: 2.0526 - val_mse: 2.0526 - val_mae: 1.2866\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 0s 348us/step - loss: 3.6473 - mse: 3.6473 - mae: 1.6664 - val_loss: 1.7313 - val_mse: 1.7313 - val_mae: 1.1424\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 0s 437us/step - loss: 2.9746 - mse: 2.9746 - mae: 1.4537 - val_loss: 1.3510 - val_mse: 1.3510 - val_mae: 0.9463\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 0s 470us/step - loss: 2.2614 - mse: 2.2614 - mae: 1.1929 - val_loss: 0.9947 - val_mse: 0.9947 - val_mae: 0.7344\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 0s 497us/step - loss: 1.6786 - mse: 1.6786 - mae: 0.9611 - val_loss: 0.7082 - val_mse: 0.7082 - val_mae: 0.5705\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 0s 250us/step - loss: 1.2916 - mse: 1.2916 - mae: 0.8336 - val_loss: 0.5431 - val_mse: 0.5431 - val_mae: 0.5254\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 0s 358us/step - loss: 1.0957 - mse: 1.0957 - mae: 0.7778 - val_loss: 0.4757 - val_mse: 0.4757 - val_mae: 0.5182\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 0s 413us/step - loss: 1.0351 - mse: 1.0351 - mae: 0.7658 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.5379\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 0s 233us/step - loss: 1.0415 - mse: 1.0415 - mae: 0.7754 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.5597\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 0s 715us/step - loss: 1.0566 - mse: 1.0566 - mae: 0.7864 - val_loss: 0.4838 - val_mse: 0.4838 - val_mae: 0.5679\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 0s 534us/step - loss: 1.0516 - mse: 1.0516 - mae: 0.7863 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.5648\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 0s 241us/step - loss: 1.0280 - mse: 1.0280 - mae: 0.7770 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.5551\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 0s 241us/step - loss: 0.9988 - mse: 0.9988 - mae: 0.7654 - val_loss: 0.4647 - val_mse: 0.4647 - val_mae: 0.5427\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 0s 349us/step - loss: 0.9735 - mse: 0.9735 - mae: 0.7545 - val_loss: 0.4608 - val_mse: 0.4608 - val_mae: 0.5326\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 0s 347us/step - loss: 0.9552 - mse: 0.9552 - mae: 0.7464 - val_loss: 0.4599 - val_mse: 0.4599 - val_mae: 0.5265\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 0s 589us/step - loss: 0.9426 - mse: 0.9426 - mae: 0.7399 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5225\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 0s 303us/step - loss: 0.9327 - mse: 0.9327 - mae: 0.7353 - val_loss: 0.4597 - val_mse: 0.4597 - val_mae: 0.5200\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 0s 261us/step - loss: 0.9233 - mse: 0.9233 - mae: 0.7315 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.5196\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 0s 397us/step - loss: 0.9132 - mse: 0.9132 - mae: 0.7282 - val_loss: 0.4577 - val_mse: 0.4577 - val_mae: 0.5206\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 0s 326us/step - loss: 0.9029 - mse: 0.9029 - mae: 0.7254 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.5224\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 0s 455us/step - loss: 0.8932 - mse: 0.8932 - mae: 0.7232 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.5244\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 0s 310us/step - loss: 0.8844 - mse: 0.8844 - mae: 0.7213 - val_loss: 0.4552 - val_mse: 0.4552 - val_mae: 0.5269\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 0s 315us/step - loss: 0.8766 - mse: 0.8766 - mae: 0.7199 - val_loss: 0.4554 - val_mse: 0.4554 - val_mae: 0.5294\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 0s 526us/step - loss: 0.8696 - mse: 0.8696 - mae: 0.7183 - val_loss: 0.4556 - val_mse: 0.4556 - val_mae: 0.5314\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 0s 218us/step - loss: 0.8627 - mse: 0.8627 - mae: 0.7159 - val_loss: 0.4559 - val_mse: 0.4559 - val_mae: 0.5329\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 0s 281us/step - loss: 0.8566 - mse: 0.8566 - mae: 0.7132 - val_loss: 0.4558 - val_mse: 0.4558 - val_mae: 0.5336\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 0s 355us/step - loss: 0.8506 - mse: 0.8506 - mae: 0.7103 - val_loss: 0.4553 - val_mse: 0.4553 - val_mae: 0.5336\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 0s 432us/step - loss: 0.8449 - mse: 0.8449 - mae: 0.7081 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.5332\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 0s 493us/step - loss: 0.8397 - mse: 0.8397 - mae: 0.7060 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.5329\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 0s 498us/step - loss: 0.8350 - mse: 0.8350 - mae: 0.7042 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.5331\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 0s 454us/step - loss: 0.8307 - mse: 0.8307 - mae: 0.7026 - val_loss: 0.4529 - val_mse: 0.4529 - val_mae: 0.5334\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 0s 983us/step - loss: 0.8266 - mse: 0.8266 - mae: 0.7010 - val_loss: 0.4523 - val_mse: 0.4523 - val_mae: 0.5337\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 0s 410us/step - loss: 0.8225 - mse: 0.8225 - mae: 0.6995 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.5337\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 0s 356us/step - loss: 0.8186 - mse: 0.8186 - mae: 0.6981 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.5334\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 0s 407us/step - loss: 0.8148 - mse: 0.8148 - mae: 0.6967 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.5333\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 0s 512us/step - loss: 0.8109 - mse: 0.8109 - mae: 0.6951 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.5334\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 0s 437us/step - loss: 0.8073 - mse: 0.8073 - mae: 0.6935 - val_loss: 0.4468 - val_mse: 0.4468 - val_mae: 0.5333\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 0s 676us/step - loss: 0.8037 - mse: 0.8037 - mae: 0.6918 - val_loss: 0.4454 - val_mse: 0.4454 - val_mae: 0.5327\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 0s 401us/step - loss: 0.8004 - mse: 0.8004 - mae: 0.6901 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.5323\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 0s 423us/step - loss: 0.7972 - mse: 0.7972 - mae: 0.6886 - val_loss: 0.4440 - val_mse: 0.4440 - val_mae: 0.5325\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 0s 357us/step - loss: 0.7946 - mse: 0.7946 - mae: 0.6881 - val_loss: 0.4434 - val_mse: 0.4434 - val_mae: 0.5324\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 0s 460us/step - loss: 0.7920 - mse: 0.7920 - mae: 0.6870 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.5319\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 0s 719us/step - loss: 0.7890 - mse: 0.7890 - mae: 0.6855 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.5317\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 0s 562us/step - loss: 0.7864 - mse: 0.7864 - mae: 0.6844 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.5316\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 0s 623us/step - loss: 0.7840 - mse: 0.7840 - mae: 0.6834 - val_loss: 0.4407 - val_mse: 0.4407 - val_mae: 0.5314\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 0s 302us/step - loss: 0.7816 - mse: 0.7816 - mae: 0.6825 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.5312\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 0s 568us/step - loss: 0.7791 - mse: 0.7791 - mae: 0.6814 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.5309\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 0s 554us/step - loss: 0.7767 - mse: 0.7767 - mae: 0.6802 - val_loss: 0.4385 - val_mse: 0.4385 - val_mae: 0.5307\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 0s 691us/step - loss: 0.7743 - mse: 0.7743 - mae: 0.6794 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.5306\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 0s 513us/step - loss: 0.7720 - mse: 0.7720 - mae: 0.6784 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.5304\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 0s 515us/step - loss: 0.7698 - mse: 0.7698 - mae: 0.6774 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.5303\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 0s 593us/step - loss: 0.7676 - mse: 0.7676 - mae: 0.6766 - val_loss: 0.4366 - val_mse: 0.4366 - val_mae: 0.5301\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - 0s 221us/step - loss: 0.7655 - mse: 0.7655 - mae: 0.6757 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.5299\n",
      "Epoch 60/100\n",
      "109/109 [==============================] - 0s 646us/step - loss: 0.7634 - mse: 0.7634 - mae: 0.6745 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.5301\n",
      "Epoch 61/100\n",
      "109/109 [==============================] - 0s 788us/step - loss: 0.7613 - mse: 0.7613 - mae: 0.6737 - val_loss: 0.4359 - val_mse: 0.4359 - val_mae: 0.5305\n",
      "Epoch 62/100\n",
      "109/109 [==============================] - 0s 488us/step - loss: 0.7595 - mse: 0.7595 - mae: 0.6730 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.5307\n",
      "Epoch 63/100\n",
      "109/109 [==============================] - 0s 633us/step - loss: 0.7576 - mse: 0.7576 - mae: 0.6719 - val_loss: 0.4352 - val_mse: 0.4352 - val_mae: 0.5307\n",
      "Epoch 64/100\n",
      "109/109 [==============================] - 0s 223us/step - loss: 0.7557 - mse: 0.7557 - mae: 0.6708 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.5308\n",
      "Epoch 65/100\n",
      "109/109 [==============================] - 0s 282us/step - loss: 0.7536 - mse: 0.7536 - mae: 0.6700 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.5310\n",
      "Epoch 66/100\n",
      "109/109 [==============================] - 0s 904us/step - loss: 0.7517 - mse: 0.7517 - mae: 0.6690 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.5308\n",
      "Epoch 67/100\n",
      "109/109 [==============================] - 0s 401us/step - loss: 0.7500 - mse: 0.7500 - mae: 0.6679 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.5305\n",
      "Epoch 68/100\n",
      "109/109 [==============================] - 0s 576us/step - loss: 0.7482 - mse: 0.7482 - mae: 0.6669 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.5306\n",
      "Epoch 69/100\n",
      "109/109 [==============================] - 0s 269us/step - loss: 0.7459 - mse: 0.7459 - mae: 0.6659 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.5314\n",
      "Epoch 70/100\n",
      "109/109 [==============================] - 0s 706us/step - loss: 0.7438 - mse: 0.7438 - mae: 0.6652 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.5317\n",
      "Epoch 71/100\n",
      "109/109 [==============================] - 0s 388us/step - loss: 0.7419 - mse: 0.7419 - mae: 0.6642 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.5317\n",
      "Epoch 72/100\n",
      "109/109 [==============================] - 0s 220us/step - loss: 0.7396 - mse: 0.7396 - mae: 0.6632 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.5320\n",
      "Epoch 73/100\n",
      "109/109 [==============================] - 0s 219us/step - loss: 0.7375 - mse: 0.7375 - mae: 0.6625 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.5321\n",
      "Epoch 74/100\n",
      "109/109 [==============================] - 0s 493us/step - loss: 0.7356 - mse: 0.7356 - mae: 0.6615 - val_loss: 0.4346 - val_mse: 0.4346 - val_mae: 0.5316\n",
      "Epoch 75/100\n",
      "109/109 [==============================] - 0s 250us/step - loss: 0.7333 - mse: 0.7333 - mae: 0.6602 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.5315\n",
      "Epoch 76/100\n",
      "109/109 [==============================] - 0s 337us/step - loss: 0.7307 - mse: 0.7307 - mae: 0.6589 - val_loss: 0.4334 - val_mse: 0.4334 - val_mae: 0.5313\n",
      "Epoch 77/100\n",
      "109/109 [==============================] - 0s 549us/step - loss: 0.7286 - mse: 0.7286 - mae: 0.6575 - val_loss: 0.4327 - val_mse: 0.4327 - val_mae: 0.5307\n",
      "Epoch 78/100\n",
      "109/109 [==============================] - 0s 279us/step - loss: 0.7257 - mse: 0.7257 - mae: 0.6563 - val_loss: 0.4322 - val_mse: 0.4322 - val_mae: 0.5303\n",
      "Epoch 79/100\n",
      "109/109 [==============================] - 0s 300us/step - loss: 0.7234 - mse: 0.7234 - mae: 0.6554 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.5303\n",
      "Epoch 80/100\n",
      "109/109 [==============================] - 0s 424us/step - loss: 0.7208 - mse: 0.7208 - mae: 0.6542 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.5305\n",
      "Epoch 81/100\n",
      "109/109 [==============================] - 0s 634us/step - loss: 0.7178 - mse: 0.7178 - mae: 0.6526 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.5307\n",
      "Epoch 82/100\n",
      "109/109 [==============================] - 0s 441us/step - loss: 0.7152 - mse: 0.7152 - mae: 0.6512 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.5311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "109/109 [==============================] - 0s 232us/step - loss: 0.7127 - mse: 0.7127 - mae: 0.6501 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.5310\n",
      "Epoch 84/100\n",
      "109/109 [==============================] - 0s 195us/step - loss: 0.7101 - mse: 0.7101 - mae: 0.6494 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.5313\n",
      "Epoch 85/100\n",
      "109/109 [==============================] - 0s 340us/step - loss: 0.7076 - mse: 0.7076 - mae: 0.6483 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.5313\n",
      "Epoch 86/100\n",
      "109/109 [==============================] - 0s 359us/step - loss: 0.7051 - mse: 0.7051 - mae: 0.6470 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.5317\n",
      "Epoch 87/100\n",
      "109/109 [==============================] - 0s 468us/step - loss: 0.7024 - mse: 0.7024 - mae: 0.6457 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.5314\n",
      "Epoch 88/100\n",
      "109/109 [==============================] - 0s 263us/step - loss: 0.7004 - mse: 0.7004 - mae: 0.6452 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.5316\n",
      "Epoch 89/100\n",
      "109/109 [==============================] - 0s 226us/step - loss: 0.6985 - mse: 0.6985 - mae: 0.6446 - val_loss: 0.4320 - val_mse: 0.4320 - val_mae: 0.5319\n",
      "Epoch 90/100\n",
      "109/109 [==============================] - 0s 623us/step - loss: 0.6966 - mse: 0.6966 - mae: 0.6435 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.5322\n",
      "Epoch 91/100\n",
      "109/109 [==============================] - 0s 283us/step - loss: 0.6947 - mse: 0.6947 - mae: 0.6425 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.5330\n",
      "Epoch 92/100\n",
      "109/109 [==============================] - 0s 869us/step - loss: 0.6927 - mse: 0.6927 - mae: 0.6416 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.5338\n",
      "Epoch 93/100\n",
      "109/109 [==============================] - 0s 300us/step - loss: 0.6907 - mse: 0.6907 - mae: 0.6411 - val_loss: 0.4347 - val_mse: 0.4347 - val_mae: 0.5342\n",
      "Epoch 94/100\n",
      "109/109 [==============================] - 0s 525us/step - loss: 0.6889 - mse: 0.6889 - mae: 0.6403 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.5343\n",
      "Epoch 95/100\n",
      "109/109 [==============================] - 0s 500us/step - loss: 0.6868 - mse: 0.6868 - mae: 0.6389 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.5334\n",
      "34\n",
      "[34]\n",
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 12.1256 - mse: 12.1256 - mae: 3.1931 - val_loss: 14.6373 - val_mse: 14.6373 - val_mae: 3.6141\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 592us/step - loss: 10.9628 - mse: 10.9628 - mae: 3.0096 - val_loss: 13.2973 - val_mse: 13.2973 - val_mae: 3.4280\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 552us/step - loss: 9.9550 - mse: 9.9550 - mae: 2.8396 - val_loss: 12.1166 - val_mse: 12.1166 - val_mae: 3.2499\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 689us/step - loss: 9.0365 - mse: 9.0365 - mae: 2.6761 - val_loss: 11.1101 - val_mse: 11.1101 - val_mae: 3.0804\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 213us/step - loss: 8.1494 - mse: 8.1494 - mae: 2.4986 - val_loss: 10.1134 - val_mse: 10.1134 - val_mae: 2.8936\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 422us/step - loss: 7.1633 - mse: 7.1633 - mae: 2.2798 - val_loss: 8.8527 - val_mse: 8.8527 - val_mae: 2.6515\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 597us/step - loss: 5.9582 - mse: 5.9582 - mae: 2.0222 - val_loss: 6.9551 - val_mse: 6.9551 - val_mae: 2.3237\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 292us/step - loss: 4.5336 - mse: 4.5336 - mae: 1.6904 - val_loss: 4.9123 - val_mse: 4.9123 - val_mae: 1.8953\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 392us/step - loss: 3.2609 - mse: 3.2609 - mae: 1.4032 - val_loss: 3.2648 - val_mse: 3.2648 - val_mae: 1.5191\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 418us/step - loss: 2.5606 - mse: 2.5606 - mae: 1.2291 - val_loss: 2.3636 - val_mse: 2.3636 - val_mae: 1.2921\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 428us/step - loss: 2.3727 - mse: 2.3727 - mae: 1.1942 - val_loss: 2.0107 - val_mse: 2.0107 - val_mae: 1.1823\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 472us/step - loss: 2.4509 - mse: 2.4509 - mae: 1.2531 - val_loss: 1.9296 - val_mse: 1.9296 - val_mae: 1.1779\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 695us/step - loss: 2.5430 - mse: 2.5430 - mae: 1.2915 - val_loss: 1.8978 - val_mse: 1.8978 - val_mae: 1.1687\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 282us/step - loss: 2.5300 - mse: 2.5300 - mae: 1.2952 - val_loss: 1.8563 - val_mse: 1.8563 - val_mae: 1.1557\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 373us/step - loss: 2.4305 - mse: 2.4305 - mae: 1.2691 - val_loss: 1.8314 - val_mse: 1.8314 - val_mae: 1.1429\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 488us/step - loss: 2.3126 - mse: 2.3126 - mae: 1.2347 - val_loss: 1.8429 - val_mse: 1.8429 - val_mae: 1.1379\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 398us/step - loss: 2.2234 - mse: 2.2234 - mae: 1.2033 - val_loss: 1.8795 - val_mse: 1.8795 - val_mae: 1.1519\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 283us/step - loss: 2.1684 - mse: 2.1684 - mae: 1.1780 - val_loss: 1.9099 - val_mse: 1.9099 - val_mae: 1.1651\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 366us/step - loss: 2.1314 - mse: 2.1314 - mae: 1.1588 - val_loss: 1.9126 - val_mse: 1.9126 - val_mae: 1.1674\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 233us/step - loss: 2.0989 - mse: 2.0989 - mae: 1.1459 - val_loss: 1.8846 - val_mse: 1.8846 - val_mae: 1.1604\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 251us/step - loss: 2.0672 - mse: 2.0672 - mae: 1.1387 - val_loss: 1.8387 - val_mse: 1.8387 - val_mae: 1.1476\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 531us/step - loss: 2.0391 - mse: 2.0391 - mae: 1.1358 - val_loss: 1.7907 - val_mse: 1.7907 - val_mae: 1.1330\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 323us/step - loss: 2.0146 - mse: 2.0146 - mae: 1.1345 - val_loss: 1.7448 - val_mse: 1.7448 - val_mae: 1.1181\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 291us/step - loss: 1.9935 - mse: 1.9935 - mae: 1.1333 - val_loss: 1.7066 - val_mse: 1.7066 - val_mae: 1.1050\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 412us/step - loss: 1.9748 - mse: 1.9748 - mae: 1.1318 - val_loss: 1.6784 - val_mse: 1.6784 - val_mae: 1.0953\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 336us/step - loss: 1.9561 - mse: 1.9561 - mae: 1.1283 - val_loss: 1.6589 - val_mse: 1.6589 - val_mae: 1.0890\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 731us/step - loss: 1.9368 - mse: 1.9368 - mae: 1.1226 - val_loss: 1.6448 - val_mse: 1.6448 - val_mae: 1.0850\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 391us/step - loss: 1.9178 - mse: 1.9178 - mae: 1.1162 - val_loss: 1.6338 - val_mse: 1.6338 - val_mae: 1.0822\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 818us/step - loss: 1.8994 - mse: 1.8994 - mae: 1.1096 - val_loss: 1.6246 - val_mse: 1.6246 - val_mae: 1.0797\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 451us/step - loss: 1.8820 - mse: 1.8820 - mae: 1.1038 - val_loss: 1.6145 - val_mse: 1.6145 - val_mae: 1.0766\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 204us/step - loss: 1.8653 - mse: 1.8653 - mae: 1.0986 - val_loss: 1.6029 - val_mse: 1.6029 - val_mae: 1.0726\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 205us/step - loss: 1.8494 - mse: 1.8494 - mae: 1.0942 - val_loss: 1.5892 - val_mse: 1.5892 - val_mae: 1.0675\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 359us/step - loss: 1.8340 - mse: 1.8340 - mae: 1.0901 - val_loss: 1.5745 - val_mse: 1.5745 - val_mae: 1.0618\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 223us/step - loss: 1.8197 - mse: 1.8197 - mae: 1.0868 - val_loss: 1.5596 - val_mse: 1.5596 - val_mae: 1.0557\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 853us/step - loss: 1.8059 - mse: 1.8059 - mae: 1.0835 - val_loss: 1.5458 - val_mse: 1.5458 - val_mae: 1.0500\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 400us/step - loss: 1.7930 - mse: 1.7930 - mae: 1.0802 - val_loss: 1.5329 - val_mse: 1.5329 - val_mae: 1.0446\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 413us/step - loss: 1.7804 - mse: 1.7804 - mae: 1.0769 - val_loss: 1.5216 - val_mse: 1.5216 - val_mae: 1.0397\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 389us/step - loss: 1.7682 - mse: 1.7682 - mae: 1.0735 - val_loss: 1.5115 - val_mse: 1.5115 - val_mae: 1.0353\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 450us/step - loss: 1.7565 - mse: 1.7565 - mae: 1.0701 - val_loss: 1.5022 - val_mse: 1.5022 - val_mae: 1.0310\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 416us/step - loss: 1.7455 - mse: 1.7455 - mae: 1.0668 - val_loss: 1.4934 - val_mse: 1.4934 - val_mae: 1.0267\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 418us/step - loss: 1.7346 - mse: 1.7346 - mae: 1.0636 - val_loss: 1.4843 - val_mse: 1.4843 - val_mae: 1.0225\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 0s 429us/step - loss: 1.7243 - mse: 1.7243 - mae: 1.0605 - val_loss: 1.4760 - val_mse: 1.4760 - val_mae: 1.0186\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 0s 582us/step - loss: 1.7150 - mse: 1.7150 - mae: 1.0576 - val_loss: 1.4676 - val_mse: 1.4676 - val_mae: 1.0144\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 0s 358us/step - loss: 1.7054 - mse: 1.7054 - mae: 1.0547 - val_loss: 1.4584 - val_mse: 1.4584 - val_mae: 1.0095\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 0s 572us/step - loss: 1.6967 - mse: 1.6967 - mae: 1.0519 - val_loss: 1.4509 - val_mse: 1.4509 - val_mae: 1.0054\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 0s 719us/step - loss: 1.6884 - mse: 1.6884 - mae: 1.0491 - val_loss: 1.4427 - val_mse: 1.4427 - val_mae: 1.0001\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 0s 350us/step - loss: 1.6797 - mse: 1.6797 - mae: 1.0464 - val_loss: 1.4343 - val_mse: 1.4343 - val_mae: 0.9950\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 0s 810us/step - loss: 1.6717 - mse: 1.6717 - mae: 1.0439 - val_loss: 1.4272 - val_mse: 1.4272 - val_mae: 0.9908\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 0s 525us/step - loss: 1.6639 - mse: 1.6639 - mae: 1.0412 - val_loss: 1.4213 - val_mse: 1.4213 - val_mae: 0.9871\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 0s 470us/step - loss: 1.6562 - mse: 1.6562 - mae: 1.0386 - val_loss: 1.4152 - val_mse: 1.4152 - val_mae: 0.9834\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 0s 275us/step - loss: 1.6488 - mse: 1.6488 - mae: 1.0360 - val_loss: 1.4093 - val_mse: 1.4093 - val_mae: 0.9808\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 0s 424us/step - loss: 1.6419 - mse: 1.6419 - mae: 1.0335 - val_loss: 1.4042 - val_mse: 1.4042 - val_mae: 0.9786\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 0s 476us/step - loss: 1.6351 - mse: 1.6351 - mae: 1.0310 - val_loss: 1.3994 - val_mse: 1.3994 - val_mae: 0.9766\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 0s 373us/step - loss: 1.6285 - mse: 1.6285 - mae: 1.0284 - val_loss: 1.3948 - val_mse: 1.3948 - val_mae: 0.9747\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 0s 340us/step - loss: 1.6222 - mse: 1.6222 - mae: 1.0260 - val_loss: 1.3906 - val_mse: 1.3906 - val_mae: 0.9730\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 0s 348us/step - loss: 1.6165 - mse: 1.6165 - mae: 1.0238 - val_loss: 1.3873 - val_mse: 1.3873 - val_mae: 0.9715\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 0s 351us/step - loss: 1.6106 - mse: 1.6106 - mae: 1.0214 - val_loss: 1.3840 - val_mse: 1.3840 - val_mae: 0.9699\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 0s 292us/step - loss: 1.6054 - mse: 1.6054 - mae: 1.0194 - val_loss: 1.3793 - val_mse: 1.3793 - val_mae: 0.9673\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 0s 303us/step - loss: 1.5998 - mse: 1.5998 - mae: 1.0179 - val_loss: 1.3749 - val_mse: 1.3749 - val_mae: 0.9648\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 0s 280us/step - loss: 1.5949 - mse: 1.5949 - mae: 1.0164 - val_loss: 1.3718 - val_mse: 1.3718 - val_mae: 0.9629\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 0s 386us/step - loss: 1.5897 - mse: 1.5897 - mae: 1.0148 - val_loss: 1.3683 - val_mse: 1.3683 - val_mae: 0.9608\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 0s 593us/step - loss: 1.5847 - mse: 1.5847 - mae: 1.0132 - val_loss: 1.3643 - val_mse: 1.3643 - val_mae: 0.9587\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 0s 417us/step - loss: 1.5799 - mse: 1.5799 - mae: 1.0115 - val_loss: 1.3604 - val_mse: 1.3604 - val_mae: 0.9570\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 0s 744us/step - loss: 1.5752 - mse: 1.5752 - mae: 1.0100 - val_loss: 1.3573 - val_mse: 1.3573 - val_mae: 0.9556\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 0s 224us/step - loss: 1.5708 - mse: 1.5708 - mae: 1.0085 - val_loss: 1.3558 - val_mse: 1.3558 - val_mae: 0.9547\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 0s 441us/step - loss: 1.5667 - mse: 1.5667 - mae: 1.0070 - val_loss: 1.3528 - val_mse: 1.3528 - val_mae: 0.9528\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 0s 515us/step - loss: 1.5618 - mse: 1.5618 - mae: 1.0055 - val_loss: 1.3497 - val_mse: 1.3497 - val_mae: 0.9508\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 0s 399us/step - loss: 1.5575 - mse: 1.5575 - mae: 1.0042 - val_loss: 1.3463 - val_mse: 1.3463 - val_mae: 0.9489\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 0s 519us/step - loss: 1.5534 - mse: 1.5534 - mae: 1.0029 - val_loss: 1.3432 - val_mse: 1.3432 - val_mae: 0.9472\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 0s 358us/step - loss: 1.5495 - mse: 1.5495 - mae: 1.0016 - val_loss: 1.3405 - val_mse: 1.3405 - val_mae: 0.9457\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.3741 - mse: 1.3741 - mae: 0.943 - 0s 253us/step - loss: 1.5455 - mse: 1.5455 - mae: 1.0002 - val_loss: 1.3379 - val_mse: 1.3379 - val_mae: 0.9444\n",
      "Epoch 72/100\n",
      "108/108 [==============================] - 0s 374us/step - loss: 1.5417 - mse: 1.5417 - mae: 0.9989 - val_loss: 1.3362 - val_mse: 1.3362 - val_mae: 0.9434\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 0s 370us/step - loss: 1.5379 - mse: 1.5379 - mae: 0.9975 - val_loss: 1.3332 - val_mse: 1.3332 - val_mae: 0.9418\n",
      "Epoch 74/100\n",
      "108/108 [==============================] - 0s 378us/step - loss: 1.5338 - mse: 1.5338 - mae: 0.9961 - val_loss: 1.3302 - val_mse: 1.3302 - val_mae: 0.9400\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 0s 429us/step - loss: 1.5302 - mse: 1.5302 - mae: 0.9949 - val_loss: 1.3282 - val_mse: 1.3282 - val_mae: 0.9387\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 0s 304us/step - loss: 1.5264 - mse: 1.5264 - mae: 0.9936 - val_loss: 1.3258 - val_mse: 1.3258 - val_mae: 0.9375\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 0s 376us/step - loss: 1.5228 - mse: 1.5228 - mae: 0.9922 - val_loss: 1.3234 - val_mse: 1.3234 - val_mae: 0.9363\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.5196 - mse: 1.5196 - mae: 0.9910 - val_loss: 1.3210 - val_mse: 1.3210 - val_mae: 0.9345\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 0s 329us/step - loss: 1.5157 - mse: 1.5157 - mae: 0.9897 - val_loss: 1.3185 - val_mse: 1.3185 - val_mae: 0.9329\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.5123 - mse: 1.5123 - mae: 0.9886 - val_loss: 1.3166 - val_mse: 1.3166 - val_mae: 0.9318\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 0s 339us/step - loss: 1.5088 - mse: 1.5088 - mae: 0.9873 - val_loss: 1.3160 - val_mse: 1.3160 - val_mae: 0.9313\n",
      "Epoch 82/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.5051 - mse: 1.5051 - mae: 0.9859 - val_loss: 1.3150 - val_mse: 1.3150 - val_mae: 0.9309\n",
      "Epoch 83/100\n",
      "108/108 [==============================] - 0s 638us/step - loss: 1.5014 - mse: 1.5014 - mae: 0.9845 - val_loss: 1.3136 - val_mse: 1.3136 - val_mae: 0.9301\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 293us/step - loss: 1.4979 - mse: 1.4979 - mae: 0.9832 - val_loss: 1.3128 - val_mse: 1.3128 - val_mae: 0.9294\n",
      "Epoch 85/100\n",
      "108/108 [==============================] - 0s 337us/step - loss: 1.4943 - mse: 1.4943 - mae: 0.9818 - val_loss: 1.3120 - val_mse: 1.3120 - val_mae: 0.9288\n",
      "Epoch 86/100\n",
      "108/108 [==============================] - 0s 371us/step - loss: 1.4909 - mse: 1.4909 - mae: 0.9805 - val_loss: 1.3119 - val_mse: 1.3119 - val_mae: 0.9285\n",
      "Epoch 87/100\n",
      "108/108 [==============================] - 0s 497us/step - loss: 1.4873 - mse: 1.4873 - mae: 0.9790 - val_loss: 1.3106 - val_mse: 1.3106 - val_mae: 0.9276\n",
      "Epoch 88/100\n",
      "108/108 [==============================] - 0s 536us/step - loss: 1.4838 - mse: 1.4838 - mae: 0.9777 - val_loss: 1.3089 - val_mse: 1.3089 - val_mae: 0.9267\n",
      "Epoch 89/100\n",
      "108/108 [==============================] - 0s 228us/step - loss: 1.4806 - mse: 1.4806 - mae: 0.9765 - val_loss: 1.3098 - val_mse: 1.3098 - val_mae: 0.9269\n",
      "Epoch 90/100\n",
      "108/108 [==============================] - 0s 233us/step - loss: 1.4773 - mse: 1.4773 - mae: 0.9750 - val_loss: 1.3126 - val_mse: 1.3126 - val_mae: 0.9277\n",
      "Epoch 91/100\n",
      "108/108 [==============================] - 0s 444us/step - loss: 1.4738 - mse: 1.4738 - mae: 0.9734 - val_loss: 1.3109 - val_mse: 1.3109 - val_mae: 0.9271\n",
      "Epoch 92/100\n",
      "108/108 [==============================] - 0s 258us/step - loss: 1.4705 - mse: 1.4705 - mae: 0.9721 - val_loss: 1.3093 - val_mse: 1.3093 - val_mae: 0.9262\n",
      "Epoch 93/100\n",
      "108/108 [==============================] - 0s 272us/step - loss: 1.4671 - mse: 1.4671 - mae: 0.9707 - val_loss: 1.3092 - val_mse: 1.3092 - val_mae: 0.9258\n",
      "Epoch 94/100\n",
      "108/108 [==============================] - 0s 335us/step - loss: 1.4638 - mse: 1.4638 - mae: 0.9694 - val_loss: 1.3095 - val_mse: 1.3095 - val_mae: 0.9255\n",
      "Epoch 95/100\n",
      "108/108 [==============================] - 0s 290us/step - loss: 1.4603 - mse: 1.4603 - mae: 0.9679 - val_loss: 1.3081 - val_mse: 1.3081 - val_mae: 0.9246\n",
      "Epoch 96/100\n",
      "108/108 [==============================] - 0s 600us/step - loss: 1.4571 - mse: 1.4571 - mae: 0.9667 - val_loss: 1.3077 - val_mse: 1.3077 - val_mae: 0.9240\n",
      "Epoch 97/100\n",
      "108/108 [==============================] - 0s 324us/step - loss: 1.4540 - mse: 1.4540 - mae: 0.9655 - val_loss: 1.3081 - val_mse: 1.3081 - val_mae: 0.9237\n",
      "Epoch 98/100\n",
      "108/108 [==============================] - 0s 391us/step - loss: 1.4514 - mse: 1.4514 - mae: 0.9642 - val_loss: 1.3105 - val_mse: 1.3105 - val_mae: 0.9243\n",
      "Epoch 99/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.4481 - mse: 1.4481 - mae: 0.9627 - val_loss: 1.3082 - val_mse: 1.3082 - val_mae: 0.9234\n",
      "Epoch 100/100\n",
      "108/108 [==============================] - 0s 408us/step - loss: 1.4449 - mse: 1.4449 - mae: 0.9614 - val_loss: 1.3067 - val_mse: 1.3067 - val_mae: 0.9226\n",
      "35\n",
      "[35]\n",
      "Train on 97 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 7.8470 - mse: 7.8470 - mae: 2.6416 - val_loss: 8.6477 - val_mse: 8.6477 - val_mae: 2.8139\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 423us/step - loss: 6.6292 - mse: 6.6292 - mae: 2.4047 - val_loss: 7.4344 - val_mse: 7.4344 - val_mae: 2.5949\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 481us/step - loss: 5.7381 - mse: 5.7381 - mae: 2.2146 - val_loss: 6.4805 - val_mse: 6.4805 - val_mae: 2.4088\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 469us/step - loss: 5.0797 - mse: 5.0797 - mae: 2.0653 - val_loss: 5.8415 - val_mse: 5.8415 - val_mae: 2.2759\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 450us/step - loss: 4.5925 - mse: 4.5925 - mae: 1.9509 - val_loss: 5.4168 - val_mse: 5.4168 - val_mae: 2.1828\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 534us/step - loss: 4.2349 - mse: 4.2349 - mae: 1.8622 - val_loss: 5.0695 - val_mse: 5.0695 - val_mae: 2.1026\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 382us/step - loss: 3.9507 - mse: 3.9507 - mae: 1.7869 - val_loss: 4.7878 - val_mse: 4.7878 - val_mae: 2.0299\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 488us/step - loss: 3.7109 - mse: 3.7109 - mae: 1.7177 - val_loss: 4.5404 - val_mse: 4.5404 - val_mae: 1.9582\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 716us/step - loss: 3.4972 - mse: 3.4972 - mae: 1.6495 - val_loss: 4.3002 - val_mse: 4.3002 - val_mae: 1.8809\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 558us/step - loss: 3.2822 - mse: 3.2822 - mae: 1.5746 - val_loss: 3.9715 - val_mse: 3.9715 - val_mae: 1.7730\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 620us/step - loss: 3.0229 - mse: 3.0229 - mae: 1.4736 - val_loss: 3.5284 - val_mse: 3.5284 - val_mae: 1.6209\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 636us/step - loss: 2.6656 - mse: 2.6656 - mae: 1.3275 - val_loss: 2.9437 - val_mse: 2.9437 - val_mae: 1.4548\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 545us/step - loss: 2.2183 - mse: 2.2183 - mae: 1.1379 - val_loss: 2.2666 - val_mse: 2.2666 - val_mae: 1.2706\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 381us/step - loss: 1.7639 - mse: 1.7639 - mae: 0.9467 - val_loss: 1.6957 - val_mse: 1.6957 - val_mae: 1.0572\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 307us/step - loss: 1.4079 - mse: 1.4079 - mae: 0.8265 - val_loss: 1.3608 - val_mse: 1.3608 - val_mae: 0.8655\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 640us/step - loss: 1.2498 - mse: 1.2498 - mae: 0.8115 - val_loss: 1.2578 - val_mse: 1.2578 - val_mae: 0.8000\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 421us/step - loss: 1.2315 - mse: 1.2315 - mae: 0.8484 - val_loss: 1.2392 - val_mse: 1.2392 - val_mae: 0.7693\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 397us/step - loss: 1.2386 - mse: 1.2386 - mae: 0.8706 - val_loss: 1.2181 - val_mse: 1.2181 - val_mae: 0.7597\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 552us/step - loss: 1.2181 - mse: 1.2181 - mae: 0.8672 - val_loss: 1.1799 - val_mse: 1.1799 - val_mae: 0.7505\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 397us/step - loss: 1.1792 - mse: 1.1792 - mae: 0.8455 - val_loss: 1.1473 - val_mse: 1.1473 - val_mae: 0.7535\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 503us/step - loss: 1.1448 - mse: 1.1448 - mae: 0.8187 - val_loss: 1.1346 - val_mse: 1.1346 - val_mae: 0.7608\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 532us/step - loss: 1.1235 - mse: 1.1235 - mae: 0.7958 - val_loss: 1.1343 - val_mse: 1.1343 - val_mae: 0.7644\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 417us/step - loss: 1.1135 - mse: 1.1135 - mae: 0.7805 - val_loss: 1.1331 - val_mse: 1.1331 - val_mae: 0.7711\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 332us/step - loss: 1.1054 - mse: 1.1054 - mae: 0.7711 - val_loss: 1.1231 - val_mse: 1.1231 - val_mae: 0.7727\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 389us/step - loss: 1.0934 - mse: 1.0934 - mae: 0.7652 - val_loss: 1.1032 - val_mse: 1.1032 - val_mae: 0.7650\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 605us/step - loss: 1.0773 - mse: 1.0773 - mae: 0.7619 - val_loss: 1.0779 - val_mse: 1.0779 - val_mae: 0.7530\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 330us/step - loss: 1.0596 - mse: 1.0596 - mae: 0.7607 - val_loss: 1.0518 - val_mse: 1.0518 - val_mae: 0.7390\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 318us/step - loss: 1.0428 - mse: 1.0428 - mae: 0.7605 - val_loss: 1.0288 - val_mse: 1.0288 - val_mae: 0.7257\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 444us/step - loss: 1.0278 - mse: 1.0278 - mae: 0.7603 - val_loss: 1.0099 - val_mse: 1.0099 - val_mae: 0.7148\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 389us/step - loss: 1.0146 - mse: 1.0146 - mae: 0.7590 - val_loss: 0.9949 - val_mse: 0.9949 - val_mae: 0.7089\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 581us/step - loss: 1.0025 - mse: 1.0025 - mae: 0.7563 - val_loss: 0.9832 - val_mse: 0.9832 - val_mae: 0.7052\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 515us/step - loss: 0.9910 - mse: 0.9910 - mae: 0.7524 - val_loss: 0.9739 - val_mse: 0.9739 - val_mae: 0.7029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 567us/step - loss: 0.9800 - mse: 0.9800 - mae: 0.7479 - val_loss: 0.9658 - val_mse: 0.9658 - val_mae: 0.7012\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 519us/step - loss: 0.9691 - mse: 0.9691 - mae: 0.7431 - val_loss: 0.9582 - val_mse: 0.9582 - val_mae: 0.6992\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 532us/step - loss: 0.9582 - mse: 0.9582 - mae: 0.7387 - val_loss: 0.9501 - val_mse: 0.9501 - val_mae: 0.6964\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 445us/step - loss: 0.9472 - mse: 0.9472 - mae: 0.7350 - val_loss: 0.9416 - val_mse: 0.9416 - val_mae: 0.6930\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 474us/step - loss: 0.9359 - mse: 0.9359 - mae: 0.7317 - val_loss: 0.9327 - val_mse: 0.9327 - val_mae: 0.6889\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 395us/step - loss: 0.9245 - mse: 0.9245 - mae: 0.7287 - val_loss: 0.9238 - val_mse: 0.9238 - val_mae: 0.6846\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 367us/step - loss: 0.9130 - mse: 0.9130 - mae: 0.7260 - val_loss: 0.9152 - val_mse: 0.9152 - val_mae: 0.6799\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 408us/step - loss: 0.9014 - mse: 0.9014 - mae: 0.7235 - val_loss: 0.9070 - val_mse: 0.9070 - val_mae: 0.6750\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 482us/step - loss: 0.8900 - mse: 0.8900 - mae: 0.7211 - val_loss: 0.9004 - val_mse: 0.9004 - val_mae: 0.6707\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 320us/step - loss: 0.8790 - mse: 0.8790 - mae: 0.7187 - val_loss: 0.8947 - val_mse: 0.8947 - val_mae: 0.6668\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 482us/step - loss: 0.8683 - mse: 0.8683 - mae: 0.7158 - val_loss: 0.8885 - val_mse: 0.8885 - val_mae: 0.6628\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 394us/step - loss: 0.8578 - mse: 0.8578 - mae: 0.7126 - val_loss: 0.8829 - val_mse: 0.8829 - val_mae: 0.6590\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 487us/step - loss: 0.8476 - mse: 0.8476 - mae: 0.7094 - val_loss: 0.8780 - val_mse: 0.8780 - val_mae: 0.6551\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 345us/step - loss: 0.8381 - mse: 0.8381 - mae: 0.7062 - val_loss: 0.8735 - val_mse: 0.8735 - val_mae: 0.6512\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 296us/step - loss: 0.8289 - mse: 0.8289 - mae: 0.7033 - val_loss: 0.8692 - val_mse: 0.8692 - val_mae: 0.6470\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 329us/step - loss: 0.8200 - mse: 0.8200 - mae: 0.7006 - val_loss: 0.8652 - val_mse: 0.8652 - val_mae: 0.6423\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 376us/step - loss: 0.8116 - mse: 0.8116 - mae: 0.6984 - val_loss: 0.8611 - val_mse: 0.8611 - val_mae: 0.6378\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 317us/step - loss: 0.8037 - mse: 0.8037 - mae: 0.6965 - val_loss: 0.8568 - val_mse: 0.8568 - val_mae: 0.6337\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 384us/step - loss: 0.7963 - mse: 0.7963 - mae: 0.6947 - val_loss: 0.8519 - val_mse: 0.8519 - val_mae: 0.6295\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 0s 397us/step - loss: 0.7893 - mse: 0.7893 - mae: 0.6929 - val_loss: 0.8473 - val_mse: 0.8473 - val_mae: 0.6254\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 0s 406us/step - loss: 0.7828 - mse: 0.7828 - mae: 0.6912 - val_loss: 0.8429 - val_mse: 0.8429 - val_mae: 0.6211\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 0s 497us/step - loss: 0.7767 - mse: 0.7767 - mae: 0.6899 - val_loss: 0.8386 - val_mse: 0.8386 - val_mae: 0.6172\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 0s 486us/step - loss: 0.7709 - mse: 0.7709 - mae: 0.6884 - val_loss: 0.8347 - val_mse: 0.8347 - val_mae: 0.6139\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 0s 510us/step - loss: 0.7653 - mse: 0.7653 - mae: 0.6868 - val_loss: 0.8313 - val_mse: 0.8313 - val_mae: 0.6109\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 0s 484us/step - loss: 0.7600 - mse: 0.7600 - mae: 0.6850 - val_loss: 0.8284 - val_mse: 0.8284 - val_mae: 0.6083\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 0s 568us/step - loss: 0.7550 - mse: 0.7550 - mae: 0.6833 - val_loss: 0.8249 - val_mse: 0.8249 - val_mae: 0.6065\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 0s 432us/step - loss: 0.7506 - mse: 0.7506 - mae: 0.6820 - val_loss: 0.8207 - val_mse: 0.8207 - val_mae: 0.6052\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 0s 430us/step - loss: 0.7465 - mse: 0.7465 - mae: 0.6808 - val_loss: 0.8167 - val_mse: 0.8167 - val_mae: 0.6037\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 0s 328us/step - loss: 0.7426 - mse: 0.7426 - mae: 0.6798 - val_loss: 0.8127 - val_mse: 0.8127 - val_mae: 0.6016\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 0s 414us/step - loss: 0.7387 - mse: 0.7387 - mae: 0.6790 - val_loss: 0.8088 - val_mse: 0.8088 - val_mae: 0.5994\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 0s 393us/step - loss: 0.7348 - mse: 0.7348 - mae: 0.6784 - val_loss: 0.8051 - val_mse: 0.8051 - val_mae: 0.5970\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 0s 255us/step - loss: 0.7310 - mse: 0.7310 - mae: 0.6777 - val_loss: 0.8018 - val_mse: 0.8018 - val_mae: 0.5950\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 0s 307us/step - loss: 0.7274 - mse: 0.7274 - mae: 0.6768 - val_loss: 0.7989 - val_mse: 0.7989 - val_mae: 0.5940\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 0s 413us/step - loss: 0.7240 - mse: 0.7240 - mae: 0.6757 - val_loss: 0.7963 - val_mse: 0.7963 - val_mae: 0.5934\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 0s 440us/step - loss: 0.7209 - mse: 0.7209 - mae: 0.6745 - val_loss: 0.7937 - val_mse: 0.7937 - val_mae: 0.5925\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 0s 762us/step - loss: 0.7179 - mse: 0.7179 - mae: 0.6733 - val_loss: 0.7917 - val_mse: 0.7917 - val_mae: 0.5919\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 0s 409us/step - loss: 0.7153 - mse: 0.7153 - mae: 0.6721 - val_loss: 0.7901 - val_mse: 0.7901 - val_mae: 0.5914\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 0s 679us/step - loss: 0.7127 - mse: 0.7127 - mae: 0.6708 - val_loss: 0.7887 - val_mse: 0.7887 - val_mae: 0.5909\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 0s 277us/step - loss: 0.7102 - mse: 0.7102 - mae: 0.6695 - val_loss: 0.7874 - val_mse: 0.7874 - val_mae: 0.5904\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 0s 392us/step - loss: 0.7077 - mse: 0.7077 - mae: 0.6682 - val_loss: 0.7857 - val_mse: 0.7857 - val_mae: 0.5895\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 0s 539us/step - loss: 0.7049 - mse: 0.7049 - mae: 0.6672 - val_loss: 0.7839 - val_mse: 0.7839 - val_mae: 0.5886\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 0s 259us/step - loss: 0.7023 - mse: 0.7023 - mae: 0.6663 - val_loss: 0.7820 - val_mse: 0.7820 - val_mae: 0.5876\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 0s 371us/step - loss: 0.6996 - mse: 0.6996 - mae: 0.6652 - val_loss: 0.7803 - val_mse: 0.7803 - val_mae: 0.5868\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 0s 415us/step - loss: 0.6972 - mse: 0.6972 - mae: 0.6640 - val_loss: 0.7794 - val_mse: 0.7794 - val_mae: 0.5866\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 0s 338us/step - loss: 0.6949 - mse: 0.6949 - mae: 0.6626 - val_loss: 0.7788 - val_mse: 0.7788 - val_mae: 0.5866\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 0s 298us/step - loss: 0.6928 - mse: 0.6928 - mae: 0.6610 - val_loss: 0.7787 - val_mse: 0.7787 - val_mae: 0.5868\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 0s 350us/step - loss: 0.6908 - mse: 0.6908 - mae: 0.6596 - val_loss: 0.7785 - val_mse: 0.7785 - val_mae: 0.5867\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 0s 379us/step - loss: 0.6887 - mse: 0.6887 - mae: 0.6583 - val_loss: 0.7781 - val_mse: 0.7781 - val_mae: 0.5865\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 0s 586us/step - loss: 0.6866 - mse: 0.6866 - mae: 0.6569 - val_loss: 0.7778 - val_mse: 0.7778 - val_mae: 0.5865\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 0s 565us/step - loss: 0.6846 - mse: 0.6846 - mae: 0.6554 - val_loss: 0.7775 - val_mse: 0.7775 - val_mae: 0.5863\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 0s 644us/step - loss: 0.6826 - mse: 0.6826 - mae: 0.6540 - val_loss: 0.7770 - val_mse: 0.7770 - val_mae: 0.5859\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 0s 256us/step - loss: 0.6805 - mse: 0.6805 - mae: 0.6528 - val_loss: 0.7765 - val_mse: 0.7765 - val_mae: 0.5856\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 0s 374us/step - loss: 0.6784 - mse: 0.6784 - mae: 0.6518 - val_loss: 0.7756 - val_mse: 0.7756 - val_mae: 0.5852\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 0s 340us/step - loss: 0.6762 - mse: 0.6762 - mae: 0.6507 - val_loss: 0.7748 - val_mse: 0.7748 - val_mae: 0.5848\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 0s 382us/step - loss: 0.6738 - mse: 0.6738 - mae: 0.6493 - val_loss: 0.7748 - val_mse: 0.7748 - val_mae: 0.5850\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 0s 653us/step - loss: 0.6718 - mse: 0.6718 - mae: 0.6477 - val_loss: 0.7752 - val_mse: 0.7752 - val_mae: 0.5855\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 0s 305us/step - loss: 0.6698 - mse: 0.6698 - mae: 0.6463 - val_loss: 0.7753 - val_mse: 0.7753 - val_mae: 0.5857\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 0s 405us/step - loss: 0.6679 - mse: 0.6679 - mae: 0.6451 - val_loss: 0.7753 - val_mse: 0.7753 - val_mae: 0.5857\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 0s 418us/step - loss: 0.6660 - mse: 0.6660 - mae: 0.6437 - val_loss: 0.7755 - val_mse: 0.7755 - val_mae: 0.5860\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 0s 421us/step - loss: 0.6642 - mse: 0.6642 - mae: 0.6422 - val_loss: 0.7754 - val_mse: 0.7754 - val_mae: 0.5860\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 0s 276us/step - loss: 0.6623 - mse: 0.6623 - mae: 0.6411 - val_loss: 0.7749 - val_mse: 0.7749 - val_mae: 0.5856\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 0s 491us/step - loss: 0.6602 - mse: 0.6602 - mae: 0.6403 - val_loss: 0.7751 - val_mse: 0.7751 - val_mae: 0.5857\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 0s 285us/step - loss: 0.6583 - mse: 0.6583 - mae: 0.6390 - val_loss: 0.7761 - val_mse: 0.7761 - val_mae: 0.5864\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 0s 329us/step - loss: 0.6566 - mse: 0.6566 - mae: 0.6373 - val_loss: 0.7772 - val_mse: 0.7772 - val_mae: 0.5871\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 0s 404us/step - loss: 0.6548 - mse: 0.6548 - mae: 0.6358 - val_loss: 0.7778 - val_mse: 0.7778 - val_mae: 0.5870\n",
      "36\n",
      "[36]\n",
      "Train on 112 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 18.2584 - mse: 18.2584 - mae: 3.9033 - val_loss: 18.2290 - val_mse: 18.2290 - val_mae: 4.0040\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 423us/step - loss: 12.2486 - mse: 12.2486 - mae: 3.0654 - val_loss: 11.4784 - val_mse: 11.4784 - val_mae: 3.1168\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 280us/step - loss: 7.9005 - mse: 7.9005 - mae: 2.2916 - val_loss: 6.9814 - val_mse: 6.9814 - val_mae: 2.3430\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 302us/step - loss: 5.1292 - mse: 5.1292 - mae: 1.7345 - val_loss: 4.2802 - val_mse: 4.2802 - val_mae: 1.7297\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 245us/step - loss: 3.5717 - mse: 3.5717 - mae: 1.3931 - val_loss: 3.0313 - val_mse: 3.0313 - val_mae: 1.3857\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 206us/step - loss: 2.8026 - mse: 2.8026 - mae: 1.2352 - val_loss: 2.4929 - val_mse: 2.4929 - val_mae: 1.2333\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 453us/step - loss: 2.5108 - mse: 2.5108 - mae: 1.1891 - val_loss: 2.3304 - val_mse: 2.3304 - val_mae: 1.2027\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 424us/step - loss: 2.4364 - mse: 2.4364 - mae: 1.1925 - val_loss: 2.3295 - val_mse: 2.3295 - val_mae: 1.2011\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 499us/step - loss: 2.4192 - mse: 2.4192 - mae: 1.2038 - val_loss: 2.3506 - val_mse: 2.3506 - val_mae: 1.2140\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 251us/step - loss: 2.3780 - mse: 2.3780 - mae: 1.1961 - val_loss: 2.3564 - val_mse: 2.3564 - val_mae: 1.2102\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 299us/step - loss: 2.3168 - mse: 2.3168 - mae: 1.1763 - val_loss: 2.3529 - val_mse: 2.3529 - val_mae: 1.1976\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 419us/step - loss: 2.2496 - mse: 2.2496 - mae: 1.1554 - val_loss: 2.3676 - val_mse: 2.3676 - val_mae: 1.1871\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 404us/step - loss: 2.1855 - mse: 2.1855 - mae: 1.1345 - val_loss: 2.3966 - val_mse: 2.3966 - val_mae: 1.1828\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 425us/step - loss: 2.1391 - mse: 2.1391 - mae: 1.1180 - val_loss: 2.4339 - val_mse: 2.4339 - val_mae: 1.1786\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 424us/step - loss: 2.1135 - mse: 2.1135 - mae: 1.1088 - val_loss: 2.4583 - val_mse: 2.4583 - val_mae: 1.1803\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 381us/step - loss: 2.0954 - mse: 2.0954 - mae: 1.1051 - val_loss: 2.4648 - val_mse: 2.4648 - val_mae: 1.1797\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 380us/step - loss: 2.0746 - mse: 2.0746 - mae: 1.1012 - val_loss: 2.4569 - val_mse: 2.4569 - val_mae: 1.1752\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 394us/step - loss: 2.0521 - mse: 2.0521 - mae: 1.0975 - val_loss: 2.4423 - val_mse: 2.4423 - val_mae: 1.1758\n",
      "37\n",
      "[37]\n",
      "Train on 84 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.5455 - mse: 1.5455 - mae: 0.9145 - val_loss: 0.2657 - val_mse: 0.2657 - val_mae: 0.4099\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 592us/step - loss: 1.3621 - mse: 1.3621 - mae: 0.8350 - val_loss: 0.2344 - val_mse: 0.2344 - val_mae: 0.3706\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 441us/step - loss: 1.2966 - mse: 1.2966 - mae: 0.8071 - val_loss: 0.2383 - val_mse: 0.2383 - val_mae: 0.3568\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 398us/step - loss: 1.2726 - mse: 1.2726 - mae: 0.7885 - val_loss: 0.2408 - val_mse: 0.2408 - val_mae: 0.3511\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 413us/step - loss: 1.2459 - mse: 1.2459 - mae: 0.7725 - val_loss: 0.2323 - val_mse: 0.2323 - val_mae: 0.3418\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 414us/step - loss: 1.2080 - mse: 1.2080 - mae: 0.7578 - val_loss: 0.2173 - val_mse: 0.2173 - val_mae: 0.3298\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 455us/step - loss: 1.1665 - mse: 1.1665 - mae: 0.7448 - val_loss: 0.2041 - val_mse: 0.2041 - val_mae: 0.3190\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 269us/step - loss: 1.1313 - mse: 1.1313 - mae: 0.7385 - val_loss: 0.1964 - val_mse: 0.1964 - val_mae: 0.3147\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 243us/step - loss: 1.1053 - mse: 1.1053 - mae: 0.7433 - val_loss: 0.1926 - val_mse: 0.1926 - val_mae: 0.3129\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 686us/step - loss: 1.0838 - mse: 1.0838 - mae: 0.7465 - val_loss: 0.1894 - val_mse: 0.1894 - val_mae: 0.3096\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 271us/step - loss: 1.0621 - mse: 1.0621 - mae: 0.7446 - val_loss: 0.1850 - val_mse: 0.1850 - val_mae: 0.3033\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 732us/step - loss: 1.0399 - mse: 1.0399 - mae: 0.7383 - val_loss: 0.1797 - val_mse: 0.1797 - val_mae: 0.2960\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 336us/step - loss: 1.0183 - mse: 1.0183 - mae: 0.7293 - val_loss: 0.1758 - val_mse: 0.1758 - val_mae: 0.2893\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 562us/step - loss: 0.9986 - mse: 0.9986 - mae: 0.7198 - val_loss: 0.1730 - val_mse: 0.1730 - val_mae: 0.2824\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 260us/step - loss: 0.9809 - mse: 0.9809 - mae: 0.7107 - val_loss: 0.1705 - val_mse: 0.1705 - val_mae: 0.2780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 509us/step - loss: 0.9643 - mse: 0.9643 - mae: 0.7037 - val_loss: 0.1680 - val_mse: 0.1680 - val_mae: 0.2763\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 258us/step - loss: 0.9485 - mse: 0.9485 - mae: 0.6992 - val_loss: 0.1655 - val_mse: 0.1655 - val_mae: 0.2766\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 467us/step - loss: 0.9336 - mse: 0.9336 - mae: 0.6966 - val_loss: 0.1634 - val_mse: 0.1634 - val_mae: 0.2781\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 263us/step - loss: 0.9196 - mse: 0.9196 - mae: 0.6950 - val_loss: 0.1615 - val_mse: 0.1615 - val_mae: 0.2807\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 364us/step - loss: 0.9066 - mse: 0.9066 - mae: 0.6941 - val_loss: 0.1599 - val_mse: 0.1599 - val_mae: 0.2825\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.8945 - mse: 0.8945 - mae: 0.6920 - val_loss: 0.1581 - val_mse: 0.1581 - val_mae: 0.2823\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 353us/step - loss: 0.8830 - mse: 0.8830 - mae: 0.6883 - val_loss: 0.1562 - val_mse: 0.1562 - val_mae: 0.2801\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 300us/step - loss: 0.8717 - mse: 0.8717 - mae: 0.6834 - val_loss: 0.1543 - val_mse: 0.1543 - val_mae: 0.2771\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 395us/step - loss: 0.8608 - mse: 0.8608 - mae: 0.6777 - val_loss: 0.1525 - val_mse: 0.1525 - val_mae: 0.2740\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 377us/step - loss: 0.8507 - mse: 0.8507 - mae: 0.6722 - val_loss: 0.1508 - val_mse: 0.1508 - val_mae: 0.2716\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 323us/step - loss: 0.8416 - mse: 0.8416 - mae: 0.6681 - val_loss: 0.1494 - val_mse: 0.1494 - val_mae: 0.2708\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 460us/step - loss: 0.8330 - mse: 0.8330 - mae: 0.6652 - val_loss: 0.1482 - val_mse: 0.1482 - val_mae: 0.2705\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 341us/step - loss: 0.8247 - mse: 0.8247 - mae: 0.6629 - val_loss: 0.1468 - val_mse: 0.1468 - val_mae: 0.2710\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 407us/step - loss: 0.8166 - mse: 0.8166 - mae: 0.6607 - val_loss: 0.1456 - val_mse: 0.1456 - val_mae: 0.2720\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 378us/step - loss: 0.8092 - mse: 0.8092 - mae: 0.6586 - val_loss: 0.1445 - val_mse: 0.1445 - val_mae: 0.2730\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 843us/step - loss: 0.8023 - mse: 0.8023 - mae: 0.6568 - val_loss: 0.1435 - val_mse: 0.1435 - val_mae: 0.2735\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 242us/step - loss: 0.7959 - mse: 0.7959 - mae: 0.6545 - val_loss: 0.1424 - val_mse: 0.1424 - val_mae: 0.2733\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 806us/step - loss: 0.7895 - mse: 0.7895 - mae: 0.6513 - val_loss: 0.1410 - val_mse: 0.1410 - val_mae: 0.2726\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 263us/step - loss: 0.7832 - mse: 0.7832 - mae: 0.6477 - val_loss: 0.1396 - val_mse: 0.1396 - val_mae: 0.2721\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 490us/step - loss: 0.7771 - mse: 0.7771 - mae: 0.6443 - val_loss: 0.1386 - val_mse: 0.1386 - val_mae: 0.2722\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 517us/step - loss: 0.7713 - mse: 0.7713 - mae: 0.6417 - val_loss: 0.1382 - val_mse: 0.1382 - val_mae: 0.2730\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 465us/step - loss: 0.7652 - mse: 0.7652 - mae: 0.6395 - val_loss: 0.1379 - val_mse: 0.1379 - val_mae: 0.2741\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 438us/step - loss: 0.7595 - mse: 0.7595 - mae: 0.6373 - val_loss: 0.1379 - val_mse: 0.1379 - val_mae: 0.2750\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7539 - mse: 0.7539 - mae: 0.6347 - val_loss: 0.1378 - val_mse: 0.1378 - val_mae: 0.2756\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 420us/step - loss: 0.7484 - mse: 0.7484 - mae: 0.6318 - val_loss: 0.1375 - val_mse: 0.1375 - val_mae: 0.2757\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 427us/step - loss: 0.7428 - mse: 0.7428 - mae: 0.6290 - val_loss: 0.1370 - val_mse: 0.1370 - val_mae: 0.2753\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 449us/step - loss: 0.7372 - mse: 0.7372 - mae: 0.6261 - val_loss: 0.1365 - val_mse: 0.1365 - val_mae: 0.2755\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 450us/step - loss: 0.7316 - mse: 0.7316 - mae: 0.6234 - val_loss: 0.1367 - val_mse: 0.1367 - val_mae: 0.2770\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 427us/step - loss: 0.7261 - mse: 0.7261 - mae: 0.6212 - val_loss: 0.1369 - val_mse: 0.1369 - val_mae: 0.2788\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 392us/step - loss: 0.7206 - mse: 0.7206 - mae: 0.6188 - val_loss: 0.1370 - val_mse: 0.1370 - val_mae: 0.2802\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 414us/step - loss: 0.7156 - mse: 0.7156 - mae: 0.6169 - val_loss: 0.1375 - val_mse: 0.1375 - val_mae: 0.2819\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 399us/step - loss: 0.7105 - mse: 0.7105 - mae: 0.6151 - val_loss: 0.1376 - val_mse: 0.1376 - val_mae: 0.2828\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7054 - mse: 0.7054 - mae: 0.6129 - val_loss: 0.1370 - val_mse: 0.1370 - val_mae: 0.2826\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 547us/step - loss: 0.7004 - mse: 0.7004 - mae: 0.6099 - val_loss: 0.1357 - val_mse: 0.1357 - val_mae: 0.2815\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 387us/step - loss: 0.6955 - mse: 0.6955 - mae: 0.6065 - val_loss: 0.1346 - val_mse: 0.1346 - val_mae: 0.2806\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 412us/step - loss: 0.6905 - mse: 0.6905 - mae: 0.6035 - val_loss: 0.1343 - val_mse: 0.1343 - val_mae: 0.2810\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 420us/step - loss: 0.6855 - mse: 0.6855 - mae: 0.6014 - val_loss: 0.1349 - val_mse: 0.1349 - val_mae: 0.2831\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 408us/step - loss: 0.6806 - mse: 0.6806 - mae: 0.6003 - val_loss: 0.1362 - val_mse: 0.1362 - val_mae: 0.2863\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 502us/step - loss: 0.6751 - mse: 0.6751 - mae: 0.5989 - val_loss: 0.1360 - val_mse: 0.1360 - val_mae: 0.2870\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 602us/step - loss: 0.6694 - mse: 0.6694 - mae: 0.5960 - val_loss: 0.1346 - val_mse: 0.1346 - val_mae: 0.2857\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 616us/step - loss: 0.6636 - mse: 0.6636 - mae: 0.5919 - val_loss: 0.1324 - val_mse: 0.1324 - val_mae: 0.2836\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 525us/step - loss: 0.6584 - mse: 0.6584 - mae: 0.5883 - val_loss: 0.1322 - val_mse: 0.1322 - val_mae: 0.2847\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 438us/step - loss: 0.6527 - mse: 0.6527 - mae: 0.5860 - val_loss: 0.1333 - val_mse: 0.1333 - val_mae: 0.2874\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 505us/step - loss: 0.6461 - mse: 0.6461 - mae: 0.5833 - val_loss: 0.1332 - val_mse: 0.1332 - val_mae: 0.2884\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 470us/step - loss: 0.6383 - mse: 0.6383 - mae: 0.5793 - val_loss: 0.1332 - val_mse: 0.1332 - val_mae: 0.2889\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 799us/step - loss: 0.6307 - mse: 0.6307 - mae: 0.5758 - val_loss: 0.1343 - val_mse: 0.1343 - val_mae: 0.2906\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 358us/step - loss: 0.6242 - mse: 0.6242 - mae: 0.5736 - val_loss: 0.1367 - val_mse: 0.1367 - val_mae: 0.2943\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 355us/step - loss: 0.6188 - mse: 0.6188 - mae: 0.5718 - val_loss: 0.1382 - val_mse: 0.1382 - val_mae: 0.2967\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 375us/step - loss: 0.6132 - mse: 0.6132 - mae: 0.5695 - val_loss: 0.1394 - val_mse: 0.1394 - val_mae: 0.2989\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 423us/step - loss: 0.6062 - mse: 0.6062 - mae: 0.5667 - val_loss: 0.1399 - val_mse: 0.1399 - val_mae: 0.2992\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 366us/step - loss: 0.5998 - mse: 0.5998 - mae: 0.5624 - val_loss: 0.1384 - val_mse: 0.1384 - val_mae: 0.2970\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 399us/step - loss: 0.5942 - mse: 0.5942 - mae: 0.5568 - val_loss: 0.1371 - val_mse: 0.1371 - val_mae: 0.2950\n",
      "38\n",
      "[38]\n",
      "Train on 96 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 1.6896 - mse: 1.6896 - mae: 1.0253 - val_loss: 1.4655 - val_mse: 1.4655 - val_mae: 1.0290\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 298us/step - loss: 1.3874 - mse: 1.3874 - mae: 0.9121 - val_loss: 1.4208 - val_mse: 1.4208 - val_mae: 1.0330\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 337us/step - loss: 1.2938 - mse: 1.2938 - mae: 0.8604 - val_loss: 1.4136 - val_mse: 1.4136 - val_mae: 1.0261\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 257us/step - loss: 1.2428 - mse: 1.2428 - mae: 0.8334 - val_loss: 1.3750 - val_mse: 1.3750 - val_mae: 1.0119\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 286us/step - loss: 1.1840 - mse: 1.1840 - mae: 0.8122 - val_loss: 1.3223 - val_mse: 1.3223 - val_mae: 0.9946\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 289us/step - loss: 1.1293 - mse: 1.1293 - mae: 0.7964 - val_loss: 1.2764 - val_mse: 1.2764 - val_mae: 0.9778\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.3678 - mse: 1.3678 - mae: 0.882 - 0s 275us/step - loss: 1.0901 - mse: 1.0901 - mae: 0.7885 - val_loss: 1.2475 - val_mse: 1.2475 - val_mae: 0.9638\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 279us/step - loss: 1.0631 - mse: 1.0631 - mae: 0.7857 - val_loss: 1.2261 - val_mse: 1.2261 - val_mae: 0.9552\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 733us/step - loss: 1.0395 - mse: 1.0395 - mae: 0.7797 - val_loss: 1.2084 - val_mse: 1.2084 - val_mae: 0.9483\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 267us/step - loss: 1.0141 - mse: 1.0141 - mae: 0.7688 - val_loss: 1.1942 - val_mse: 1.1942 - val_mae: 0.9420\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 299us/step - loss: 0.9891 - mse: 0.9891 - mae: 0.7554 - val_loss: 1.1813 - val_mse: 1.1813 - val_mae: 0.9358\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 304us/step - loss: 0.9674 - mse: 0.9674 - mae: 0.7429 - val_loss: 1.1689 - val_mse: 1.1689 - val_mae: 0.9301\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 352us/step - loss: 0.9485 - mse: 0.9485 - mae: 0.7327 - val_loss: 1.1583 - val_mse: 1.1583 - val_mae: 0.9254\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 469us/step - loss: 0.9312 - mse: 0.9312 - mae: 0.7248 - val_loss: 1.1450 - val_mse: 1.1450 - val_mae: 0.9203\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 556us/step - loss: 0.9151 - mse: 0.9151 - mae: 0.7193 - val_loss: 1.1299 - val_mse: 1.1299 - val_mae: 0.9146\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 574us/step - loss: 0.9009 - mse: 0.9009 - mae: 0.7151 - val_loss: 1.1154 - val_mse: 1.1154 - val_mae: 0.9100\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 397us/step - loss: 0.8881 - mse: 0.8881 - mae: 0.7111 - val_loss: 1.1014 - val_mse: 1.1014 - val_mae: 0.9054\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 460us/step - loss: 0.8768 - mse: 0.8768 - mae: 0.7074 - val_loss: 1.0879 - val_mse: 1.0879 - val_mae: 0.9000\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 383us/step - loss: 0.8663 - mse: 0.8663 - mae: 0.7030 - val_loss: 1.0726 - val_mse: 1.0726 - val_mae: 0.8940\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 392us/step - loss: 0.8563 - mse: 0.8563 - mae: 0.6984 - val_loss: 1.0551 - val_mse: 1.0551 - val_mae: 0.8873\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 414us/step - loss: 0.8469 - mse: 0.8469 - mae: 0.6941 - val_loss: 1.0404 - val_mse: 1.0404 - val_mae: 0.8812\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.8379 - mse: 0.8379 - mae: 0.6898 - val_loss: 1.0281 - val_mse: 1.0281 - val_mae: 0.8759\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 390us/step - loss: 0.8286 - mse: 0.8286 - mae: 0.6857 - val_loss: 1.0126 - val_mse: 1.0126 - val_mae: 0.8695\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 688us/step - loss: 0.8202 - mse: 0.8202 - mae: 0.6824 - val_loss: 0.9995 - val_mse: 0.9995 - val_mae: 0.8633\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 694us/step - loss: 0.8123 - mse: 0.8123 - mae: 0.6791 - val_loss: 0.9873 - val_mse: 0.9873 - val_mae: 0.8571\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 486us/step - loss: 0.8049 - mse: 0.8049 - mae: 0.6758 - val_loss: 0.9763 - val_mse: 0.9763 - val_mae: 0.8512\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 510us/step - loss: 0.7977 - mse: 0.7977 - mae: 0.6722 - val_loss: 0.9654 - val_mse: 0.9654 - val_mae: 0.8453\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 408us/step - loss: 0.7905 - mse: 0.7905 - mae: 0.6686 - val_loss: 0.9541 - val_mse: 0.9541 - val_mae: 0.8393\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 511us/step - loss: 0.7836 - mse: 0.7836 - mae: 0.6653 - val_loss: 0.9420 - val_mse: 0.9420 - val_mae: 0.8332\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.7766 - mse: 0.7766 - mae: 0.6622 - val_loss: 0.9307 - val_mse: 0.9307 - val_mae: 0.8275\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 658us/step - loss: 0.7702 - mse: 0.7702 - mae: 0.6594 - val_loss: 0.9203 - val_mse: 0.9203 - val_mae: 0.8222\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 530us/step - loss: 0.7640 - mse: 0.7640 - mae: 0.6567 - val_loss: 0.9103 - val_mse: 0.9103 - val_mae: 0.8171\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 630us/step - loss: 0.7581 - mse: 0.7581 - mae: 0.6543 - val_loss: 0.9013 - val_mse: 0.9013 - val_mae: 0.8124\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 629us/step - loss: 0.7524 - mse: 0.7524 - mae: 0.6514 - val_loss: 0.8927 - val_mse: 0.8927 - val_mae: 0.8082\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 440us/step - loss: 0.7469 - mse: 0.7469 - mae: 0.6490 - val_loss: 0.8837 - val_mse: 0.8837 - val_mae: 0.8041\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 596us/step - loss: 0.7416 - mse: 0.7416 - mae: 0.6472 - val_loss: 0.8755 - val_mse: 0.8755 - val_mae: 0.8002\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.7365 - mse: 0.7365 - mae: 0.6455 - val_loss: 0.8680 - val_mse: 0.8680 - val_mae: 0.7966\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 510us/step - loss: 0.7314 - mse: 0.7314 - mae: 0.6436 - val_loss: 0.8613 - val_mse: 0.8613 - val_mae: 0.7931\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 477us/step - loss: 0.7265 - mse: 0.7265 - mae: 0.6416 - val_loss: 0.8549 - val_mse: 0.8549 - val_mae: 0.7897\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 531us/step - loss: 0.7218 - mse: 0.7218 - mae: 0.6395 - val_loss: 0.8489 - val_mse: 0.8489 - val_mae: 0.7865\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 664us/step - loss: 0.7169 - mse: 0.7169 - mae: 0.6372 - val_loss: 0.8434 - val_mse: 0.8434 - val_mae: 0.7833\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 398us/step - loss: 0.7122 - mse: 0.7122 - mae: 0.6349 - val_loss: 0.8380 - val_mse: 0.8380 - val_mae: 0.7802\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 254us/step - loss: 0.7075 - mse: 0.7075 - mae: 0.6324 - val_loss: 0.8327 - val_mse: 0.8327 - val_mae: 0.7773\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 625us/step - loss: 0.7029 - mse: 0.7029 - mae: 0.6299 - val_loss: 0.8285 - val_mse: 0.8285 - val_mae: 0.7746\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 753us/step - loss: 0.6984 - mse: 0.6984 - mae: 0.6272 - val_loss: 0.8255 - val_mse: 0.8255 - val_mae: 0.7720\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 404us/step - loss: 0.6937 - mse: 0.6937 - mae: 0.6244 - val_loss: 0.8211 - val_mse: 0.8211 - val_mae: 0.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 368us/step - loss: 0.6897 - mse: 0.6897 - mae: 0.6222 - val_loss: 0.8167 - val_mse: 0.8167 - val_mae: 0.7665\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 344us/step - loss: 0.6858 - mse: 0.6858 - mae: 0.6201 - val_loss: 0.8129 - val_mse: 0.8129 - val_mae: 0.7638\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 324us/step - loss: 0.6817 - mse: 0.6817 - mae: 0.6178 - val_loss: 0.8096 - val_mse: 0.8096 - val_mae: 0.7613\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 495us/step - loss: 0.6778 - mse: 0.6778 - mae: 0.6157 - val_loss: 0.8045 - val_mse: 0.8045 - val_mae: 0.7586\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 437us/step - loss: 0.6738 - mse: 0.6738 - mae: 0.6143 - val_loss: 0.7999 - val_mse: 0.7999 - val_mae: 0.7560\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 396us/step - loss: 0.6702 - mse: 0.6702 - mae: 0.6128 - val_loss: 0.7965 - val_mse: 0.7965 - val_mae: 0.7535\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 274us/step - loss: 0.6668 - mse: 0.6668 - mae: 0.6108 - val_loss: 0.7930 - val_mse: 0.7930 - val_mae: 0.7509\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 288us/step - loss: 0.6632 - mse: 0.6632 - mae: 0.6087 - val_loss: 0.7889 - val_mse: 0.7889 - val_mae: 0.7483\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 357us/step - loss: 0.6597 - mse: 0.6597 - mae: 0.6067 - val_loss: 0.7840 - val_mse: 0.7840 - val_mae: 0.7456\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 402us/step - loss: 0.6564 - mse: 0.6564 - mae: 0.6054 - val_loss: 0.7803 - val_mse: 0.7803 - val_mae: 0.7431\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 451us/step - loss: 0.6530 - mse: 0.6530 - mae: 0.6038 - val_loss: 0.7775 - val_mse: 0.7775 - val_mae: 0.7409\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 344us/step - loss: 0.6498 - mse: 0.6498 - mae: 0.6014 - val_loss: 0.7740 - val_mse: 0.7740 - val_mae: 0.7386\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 274us/step - loss: 0.6466 - mse: 0.6466 - mae: 0.5992 - val_loss: 0.7700 - val_mse: 0.7700 - val_mae: 0.7362\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 387us/step - loss: 0.6433 - mse: 0.6433 - mae: 0.5974 - val_loss: 0.7665 - val_mse: 0.7665 - val_mae: 0.7340\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 284us/step - loss: 0.6403 - mse: 0.6403 - mae: 0.5963 - val_loss: 0.7636 - val_mse: 0.7636 - val_mae: 0.7320\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 443us/step - loss: 0.6373 - mse: 0.6373 - mae: 0.5943 - val_loss: 0.7619 - val_mse: 0.7619 - val_mae: 0.7303\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 530us/step - loss: 0.6345 - mse: 0.6345 - mae: 0.5918 - val_loss: 0.7571 - val_mse: 0.7571 - val_mae: 0.7279\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 361us/step - loss: 0.6314 - mse: 0.6314 - mae: 0.5908 - val_loss: 0.7536 - val_mse: 0.7536 - val_mae: 0.7260\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 467us/step - loss: 0.6287 - mse: 0.6287 - mae: 0.5897 - val_loss: 0.7524 - val_mse: 0.7524 - val_mae: 0.7244\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 391us/step - loss: 0.6260 - mse: 0.6260 - mae: 0.5879 - val_loss: 0.7521 - val_mse: 0.7521 - val_mae: 0.7230\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 536us/step - loss: 0.6234 - mse: 0.6234 - mae: 0.5856 - val_loss: 0.7506 - val_mse: 0.7506 - val_mae: 0.7213\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 518us/step - loss: 0.6204 - mse: 0.6204 - mae: 0.5842 - val_loss: 0.7459 - val_mse: 0.7459 - val_mae: 0.7191\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 448us/step - loss: 0.6185 - mse: 0.6185 - mae: 0.5827 - val_loss: 0.7434 - val_mse: 0.7434 - val_mae: 0.7176\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 799us/step - loss: 0.6155 - mse: 0.6155 - mae: 0.5824 - val_loss: 0.7437 - val_mse: 0.7437 - val_mae: 0.7166\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 454us/step - loss: 0.6131 - mse: 0.6131 - mae: 0.5810 - val_loss: 0.7441 - val_mse: 0.7441 - val_mae: 0.7154\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 446us/step - loss: 0.6107 - mse: 0.6107 - mae: 0.5779 - val_loss: 0.7436 - val_mse: 0.7436 - val_mae: 0.7142\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 417us/step - loss: 0.6082 - mse: 0.6082 - mae: 0.5760 - val_loss: 0.7411 - val_mse: 0.7411 - val_mae: 0.7126\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 727us/step - loss: 0.6053 - mse: 0.6053 - mae: 0.5754 - val_loss: 0.7390 - val_mse: 0.7390 - val_mae: 0.7113\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 627us/step - loss: 0.6027 - mse: 0.6027 - mae: 0.5742 - val_loss: 0.7380 - val_mse: 0.7380 - val_mae: 0.7101\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 446us/step - loss: 0.6007 - mse: 0.6007 - mae: 0.5722 - val_loss: 0.7367 - val_mse: 0.7367 - val_mae: 0.7088\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.5982 - mse: 0.5982 - mae: 0.5705 - val_loss: 0.7350 - val_mse: 0.7350 - val_mae: 0.7070\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 624us/step - loss: 0.5959 - mse: 0.5959 - mae: 0.5686 - val_loss: 0.7333 - val_mse: 0.7333 - val_mae: 0.7057\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 589us/step - loss: 0.5933 - mse: 0.5933 - mae: 0.5675 - val_loss: 0.7317 - val_mse: 0.7317 - val_mae: 0.7051\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 418us/step - loss: 0.5910 - mse: 0.5910 - mae: 0.5667 - val_loss: 0.7314 - val_mse: 0.7314 - val_mae: 0.7044\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 355us/step - loss: 0.5889 - mse: 0.5889 - mae: 0.5656 - val_loss: 0.7314 - val_mse: 0.7314 - val_mae: 0.7046\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 535us/step - loss: 0.5867 - mse: 0.5867 - mae: 0.5652 - val_loss: 0.7304 - val_mse: 0.7304 - val_mae: 0.7029\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 299us/step - loss: 0.5842 - mse: 0.5842 - mae: 0.5620 - val_loss: 0.7300 - val_mse: 0.7300 - val_mae: 0.7007\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 456us/step - loss: 0.5829 - mse: 0.5829 - mae: 0.5594 - val_loss: 0.7299 - val_mse: 0.7299 - val_mae: 0.7017\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 454us/step - loss: 0.5794 - mse: 0.5794 - mae: 0.5602 - val_loss: 0.7283 - val_mse: 0.7283 - val_mae: 0.7020\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 381us/step - loss: 0.5771 - mse: 0.5771 - mae: 0.5598 - val_loss: 0.7268 - val_mse: 0.7268 - val_mae: 0.7002\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 318us/step - loss: 0.5754 - mse: 0.5754 - mae: 0.5570 - val_loss: 0.7265 - val_mse: 0.7265 - val_mae: 0.6991\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 335us/step - loss: 0.5729 - mse: 0.5729 - mae: 0.5556 - val_loss: 0.7272 - val_mse: 0.7272 - val_mae: 0.6996\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 319us/step - loss: 0.5703 - mse: 0.5703 - mae: 0.5550 - val_loss: 0.7262 - val_mse: 0.7262 - val_mae: 0.6982\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 237us/step - loss: 0.5681 - mse: 0.5681 - mae: 0.5520 - val_loss: 0.7252 - val_mse: 0.7252 - val_mae: 0.6965\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 523us/step - loss: 0.5660 - mse: 0.5660 - mae: 0.5502 - val_loss: 0.7248 - val_mse: 0.7248 - val_mae: 0.6971\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 359us/step - loss: 0.5634 - mse: 0.5634 - mae: 0.5503 - val_loss: 0.7240 - val_mse: 0.7240 - val_mae: 0.6972\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 424us/step - loss: 0.5612 - mse: 0.5612 - mae: 0.5496 - val_loss: 0.7235 - val_mse: 0.7235 - val_mae: 0.6961\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 468us/step - loss: 0.5591 - mse: 0.5591 - mae: 0.5470 - val_loss: 0.7227 - val_mse: 0.7227 - val_mae: 0.6944\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 400us/step - loss: 0.5571 - mse: 0.5571 - mae: 0.5447 - val_loss: 0.7223 - val_mse: 0.7223 - val_mae: 0.6940\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.5545 - mse: 0.5545 - mae: 0.5442 - val_loss: 0.7219 - val_mse: 0.7219 - val_mae: 0.6949\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 358us/step - loss: 0.5523 - mse: 0.5523 - mae: 0.5442 - val_loss: 0.7219 - val_mse: 0.7219 - val_mae: 0.6936\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 436us/step - loss: 0.5499 - mse: 0.5499 - mae: 0.5412 - val_loss: 0.7230 - val_mse: 0.7230 - val_mae: 0.6923\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 482us/step - loss: 0.5480 - mse: 0.5480 - mae: 0.5392 - val_loss: 0.7232 - val_mse: 0.7232 - val_mae: 0.6923\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 331us/step - loss: 0.5453 - mse: 0.5453 - mae: 0.5390 - val_loss: 0.7215 - val_mse: 0.7215 - val_mae: 0.6933\n",
      "39\n",
      "[39]\n",
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 14ms/step - loss: 6.5625 - mse: 6.5625 - mae: 2.2063 - val_loss: 6.0798 - val_mse: 6.0798 - val_mae: 2.2626\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 337us/step - loss: 5.5006 - mse: 5.5006 - mae: 1.9579 - val_loss: 5.1913 - val_mse: 5.1913 - val_mae: 2.0472\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 234us/step - loss: 4.5967 - mse: 4.5967 - mae: 1.7149 - val_loss: 4.3860 - val_mse: 4.3860 - val_mae: 1.8347\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 365us/step - loss: 3.7854 - mse: 3.7854 - mae: 1.4960 - val_loss: 3.4084 - val_mse: 3.4084 - val_mae: 1.5982\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 432us/step - loss: 3.1091 - mse: 3.1091 - mae: 1.3278 - val_loss: 2.4941 - val_mse: 2.4941 - val_mae: 1.3387\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 362us/step - loss: 2.6139 - mse: 2.6139 - mae: 1.2181 - val_loss: 1.7857 - val_mse: 1.7857 - val_mae: 1.1523\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 234us/step - loss: 2.3429 - mse: 2.3429 - mae: 1.1566 - val_loss: 1.3643 - val_mse: 1.3643 - val_mae: 0.9925\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 353us/step - loss: 2.2636 - mse: 2.2636 - mae: 1.1241 - val_loss: 1.1778 - val_mse: 1.1778 - val_mae: 0.8867\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 426us/step - loss: 2.2766 - mse: 2.2766 - mae: 1.1189 - val_loss: 1.0989 - val_mse: 1.0989 - val_mae: 0.8321\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 396us/step - loss: 2.2876 - mse: 2.2876 - mae: 1.1200 - val_loss: 1.0531 - val_mse: 1.0531 - val_mae: 0.8035\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 435us/step - loss: 2.2457 - mse: 2.2457 - mae: 1.1088 - val_loss: 1.0140 - val_mse: 1.0140 - val_mae: 0.7893\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 687us/step - loss: 2.1635 - mse: 2.1635 - mae: 1.0874 - val_loss: 0.9863 - val_mse: 0.9863 - val_mae: 0.7844\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 478us/step - loss: 2.0756 - mse: 2.0756 - mae: 1.0638 - val_loss: 0.9705 - val_mse: 0.9705 - val_mae: 0.7862\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 275us/step - loss: 2.0025 - mse: 2.0025 - mae: 1.0450 - val_loss: 0.9626 - val_mse: 0.9626 - val_mae: 0.7924\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 291us/step - loss: 1.9467 - mse: 1.9467 - mae: 1.0304 - val_loss: 0.9518 - val_mse: 0.9518 - val_mae: 0.7938\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 327us/step - loss: 1.9012 - mse: 1.9012 - mae: 1.0172 - val_loss: 0.9293 - val_mse: 0.9293 - val_mae: 0.7843\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 293us/step - loss: 1.8616 - mse: 1.8616 - mae: 1.0054 - val_loss: 0.8951 - val_mse: 0.8951 - val_mae: 0.7659\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 327us/step - loss: 1.8267 - mse: 1.8267 - mae: 0.9947 - val_loss: 0.8556 - val_mse: 0.8556 - val_mae: 0.7431\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 363us/step - loss: 1.7952 - mse: 1.7952 - mae: 0.9848 - val_loss: 0.8165 - val_mse: 0.8165 - val_mae: 0.7188\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 380us/step - loss: 1.7691 - mse: 1.7691 - mae: 0.9770 - val_loss: 0.7818 - val_mse: 0.7818 - val_mae: 0.6958\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 266us/step - loss: 1.7443 - mse: 1.7443 - mae: 0.9701 - val_loss: 0.7524 - val_mse: 0.7524 - val_mae: 0.6770\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 306us/step - loss: 1.7215 - mse: 1.7215 - mae: 0.9646 - val_loss: 0.7279 - val_mse: 0.7279 - val_mae: 0.6604\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 237us/step - loss: 1.7014 - mse: 1.7014 - mae: 0.9607 - val_loss: 0.7090 - val_mse: 0.7090 - val_mae: 0.6486\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 281us/step - loss: 1.6810 - mse: 1.6810 - mae: 0.9565 - val_loss: 0.6946 - val_mse: 0.6946 - val_mae: 0.6412\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 274us/step - loss: 1.6600 - mse: 1.6600 - mae: 0.9515 - val_loss: 0.6830 - val_mse: 0.6830 - val_mae: 0.6358\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 384us/step - loss: 1.6400 - mse: 1.6400 - mae: 0.9466 - val_loss: 0.6731 - val_mse: 0.6731 - val_mae: 0.6312\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 566us/step - loss: 1.6204 - mse: 1.6204 - mae: 0.9414 - val_loss: 0.6639 - val_mse: 0.6639 - val_mae: 0.6265\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 467us/step - loss: 1.6014 - mse: 1.6014 - mae: 0.9359 - val_loss: 0.6556 - val_mse: 0.6556 - val_mae: 0.6217\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 347us/step - loss: 1.5834 - mse: 1.5834 - mae: 0.9305 - val_loss: 0.6481 - val_mse: 0.6481 - val_mae: 0.6170\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 330us/step - loss: 1.5664 - mse: 1.5664 - mae: 0.9254 - val_loss: 0.6415 - val_mse: 0.6415 - val_mae: 0.6123\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 660us/step - loss: 1.5520 - mse: 1.5520 - mae: 0.9209 - val_loss: 0.6365 - val_mse: 0.6365 - val_mae: 0.6103\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 623us/step - loss: 1.5369 - mse: 1.5369 - mae: 0.9162 - val_loss: 0.6334 - val_mse: 0.6334 - val_mae: 0.6110\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 520us/step - loss: 1.5219 - mse: 1.5219 - mae: 0.9113 - val_loss: 0.6310 - val_mse: 0.6310 - val_mae: 0.6117\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 740us/step - loss: 1.5078 - mse: 1.5078 - mae: 0.9066 - val_loss: 0.6289 - val_mse: 0.6289 - val_mae: 0.6116\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 391us/step - loss: 1.4954 - mse: 1.4954 - mae: 0.9031 - val_loss: 0.6253 - val_mse: 0.6253 - val_mae: 0.6097\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 594us/step - loss: 1.4843 - mse: 1.4843 - mae: 0.9001 - val_loss: 0.6219 - val_mse: 0.6219 - val_mae: 0.6075\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 556us/step - loss: 1.4738 - mse: 1.4738 - mae: 0.8977 - val_loss: 0.6198 - val_mse: 0.6198 - val_mae: 0.6067\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 363us/step - loss: 1.4630 - mse: 1.4630 - mae: 0.8949 - val_loss: 0.6197 - val_mse: 0.6197 - val_mae: 0.6081\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 349us/step - loss: 1.4514 - mse: 1.4514 - mae: 0.8918 - val_loss: 0.6211 - val_mse: 0.6211 - val_mae: 0.6112\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 400us/step - loss: 1.4401 - mse: 1.4401 - mae: 0.8882 - val_loss: 0.6225 - val_mse: 0.6225 - val_mae: 0.6139\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 425us/step - loss: 1.4294 - mse: 1.4294 - mae: 0.8846 - val_loss: 0.6237 - val_mse: 0.6237 - val_mae: 0.6155\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 398us/step - loss: 1.4200 - mse: 1.4200 - mae: 0.8819 - val_loss: 0.6265 - val_mse: 0.6265 - val_mae: 0.6182\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 313us/step - loss: 1.4102 - mse: 1.4102 - mae: 0.8787 - val_loss: 0.6292 - val_mse: 0.6292 - val_mae: 0.6212\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 308us/step - loss: 1.4000 - mse: 1.4000 - mae: 0.8751 - val_loss: 0.6306 - val_mse: 0.6306 - val_mae: 0.6227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 358us/step - loss: 1.3912 - mse: 1.3912 - mae: 0.8719 - val_loss: 0.6299 - val_mse: 0.6299 - val_mae: 0.6217\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 395us/step - loss: 1.3832 - mse: 1.3832 - mae: 0.8696 - val_loss: 0.6308 - val_mse: 0.6308 - val_mae: 0.6219\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 503us/step - loss: 1.3757 - mse: 1.3757 - mae: 0.8673 - val_loss: 0.6346 - val_mse: 0.6346 - val_mae: 0.6252\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 625us/step - loss: 1.3676 - mse: 1.3676 - mae: 0.8643 - val_loss: 0.6376 - val_mse: 0.6376 - val_mae: 0.6278\n",
      "40\n",
      "[40]\n",
      "Train on 88 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 4.0553 - mse: 4.0553 - mae: 1.6548 - val_loss: 2.7145 - val_mse: 2.7145 - val_mae: 1.5552\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 686us/step - loss: 3.8804 - mse: 3.8804 - mae: 1.6007 - val_loss: 2.5623 - val_mse: 2.5623 - val_mae: 1.5056\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 850us/step - loss: 3.6931 - mse: 3.6931 - mae: 1.5417 - val_loss: 2.4139 - val_mse: 2.4139 - val_mae: 1.4556\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 689us/step - loss: 3.5056 - mse: 3.5056 - mae: 1.4806 - val_loss: 2.2685 - val_mse: 2.2685 - val_mae: 1.4049\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 433us/step - loss: 3.3240 - mse: 3.3240 - mae: 1.4185 - val_loss: 2.1269 - val_mse: 2.1269 - val_mae: 1.3536\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 305us/step - loss: 3.1470 - mse: 3.1470 - mae: 1.3549 - val_loss: 1.9871 - val_mse: 1.9871 - val_mae: 1.3007\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 729us/step - loss: 2.9698 - mse: 2.9698 - mae: 1.2889 - val_loss: 1.8454 - val_mse: 1.8454 - val_mae: 1.2446\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 260us/step - loss: 2.7925 - mse: 2.7925 - mae: 1.2191 - val_loss: 1.7003 - val_mse: 1.7003 - val_mae: 1.1846\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 321us/step - loss: 2.6175 - mse: 2.6175 - mae: 1.1475 - val_loss: 1.5532 - val_mse: 1.5532 - val_mae: 1.1204\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 313us/step - loss: 2.4468 - mse: 2.4468 - mae: 1.0767 - val_loss: 1.4031 - val_mse: 1.4031 - val_mae: 1.0518\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 419us/step - loss: 2.2835 - mse: 2.2835 - mae: 1.0071 - val_loss: 1.2530 - val_mse: 1.2530 - val_mae: 0.9793\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 387us/step - loss: 2.1286 - mse: 2.1286 - mae: 0.9419 - val_loss: 1.1076 - val_mse: 1.1076 - val_mae: 0.9028\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 333us/step - loss: 1.9814 - mse: 1.9814 - mae: 0.8836 - val_loss: 0.9721 - val_mse: 0.9721 - val_mae: 0.8250\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 507us/step - loss: 1.8482 - mse: 1.8482 - mae: 0.8391 - val_loss: 0.8487 - val_mse: 0.8487 - val_mae: 0.7469\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 293us/step - loss: 1.7307 - mse: 1.7307 - mae: 0.8094 - val_loss: 0.7379 - val_mse: 0.7379 - val_mae: 0.6748\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 658us/step - loss: 1.6288 - mse: 1.6288 - mae: 0.7947 - val_loss: 0.6409 - val_mse: 0.6409 - val_mae: 0.6093\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 679us/step - loss: 1.5465 - mse: 1.5465 - mae: 0.7931 - val_loss: 0.5575 - val_mse: 0.5575 - val_mae: 0.5699\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 295us/step - loss: 1.4846 - mse: 1.4846 - mae: 0.7970 - val_loss: 0.4884 - val_mse: 0.4884 - val_mae: 0.5343\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 331us/step - loss: 1.4373 - mse: 1.4373 - mae: 0.8036 - val_loss: 0.4323 - val_mse: 0.4323 - val_mae: 0.5076\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 480us/step - loss: 1.4036 - mse: 1.4036 - mae: 0.8092 - val_loss: 0.3892 - val_mse: 0.3892 - val_mae: 0.4849\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 279us/step - loss: 1.3805 - mse: 1.3805 - mae: 0.8167 - val_loss: 0.3579 - val_mse: 0.3579 - val_mae: 0.4652\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 342us/step - loss: 1.3655 - mse: 1.3655 - mae: 0.8233 - val_loss: 0.3361 - val_mse: 0.3361 - val_mae: 0.4496\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 462us/step - loss: 1.3562 - mse: 1.3562 - mae: 0.8283 - val_loss: 0.3216 - val_mse: 0.3216 - val_mae: 0.4379\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 386us/step - loss: 1.3496 - mse: 1.3496 - mae: 0.8323 - val_loss: 0.3123 - val_mse: 0.3123 - val_mae: 0.4294\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 542us/step - loss: 1.3440 - mse: 1.3440 - mae: 0.8347 - val_loss: 0.3069 - val_mse: 0.3069 - val_mae: 0.4237\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 562us/step - loss: 1.3383 - mse: 1.3383 - mae: 0.8357 - val_loss: 0.3042 - val_mse: 0.3042 - val_mae: 0.4202\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 263us/step - loss: 1.3322 - mse: 1.3322 - mae: 0.8350 - val_loss: 0.3035 - val_mse: 0.3035 - val_mae: 0.4187\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 233us/step - loss: 1.3263 - mse: 1.3263 - mae: 0.8331 - val_loss: 0.3044 - val_mse: 0.3044 - val_mae: 0.4192\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 510us/step - loss: 1.3202 - mse: 1.3202 - mae: 0.8300 - val_loss: 0.3061 - val_mse: 0.3061 - val_mae: 0.4207\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 845us/step - loss: 1.3141 - mse: 1.3141 - mae: 0.8264 - val_loss: 0.3079 - val_mse: 0.3079 - val_mae: 0.4224\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 239us/step - loss: 1.3091 - mse: 1.3091 - mae: 0.8230 - val_loss: 0.3098 - val_mse: 0.3098 - val_mae: 0.4239\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 326us/step - loss: 1.3042 - mse: 1.3042 - mae: 0.8199 - val_loss: 0.3115 - val_mse: 0.3115 - val_mae: 0.4252\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 491us/step - loss: 1.2997 - mse: 1.2997 - mae: 0.8173 - val_loss: 0.3130 - val_mse: 0.3130 - val_mae: 0.4263\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 309us/step - loss: 1.2950 - mse: 1.2950 - mae: 0.8149 - val_loss: 0.3142 - val_mse: 0.3142 - val_mae: 0.4273\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 304us/step - loss: 1.2914 - mse: 1.2914 - mae: 0.8132 - val_loss: 0.3147 - val_mse: 0.3147 - val_mae: 0.4273\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 0s 504us/step - loss: 1.2870 - mse: 1.2870 - mae: 0.8117 - val_loss: 0.3151 - val_mse: 0.3151 - val_mae: 0.4272\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 0s 648us/step - loss: 1.2826 - mse: 1.2826 - mae: 0.8102 - val_loss: 0.3152 - val_mse: 0.3152 - val_mae: 0.4272\n",
      "41\n",
      "[41]\n",
      "Train on 103 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "103/103 [==============================] - 1s 13ms/step - loss: 7.9781 - mse: 7.9781 - mae: 2.6156 - val_loss: 3.9959 - val_mse: 3.9959 - val_mae: 1.8719\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 310us/step - loss: 6.1974 - mse: 6.1974 - mae: 2.2522 - val_loss: 3.0202 - val_mse: 3.0202 - val_mae: 1.5886\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 572us/step - loss: 4.7361 - mse: 4.7361 - mae: 1.9056 - val_loss: 2.2687 - val_mse: 2.2687 - val_mae: 1.3390\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 429us/step - loss: 3.6001 - mse: 3.6001 - mae: 1.5961 - val_loss: 1.6908 - val_mse: 1.6908 - val_mae: 1.1162\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 470us/step - loss: 2.8023 - mse: 2.8023 - mae: 1.3576 - val_loss: 1.2762 - val_mse: 1.2762 - val_mae: 0.9336\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 253us/step - loss: 2.2432 - mse: 2.2432 - mae: 1.1906 - val_loss: 0.9766 - val_mse: 0.9766 - val_mae: 0.8051\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 851us/step - loss: 1.8195 - mse: 1.8195 - mae: 1.0595 - val_loss: 0.7644 - val_mse: 0.7644 - val_mae: 0.7255\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.7599 - mse: 1.7599 - mae: 1.021 - 0s 558us/step - loss: 1.5186 - mse: 1.5186 - mae: 0.9737 - val_loss: 0.6173 - val_mse: 0.6173 - val_mae: 0.6691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 616us/step - loss: 1.3162 - mse: 1.3162 - mae: 0.9124 - val_loss: 0.5237 - val_mse: 0.5237 - val_mae: 0.6251\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 286us/step - loss: 1.1934 - mse: 1.1934 - mae: 0.8715 - val_loss: 0.4717 - val_mse: 0.4717 - val_mae: 0.5868\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 428us/step - loss: 1.1260 - mse: 1.1260 - mae: 0.8554 - val_loss: 0.4466 - val_mse: 0.4466 - val_mae: 0.5602\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 352us/step - loss: 1.0922 - mse: 1.0922 - mae: 0.8458 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.5437\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 623us/step - loss: 1.0740 - mse: 1.0740 - mae: 0.8379 - val_loss: 0.4320 - val_mse: 0.4320 - val_mae: 0.5391\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 643us/step - loss: 1.0626 - mse: 1.0626 - mae: 0.8325 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.5364\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 277us/step - loss: 1.0526 - mse: 1.0526 - mae: 0.8279 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.5302\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 439us/step - loss: 1.0403 - mse: 1.0403 - mae: 0.8227 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.5217\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 334us/step - loss: 1.0269 - mse: 1.0269 - mae: 0.8174 - val_loss: 0.4010 - val_mse: 0.4010 - val_mae: 0.5153\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 528us/step - loss: 1.0140 - mse: 1.0140 - mae: 0.8123 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.5124\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 713us/step - loss: 1.0015 - mse: 1.0015 - mae: 0.8063 - val_loss: 0.3881 - val_mse: 0.3881 - val_mae: 0.5109\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 528us/step - loss: 0.9909 - mse: 0.9909 - mae: 0.8002 - val_loss: 0.3837 - val_mse: 0.3837 - val_mae: 0.5089\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 953us/step - loss: 0.9817 - mse: 0.9817 - mae: 0.7948 - val_loss: 0.3801 - val_mse: 0.3801 - val_mae: 0.5067\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.9727 - mse: 0.9727 - mae: 0.7902 - val_loss: 0.3761 - val_mse: 0.3761 - val_mae: 0.5036\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 643us/step - loss: 0.9634 - mse: 0.9634 - mae: 0.7861 - val_loss: 0.3720 - val_mse: 0.3720 - val_mae: 0.5004\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 546us/step - loss: 0.9541 - mse: 0.9541 - mae: 0.7821 - val_loss: 0.3679 - val_mse: 0.3679 - val_mae: 0.4980\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 281us/step - loss: 0.9451 - mse: 0.9451 - mae: 0.7783 - val_loss: 0.3640 - val_mse: 0.3640 - val_mae: 0.4957\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 398us/step - loss: 0.9364 - mse: 0.9364 - mae: 0.7750 - val_loss: 0.3604 - val_mse: 0.3604 - val_mae: 0.4934\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.9283 - mse: 0.9283 - mae: 0.7719 - val_loss: 0.3571 - val_mse: 0.3571 - val_mae: 0.4912\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 545us/step - loss: 0.9205 - mse: 0.9205 - mae: 0.7688 - val_loss: 0.3540 - val_mse: 0.3540 - val_mae: 0.4893\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 387us/step - loss: 0.9129 - mse: 0.9129 - mae: 0.7655 - val_loss: 0.3511 - val_mse: 0.3511 - val_mae: 0.4876\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 327us/step - loss: 0.9056 - mse: 0.9056 - mae: 0.7622 - val_loss: 0.3485 - val_mse: 0.3485 - val_mae: 0.4860\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 385us/step - loss: 0.8984 - mse: 0.8984 - mae: 0.7587 - val_loss: 0.3460 - val_mse: 0.3460 - val_mae: 0.4846\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 252us/step - loss: 0.8915 - mse: 0.8915 - mae: 0.7555 - val_loss: 0.3436 - val_mse: 0.3436 - val_mae: 0.4832\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 518us/step - loss: 0.8842 - mse: 0.8842 - mae: 0.7521 - val_loss: 0.3414 - val_mse: 0.3414 - val_mae: 0.4818\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 490us/step - loss: 0.8766 - mse: 0.8766 - mae: 0.7485 - val_loss: 0.3395 - val_mse: 0.3395 - val_mae: 0.4807\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.8689 - mse: 0.8689 - mae: 0.7446 - val_loss: 0.3382 - val_mse: 0.3382 - val_mae: 0.4799\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 284us/step - loss: 0.8611 - mse: 0.8611 - mae: 0.7409 - val_loss: 0.3373 - val_mse: 0.3373 - val_mae: 0.4799\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 348us/step - loss: 0.8534 - mse: 0.8534 - mae: 0.7375 - val_loss: 0.3360 - val_mse: 0.3360 - val_mae: 0.4798\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 424us/step - loss: 0.8458 - mse: 0.8458 - mae: 0.7341 - val_loss: 0.3342 - val_mse: 0.3342 - val_mae: 0.4788\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 364us/step - loss: 0.8381 - mse: 0.8381 - mae: 0.7306 - val_loss: 0.3318 - val_mse: 0.3318 - val_mae: 0.4768\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 363us/step - loss: 0.8309 - mse: 0.8309 - mae: 0.7272 - val_loss: 0.3294 - val_mse: 0.3294 - val_mae: 0.4745\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 437us/step - loss: 0.8240 - mse: 0.8240 - mae: 0.7240 - val_loss: 0.3270 - val_mse: 0.3270 - val_mae: 0.4724\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 428us/step - loss: 0.8174 - mse: 0.8174 - mae: 0.7209 - val_loss: 0.3251 - val_mse: 0.3251 - val_mae: 0.4708\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 360us/step - loss: 0.8112 - mse: 0.8112 - mae: 0.7182 - val_loss: 0.3240 - val_mse: 0.3240 - val_mae: 0.4706\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 428us/step - loss: 0.8053 - mse: 0.8053 - mae: 0.7155 - val_loss: 0.3230 - val_mse: 0.3230 - val_mae: 0.4704\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 291us/step - loss: 0.7997 - mse: 0.7997 - mae: 0.7129 - val_loss: 0.3220 - val_mse: 0.3220 - val_mae: 0.4699\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 339us/step - loss: 0.7941 - mse: 0.7941 - mae: 0.7103 - val_loss: 0.3208 - val_mse: 0.3208 - val_mae: 0.4691\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 358us/step - loss: 0.7886 - mse: 0.7886 - mae: 0.7078 - val_loss: 0.3194 - val_mse: 0.3194 - val_mae: 0.4679\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 292us/step - loss: 0.7833 - mse: 0.7833 - mae: 0.7056 - val_loss: 0.3181 - val_mse: 0.3181 - val_mae: 0.4665\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 304us/step - loss: 0.7782 - mse: 0.7782 - mae: 0.7034 - val_loss: 0.3168 - val_mse: 0.3168 - val_mae: 0.4652\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 343us/step - loss: 0.7733 - mse: 0.7733 - mae: 0.7013 - val_loss: 0.3158 - val_mse: 0.3158 - val_mae: 0.4640\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 333us/step - loss: 0.7686 - mse: 0.7686 - mae: 0.6994 - val_loss: 0.3153 - val_mse: 0.3153 - val_mae: 0.4637\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 317us/step - loss: 0.7640 - mse: 0.7640 - mae: 0.6973 - val_loss: 0.3148 - val_mse: 0.3148 - val_mae: 0.4631\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 406us/step - loss: 0.7595 - mse: 0.7595 - mae: 0.6952 - val_loss: 0.3140 - val_mse: 0.3140 - val_mae: 0.4621\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 332us/step - loss: 0.7551 - mse: 0.7551 - mae: 0.6934 - val_loss: 0.3137 - val_mse: 0.3137 - val_mae: 0.4616\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 346us/step - loss: 0.7510 - mse: 0.7510 - mae: 0.6915 - val_loss: 0.3131 - val_mse: 0.3131 - val_mae: 0.4607\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 318us/step - loss: 0.7470 - mse: 0.7470 - mae: 0.6897 - val_loss: 0.3124 - val_mse: 0.3124 - val_mae: 0.4596\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 462us/step - loss: 0.7432 - mse: 0.7432 - mae: 0.6881 - val_loss: 0.3120 - val_mse: 0.3120 - val_mae: 0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 274us/step - loss: 0.7394 - mse: 0.7394 - mae: 0.6862 - val_loss: 0.3115 - val_mse: 0.3115 - val_mae: 0.4583\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 293us/step - loss: 0.7358 - mse: 0.7358 - mae: 0.6845 - val_loss: 0.3109 - val_mse: 0.3109 - val_mae: 0.4573\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 482us/step - loss: 0.7324 - mse: 0.7324 - mae: 0.6829 - val_loss: 0.3106 - val_mse: 0.3106 - val_mae: 0.4567\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 303us/step - loss: 0.7291 - mse: 0.7291 - mae: 0.6813 - val_loss: 0.3106 - val_mse: 0.3106 - val_mae: 0.4564\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 350us/step - loss: 0.7259 - mse: 0.7259 - mae: 0.6797 - val_loss: 0.3100 - val_mse: 0.3100 - val_mae: 0.4552\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7487 - mse: 0.7487 - mae: 0.715 - 0s 355us/step - loss: 0.7226 - mse: 0.7226 - mae: 0.6783 - val_loss: 0.3093 - val_mse: 0.3093 - val_mae: 0.4537\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 369us/step - loss: 0.7197 - mse: 0.7197 - mae: 0.6770 - val_loss: 0.3090 - val_mse: 0.3090 - val_mae: 0.4528\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 381us/step - loss: 0.7168 - mse: 0.7168 - mae: 0.6757 - val_loss: 0.3091 - val_mse: 0.3091 - val_mae: 0.4526\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 332us/step - loss: 0.7138 - mse: 0.7138 - mae: 0.6742 - val_loss: 0.3088 - val_mse: 0.3088 - val_mae: 0.4522\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 327us/step - loss: 0.7111 - mse: 0.7111 - mae: 0.6728 - val_loss: 0.3088 - val_mse: 0.3088 - val_mae: 0.4519\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 335us/step - loss: 0.7084 - mse: 0.7084 - mae: 0.6714 - val_loss: 0.3085 - val_mse: 0.3085 - val_mae: 0.4516\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 338us/step - loss: 0.7058 - mse: 0.7058 - mae: 0.6701 - val_loss: 0.3086 - val_mse: 0.3086 - val_mae: 0.4515\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 304us/step - loss: 0.7033 - mse: 0.7033 - mae: 0.6687 - val_loss: 0.3086 - val_mse: 0.3086 - val_mae: 0.4513\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 279us/step - loss: 0.7009 - mse: 0.7009 - mae: 0.6673 - val_loss: 0.3081 - val_mse: 0.3081 - val_mae: 0.4507\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 386us/step - loss: 0.6986 - mse: 0.6986 - mae: 0.6661 - val_loss: 0.3082 - val_mse: 0.3082 - val_mae: 0.4505\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 246us/step - loss: 0.6963 - mse: 0.6963 - mae: 0.6649 - val_loss: 0.3080 - val_mse: 0.3080 - val_mae: 0.4503\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 435us/step - loss: 0.6940 - mse: 0.6940 - mae: 0.6638 - val_loss: 0.3078 - val_mse: 0.3078 - val_mae: 0.4502\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 680us/step - loss: 0.6920 - mse: 0.6920 - mae: 0.6626 - val_loss: 0.3080 - val_mse: 0.3080 - val_mae: 0.4503\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 274us/step - loss: 0.6899 - mse: 0.6899 - mae: 0.6614 - val_loss: 0.3083 - val_mse: 0.3083 - val_mae: 0.4504\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 806us/step - loss: 0.6878 - mse: 0.6878 - mae: 0.6602 - val_loss: 0.3079 - val_mse: 0.3079 - val_mae: 0.4500\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 633us/step - loss: 0.6857 - mse: 0.6857 - mae: 0.6590 - val_loss: 0.3073 - val_mse: 0.3073 - val_mae: 0.4494\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 700us/step - loss: 0.6838 - mse: 0.6838 - mae: 0.6580 - val_loss: 0.3075 - val_mse: 0.3075 - val_mae: 0.4495\n",
      "Epoch 80/100\n",
      "103/103 [==============================] - 0s 336us/step - loss: 0.6820 - mse: 0.6820 - mae: 0.6568 - val_loss: 0.3080 - val_mse: 0.3080 - val_mae: 0.4496\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 0s 842us/step - loss: 0.6800 - mse: 0.6800 - mae: 0.6557 - val_loss: 0.3078 - val_mse: 0.3078 - val_mae: 0.4494\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 254us/step - loss: 0.6782 - mse: 0.6782 - mae: 0.6548 - val_loss: 0.3079 - val_mse: 0.3079 - val_mae: 0.4493\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 592us/step - loss: 0.6765 - mse: 0.6765 - mae: 0.6537 - val_loss: 0.3080 - val_mse: 0.3080 - val_mae: 0.4492\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 329us/step - loss: 0.6747 - mse: 0.6747 - mae: 0.6527 - val_loss: 0.3076 - val_mse: 0.3076 - val_mae: 0.4488\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 396us/step - loss: 0.6730 - mse: 0.6730 - mae: 0.6518 - val_loss: 0.3076 - val_mse: 0.3076 - val_mae: 0.4487\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 448us/step - loss: 0.6714 - mse: 0.6714 - mae: 0.6508 - val_loss: 0.3077 - val_mse: 0.3077 - val_mae: 0.4487\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 300us/step - loss: 0.6697 - mse: 0.6697 - mae: 0.6498 - val_loss: 0.3074 - val_mse: 0.3074 - val_mae: 0.4483\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 559us/step - loss: 0.6682 - mse: 0.6682 - mae: 0.6489 - val_loss: 0.3075 - val_mse: 0.3075 - val_mae: 0.4483\n",
      "42\n",
      "[42]\n",
      "Train on 107 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 1s 14ms/step - loss: 10.2861 - mse: 10.2861 - mae: 2.8649 - val_loss: 8.9553 - val_mse: 8.9553 - val_mae: 2.7649\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 268us/step - loss: 8.5076 - mse: 8.5076 - mae: 2.5478 - val_loss: 7.4228 - val_mse: 7.4228 - val_mae: 2.4797\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 460us/step - loss: 7.0582 - mse: 7.0582 - mae: 2.2698 - val_loss: 6.3743 - val_mse: 6.3743 - val_mae: 2.2637\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 608us/step - loss: 5.8444 - mse: 5.8444 - mae: 2.0224 - val_loss: 5.5502 - val_mse: 5.5502 - val_mae: 2.0818\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 313us/step - loss: 4.8440 - mse: 4.8440 - mae: 1.8078 - val_loss: 4.6416 - val_mse: 4.6416 - val_mae: 1.8672\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 577us/step - loss: 4.0147 - mse: 4.0147 - mae: 1.6007 - val_loss: 3.8652 - val_mse: 3.8652 - val_mae: 1.6691\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 441us/step - loss: 3.3049 - mse: 3.3049 - mae: 1.4131 - val_loss: 3.1764 - val_mse: 3.1764 - val_mae: 1.4970\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 584us/step - loss: 2.7600 - mse: 2.7600 - mae: 1.2658 - val_loss: 2.6075 - val_mse: 2.6075 - val_mae: 1.3372\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 380us/step - loss: 2.4109 - mse: 2.4109 - mae: 1.1700 - val_loss: 2.2515 - val_mse: 2.2515 - val_mae: 1.2236\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 424us/step - loss: 2.2544 - mse: 2.2544 - mae: 1.1162 - val_loss: 2.0622 - val_mse: 2.0622 - val_mae: 1.1493\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 843us/step - loss: 2.2065 - mse: 2.2065 - mae: 1.0949 - val_loss: 1.9490 - val_mse: 1.9490 - val_mae: 1.1031\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 603us/step - loss: 2.1805 - mse: 2.1805 - mae: 1.0881 - val_loss: 1.8654 - val_mse: 1.8654 - val_mae: 1.0737\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 521us/step - loss: 2.1430 - mse: 2.1430 - mae: 1.0813 - val_loss: 1.8057 - val_mse: 1.8057 - val_mae: 1.0611\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 595us/step - loss: 2.0920 - mse: 2.0920 - mae: 1.0691 - val_loss: 1.7600 - val_mse: 1.7600 - val_mae: 1.0582\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 943us/step - loss: 2.0387 - mse: 2.0387 - mae: 1.0564 - val_loss: 1.7291 - val_mse: 1.7291 - val_mae: 1.0600\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.9941 - mse: 1.9941 - mae: 1.0453 - val_loss: 1.7098 - val_mse: 1.7098 - val_mae: 1.0627\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 597us/step - loss: 1.9622 - mse: 1.9622 - mae: 1.0365 - val_loss: 1.6943 - val_mse: 1.6943 - val_mae: 1.0633\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 701us/step - loss: 1.9373 - mse: 1.9373 - mae: 1.0291 - val_loss: 1.6763 - val_mse: 1.6763 - val_mae: 1.0606\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 494us/step - loss: 1.9152 - mse: 1.9152 - mae: 1.0219 - val_loss: 1.6524 - val_mse: 1.6524 - val_mae: 1.0545\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 418us/step - loss: 1.8935 - mse: 1.8935 - mae: 1.0147 - val_loss: 1.6231 - val_mse: 1.6231 - val_mae: 1.0477\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 656us/step - loss: 1.8719 - mse: 1.8719 - mae: 1.0077 - val_loss: 1.5911 - val_mse: 1.5911 - val_mae: 1.0385\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 403us/step - loss: 1.8515 - mse: 1.8515 - mae: 1.0011 - val_loss: 1.5593 - val_mse: 1.5593 - val_mae: 1.0283\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 541us/step - loss: 1.8325 - mse: 1.8325 - mae: 0.9957 - val_loss: 1.5304 - val_mse: 1.5304 - val_mae: 1.0184\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 715us/step - loss: 1.8152 - mse: 1.8152 - mae: 0.9912 - val_loss: 1.5055 - val_mse: 1.5055 - val_mae: 1.0100\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 667us/step - loss: 1.7988 - mse: 1.7988 - mae: 0.9868 - val_loss: 1.4841 - val_mse: 1.4841 - val_mae: 1.0033\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 601us/step - loss: 1.7832 - mse: 1.7832 - mae: 0.9827 - val_loss: 1.4662 - val_mse: 1.4662 - val_mae: 0.9983\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 527us/step - loss: 1.7685 - mse: 1.7685 - mae: 0.9782 - val_loss: 1.4516 - val_mse: 1.4516 - val_mae: 0.9950\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 366us/step - loss: 1.7541 - mse: 1.7541 - mae: 0.9734 - val_loss: 1.4383 - val_mse: 1.4383 - val_mae: 0.9921\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 300us/step - loss: 1.7402 - mse: 1.7402 - mae: 0.9688 - val_loss: 1.4262 - val_mse: 1.4262 - val_mae: 0.9892\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 506us/step - loss: 1.7268 - mse: 1.7268 - mae: 0.9640 - val_loss: 1.4137 - val_mse: 1.4137 - val_mae: 0.9851\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 0s 428us/step - loss: 1.7131 - mse: 1.7131 - mae: 0.9591 - val_loss: 1.4002 - val_mse: 1.4002 - val_mae: 0.9798\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 433us/step - loss: 1.6995 - mse: 1.6995 - mae: 0.9544 - val_loss: 1.3866 - val_mse: 1.3866 - val_mae: 0.9739\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 609us/step - loss: 1.6861 - mse: 1.6861 - mae: 0.9501 - val_loss: 1.3738 - val_mse: 1.3738 - val_mae: 0.9680\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 254us/step - loss: 1.6734 - mse: 1.6734 - mae: 0.9457 - val_loss: 1.3620 - val_mse: 1.3620 - val_mae: 0.9626\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 663us/step - loss: 1.6619 - mse: 1.6619 - mae: 0.9415 - val_loss: 1.3513 - val_mse: 1.3513 - val_mae: 0.9580\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 0s 644us/step - loss: 1.6511 - mse: 1.6511 - mae: 0.9375 - val_loss: 1.3427 - val_mse: 1.3427 - val_mae: 0.9545\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 542us/step - loss: 1.6410 - mse: 1.6410 - mae: 0.9338 - val_loss: 1.3350 - val_mse: 1.3350 - val_mae: 0.9515\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 632us/step - loss: 1.6313 - mse: 1.6313 - mae: 0.9301 - val_loss: 1.3282 - val_mse: 1.3282 - val_mae: 0.9489\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 229us/step - loss: 1.6219 - mse: 1.6219 - mae: 0.9262 - val_loss: 1.3217 - val_mse: 1.3217 - val_mae: 0.9464\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 671us/step - loss: 1.6131 - mse: 1.6131 - mae: 0.9226 - val_loss: 1.3154 - val_mse: 1.3154 - val_mae: 0.9439\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 0s 701us/step - loss: 1.6047 - mse: 1.6047 - mae: 0.9194 - val_loss: 1.3093 - val_mse: 1.3093 - val_mae: 0.9418\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 233us/step - loss: 1.5967 - mse: 1.5967 - mae: 0.9163 - val_loss: 1.3037 - val_mse: 1.3037 - val_mae: 0.9396\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 589us/step - loss: 1.5887 - mse: 1.5887 - mae: 0.9133 - val_loss: 1.2980 - val_mse: 1.2980 - val_mae: 0.9374\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 572us/step - loss: 1.5807 - mse: 1.5807 - mae: 0.9106 - val_loss: 1.2924 - val_mse: 1.2924 - val_mae: 0.9350\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 427us/step - loss: 1.5731 - mse: 1.5731 - mae: 0.9083 - val_loss: 1.2879 - val_mse: 1.2879 - val_mae: 0.9332\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 661us/step - loss: 1.5657 - mse: 1.5657 - mae: 0.9060 - val_loss: 1.2845 - val_mse: 1.2845 - val_mae: 0.9319\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 572us/step - loss: 1.5588 - mse: 1.5588 - mae: 0.9039 - val_loss: 1.2828 - val_mse: 1.2828 - val_mae: 0.9317\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 398us/step - loss: 1.5525 - mse: 1.5525 - mae: 0.9017 - val_loss: 1.2819 - val_mse: 1.2819 - val_mae: 0.9318\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 930us/step - loss: 1.5462 - mse: 1.5462 - mae: 0.8996 - val_loss: 1.2808 - val_mse: 1.2808 - val_mae: 0.9314\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 889us/step - loss: 1.5398 - mse: 1.5398 - mae: 0.8974 - val_loss: 1.2793 - val_mse: 1.2793 - val_mae: 0.9307\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 633us/step - loss: 1.5334 - mse: 1.5334 - mae: 0.8955 - val_loss: 1.2780 - val_mse: 1.2780 - val_mae: 0.9297\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 403us/step - loss: 1.5271 - mse: 1.5271 - mae: 0.8936 - val_loss: 1.2761 - val_mse: 1.2761 - val_mae: 0.9284\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 297us/step - loss: 1.5211 - mse: 1.5211 - mae: 0.8920 - val_loss: 1.2743 - val_mse: 1.2743 - val_mae: 0.9273\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 543us/step - loss: 1.5154 - mse: 1.5154 - mae: 0.8903 - val_loss: 1.2733 - val_mse: 1.2733 - val_mae: 0.9263\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 0s 695us/step - loss: 1.5098 - mse: 1.5098 - mae: 0.8885 - val_loss: 1.2725 - val_mse: 1.2725 - val_mae: 0.9255\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 609us/step - loss: 1.5045 - mse: 1.5045 - mae: 0.8868 - val_loss: 1.2717 - val_mse: 1.2717 - val_mae: 0.9247\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 680us/step - loss: 1.4994 - mse: 1.4994 - mae: 0.8849 - val_loss: 1.2705 - val_mse: 1.2705 - val_mae: 0.9237\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 549us/step - loss: 1.4943 - mse: 1.4943 - mae: 0.8831 - val_loss: 1.2684 - val_mse: 1.2684 - val_mae: 0.9221\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 626us/step - loss: 1.4893 - mse: 1.4893 - mae: 0.8816 - val_loss: 1.2673 - val_mse: 1.2673 - val_mae: 0.9210\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 397us/step - loss: 1.4845 - mse: 1.4845 - mae: 0.8801 - val_loss: 1.2673 - val_mse: 1.2673 - val_mae: 0.9205\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 414us/step - loss: 1.4797 - mse: 1.4797 - mae: 0.8784 - val_loss: 1.2670 - val_mse: 1.2670 - val_mae: 0.9197\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 619us/step - loss: 1.4750 - mse: 1.4750 - mae: 0.8767 - val_loss: 1.2665 - val_mse: 1.2665 - val_mae: 0.9189\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 637us/step - loss: 1.4704 - mse: 1.4704 - mae: 0.8750 - val_loss: 1.2663 - val_mse: 1.2663 - val_mae: 0.9182\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 493us/step - loss: 1.4658 - mse: 1.4658 - mae: 0.8733 - val_loss: 1.2648 - val_mse: 1.2648 - val_mae: 0.9170\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 634us/step - loss: 1.4611 - mse: 1.4611 - mae: 0.8718 - val_loss: 1.2640 - val_mse: 1.2640 - val_mae: 0.9167\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 374us/step - loss: 1.4565 - mse: 1.4565 - mae: 0.8704 - val_loss: 1.2636 - val_mse: 1.2636 - val_mae: 0.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 485us/step - loss: 1.4520 - mse: 1.4520 - mae: 0.8688 - val_loss: 1.2640 - val_mse: 1.2640 - val_mae: 0.9172\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 247us/step - loss: 1.4474 - mse: 1.4474 - mae: 0.8670 - val_loss: 1.2641 - val_mse: 1.2641 - val_mae: 0.9174\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 423us/step - loss: 1.4428 - mse: 1.4428 - mae: 0.8653 - val_loss: 1.2645 - val_mse: 1.2645 - val_mae: 0.9177\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 319us/step - loss: 1.4384 - mse: 1.4384 - mae: 0.8636 - val_loss: 1.2648 - val_mse: 1.2648 - val_mae: 0.9178\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 287us/step - loss: 1.4339 - mse: 1.4339 - mae: 0.8619 - val_loss: 1.2658 - val_mse: 1.2658 - val_mae: 0.9181\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 302us/step - loss: 1.4297 - mse: 1.4297 - mae: 0.8600 - val_loss: 1.2665 - val_mse: 1.2665 - val_mae: 0.9185\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 255us/step - loss: 1.4255 - mse: 1.4255 - mae: 0.8586 - val_loss: 1.2659 - val_mse: 1.2659 - val_mae: 0.9185\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 445us/step - loss: 1.4212 - mse: 1.4212 - mae: 0.8576 - val_loss: 1.2651 - val_mse: 1.2651 - val_mae: 0.9186\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 585us/step - loss: 1.4169 - mse: 1.4169 - mae: 0.8566 - val_loss: 1.2643 - val_mse: 1.2643 - val_mae: 0.9187\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 435us/step - loss: 1.4127 - mse: 1.4127 - mae: 0.8555 - val_loss: 1.2632 - val_mse: 1.2632 - val_mae: 0.9184\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 630us/step - loss: 1.4084 - mse: 1.4084 - mae: 0.8543 - val_loss: 1.2634 - val_mse: 1.2634 - val_mae: 0.9186\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 673us/step - loss: 1.4039 - mse: 1.4039 - mae: 0.8528 - val_loss: 1.2646 - val_mse: 1.2646 - val_mae: 0.9192\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 843us/step - loss: 1.3995 - mse: 1.3995 - mae: 0.8511 - val_loss: 1.2659 - val_mse: 1.2659 - val_mae: 0.9200\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 568us/step - loss: 1.3952 - mse: 1.3952 - mae: 0.8495 - val_loss: 1.2668 - val_mse: 1.2668 - val_mae: 0.9205\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 828us/step - loss: 1.3911 - mse: 1.3911 - mae: 0.8481 - val_loss: 1.2673 - val_mse: 1.2673 - val_mae: 0.9207\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 239us/step - loss: 1.3872 - mse: 1.3872 - mae: 0.8468 - val_loss: 1.2683 - val_mse: 1.2683 - val_mae: 0.9210\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 336us/step - loss: 1.3831 - mse: 1.3831 - mae: 0.8455 - val_loss: 1.2704 - val_mse: 1.2704 - val_mae: 0.9219\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 674us/step - loss: 1.3790 - mse: 1.3790 - mae: 0.8442 - val_loss: 1.2721 - val_mse: 1.2721 - val_mae: 0.9226\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 465us/step - loss: 1.3750 - mse: 1.3750 - mae: 0.8428 - val_loss: 1.2734 - val_mse: 1.2734 - val_mae: 0.9232\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 722us/step - loss: 1.3709 - mse: 1.3709 - mae: 0.8415 - val_loss: 1.2753 - val_mse: 1.2753 - val_mae: 0.9239\n",
      "43\n",
      "[43]\n",
      "Train on 81 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 3.8075 - mse: 3.8075 - mae: 1.7277 - val_loss: 2.1117 - val_mse: 2.1117 - val_mae: 1.2447\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 0s 278us/step - loss: 2.8763 - mse: 2.8763 - mae: 1.4372 - val_loss: 1.4739 - val_mse: 1.4739 - val_mae: 0.9753\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 0s 398us/step - loss: 2.1223 - mse: 2.1223 - mae: 1.1615 - val_loss: 0.9989 - val_mse: 0.9989 - val_mae: 0.7698\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 0s 408us/step - loss: 1.5514 - mse: 1.5514 - mae: 0.9360 - val_loss: 0.6756 - val_mse: 0.6756 - val_mae: 0.6157\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 0s 368us/step - loss: 1.1650 - mse: 1.1650 - mae: 0.8073 - val_loss: 0.5095 - val_mse: 0.5095 - val_mae: 0.5203\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.9496 - mse: 0.9496 - mae: 0.7567 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.5366\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 0s 270us/step - loss: 0.8745 - mse: 0.8745 - mae: 0.7685 - val_loss: 0.5407 - val_mse: 0.5407 - val_mae: 0.5944\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 0s 292us/step - loss: 0.8863 - mse: 0.8863 - mae: 0.7978 - val_loss: 0.6310 - val_mse: 0.6310 - val_mae: 0.6519\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 0s 436us/step - loss: 0.9248 - mse: 0.9248 - mae: 0.8260 - val_loss: 0.6951 - val_mse: 0.6951 - val_mae: 0.6838\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 0s 508us/step - loss: 0.9448 - mse: 0.9448 - mae: 0.8374 - val_loss: 0.7086 - val_mse: 0.7086 - val_mae: 0.6898\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 0s 364us/step - loss: 0.9312 - mse: 0.9312 - mae: 0.8299 - val_loss: 0.6783 - val_mse: 0.6783 - val_mae: 0.6755\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 0s 356us/step - loss: 0.8940 - mse: 0.8940 - mae: 0.8087 - val_loss: 0.6264 - val_mse: 0.6264 - val_mae: 0.6485\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 0s 333us/step - loss: 0.8514 - mse: 0.8514 - mae: 0.7844 - val_loss: 0.5744 - val_mse: 0.5744 - val_mae: 0.6160\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 0s 365us/step - loss: 0.8174 - mse: 0.8174 - mae: 0.7622 - val_loss: 0.5346 - val_mse: 0.5346 - val_mae: 0.5875\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.7970 - mse: 0.7970 - mae: 0.7423 - val_loss: 0.5105 - val_mse: 0.5105 - val_mae: 0.5692\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 0s 285us/step - loss: 0.7865 - mse: 0.7865 - mae: 0.7286 - val_loss: 0.4985 - val_mse: 0.4985 - val_mae: 0.5566\n",
      "44\n",
      "[44]\n",
      "Train on 83 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 4.5737 - mse: 4.5737 - mae: 1.3320 - val_loss: 5.0823 - val_mse: 5.0823 - val_mae: 1.8424\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 369us/step - loss: 4.2047 - mse: 4.2047 - mae: 1.2540 - val_loss: 4.1540 - val_mse: 4.1540 - val_mae: 1.6284\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 475us/step - loss: 3.9814 - mse: 3.9814 - mae: 1.2222 - val_loss: 3.4551 - val_mse: 3.4551 - val_mae: 1.4653\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 378us/step - loss: 3.8779 - mse: 3.8779 - mae: 1.2113 - val_loss: 3.0183 - val_mse: 3.0183 - val_mae: 1.3624\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 485us/step - loss: 3.8289 - mse: 3.8289 - mae: 1.2066 - val_loss: 2.8082 - val_mse: 2.8082 - val_mae: 1.3144\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 663us/step - loss: 3.7788 - mse: 3.7788 - mae: 1.2003 - val_loss: 2.7584 - val_mse: 2.7584 - val_mae: 1.3025\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 430us/step - loss: 3.7101 - mse: 3.7101 - mae: 1.1895 - val_loss: 2.8146 - val_mse: 2.8146 - val_mae: 1.3158\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 470us/step - loss: 3.6298 - mse: 3.6298 - mae: 1.1726 - val_loss: 2.9280 - val_mse: 2.9280 - val_mae: 1.3414\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 551us/step - loss: 3.5492 - mse: 3.5492 - mae: 1.1549 - val_loss: 3.0518 - val_mse: 3.0518 - val_mae: 1.3713\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 324us/step - loss: 3.4801 - mse: 3.4801 - mae: 1.1383 - val_loss: 3.1568 - val_mse: 3.1568 - val_mae: 1.3969\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 603us/step - loss: 3.4221 - mse: 3.4221 - mae: 1.1228 - val_loss: 3.2181 - val_mse: 3.2181 - val_mae: 1.4118\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 638us/step - loss: 3.3696 - mse: 3.3696 - mae: 1.1089 - val_loss: 3.2184 - val_mse: 3.2184 - val_mae: 1.4117\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 572us/step - loss: 3.3190 - mse: 3.3190 - mae: 1.0968 - val_loss: 3.1618 - val_mse: 3.1618 - val_mae: 1.3976\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 406us/step - loss: 3.2686 - mse: 3.2686 - mae: 1.0862 - val_loss: 3.0687 - val_mse: 3.0687 - val_mae: 1.3739\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 944us/step - loss: 3.2191 - mse: 3.2191 - mae: 1.0766 - val_loss: 2.9668 - val_mse: 2.9668 - val_mae: 1.3472\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 908us/step - loss: 3.1743 - mse: 3.1743 - mae: 1.0685 - val_loss: 2.8629 - val_mse: 2.8629 - val_mae: 1.3189\n",
      "45\n",
      "[45]\n",
      "Train on 112 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 9.7901 - mse: 9.7901 - mae: 2.7751 - val_loss: 6.0437 - val_mse: 6.0437 - val_mae: 2.3539\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 479us/step - loss: 8.6752 - mse: 8.6752 - mae: 2.5832 - val_loss: 5.2965 - val_mse: 5.2965 - val_mae: 2.1966\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 344us/step - loss: 7.8392 - mse: 7.8392 - mae: 2.4295 - val_loss: 4.8874 - val_mse: 4.8874 - val_mae: 2.1035\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 283us/step - loss: 7.3292 - mse: 7.3292 - mae: 2.3268 - val_loss: 4.6768 - val_mse: 4.6768 - val_mae: 2.0489\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 358us/step - loss: 7.0238 - mse: 7.0238 - mae: 2.2620 - val_loss: 4.5880 - val_mse: 4.5880 - val_mae: 2.0232\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 274us/step - loss: 6.8382 - mse: 6.8382 - mae: 2.2228 - val_loss: 4.5335 - val_mse: 4.5335 - val_mae: 2.0083\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 390us/step - loss: 6.7185 - mse: 6.7185 - mae: 2.1972 - val_loss: 4.4901 - val_mse: 4.4901 - val_mae: 1.9970\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 286us/step - loss: 6.6340 - mse: 6.6340 - mae: 2.1781 - val_loss: 4.4528 - val_mse: 4.4528 - val_mae: 1.9873\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 699us/step - loss: 6.5753 - mse: 6.5753 - mae: 2.1645 - val_loss: 4.4214 - val_mse: 4.4214 - val_mae: 1.9792\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 501us/step - loss: 6.5327 - mse: 6.5327 - mae: 2.1544 - val_loss: 4.3937 - val_mse: 4.3937 - val_mae: 1.9721\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 503us/step - loss: 6.4985 - mse: 6.4985 - mae: 2.1463 - val_loss: 4.3704 - val_mse: 4.3704 - val_mae: 1.9664\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 242us/step - loss: 6.4683 - mse: 6.4683 - mae: 2.1393 - val_loss: 4.3484 - val_mse: 4.3484 - val_mae: 1.9609\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 431us/step - loss: 6.4410 - mse: 6.4410 - mae: 2.1329 - val_loss: 4.3281 - val_mse: 4.3281 - val_mae: 1.9559\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 416us/step - loss: 6.4168 - mse: 6.4168 - mae: 2.1272 - val_loss: 4.3092 - val_mse: 4.3092 - val_mae: 1.9511\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 424us/step - loss: 6.3942 - mse: 6.3942 - mae: 2.1218 - val_loss: 4.2910 - val_mse: 4.2910 - val_mae: 1.9465\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 370us/step - loss: 6.3733 - mse: 6.3733 - mae: 2.1169 - val_loss: 4.2736 - val_mse: 4.2736 - val_mae: 1.9421\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 339us/step - loss: 6.3539 - mse: 6.3539 - mae: 2.1124 - val_loss: 4.2568 - val_mse: 4.2568 - val_mae: 1.9378\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 531us/step - loss: 6.3347 - mse: 6.3347 - mae: 2.1079 - val_loss: 4.2406 - val_mse: 4.2406 - val_mae: 1.9336\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 440us/step - loss: 6.3169 - mse: 6.3169 - mae: 2.1037 - val_loss: 4.2246 - val_mse: 4.2246 - val_mae: 1.9295\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 408us/step - loss: 6.2992 - mse: 6.2992 - mae: 2.0995 - val_loss: 4.2085 - val_mse: 4.2085 - val_mae: 1.9254\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 354us/step - loss: 6.2810 - mse: 6.2810 - mae: 2.0952 - val_loss: 4.1917 - val_mse: 4.1917 - val_mae: 1.9209\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 314us/step - loss: 6.2622 - mse: 6.2622 - mae: 2.0908 - val_loss: 4.1740 - val_mse: 4.1740 - val_mae: 1.9162\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 341us/step - loss: 6.2420 - mse: 6.2420 - mae: 2.0860 - val_loss: 4.1542 - val_mse: 4.1542 - val_mae: 1.9107\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 348us/step - loss: 6.2193 - mse: 6.2193 - mae: 2.0805 - val_loss: 4.1323 - val_mse: 4.1323 - val_mae: 1.9044\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 485us/step - loss: 6.1922 - mse: 6.1922 - mae: 2.0739 - val_loss: 4.1057 - val_mse: 4.1057 - val_mae: 1.8969\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 318us/step - loss: 6.1581 - mse: 6.1581 - mae: 2.0654 - val_loss: 4.0746 - val_mse: 4.0746 - val_mae: 1.8881\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 506us/step - loss: 6.1094 - mse: 6.1094 - mae: 2.0535 - val_loss: 4.0282 - val_mse: 4.0282 - val_mae: 1.8752\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 423us/step - loss: 6.0458 - mse: 6.0458 - mae: 2.0376 - val_loss: 3.9588 - val_mse: 3.9588 - val_mae: 1.8558\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 333us/step - loss: 5.9628 - mse: 5.9628 - mae: 2.0166 - val_loss: 3.8616 - val_mse: 3.8616 - val_mae: 1.8282\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 329us/step - loss: 5.8519 - mse: 5.8519 - mae: 1.9878 - val_loss: 3.7393 - val_mse: 3.7393 - val_mae: 1.7926\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 271us/step - loss: 5.7033 - mse: 5.7033 - mae: 1.9490 - val_loss: 3.5836 - val_mse: 3.5836 - val_mae: 1.7469\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 256us/step - loss: 5.5099 - mse: 5.5099 - mae: 1.8978 - val_loss: 3.3928 - val_mse: 3.3928 - val_mae: 1.6894\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 331us/step - loss: 5.2653 - mse: 5.2653 - mae: 1.8319 - val_loss: 3.1675 - val_mse: 3.1675 - val_mae: 1.6188\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 371us/step - loss: 4.9771 - mse: 4.9771 - mae: 1.7508 - val_loss: 2.9107 - val_mse: 2.9107 - val_mae: 1.5340\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 544us/step - loss: 4.6530 - mse: 4.6530 - mae: 1.6542 - val_loss: 2.6246 - val_mse: 2.6246 - val_mae: 1.4332\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 261us/step - loss: 4.2961 - mse: 4.2961 - mae: 1.5458 - val_loss: 2.3182 - val_mse: 2.3182 - val_mae: 1.3214\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 254us/step - loss: 3.9195 - mse: 3.9195 - mae: 1.4280 - val_loss: 2.0027 - val_mse: 2.0027 - val_mae: 1.2096\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 982us/step - loss: 3.5360 - mse: 3.5360 - mae: 1.3216 - val_loss: 1.6900 - val_mse: 1.6900 - val_mae: 1.0914\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 236us/step - loss: 3.1640 - mse: 3.1640 - mae: 1.2450 - val_loss: 1.3954 - val_mse: 1.3954 - val_mae: 0.9694\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 500us/step - loss: 2.8219 - mse: 2.8219 - mae: 1.1795 - val_loss: 1.1387 - val_mse: 1.1387 - val_mae: 0.8643\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 274us/step - loss: 2.5318 - mse: 2.5318 - mae: 1.1280 - val_loss: 0.9389 - val_mse: 0.9389 - val_mae: 0.7645\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 234us/step - loss: 2.3136 - mse: 2.3136 - mae: 1.1082 - val_loss: 0.8068 - val_mse: 0.8068 - val_mae: 0.6697\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 676us/step - loss: 2.1722 - mse: 2.1722 - mae: 1.1076 - val_loss: 0.7388 - val_mse: 0.7388 - val_mae: 0.5968\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 282us/step - loss: 2.1015 - mse: 2.1015 - mae: 1.1225 - val_loss: 0.7196 - val_mse: 0.7196 - val_mae: 0.5697\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 667us/step - loss: 2.0805 - mse: 2.0805 - mae: 1.1383 - val_loss: 0.7256 - val_mse: 0.7256 - val_mae: 0.5694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 318us/step - loss: 2.0817 - mse: 2.0817 - mae: 1.1531 - val_loss: 0.7349 - val_mse: 0.7349 - val_mae: 0.5819\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 325us/step - loss: 2.0839 - mse: 2.0839 - mae: 1.1600 - val_loss: 0.7366 - val_mse: 0.7366 - val_mae: 0.5864\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 769us/step - loss: 2.0789 - mse: 2.0789 - mae: 1.1592 - val_loss: 0.7302 - val_mse: 0.7302 - val_mae: 0.5802\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 0s 396us/step - loss: 2.0687 - mse: 2.0687 - mae: 1.1532 - val_loss: 0.7206 - val_mse: 0.7206 - val_mae: 0.5691\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 368us/step - loss: 2.0579 - mse: 2.0579 - mae: 1.1447 - val_loss: 0.7118 - val_mse: 0.7118 - val_mae: 0.5628\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 260us/step - loss: 2.0496 - mse: 2.0496 - mae: 1.1363 - val_loss: 0.7058 - val_mse: 0.7058 - val_mae: 0.5603\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 0s 399us/step - loss: 2.0442 - mse: 2.0442 - mae: 1.1295 - val_loss: 0.7021 - val_mse: 0.7021 - val_mae: 0.5582\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 432us/step - loss: 2.0407 - mse: 2.0407 - mae: 1.1247 - val_loss: 0.6997 - val_mse: 0.6997 - val_mae: 0.5574\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 0s 296us/step - loss: 2.0376 - mse: 2.0376 - mae: 1.1214 - val_loss: 0.6977 - val_mse: 0.6977 - val_mae: 0.5569\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 298us/step - loss: 2.0345 - mse: 2.0345 - mae: 1.1196 - val_loss: 0.6958 - val_mse: 0.6958 - val_mae: 0.5560\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 0s 414us/step - loss: 2.0309 - mse: 2.0309 - mae: 1.1188 - val_loss: 0.6937 - val_mse: 0.6937 - val_mae: 0.5547\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 0s 273us/step - loss: 2.0270 - mse: 2.0270 - mae: 1.1186 - val_loss: 0.6916 - val_mse: 0.6916 - val_mae: 0.5530\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 369us/step - loss: 2.0230 - mse: 2.0230 - mae: 1.1188 - val_loss: 0.6896 - val_mse: 0.6896 - val_mae: 0.5512\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 559us/step - loss: 2.0191 - mse: 2.0191 - mae: 1.1189 - val_loss: 0.6877 - val_mse: 0.6877 - val_mae: 0.5500\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 524us/step - loss: 2.0152 - mse: 2.0152 - mae: 1.1190 - val_loss: 0.6859 - val_mse: 0.6859 - val_mae: 0.5491\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 550us/step - loss: 2.0114 - mse: 2.0114 - mae: 1.1189 - val_loss: 0.6842 - val_mse: 0.6842 - val_mae: 0.5482\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 550us/step - loss: 2.0078 - mse: 2.0078 - mae: 1.1185 - val_loss: 0.6825 - val_mse: 0.6825 - val_mae: 0.5472\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 460us/step - loss: 2.0042 - mse: 2.0042 - mae: 1.1179 - val_loss: 0.6807 - val_mse: 0.6807 - val_mae: 0.5461\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 579us/step - loss: 2.0007 - mse: 2.0007 - mae: 1.1170 - val_loss: 0.6788 - val_mse: 0.6788 - val_mae: 0.5450\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 680us/step - loss: 1.9972 - mse: 1.9972 - mae: 1.1161 - val_loss: 0.6769 - val_mse: 0.6769 - val_mae: 0.5441\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 546us/step - loss: 1.9938 - mse: 1.9938 - mae: 1.1150 - val_loss: 0.6750 - val_mse: 0.6750 - val_mae: 0.5432\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 262us/step - loss: 1.9904 - mse: 1.9904 - mae: 1.1140 - val_loss: 0.6731 - val_mse: 0.6731 - val_mae: 0.5423\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 556us/step - loss: 1.9870 - mse: 1.9870 - mae: 1.1130 - val_loss: 0.6712 - val_mse: 0.6712 - val_mae: 0.5414\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 734us/step - loss: 1.9838 - mse: 1.9838 - mae: 1.1120 - val_loss: 0.6694 - val_mse: 0.6694 - val_mae: 0.5405\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 702us/step - loss: 1.9805 - mse: 1.9805 - mae: 1.1110 - val_loss: 0.6677 - val_mse: 0.6677 - val_mae: 0.5396\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 927us/step - loss: 1.9773 - mse: 1.9773 - mae: 1.1102 - val_loss: 0.6660 - val_mse: 0.6660 - val_mae: 0.5388\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 393us/step - loss: 1.9742 - mse: 1.9742 - mae: 1.1093 - val_loss: 0.6643 - val_mse: 0.6643 - val_mae: 0.5379\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 777us/step - loss: 1.9711 - mse: 1.9711 - mae: 1.1085 - val_loss: 0.6626 - val_mse: 0.6626 - val_mae: 0.5371\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 455us/step - loss: 1.9680 - mse: 1.9680 - mae: 1.1077 - val_loss: 0.6610 - val_mse: 0.6610 - val_mae: 0.5362\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 601us/step - loss: 1.9649 - mse: 1.9649 - mae: 1.1068 - val_loss: 0.6594 - val_mse: 0.6594 - val_mae: 0.5354\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 273us/step - loss: 1.9619 - mse: 1.9619 - mae: 1.1060 - val_loss: 0.6578 - val_mse: 0.6578 - val_mae: 0.5346\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 273us/step - loss: 1.9590 - mse: 1.9590 - mae: 1.1052 - val_loss: 0.6563 - val_mse: 0.6563 - val_mae: 0.5338\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 244us/step - loss: 1.9561 - mse: 1.9561 - mae: 1.1043 - val_loss: 0.6548 - val_mse: 0.6548 - val_mae: 0.5330\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 0s 228us/step - loss: 1.9532 - mse: 1.9532 - mae: 1.1035 - val_loss: 0.6534 - val_mse: 0.6534 - val_mae: 0.5324\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 217us/step - loss: 1.9504 - mse: 1.9504 - mae: 1.1026 - val_loss: 0.6519 - val_mse: 0.6519 - val_mae: 0.5318\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 0s 428us/step - loss: 1.9476 - mse: 1.9476 - mae: 1.1018 - val_loss: 0.6505 - val_mse: 0.6505 - val_mae: 0.5312\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 0s 394us/step - loss: 1.9447 - mse: 1.9447 - mae: 1.1009 - val_loss: 0.6491 - val_mse: 0.6491 - val_mae: 0.5307\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 0s 433us/step - loss: 1.9419 - mse: 1.9419 - mae: 1.1001 - val_loss: 0.6477 - val_mse: 0.6477 - val_mae: 0.5301\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 0s 475us/step - loss: 1.9392 - mse: 1.9392 - mae: 1.0993 - val_loss: 0.6463 - val_mse: 0.6463 - val_mae: 0.5296\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 0s 283us/step - loss: 1.9364 - mse: 1.9364 - mae: 1.0985 - val_loss: 0.6449 - val_mse: 0.6449 - val_mae: 0.5291\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 0s 760us/step - loss: 1.9337 - mse: 1.9337 - mae: 1.0977 - val_loss: 0.6436 - val_mse: 0.6436 - val_mae: 0.5285\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 0s 682us/step - loss: 1.9310 - mse: 1.9310 - mae: 1.0969 - val_loss: 0.6423 - val_mse: 0.6423 - val_mae: 0.5280\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 0s 335us/step - loss: 1.9284 - mse: 1.9284 - mae: 1.0962 - val_loss: 0.6410 - val_mse: 0.6410 - val_mae: 0.5275\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 0s 402us/step - loss: 1.9259 - mse: 1.9259 - mae: 1.0955 - val_loss: 0.6398 - val_mse: 0.6398 - val_mae: 0.5269\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 0s 274us/step - loss: 1.9233 - mse: 1.9233 - mae: 1.0949 - val_loss: 0.6386 - val_mse: 0.6386 - val_mae: 0.5264\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 287us/step - loss: 1.9208 - mse: 1.9208 - mae: 1.0942 - val_loss: 0.6374 - val_mse: 0.6374 - val_mae: 0.5259\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 237us/step - loss: 1.9183 - mse: 1.9183 - mae: 1.0935 - val_loss: 0.6363 - val_mse: 0.6363 - val_mae: 0.5254\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 254us/step - loss: 1.9158 - mse: 1.9158 - mae: 1.0929 - val_loss: 0.6350 - val_mse: 0.6350 - val_mae: 0.5249\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 254us/step - loss: 1.9134 - mse: 1.9134 - mae: 1.0922 - val_loss: 0.6337 - val_mse: 0.6337 - val_mae: 0.5245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 267us/step - loss: 1.9110 - mse: 1.9110 - mae: 1.0916 - val_loss: 0.6325 - val_mse: 0.6325 - val_mae: 0.5240\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 378us/step - loss: 1.9086 - mse: 1.9086 - mae: 1.0909 - val_loss: 0.6314 - val_mse: 0.6314 - val_mae: 0.5235\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 0s 419us/step - loss: 1.9063 - mse: 1.9063 - mae: 1.0903 - val_loss: 0.6301 - val_mse: 0.6301 - val_mae: 0.5230\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 437us/step - loss: 1.9040 - mse: 1.9040 - mae: 1.0896 - val_loss: 0.6289 - val_mse: 0.6289 - val_mae: 0.5225\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 286us/step - loss: 1.9017 - mse: 1.9017 - mae: 1.0890 - val_loss: 0.6278 - val_mse: 0.6278 - val_mae: 0.5220\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 476us/step - loss: 1.8994 - mse: 1.8994 - mae: 1.0883 - val_loss: 0.6267 - val_mse: 0.6267 - val_mae: 0.5218\n",
      "46\n",
      "[46]\n",
      "Train on 101 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 7.7212 - mse: 7.7212 - mae: 2.5156 - val_loss: 7.9836 - val_mse: 7.9836 - val_mae: 2.6341\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 464us/step - loss: 7.3469 - mse: 7.3469 - mae: 2.4443 - val_loss: 7.6656 - val_mse: 7.6656 - val_mae: 2.5724\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 367us/step - loss: 7.0222 - mse: 7.0222 - mae: 2.3789 - val_loss: 7.3837 - val_mse: 7.3837 - val_mae: 2.5177\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 415us/step - loss: 6.7406 - mse: 6.7406 - mae: 2.3199 - val_loss: 7.1341 - val_mse: 7.1341 - val_mae: 2.4696\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 505us/step - loss: 6.4965 - mse: 6.4965 - mae: 2.2673 - val_loss: 6.9180 - val_mse: 6.9180 - val_mae: 2.4276\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 523us/step - loss: 6.2911 - mse: 6.2911 - mae: 2.2225 - val_loss: 6.7380 - val_mse: 6.7380 - val_mae: 2.3918\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 407us/step - loss: 6.1297 - mse: 6.1297 - mae: 2.1870 - val_loss: 6.5843 - val_mse: 6.5843 - val_mae: 2.3606\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 428us/step - loss: 5.9971 - mse: 5.9971 - mae: 2.1582 - val_loss: 6.4536 - val_mse: 6.4536 - val_mae: 2.3337\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 432us/step - loss: 5.8933 - mse: 5.8933 - mae: 2.1349 - val_loss: 6.3637 - val_mse: 6.3637 - val_mae: 2.3140\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 435us/step - loss: 5.8158 - mse: 5.8158 - mae: 2.1170 - val_loss: 6.3094 - val_mse: 6.3094 - val_mae: 2.3004\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 375us/step - loss: 5.7595 - mse: 5.7595 - mae: 2.1037 - val_loss: 6.2640 - val_mse: 6.2640 - val_mae: 2.2884\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 382us/step - loss: 5.7131 - mse: 5.7131 - mae: 2.0929 - val_loss: 6.2252 - val_mse: 6.2252 - val_mae: 2.2781\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 434us/step - loss: 5.6742 - mse: 5.6742 - mae: 2.0839 - val_loss: 6.1915 - val_mse: 6.1915 - val_mae: 2.2690\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 253us/step - loss: 5.6363 - mse: 5.6363 - mae: 2.0749 - val_loss: 6.1645 - val_mse: 6.1645 - val_mae: 2.2610\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 875us/step - loss: 5.5929 - mse: 5.5929 - mae: 2.0649 - val_loss: 6.1251 - val_mse: 6.1251 - val_mae: 2.2485\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 751us/step - loss: 5.5360 - mse: 5.5360 - mae: 2.0508 - val_loss: 6.0796 - val_mse: 6.0796 - val_mae: 2.2325\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 326us/step - loss: 5.4376 - mse: 5.4376 - mae: 2.0251 - val_loss: 5.9746 - val_mse: 5.9746 - val_mae: 2.1999\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 509us/step - loss: 5.2418 - mse: 5.2418 - mae: 1.9754 - val_loss: 5.7318 - val_mse: 5.7318 - val_mae: 2.1366\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 4.9074 - mse: 4.9074 - mae: 1.8811 - val_loss: 5.2296 - val_mse: 5.2296 - val_mae: 2.0110\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 315us/step - loss: 4.3284 - mse: 4.3284 - mae: 1.7143 - val_loss: 4.4629 - val_mse: 4.4629 - val_mae: 1.8091\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 472us/step - loss: 3.5866 - mse: 3.5866 - mae: 1.4947 - val_loss: 3.5666 - val_mse: 3.5666 - val_mae: 1.5813\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 334us/step - loss: 2.8477 - mse: 2.8477 - mae: 1.2876 - val_loss: 2.7467 - val_mse: 2.7467 - val_mae: 1.3793\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 331us/step - loss: 2.2400 - mse: 2.2400 - mae: 1.1196 - val_loss: 2.0739 - val_mse: 2.0739 - val_mae: 1.2078\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 307us/step - loss: 1.8096 - mse: 1.8096 - mae: 1.0110 - val_loss: 1.5918 - val_mse: 1.5918 - val_mae: 1.0932\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 398us/step - loss: 1.5807 - mse: 1.5807 - mae: 0.9407 - val_loss: 1.3075 - val_mse: 1.3075 - val_mae: 1.0081\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 357us/step - loss: 1.5203 - mse: 1.5203 - mae: 0.9249 - val_loss: 1.1758 - val_mse: 1.1758 - val_mae: 0.9540\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 339us/step - loss: 1.5530 - mse: 1.5530 - mae: 0.9572 - val_loss: 1.1322 - val_mse: 1.1322 - val_mae: 0.9363\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 514us/step - loss: 1.5895 - mse: 1.5895 - mae: 0.9794 - val_loss: 1.1223 - val_mse: 1.1223 - val_mae: 0.9318\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 306us/step - loss: 1.5860 - mse: 1.5860 - mae: 0.9801 - val_loss: 1.1248 - val_mse: 1.1248 - val_mae: 0.9299\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 325us/step - loss: 1.5526 - mse: 1.5526 - mae: 0.9639 - val_loss: 1.1402 - val_mse: 1.1402 - val_mae: 0.9330\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 401us/step - loss: 1.5142 - mse: 1.5142 - mae: 0.9415 - val_loss: 1.1670 - val_mse: 1.1670 - val_mae: 0.9414\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 264us/step - loss: 1.4857 - mse: 1.4857 - mae: 0.9258 - val_loss: 1.1965 - val_mse: 1.1965 - val_mae: 0.9539\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 965us/step - loss: 1.4686 - mse: 1.4686 - mae: 0.9154 - val_loss: 1.2193 - val_mse: 1.2193 - val_mae: 0.9617\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 355us/step - loss: 1.4580 - mse: 1.4580 - mae: 0.9085 - val_loss: 1.2306 - val_mse: 1.2306 - val_mae: 0.9664\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 563us/step - loss: 1.4494 - mse: 1.4494 - mae: 0.9037 - val_loss: 1.2304 - val_mse: 1.2304 - val_mae: 0.9655\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 720us/step - loss: 1.4411 - mse: 1.4411 - mae: 0.9003 - val_loss: 1.2212 - val_mse: 1.2212 - val_mae: 0.9604\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.4329 - mse: 1.4329 - mae: 0.8978 - val_loss: 1.2076 - val_mse: 1.2076 - val_mae: 0.9532\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 873us/step - loss: 1.4254 - mse: 1.4254 - mae: 0.8959 - val_loss: 1.1936 - val_mse: 1.1936 - val_mae: 0.9455\n",
      "47\n",
      "[47]\n",
      "Train on 87 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 4.6408 - mse: 4.6408 - mae: 1.6956 - val_loss: 2.1711 - val_mse: 2.1711 - val_mae: 1.2322\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 646us/step - loss: 3.5644 - mse: 3.5644 - mae: 1.4462 - val_loss: 1.4743 - val_mse: 1.4743 - val_mae: 0.9598\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 314us/step - loss: 2.9846 - mse: 2.9846 - mae: 1.2829 - val_loss: 1.1369 - val_mse: 1.1369 - val_mae: 0.7881\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 854us/step - loss: 2.7475 - mse: 2.7475 - mae: 1.2081 - val_loss: 0.9970 - val_mse: 0.9970 - val_mae: 0.7455\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 561us/step - loss: 2.6876 - mse: 2.6876 - mae: 1.1719 - val_loss: 0.9584 - val_mse: 0.9584 - val_mae: 0.7666\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 529us/step - loss: 2.6822 - mse: 2.6822 - mae: 1.1616 - val_loss: 0.9517 - val_mse: 0.9517 - val_mae: 0.7801\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 715us/step - loss: 2.6677 - mse: 2.6677 - mae: 1.1521 - val_loss: 0.9451 - val_mse: 0.9451 - val_mae: 0.7833\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 484us/step - loss: 2.6248 - mse: 2.6248 - mae: 1.1406 - val_loss: 0.9312 - val_mse: 0.9312 - val_mae: 0.7779\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 754us/step - loss: 2.5570 - mse: 2.5570 - mae: 1.1258 - val_loss: 0.9135 - val_mse: 0.9135 - val_mae: 0.7647\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - ETA: 0s - loss: 3.9436 - mse: 3.9436 - mae: 1.430 - 0s 490us/step - loss: 2.4791 - mse: 2.4791 - mae: 1.1098 - val_loss: 0.9031 - val_mse: 0.9031 - val_mae: 0.7495\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 426us/step - loss: 2.3992 - mse: 2.3992 - mae: 1.0966 - val_loss: 0.9064 - val_mse: 0.9064 - val_mae: 0.7435\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 307us/step - loss: 2.3236 - mse: 2.3236 - mae: 1.0900 - val_loss: 0.9197 - val_mse: 0.9197 - val_mae: 0.7449\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 296us/step - loss: 2.2602 - mse: 2.2602 - mae: 1.0861 - val_loss: 0.9384 - val_mse: 0.9384 - val_mae: 0.7449\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 502us/step - loss: 2.2056 - mse: 2.2056 - mae: 1.0824 - val_loss: 0.9581 - val_mse: 0.9581 - val_mae: 0.7467\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 388us/step - loss: 2.1528 - mse: 2.1528 - mae: 1.0766 - val_loss: 0.9713 - val_mse: 0.9713 - val_mae: 0.7564\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 634us/step - loss: 2.1066 - mse: 2.1066 - mae: 1.0679 - val_loss: 0.9736 - val_mse: 0.9736 - val_mae: 0.7609\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 499us/step - loss: 2.0573 - mse: 2.0573 - mae: 1.0547 - val_loss: 0.9663 - val_mse: 0.9663 - val_mae: 0.7631\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 737us/step - loss: 2.0077 - mse: 2.0077 - mae: 1.0390 - val_loss: 0.9544 - val_mse: 0.9544 - val_mae: 0.7662\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 450us/step - loss: 1.9603 - mse: 1.9603 - mae: 1.0230 - val_loss: 0.9418 - val_mse: 0.9418 - val_mae: 0.7677\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - ETA: 0s - loss: 3.1887 - mse: 3.1887 - mae: 1.307 - 0s 553us/step - loss: 1.9194 - mse: 1.9194 - mae: 1.0079 - val_loss: 0.9334 - val_mse: 0.9334 - val_mae: 0.7698\n",
      "48\n",
      "[48]\n",
      "Train on 99 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 2s 20ms/step - loss: 15.5105 - mse: 15.5105 - mae: 3.5978 - val_loss: 6.2377 - val_mse: 6.2377 - val_mae: 2.2821\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 396us/step - loss: 11.1339 - mse: 11.1339 - mae: 2.9380 - val_loss: 4.3333 - val_mse: 4.3333 - val_mae: 1.8189\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 514us/step - loss: 7.8248 - mse: 7.8248 - mae: 2.3531 - val_loss: 2.9447 - val_mse: 2.9447 - val_mae: 1.3821\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 294us/step - loss: 5.4564 - mse: 5.4564 - mae: 1.8744 - val_loss: 2.0351 - val_mse: 2.0351 - val_mae: 1.1083\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 374us/step - loss: 3.8806 - mse: 3.8806 - mae: 1.5511 - val_loss: 1.4595 - val_mse: 1.4595 - val_mae: 0.8741\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 818us/step - loss: 2.9732 - mse: 2.9732 - mae: 1.3705 - val_loss: 1.1248 - val_mse: 1.1248 - val_mae: 0.7356\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 379us/step - loss: 2.4540 - mse: 2.4540 - mae: 1.2452 - val_loss: 0.9702 - val_mse: 0.9702 - val_mae: 0.7164\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 346us/step - loss: 2.1656 - mse: 2.1656 - mae: 1.1747 - val_loss: 0.9186 - val_mse: 0.9186 - val_mae: 0.7301\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 744us/step - loss: 2.0173 - mse: 2.0173 - mae: 1.1440 - val_loss: 0.9377 - val_mse: 0.9377 - val_mae: 0.7448\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 595us/step - loss: 1.9609 - mse: 1.9609 - mae: 1.1281 - val_loss: 0.9735 - val_mse: 0.9735 - val_mae: 0.7701\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 320us/step - loss: 1.9464 - mse: 1.9464 - mae: 1.1215 - val_loss: 1.0006 - val_mse: 1.0006 - val_mae: 0.7908\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 345us/step - loss: 1.9416 - mse: 1.9416 - mae: 1.1212 - val_loss: 1.0129 - val_mse: 1.0129 - val_mae: 0.8004\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 535us/step - loss: 1.9308 - mse: 1.9308 - mae: 1.1192 - val_loss: 1.0097 - val_mse: 1.0097 - val_mae: 0.8011\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 441us/step - loss: 1.9117 - mse: 1.9117 - mae: 1.1140 - val_loss: 0.9961 - val_mse: 0.9961 - val_mae: 0.7957\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.8913 - mse: 1.8913 - mae: 1.1077 - val_loss: 0.9788 - val_mse: 0.9788 - val_mae: 0.7874\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.8730 - mse: 1.8730 - mae: 1.1032 - val_loss: 0.9622 - val_mse: 0.9622 - val_mae: 0.7783\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 668us/step - loss: 1.8583 - mse: 1.8583 - mae: 1.0999 - val_loss: 0.9486 - val_mse: 0.9486 - val_mae: 0.7701\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 583us/step - loss: 1.8475 - mse: 1.8475 - mae: 1.0976 - val_loss: 0.9397 - val_mse: 0.9397 - val_mae: 0.7640\n",
      "49\n",
      "[49]\n",
      "Train on 99 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 35.6579 - mse: 35.6579 - mae: 4.9713 - val_loss: 11.8193 - val_mse: 11.8193 - val_mae: 3.2533\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 538us/step - loss: 27.2755 - mse: 27.2755 - mae: 4.2882 - val_loss: 9.1895 - val_mse: 9.1895 - val_mae: 2.8448\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 835us/step - loss: 20.2267 - mse: 20.2267 - mae: 3.6157 - val_loss: 7.0148 - val_mse: 7.0148 - val_mae: 2.4552\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 650us/step - loss: 14.7694 - mse: 14.7694 - mae: 3.0145 - val_loss: 5.2123 - val_mse: 5.2123 - val_mae: 2.0770\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 917us/step - loss: 10.6981 - mse: 10.6981 - mae: 2.4908 - val_loss: 3.7739 - val_mse: 3.7739 - val_mae: 1.7154\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 681us/step - loss: 7.7773 - mse: 7.7773 - mae: 2.0727 - val_loss: 2.6774 - val_mse: 2.6774 - val_mae: 1.3892\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 432us/step - loss: 5.8845 - mse: 5.8845 - mae: 1.8303 - val_loss: 1.9046 - val_mse: 1.9046 - val_mae: 1.1463\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 554us/step - loss: 4.8185 - mse: 4.8185 - mae: 1.6667 - val_loss: 1.3999 - val_mse: 1.3999 - val_mae: 0.9696\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 571us/step - loss: 4.3324 - mse: 4.3324 - mae: 1.5559 - val_loss: 1.0961 - val_mse: 1.0961 - val_mae: 0.8541\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 610us/step - loss: 4.1871 - mse: 4.1871 - mae: 1.5085 - val_loss: 0.9282 - val_mse: 0.9282 - val_mae: 0.7823\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 601us/step - loss: 4.1706 - mse: 4.1706 - mae: 1.4963 - val_loss: 0.8421 - val_mse: 0.8421 - val_mae: 0.7347\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 658us/step - loss: 4.1376 - mse: 4.1376 - mae: 1.4813 - val_loss: 0.8060 - val_mse: 0.8060 - val_mae: 0.7090\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 784us/step - loss: 4.0404 - mse: 4.0404 - mae: 1.4652 - val_loss: 0.7995 - val_mse: 0.7995 - val_mae: 0.7043\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 336us/step - loss: 3.8680 - mse: 3.8680 - mae: 1.4368 - val_loss: 0.8141 - val_mse: 0.8141 - val_mae: 0.7216\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 758us/step - loss: 3.6992 - mse: 3.6992 - mae: 1.4102 - val_loss: 0.8419 - val_mse: 0.8419 - val_mae: 0.7436\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 728us/step - loss: 3.5734 - mse: 3.5734 - mae: 1.3907 - val_loss: 0.8780 - val_mse: 0.8780 - val_mae: 0.7638\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 479us/step - loss: 3.4913 - mse: 3.4913 - mae: 1.3776 - val_loss: 0.9046 - val_mse: 0.9046 - val_mae: 0.7781\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 682us/step - loss: 3.4367 - mse: 3.4367 - mae: 1.3656 - val_loss: 0.9120 - val_mse: 0.9120 - val_mae: 0.7815\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 506us/step - loss: 3.3885 - mse: 3.3885 - mae: 1.3533 - val_loss: 0.9004 - val_mse: 0.9004 - val_mae: 0.7754\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 505us/step - loss: 3.3365 - mse: 3.3365 - mae: 1.3411 - val_loss: 0.8774 - val_mse: 0.8774 - val_mae: 0.7635\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 511us/step - loss: 3.2811 - mse: 3.2811 - mae: 1.3290 - val_loss: 0.8499 - val_mse: 0.8499 - val_mae: 0.7489\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 276us/step - loss: 3.2279 - mse: 3.2279 - mae: 1.3180 - val_loss: 0.8220 - val_mse: 0.8220 - val_mae: 0.7333\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 698us/step - loss: 3.1774 - mse: 3.1774 - mae: 1.3080 - val_loss: 0.7997 - val_mse: 0.7997 - val_mae: 0.7204\n",
      "50\n",
      "[50]\n",
      "Train on 101 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.9018 - mse: 1.9018 - mae: 1.0311 - val_loss: 0.7079 - val_mse: 0.7079 - val_mae: 0.5818\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 457us/step - loss: 1.8641 - mse: 1.8641 - mae: 1.0274 - val_loss: 0.7209 - val_mse: 0.7209 - val_mae: 0.6183\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 337us/step - loss: 1.8429 - mse: 1.8429 - mae: 1.0242 - val_loss: 0.7066 - val_mse: 0.7066 - val_mae: 0.6094\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 419us/step - loss: 1.8154 - mse: 1.8154 - mae: 1.0157 - val_loss: 0.6843 - val_mse: 0.6843 - val_mae: 0.5851\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 256us/step - loss: 1.7888 - mse: 1.7888 - mae: 1.0068 - val_loss: 0.6695 - val_mse: 0.6695 - val_mae: 0.5723\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 728us/step - loss: 1.7655 - mse: 1.7655 - mae: 1.0004 - val_loss: 0.6640 - val_mse: 0.6640 - val_mae: 0.5770\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 540us/step - loss: 1.7450 - mse: 1.7450 - mae: 0.9962 - val_loss: 0.6625 - val_mse: 0.6625 - val_mae: 0.5876\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 466us/step - loss: 1.7270 - mse: 1.7270 - mae: 0.9929 - val_loss: 0.6590 - val_mse: 0.6590 - val_mae: 0.5933\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 463us/step - loss: 1.7096 - mse: 1.7096 - mae: 0.9894 - val_loss: 0.6511 - val_mse: 0.6511 - val_mae: 0.5910\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 416us/step - loss: 1.6921 - mse: 1.6921 - mae: 0.9849 - val_loss: 0.6416 - val_mse: 0.6416 - val_mae: 0.5853\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 486us/step - loss: 1.6749 - mse: 1.6749 - mae: 0.9799 - val_loss: 0.6339 - val_mse: 0.6339 - val_mae: 0.5815\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 803us/step - loss: 1.6594 - mse: 1.6594 - mae: 0.9754 - val_loss: 0.6294 - val_mse: 0.6294 - val_mae: 0.5820\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 382us/step - loss: 1.6449 - mse: 1.6449 - mae: 0.9714 - val_loss: 0.6269 - val_mse: 0.6269 - val_mae: 0.5845\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 801us/step - loss: 1.6311 - mse: 1.6311 - mae: 0.9675 - val_loss: 0.6236 - val_mse: 0.6236 - val_mae: 0.5852\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 719us/step - loss: 1.6177 - mse: 1.6177 - mae: 0.9632 - val_loss: 0.6187 - val_mse: 0.6187 - val_mae: 0.5830\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 477us/step - loss: 1.6041 - mse: 1.6041 - mae: 0.9585 - val_loss: 0.6137 - val_mse: 0.6137 - val_mae: 0.5801\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 765us/step - loss: 1.5911 - mse: 1.5911 - mae: 0.9540 - val_loss: 0.6100 - val_mse: 0.6100 - val_mae: 0.5786\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 422us/step - loss: 1.5790 - mse: 1.5790 - mae: 0.9499 - val_loss: 0.6068 - val_mse: 0.6068 - val_mae: 0.5781\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 347us/step - loss: 1.5677 - mse: 1.5677 - mae: 0.9466 - val_loss: 0.6038 - val_mse: 0.6038 - val_mae: 0.5776\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 622us/step - loss: 1.5566 - mse: 1.5566 - mae: 0.9433 - val_loss: 0.6013 - val_mse: 0.6013 - val_mae: 0.5771\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 720us/step - loss: 1.5459 - mse: 1.5459 - mae: 0.9401 - val_loss: 0.5987 - val_mse: 0.5987 - val_mae: 0.5765\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 328us/step - loss: 1.5352 - mse: 1.5352 - mae: 0.9371 - val_loss: 0.5967 - val_mse: 0.5967 - val_mae: 0.5764\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 716us/step - loss: 1.5248 - mse: 1.5248 - mae: 0.9345 - val_loss: 0.5956 - val_mse: 0.5956 - val_mae: 0.5767\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 374us/step - loss: 1.5142 - mse: 1.5142 - mae: 0.9316 - val_loss: 0.5944 - val_mse: 0.5944 - val_mae: 0.5769\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 492us/step - loss: 1.5038 - mse: 1.5038 - mae: 0.9286 - val_loss: 0.5928 - val_mse: 0.5928 - val_mae: 0.5765\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 306us/step - loss: 1.4937 - mse: 1.4937 - mae: 0.9255 - val_loss: 0.5910 - val_mse: 0.5910 - val_mae: 0.5754\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 384us/step - loss: 1.4836 - mse: 1.4836 - mae: 0.9223 - val_loss: 0.5885 - val_mse: 0.5885 - val_mae: 0.5737\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 390us/step - loss: 1.4740 - mse: 1.4740 - mae: 0.9194 - val_loss: 0.5866 - val_mse: 0.5866 - val_mae: 0.5728\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 749us/step - loss: 1.4648 - mse: 1.4648 - mae: 0.9167 - val_loss: 0.5836 - val_mse: 0.5836 - val_mae: 0.5715\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 461us/step - loss: 1.4560 - mse: 1.4560 - mae: 0.9140 - val_loss: 0.5795 - val_mse: 0.5795 - val_mae: 0.5694\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 709us/step - loss: 1.4472 - mse: 1.4472 - mae: 0.9113 - val_loss: 0.5762 - val_mse: 0.5762 - val_mae: 0.5683\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 363us/step - loss: 1.4386 - mse: 1.4386 - mae: 0.9089 - val_loss: 0.5738 - val_mse: 0.5738 - val_mae: 0.5680\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 488us/step - loss: 1.4304 - mse: 1.4304 - mae: 0.9068 - val_loss: 0.5724 - val_mse: 0.5724 - val_mae: 0.5677\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 466us/step - loss: 1.4223 - mse: 1.4223 - mae: 0.9045 - val_loss: 0.5706 - val_mse: 0.5706 - val_mae: 0.5667\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 498us/step - loss: 1.4142 - mse: 1.4142 - mae: 0.9020 - val_loss: 0.5691 - val_mse: 0.5691 - val_mae: 0.5666\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 592us/step - loss: 1.4066 - mse: 1.4066 - mae: 0.8993 - val_loss: 0.5657 - val_mse: 0.5657 - val_mae: 0.5653\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 990us/step - loss: 1.3992 - mse: 1.3992 - mae: 0.8968 - val_loss: 0.5638 - val_mse: 0.5638 - val_mae: 0.5658\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 337us/step - loss: 1.3920 - mse: 1.3920 - mae: 0.8948 - val_loss: 0.5618 - val_mse: 0.5618 - val_mae: 0.5661\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 782us/step - loss: 1.3847 - mse: 1.3847 - mae: 0.8924 - val_loss: 0.5582 - val_mse: 0.5582 - val_mae: 0.5650\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 775us/step - loss: 1.3771 - mse: 1.3771 - mae: 0.8895 - val_loss: 0.5551 - val_mse: 0.5551 - val_mae: 0.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 459us/step - loss: 1.3695 - mse: 1.3695 - mae: 0.8865 - val_loss: 0.5532 - val_mse: 0.5532 - val_mae: 0.5625\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 418us/step - loss: 1.3622 - mse: 1.3622 - mae: 0.8838 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5642\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 298us/step - loss: 1.3556 - mse: 1.3556 - mae: 0.8818 - val_loss: 0.5536 - val_mse: 0.5536 - val_mae: 0.5659\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 739us/step - loss: 1.3485 - mse: 1.3485 - mae: 0.8798 - val_loss: 0.5540 - val_mse: 0.5540 - val_mae: 0.5676\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 412us/step - loss: 1.3410 - mse: 1.3410 - mae: 0.8771 - val_loss: 0.5562 - val_mse: 0.5562 - val_mae: 0.5696\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 338us/step - loss: 1.3331 - mse: 1.3331 - mae: 0.8742 - val_loss: 0.5571 - val_mse: 0.5571 - val_mae: 0.5698\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 439us/step - loss: 1.3256 - mse: 1.3256 - mae: 0.8714 - val_loss: 0.5575 - val_mse: 0.5575 - val_mae: 0.5707\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 790us/step - loss: 1.3189 - mse: 1.3189 - mae: 0.8692 - val_loss: 0.5595 - val_mse: 0.5595 - val_mae: 0.5737\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 488us/step - loss: 1.3121 - mse: 1.3121 - mae: 0.8672 - val_loss: 0.5611 - val_mse: 0.5611 - val_mae: 0.5764\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 688us/step - loss: 1.3055 - mse: 1.3055 - mae: 0.8652 - val_loss: 0.5590 - val_mse: 0.5590 - val_mae: 0.5758\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 875us/step - loss: 1.2980 - mse: 1.2980 - mae: 0.8622 - val_loss: 0.5581 - val_mse: 0.5581 - val_mae: 0.5755\n",
      "51\n",
      "[51]\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "116/116 [==============================] - 2s 14ms/step - loss: 4.6321 - mse: 4.6321 - mae: 1.6555 - val_loss: 1.2396 - val_mse: 1.2396 - val_mae: 0.8576\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 0s 472us/step - loss: 3.9431 - mse: 3.9431 - mae: 1.4872 - val_loss: 0.9892 - val_mse: 0.9892 - val_mae: 0.7317\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 0s 595us/step - loss: 3.3535 - mse: 3.3535 - mae: 1.3396 - val_loss: 0.7949 - val_mse: 0.7949 - val_mae: 0.6320\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 0s 402us/step - loss: 2.8377 - mse: 2.8377 - mae: 1.2196 - val_loss: 0.6593 - val_mse: 0.6593 - val_mae: 0.5574\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 0s 500us/step - loss: 2.4840 - mse: 2.4840 - mae: 1.1589 - val_loss: 0.6046 - val_mse: 0.6046 - val_mae: 0.5417\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 0s 325us/step - loss: 2.2959 - mse: 2.2959 - mae: 1.1466 - val_loss: 0.6148 - val_mse: 0.6148 - val_mae: 0.5638\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 0s 311us/step - loss: 2.2417 - mse: 2.2417 - mae: 1.1585 - val_loss: 0.6647 - val_mse: 0.6647 - val_mae: 0.5984\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 0s 486us/step - loss: 2.2451 - mse: 2.2451 - mae: 1.1723 - val_loss: 0.7003 - val_mse: 0.7003 - val_mae: 0.6231\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 0s 403us/step - loss: 2.2359 - mse: 2.2359 - mae: 1.1770 - val_loss: 0.7032 - val_mse: 0.7032 - val_mae: 0.6250\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 0s 383us/step - loss: 2.1944 - mse: 2.1944 - mae: 1.1661 - val_loss: 0.6825 - val_mse: 0.6825 - val_mae: 0.6124\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 0s 313us/step - loss: 2.1428 - mse: 2.1428 - mae: 1.1481 - val_loss: 0.6605 - val_mse: 0.6605 - val_mae: 0.6003\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 0s 240us/step - loss: 2.1011 - mse: 2.1011 - mae: 1.1301 - val_loss: 0.6462 - val_mse: 0.6462 - val_mae: 0.5906\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 0s 389us/step - loss: 2.0695 - mse: 2.0695 - mae: 1.1156 - val_loss: 0.6374 - val_mse: 0.6374 - val_mae: 0.5854\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 0s 301us/step - loss: 2.0452 - mse: 2.0452 - mae: 1.1050 - val_loss: 0.6339 - val_mse: 0.6339 - val_mae: 0.5857\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 0s 509us/step - loss: 2.0220 - mse: 2.0220 - mae: 1.0969 - val_loss: 0.6354 - val_mse: 0.6354 - val_mae: 0.5878\n",
      "52\n",
      "[52]\n",
      "Train on 108 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 4.6220 - mse: 4.6220 - mae: 1.6099 - val_loss: 8.1654 - val_mse: 8.1654 - val_mae: 2.3424\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 3.8901 - mse: 3.8901 - mae: 1.4108 - val_loss: 6.2351 - val_mse: 6.2351 - val_mae: 2.0060\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 3.2432 - mse: 3.2432 - mae: 1.2420 - val_loss: 4.5845 - val_mse: 4.5845 - val_mae: 1.6900\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 423us/step - loss: 2.7407 - mse: 2.7407 - mae: 1.1365 - val_loss: 3.3657 - val_mse: 3.3657 - val_mae: 1.4245\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 319us/step - loss: 2.4684 - mse: 2.4684 - mae: 1.1148 - val_loss: 2.6004 - val_mse: 2.6004 - val_mae: 1.2743\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 897us/step - loss: 2.3924 - mse: 2.3924 - mae: 1.1635 - val_loss: 2.2358 - val_mse: 2.2358 - val_mae: 1.1797\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 391us/step - loss: 2.4075 - mse: 2.4075 - mae: 1.2075 - val_loss: 2.1093 - val_mse: 2.1093 - val_mae: 1.1528\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 296us/step - loss: 2.3909 - mse: 2.3909 - mae: 1.2125 - val_loss: 2.0970 - val_mse: 2.0970 - val_mae: 1.1512\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 683us/step - loss: 2.3233 - mse: 2.3233 - mae: 1.1844 - val_loss: 2.1660 - val_mse: 2.1660 - val_mae: 1.1671\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 529us/step - loss: 2.2500 - mse: 2.2500 - mae: 1.1461 - val_loss: 2.2853 - val_mse: 2.2853 - val_mae: 1.2100\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 356us/step - loss: 2.1983 - mse: 2.1983 - mae: 1.1161 - val_loss: 2.4083 - val_mse: 2.4083 - val_mae: 1.2472\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 490us/step - loss: 2.1673 - mse: 2.1673 - mae: 1.0972 - val_loss: 2.4802 - val_mse: 2.4802 - val_mae: 1.2670\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 417us/step - loss: 2.1413 - mse: 2.1413 - mae: 1.0867 - val_loss: 2.4855 - val_mse: 2.4855 - val_mae: 1.2700\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 327us/step - loss: 2.1132 - mse: 2.1132 - mae: 1.0813 - val_loss: 2.4398 - val_mse: 2.4398 - val_mae: 1.2608\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 2.0835 - mse: 2.0835 - mae: 1.0803 - val_loss: 2.3715 - val_mse: 2.3715 - val_mae: 1.2454\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 323us/step - loss: 2.0565 - mse: 2.0565 - mae: 1.0824 - val_loss: 2.3048 - val_mse: 2.3048 - val_mae: 1.2297\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 318us/step - loss: 2.0331 - mse: 2.0331 - mae: 1.0838 - val_loss: 2.2666 - val_mse: 2.2666 - val_mae: 1.2200\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 374us/step - loss: 2.0123 - mse: 2.0123 - mae: 1.0821 - val_loss: 2.2590 - val_mse: 2.2590 - val_mae: 1.2177\n",
      "53\n",
      "[53]\n",
      "Train on 111 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 2.3530 - mse: 2.3530 - mae: 1.0798 - val_loss: 0.7815 - val_mse: 0.7815 - val_mae: 0.5841\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 0s 294us/step - loss: 1.9106 - mse: 1.9106 - mae: 0.9708 - val_loss: 0.7181 - val_mse: 0.7181 - val_mae: 0.6209\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 0s 337us/step - loss: 1.7044 - mse: 1.7044 - mae: 0.9443 - val_loss: 0.7522 - val_mse: 0.7522 - val_mae: 0.6912\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 0s 400us/step - loss: 1.6231 - mse: 1.6231 - mae: 0.9448 - val_loss: 0.7905 - val_mse: 0.7905 - val_mae: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "111/111 [==============================] - 0s 389us/step - loss: 1.5742 - mse: 1.5742 - mae: 0.9401 - val_loss: 0.7836 - val_mse: 0.7836 - val_mae: 0.7329\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 0s 546us/step - loss: 1.5185 - mse: 1.5185 - mae: 0.9203 - val_loss: 0.7481 - val_mse: 0.7481 - val_mae: 0.7026\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 0s 416us/step - loss: 1.4686 - mse: 1.4686 - mae: 0.8929 - val_loss: 0.7068 - val_mse: 0.7068 - val_mae: 0.6590\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 0s 375us/step - loss: 1.4340 - mse: 1.4340 - mae: 0.8707 - val_loss: 0.6787 - val_mse: 0.6787 - val_mae: 0.6250\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 0s 387us/step - loss: 1.4125 - mse: 1.4125 - mae: 0.8558 - val_loss: 0.6659 - val_mse: 0.6659 - val_mae: 0.6176\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 0s 382us/step - loss: 1.3952 - mse: 1.3952 - mae: 0.8464 - val_loss: 0.6616 - val_mse: 0.6616 - val_mae: 0.6172\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 0s 377us/step - loss: 1.3764 - mse: 1.3764 - mae: 0.8400 - val_loss: 0.6615 - val_mse: 0.6615 - val_mae: 0.6210\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 0s 445us/step - loss: 1.3557 - mse: 1.3557 - mae: 0.8342 - val_loss: 0.6645 - val_mse: 0.6645 - val_mae: 0.6262\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 0s 386us/step - loss: 1.3358 - mse: 1.3358 - mae: 0.8301 - val_loss: 0.6691 - val_mse: 0.6691 - val_mae: 0.6332\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 0s 526us/step - loss: 1.3183 - mse: 1.3183 - mae: 0.8276 - val_loss: 0.6733 - val_mse: 0.6733 - val_mae: 0.6391\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 0s 441us/step - loss: 1.3028 - mse: 1.3028 - mae: 0.8241 - val_loss: 0.6753 - val_mse: 0.6753 - val_mae: 0.6424\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 0s 545us/step - loss: 1.2885 - mse: 1.2885 - mae: 0.8196 - val_loss: 0.6746 - val_mse: 0.6746 - val_mae: 0.6430\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 0s 380us/step - loss: 1.2756 - mse: 1.2756 - mae: 0.8149 - val_loss: 0.6722 - val_mse: 0.6722 - val_mae: 0.6419\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 0s 539us/step - loss: 1.2639 - mse: 1.2639 - mae: 0.8104 - val_loss: 0.6688 - val_mse: 0.6688 - val_mae: 0.6403\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 0s 503us/step - loss: 1.2530 - mse: 1.2530 - mae: 0.8066 - val_loss: 0.6661 - val_mse: 0.6661 - val_mae: 0.6403\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 0s 335us/step - loss: 1.2425 - mse: 1.2425 - mae: 0.8031 - val_loss: 0.6646 - val_mse: 0.6646 - val_mae: 0.6411\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 0s 384us/step - loss: 1.2316 - mse: 1.2316 - mae: 0.7998 - val_loss: 0.6635 - val_mse: 0.6635 - val_mae: 0.6421\n",
      "54\n",
      "[54]\n",
      "Train on 84 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 3.9223 - mse: 3.9223 - mae: 1.4052 - val_loss: 0.2984 - val_mse: 0.2984 - val_mae: 0.4337\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 793us/step - loss: 3.7500 - mse: 3.7500 - mae: 1.3674 - val_loss: 0.2762 - val_mse: 0.2762 - val_mae: 0.4143\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 964us/step - loss: 3.6101 - mse: 3.6101 - mae: 1.3306 - val_loss: 0.2586 - val_mse: 0.2586 - val_mae: 0.3950\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 430us/step - loss: 3.4881 - mse: 3.4881 - mae: 1.3006 - val_loss: 0.2449 - val_mse: 0.2449 - val_mae: 0.3816\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 646us/step - loss: 3.3740 - mse: 3.3740 - mae: 1.2722 - val_loss: 0.2246 - val_mse: 0.2246 - val_mae: 0.3624\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 422us/step - loss: 3.2713 - mse: 3.2713 - mae: 1.2449 - val_loss: 0.2069 - val_mse: 0.2069 - val_mae: 0.3424\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 542us/step - loss: 3.1856 - mse: 3.1856 - mae: 1.2252 - val_loss: 0.1953 - val_mse: 0.1953 - val_mae: 0.3289\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 453us/step - loss: 3.1155 - mse: 3.1155 - mae: 1.2126 - val_loss: 0.1858 - val_mse: 0.1858 - val_mae: 0.3168\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 460us/step - loss: 3.0512 - mse: 3.0512 - mae: 1.2015 - val_loss: 0.1790 - val_mse: 0.1790 - val_mae: 0.3063\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 570us/step - loss: 3.0036 - mse: 3.0036 - mae: 1.1930 - val_loss: 0.1736 - val_mse: 0.1736 - val_mae: 0.2974\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 520us/step - loss: 2.9589 - mse: 2.9589 - mae: 1.1866 - val_loss: 0.1692 - val_mse: 0.1692 - val_mae: 0.2897\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 838us/step - loss: 2.9182 - mse: 2.9182 - mae: 1.1800 - val_loss: 0.1652 - val_mse: 0.1652 - val_mae: 0.2826\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 341us/step - loss: 2.8802 - mse: 2.8802 - mae: 1.1737 - val_loss: 0.1616 - val_mse: 0.1616 - val_mae: 0.2776\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 500us/step - loss: 2.8444 - mse: 2.8444 - mae: 1.1668 - val_loss: 0.1584 - val_mse: 0.1584 - val_mae: 0.2736\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 793us/step - loss: 2.8100 - mse: 2.8100 - mae: 1.1595 - val_loss: 0.1559 - val_mse: 0.1559 - val_mae: 0.2704\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 419us/step - loss: 2.7768 - mse: 2.7768 - mae: 1.1521 - val_loss: 0.1542 - val_mse: 0.1542 - val_mae: 0.2681\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 579us/step - loss: 2.7438 - mse: 2.7438 - mae: 1.1453 - val_loss: 0.1533 - val_mse: 0.1533 - val_mae: 0.2659\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 285us/step - loss: 2.7118 - mse: 2.7118 - mae: 1.1393 - val_loss: 0.1526 - val_mse: 0.1526 - val_mae: 0.2638\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 431us/step - loss: 2.6806 - mse: 2.6806 - mae: 1.1334 - val_loss: 0.1519 - val_mse: 0.1519 - val_mae: 0.2622\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 340us/step - loss: 2.6524 - mse: 2.6524 - mae: 1.1288 - val_loss: 0.1515 - val_mse: 0.1515 - val_mae: 0.2609\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 556us/step - loss: 2.6245 - mse: 2.6245 - mae: 1.1252 - val_loss: 0.1511 - val_mse: 0.1511 - val_mae: 0.2595\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 2.5986 - mse: 2.5986 - mae: 1.1211 - val_loss: 0.1509 - val_mse: 0.1509 - val_mae: 0.2598\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 823us/step - loss: 2.5737 - mse: 2.5737 - mae: 1.1173 - val_loss: 0.1514 - val_mse: 0.1514 - val_mae: 0.2618\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 337us/step - loss: 2.5487 - mse: 2.5487 - mae: 1.1135 - val_loss: 0.1521 - val_mse: 0.1521 - val_mae: 0.2643\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 482us/step - loss: 2.5250 - mse: 2.5250 - mae: 1.1098 - val_loss: 0.1521 - val_mse: 0.1521 - val_mae: 0.2664\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 309us/step - loss: 2.5022 - mse: 2.5022 - mae: 1.1052 - val_loss: 0.1514 - val_mse: 0.1514 - val_mae: 0.2674\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 593us/step - loss: 2.4799 - mse: 2.4799 - mae: 1.0999 - val_loss: 0.1502 - val_mse: 0.1502 - val_mae: 0.2679\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 672us/step - loss: 2.4589 - mse: 2.4589 - mae: 1.0943 - val_loss: 0.1491 - val_mse: 0.1491 - val_mae: 0.2685\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 342us/step - loss: 2.4387 - mse: 2.4387 - mae: 1.0889 - val_loss: 0.1488 - val_mse: 0.1488 - val_mae: 0.2700\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 445us/step - loss: 2.4192 - mse: 2.4192 - mae: 1.0845 - val_loss: 0.1496 - val_mse: 0.1496 - val_mae: 0.2729\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 812us/step - loss: 2.4009 - mse: 2.4009 - mae: 1.0809 - val_loss: 0.1502 - val_mse: 0.1502 - val_mae: 0.2754\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 891us/step - loss: 2.3827 - mse: 2.3827 - mae: 1.0769 - val_loss: 0.1500 - val_mse: 0.1500 - val_mae: 0.2773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 486us/step - loss: 2.3643 - mse: 2.3643 - mae: 1.0725 - val_loss: 0.1498 - val_mse: 0.1498 - val_mae: 0.2787\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 745us/step - loss: 2.3461 - mse: 2.3461 - mae: 1.0678 - val_loss: 0.1495 - val_mse: 0.1495 - val_mae: 0.2800\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 918us/step - loss: 2.3279 - mse: 2.3279 - mae: 1.0627 - val_loss: 0.1490 - val_mse: 0.1490 - val_mae: 0.2809\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 361us/step - loss: 2.3098 - mse: 2.3098 - mae: 1.0577 - val_loss: 0.1489 - val_mse: 0.1489 - val_mae: 0.2825\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 500us/step - loss: 2.2916 - mse: 2.2916 - mae: 1.0527 - val_loss: 0.1492 - val_mse: 0.1492 - val_mae: 0.2843\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 808us/step - loss: 2.2734 - mse: 2.2734 - mae: 1.0476 - val_loss: 0.1496 - val_mse: 0.1496 - val_mae: 0.2857\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 742us/step - loss: 2.2544 - mse: 2.2544 - mae: 1.0417 - val_loss: 0.1505 - val_mse: 0.1505 - val_mae: 0.2890\n",
      "55\n",
      "[55]\n",
      "Train on 89 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 2s 22ms/step - loss: 4.4652 - mse: 4.4652 - mae: 1.8564 - val_loss: 4.0020 - val_mse: 4.0020 - val_mae: 1.9440\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 364us/step - loss: 4.1022 - mse: 4.1022 - mae: 1.7574 - val_loss: 3.6365 - val_mse: 3.6365 - val_mae: 1.8452\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 947us/step - loss: 3.7718 - mse: 3.7718 - mae: 1.6605 - val_loss: 3.3032 - val_mse: 3.3032 - val_mae: 1.7488\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 526us/step - loss: 3.4674 - mse: 3.4674 - mae: 1.5656 - val_loss: 2.9915 - val_mse: 2.9915 - val_mae: 1.6532\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 560us/step - loss: 3.1920 - mse: 3.1920 - mae: 1.4777 - val_loss: 2.7109 - val_mse: 2.7109 - val_mae: 1.5629\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 534us/step - loss: 2.9444 - mse: 2.9444 - mae: 1.3960 - val_loss: 2.4461 - val_mse: 2.4461 - val_mae: 1.4731\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 691us/step - loss: 2.7078 - mse: 2.7078 - mae: 1.3132 - val_loss: 2.1918 - val_mse: 2.1918 - val_mae: 1.3827\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 677us/step - loss: 2.4852 - mse: 2.4852 - mae: 1.2325 - val_loss: 1.9519 - val_mse: 1.9519 - val_mae: 1.2916\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 293us/step - loss: 2.2762 - mse: 2.2762 - mae: 1.1549 - val_loss: 1.7198 - val_mse: 1.7198 - val_mae: 1.1966\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 404us/step - loss: 2.0809 - mse: 2.0809 - mae: 1.0834 - val_loss: 1.4995 - val_mse: 1.4995 - val_mae: 1.0990\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 303us/step - loss: 1.8994 - mse: 1.8994 - mae: 1.0192 - val_loss: 1.2961 - val_mse: 1.2961 - val_mae: 1.0000\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 588us/step - loss: 1.7304 - mse: 1.7304 - mae: 0.9633 - val_loss: 1.1088 - val_mse: 1.1088 - val_mae: 0.8991\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 296us/step - loss: 1.5796 - mse: 1.5796 - mae: 0.9165 - val_loss: 0.9388 - val_mse: 0.9388 - val_mae: 0.7966\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 690us/step - loss: 1.4488 - mse: 1.4488 - mae: 0.8727 - val_loss: 0.7905 - val_mse: 0.7905 - val_mae: 0.7014\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 583us/step - loss: 1.3395 - mse: 1.3395 - mae: 0.8357 - val_loss: 0.6653 - val_mse: 0.6653 - val_mae: 0.6084\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 819us/step - loss: 1.2515 - mse: 1.2515 - mae: 0.8081 - val_loss: 0.5635 - val_mse: 0.5635 - val_mae: 0.5355\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 323us/step - loss: 1.1860 - mse: 1.1860 - mae: 0.7918 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.4723\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 585us/step - loss: 1.1409 - mse: 1.1409 - mae: 0.7823 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4401\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 977us/step - loss: 1.1134 - mse: 1.1134 - mae: 0.7795 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4287\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 368us/step - loss: 1.0988 - mse: 1.0988 - mae: 0.7786 - val_loss: 0.3696 - val_mse: 0.3696 - val_mae: 0.4239\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 326us/step - loss: 1.0922 - mse: 1.0922 - mae: 0.7791 - val_loss: 0.3562 - val_mse: 0.3562 - val_mae: 0.4272\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 272us/step - loss: 1.0888 - mse: 1.0888 - mae: 0.7808 - val_loss: 0.3489 - val_mse: 0.3489 - val_mae: 0.4318\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 280us/step - loss: 1.0852 - mse: 1.0852 - mae: 0.7827 - val_loss: 0.3448 - val_mse: 0.3448 - val_mae: 0.4338\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 549us/step - loss: 1.0805 - mse: 1.0805 - mae: 0.7827 - val_loss: 0.3424 - val_mse: 0.3424 - val_mae: 0.4334\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 497us/step - loss: 1.0738 - mse: 1.0738 - mae: 0.7808 - val_loss: 0.3408 - val_mse: 0.3408 - val_mae: 0.4311\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 558us/step - loss: 1.0654 - mse: 1.0654 - mae: 0.7773 - val_loss: 0.3401 - val_mse: 0.3401 - val_mae: 0.4277\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 968us/step - loss: 1.0563 - mse: 1.0563 - mae: 0.7729 - val_loss: 0.3402 - val_mse: 0.3402 - val_mae: 0.4234\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 514us/step - loss: 1.0473 - mse: 1.0473 - mae: 0.7681 - val_loss: 0.3411 - val_mse: 0.3411 - val_mae: 0.4190\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 688us/step - loss: 1.0387 - mse: 1.0387 - mae: 0.7640 - val_loss: 0.3424 - val_mse: 0.3424 - val_mae: 0.4152\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 741us/step - loss: 1.0309 - mse: 1.0309 - mae: 0.7604 - val_loss: 0.3438 - val_mse: 0.3438 - val_mae: 0.4143\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 465us/step - loss: 1.0237 - mse: 1.0237 - mae: 0.7577 - val_loss: 0.3448 - val_mse: 0.3448 - val_mae: 0.4141\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 616us/step - loss: 1.0171 - mse: 1.0171 - mae: 0.7552 - val_loss: 0.3452 - val_mse: 0.3452 - val_mae: 0.4137\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 315us/step - loss: 1.0109 - mse: 1.0109 - mae: 0.7528 - val_loss: 0.3449 - val_mse: 0.3449 - val_mae: 0.4133\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 294us/step - loss: 1.0052 - mse: 1.0052 - mae: 0.7506 - val_loss: 0.3440 - val_mse: 0.3440 - val_mae: 0.4129\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 538us/step - loss: 0.9996 - mse: 0.9996 - mae: 0.7485 - val_loss: 0.3424 - val_mse: 0.3424 - val_mae: 0.4124\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 564us/step - loss: 0.9942 - mse: 0.9942 - mae: 0.7466 - val_loss: 0.3403 - val_mse: 0.3403 - val_mae: 0.4119\n",
      "56\n",
      "[56]\n",
      "Train on 88 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 4.0485 - mse: 4.0485 - mae: 1.7362 - val_loss: 3.0537 - val_mse: 3.0537 - val_mae: 1.6512\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 448us/step - loss: 3.3296 - mse: 3.3296 - mae: 1.5194 - val_loss: 2.4879 - val_mse: 2.4879 - val_mae: 1.4672\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 408us/step - loss: 2.7098 - mse: 2.7098 - mae: 1.3108 - val_loss: 1.9894 - val_mse: 1.9894 - val_mae: 1.2808\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 471us/step - loss: 2.1935 - mse: 2.1935 - mae: 1.1348 - val_loss: 1.5384 - val_mse: 1.5384 - val_mae: 1.0962\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 375us/step - loss: 1.7761 - mse: 1.7761 - mae: 1.0000 - val_loss: 1.1674 - val_mse: 1.1674 - val_mae: 0.9313\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 485us/step - loss: 1.4565 - mse: 1.4565 - mae: 0.9055 - val_loss: 0.8852 - val_mse: 0.8852 - val_mae: 0.8025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 387us/step - loss: 1.2258 - mse: 1.2258 - mae: 0.8444 - val_loss: 0.6883 - val_mse: 0.6883 - val_mae: 0.7113\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 825us/step - loss: 1.0822 - mse: 1.0822 - mae: 0.7986 - val_loss: 0.5670 - val_mse: 0.5670 - val_mae: 0.6659\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 543us/step - loss: 1.0066 - mse: 1.0066 - mae: 0.7630 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.6303\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 576us/step - loss: 0.9778 - mse: 0.9778 - mae: 0.7532 - val_loss: 0.4910 - val_mse: 0.4910 - val_mae: 0.6153\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 294us/step - loss: 0.9704 - mse: 0.9704 - mae: 0.7539 - val_loss: 0.4930 - val_mse: 0.4930 - val_mae: 0.6071\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 688us/step - loss: 0.9636 - mse: 0.9636 - mae: 0.7535 - val_loss: 0.4987 - val_mse: 0.4987 - val_mae: 0.6064\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 485us/step - loss: 0.9479 - mse: 0.9479 - mae: 0.7462 - val_loss: 0.5032 - val_mse: 0.5032 - val_mae: 0.6111\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 313us/step - loss: 0.9230 - mse: 0.9230 - mae: 0.7321 - val_loss: 0.5067 - val_mse: 0.5067 - val_mae: 0.6203\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 409us/step - loss: 0.8939 - mse: 0.8939 - mae: 0.7163 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.6316\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 692us/step - loss: 0.8647 - mse: 0.8647 - mae: 0.7008 - val_loss: 0.5205 - val_mse: 0.5205 - val_mae: 0.6431\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 448us/step - loss: 0.8395 - mse: 0.8395 - mae: 0.6868 - val_loss: 0.5305 - val_mse: 0.5305 - val_mae: 0.6539\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 420us/step - loss: 0.8206 - mse: 0.8206 - mae: 0.6773 - val_loss: 0.5404 - val_mse: 0.5404 - val_mae: 0.6614\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 502us/step - loss: 0.8064 - mse: 0.8064 - mae: 0.6692 - val_loss: 0.5491 - val_mse: 0.5491 - val_mae: 0.6661\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 305us/step - loss: 0.7941 - mse: 0.7941 - mae: 0.6609 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.6685\n",
      "57\n",
      "[57]\n",
      "Train on 94 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 2.0531 - mse: 2.0531 - mae: 1.1001 - val_loss: 1.4217 - val_mse: 1.4217 - val_mae: 0.9597\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 560us/step - loss: 1.8336 - mse: 1.8336 - mae: 0.9929 - val_loss: 1.3978 - val_mse: 1.3978 - val_mae: 0.9520\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 442us/step - loss: 1.7878 - mse: 1.7878 - mae: 0.9558 - val_loss: 1.4054 - val_mse: 1.4054 - val_mae: 0.9474\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 398us/step - loss: 1.7570 - mse: 1.7570 - mae: 0.9344 - val_loss: 1.3782 - val_mse: 1.3782 - val_mae: 0.9396\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 351us/step - loss: 1.7077 - mse: 1.7077 - mae: 0.9242 - val_loss: 1.3417 - val_mse: 1.3417 - val_mae: 0.9316\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 741us/step - loss: 1.6623 - mse: 1.6623 - mae: 0.9201 - val_loss: 1.3178 - val_mse: 1.3178 - val_mae: 0.9277\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 525us/step - loss: 1.6300 - mse: 1.6300 - mae: 0.9212 - val_loss: 1.2916 - val_mse: 1.2916 - val_mae: 0.9167\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 574us/step - loss: 1.6033 - mse: 1.6033 - mae: 0.9162 - val_loss: 1.2646 - val_mse: 1.2646 - val_mae: 0.9037\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 318us/step - loss: 1.5754 - mse: 1.5754 - mae: 0.9027 - val_loss: 1.2395 - val_mse: 1.2395 - val_mae: 0.8926\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5488 - mse: 1.5488 - mae: 0.8868 - val_loss: 1.2200 - val_mse: 1.2200 - val_mae: 0.8833\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 795us/step - loss: 1.5267 - mse: 1.5267 - mae: 0.8736 - val_loss: 1.2070 - val_mse: 1.2070 - val_mae: 0.8761\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5070 - mse: 1.5070 - mae: 0.8642 - val_loss: 1.1957 - val_mse: 1.1957 - val_mae: 0.8709\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 588us/step - loss: 1.4876 - mse: 1.4876 - mae: 0.8586 - val_loss: 1.1856 - val_mse: 1.1856 - val_mae: 0.8688\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 636us/step - loss: 1.4695 - mse: 1.4695 - mae: 0.8555 - val_loss: 1.1781 - val_mse: 1.1781 - val_mae: 0.8710\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 524us/step - loss: 1.4521 - mse: 1.4521 - mae: 0.8519 - val_loss: 1.1728 - val_mse: 1.1728 - val_mae: 0.8730\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 641us/step - loss: 1.4349 - mse: 1.4349 - mae: 0.8468 - val_loss: 1.1674 - val_mse: 1.1674 - val_mae: 0.8739\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 486us/step - loss: 1.4183 - mse: 1.4183 - mae: 0.8406 - val_loss: 1.1636 - val_mse: 1.1636 - val_mae: 0.8751\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 785us/step - loss: 1.4043 - mse: 1.4043 - mae: 0.8345 - val_loss: 1.1619 - val_mse: 1.1619 - val_mae: 0.8759\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 474us/step - loss: 1.3916 - mse: 1.3916 - mae: 0.8296 - val_loss: 1.1614 - val_mse: 1.1614 - val_mae: 0.8749\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 457us/step - loss: 1.3786 - mse: 1.3786 - mae: 0.8242 - val_loss: 1.1629 - val_mse: 1.1629 - val_mae: 0.8719\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 557us/step - loss: 1.3653 - mse: 1.3653 - mae: 0.8177 - val_loss: 1.1639 - val_mse: 1.1639 - val_mae: 0.8689\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 615us/step - loss: 1.3524 - mse: 1.3524 - mae: 0.8118 - val_loss: 1.1636 - val_mse: 1.1636 - val_mae: 0.8667\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 484us/step - loss: 1.3396 - mse: 1.3396 - mae: 0.8072 - val_loss: 1.1626 - val_mse: 1.1626 - val_mae: 0.8652\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 655us/step - loss: 1.3264 - mse: 1.3264 - mae: 0.8032 - val_loss: 1.1624 - val_mse: 1.1624 - val_mae: 0.8635\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 442us/step - loss: 1.3147 - mse: 1.3147 - mae: 0.7990 - val_loss: 1.1638 - val_mse: 1.1638 - val_mae: 0.8612\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 492us/step - loss: 1.3034 - mse: 1.3034 - mae: 0.7939 - val_loss: 1.1640 - val_mse: 1.1640 - val_mae: 0.8608\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 709us/step - loss: 1.2928 - mse: 1.2928 - mae: 0.7908 - val_loss: 1.1631 - val_mse: 1.1631 - val_mae: 0.8596\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 735us/step - loss: 1.2817 - mse: 1.2817 - mae: 0.7869 - val_loss: 1.1619 - val_mse: 1.1619 - val_mae: 0.8577\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 463us/step - loss: 1.2702 - mse: 1.2702 - mae: 0.7835 - val_loss: 1.1600 - val_mse: 1.1600 - val_mae: 0.8550\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 495us/step - loss: 1.2605 - mse: 1.2605 - mae: 0.7793 - val_loss: 1.1566 - val_mse: 1.1566 - val_mae: 0.8543\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 583us/step - loss: 1.2498 - mse: 1.2498 - mae: 0.7776 - val_loss: 1.1539 - val_mse: 1.1539 - val_mae: 0.8542\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 908us/step - loss: 1.2391 - mse: 1.2391 - mae: 0.7756 - val_loss: 1.1532 - val_mse: 1.1532 - val_mae: 0.8540\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 542us/step - loss: 1.2288 - mse: 1.2288 - mae: 0.7720 - val_loss: 1.1526 - val_mse: 1.1526 - val_mae: 0.8520\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 613us/step - loss: 1.2186 - mse: 1.2186 - mae: 0.7665 - val_loss: 1.1511 - val_mse: 1.1511 - val_mae: 0.8501\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 452us/step - loss: 1.2089 - mse: 1.2089 - mae: 0.7634 - val_loss: 1.1489 - val_mse: 1.1489 - val_mae: 0.8502\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 491us/step - loss: 1.1994 - mse: 1.1994 - mae: 0.7611 - val_loss: 1.1487 - val_mse: 1.1487 - val_mae: 0.8493\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 431us/step - loss: 1.1894 - mse: 1.1894 - mae: 0.7574 - val_loss: 1.1513 - val_mse: 1.1513 - val_mae: 0.8491\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 646us/step - loss: 1.1798 - mse: 1.1798 - mae: 0.7543 - val_loss: 1.1545 - val_mse: 1.1545 - val_mae: 0.8492\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 445us/step - loss: 1.1705 - mse: 1.1705 - mae: 0.7509 - val_loss: 1.1544 - val_mse: 1.1544 - val_mae: 0.8504\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 587us/step - loss: 1.1607 - mse: 1.1607 - mae: 0.7492 - val_loss: 1.1532 - val_mse: 1.1532 - val_mae: 0.8504\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 625us/step - loss: 1.1514 - mse: 1.1514 - mae: 0.7469 - val_loss: 1.1528 - val_mse: 1.1528 - val_mae: 0.8494\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 449us/step - loss: 1.1422 - mse: 1.1422 - mae: 0.7428 - val_loss: 1.1533 - val_mse: 1.1533 - val_mae: 0.8486\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 473us/step - loss: 1.1323 - mse: 1.1323 - mae: 0.7382 - val_loss: 1.1523 - val_mse: 1.1523 - val_mae: 0.8483\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 875us/step - loss: 1.1233 - mse: 1.1233 - mae: 0.7364 - val_loss: 1.1515 - val_mse: 1.1515 - val_mae: 0.8492\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 536us/step - loss: 1.1148 - mse: 1.1148 - mae: 0.7353 - val_loss: 1.1498 - val_mse: 1.1498 - val_mae: 0.8480\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 571us/step - loss: 1.1061 - mse: 1.1061 - mae: 0.7318 - val_loss: 1.1489 - val_mse: 1.1489 - val_mae: 0.8467\n",
      "58\n",
      "[58]\n",
      "Train on 98 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 3.0732 - mse: 3.0732 - mae: 1.4341 - val_loss: 1.2885 - val_mse: 1.2885 - val_mae: 0.8885\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 549us/step - loss: 2.2487 - mse: 2.2487 - mae: 1.1536 - val_loss: 0.9285 - val_mse: 0.9285 - val_mae: 0.7521\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 385us/step - loss: 1.6910 - mse: 1.6910 - mae: 0.9418 - val_loss: 0.7073 - val_mse: 0.7073 - val_mae: 0.6595\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 757us/step - loss: 1.3434 - mse: 1.3434 - mae: 0.8092 - val_loss: 0.5973 - val_mse: 0.5973 - val_mae: 0.6073\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 944us/step - loss: 1.1639 - mse: 1.1639 - mae: 0.7453 - val_loss: 0.5636 - val_mse: 0.5636 - val_mae: 0.5762\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 302us/step - loss: 1.0995 - mse: 1.0995 - mae: 0.7429 - val_loss: 0.5703 - val_mse: 0.5703 - val_mae: 0.5657\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 367us/step - loss: 1.0962 - mse: 1.0962 - mae: 0.7620 - val_loss: 0.5894 - val_mse: 0.5894 - val_mae: 0.5638\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 387us/step - loss: 1.1079 - mse: 1.1079 - mae: 0.7785 - val_loss: 0.5994 - val_mse: 0.5994 - val_mae: 0.5611\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 559us/step - loss: 1.1123 - mse: 1.1123 - mae: 0.7866 - val_loss: 0.5957 - val_mse: 0.5957 - val_mae: 0.5580\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 513us/step - loss: 1.1028 - mse: 1.1028 - mae: 0.7824 - val_loss: 0.5808 - val_mse: 0.5808 - val_mae: 0.5545\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 679us/step - loss: 1.0839 - mse: 1.0839 - mae: 0.7705 - val_loss: 0.5624 - val_mse: 0.5624 - val_mae: 0.5513\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 515us/step - loss: 1.0632 - mse: 1.0632 - mae: 0.7555 - val_loss: 0.5460 - val_mse: 0.5460 - val_mae: 0.5489\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 463us/step - loss: 1.0458 - mse: 1.0458 - mae: 0.7418 - val_loss: 0.5353 - val_mse: 0.5353 - val_mae: 0.5482\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 649us/step - loss: 1.0329 - mse: 1.0329 - mae: 0.7310 - val_loss: 0.5306 - val_mse: 0.5306 - val_mae: 0.5489\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 336us/step - loss: 1.0216 - mse: 1.0216 - mae: 0.7211 - val_loss: 0.5311 - val_mse: 0.5311 - val_mae: 0.5506\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 841us/step - loss: 1.0111 - mse: 1.0111 - mae: 0.7129 - val_loss: 0.5352 - val_mse: 0.5352 - val_mae: 0.5532\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 785us/step - loss: 1.0009 - mse: 1.0009 - mae: 0.7067 - val_loss: 0.5424 - val_mse: 0.5424 - val_mae: 0.5562\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 385us/step - loss: 0.9903 - mse: 0.9903 - mae: 0.7024 - val_loss: 0.5505 - val_mse: 0.5505 - val_mae: 0.5589\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 456us/step - loss: 0.9798 - mse: 0.9798 - mae: 0.6992 - val_loss: 0.5586 - val_mse: 0.5586 - val_mae: 0.5617\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 852us/step - loss: 0.9695 - mse: 0.9695 - mae: 0.6963 - val_loss: 0.5667 - val_mse: 0.5667 - val_mae: 0.5646\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 785us/step - loss: 0.9597 - mse: 0.9597 - mae: 0.6934 - val_loss: 0.5736 - val_mse: 0.5736 - val_mae: 0.5680\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 516us/step - loss: 0.9495 - mse: 0.9495 - mae: 0.6901 - val_loss: 0.5781 - val_mse: 0.5781 - val_mae: 0.5703\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9391 - mse: 0.9391 - mae: 0.6856 - val_loss: 0.5808 - val_mse: 0.5808 - val_mae: 0.5719\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 815us/step - loss: 0.9315 - mse: 0.9315 - mae: 0.6813 - val_loss: 0.5827 - val_mse: 0.5827 - val_mae: 0.5722\n",
      "59\n",
      "[59]\n",
      "Train on 113 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 7.1384 - mse: 7.1384 - mae: 2.0207 - val_loss: 2.3237 - val_mse: 2.3237 - val_mae: 1.1632\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 0s 542us/step - loss: 5.6399 - mse: 5.6399 - mae: 1.6750 - val_loss: 1.6506 - val_mse: 1.6506 - val_mae: 0.9845\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 0s 417us/step - loss: 4.4931 - mse: 4.4931 - mae: 1.4298 - val_loss: 1.2162 - val_mse: 1.2162 - val_mae: 0.8202\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 0s 448us/step - loss: 3.7716 - mse: 3.7716 - mae: 1.3189 - val_loss: 1.0617 - val_mse: 1.0617 - val_mae: 0.7893\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 0s 324us/step - loss: 3.4505 - mse: 3.4505 - mae: 1.2702 - val_loss: 1.0923 - val_mse: 1.0923 - val_mae: 0.7938\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 0s 558us/step - loss: 3.4013 - mse: 3.4013 - mae: 1.3050 - val_loss: 1.1896 - val_mse: 1.1896 - val_mae: 0.8385\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 0s 276us/step - loss: 3.4248 - mse: 3.4248 - mae: 1.3445 - val_loss: 1.2363 - val_mse: 1.2363 - val_mae: 0.8627\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 0s 449us/step - loss: 3.3864 - mse: 3.3864 - mae: 1.3442 - val_loss: 1.2005 - val_mse: 1.2005 - val_mae: 0.8527\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 0s 493us/step - loss: 3.2852 - mse: 3.2852 - mae: 1.3086 - val_loss: 1.1228 - val_mse: 1.1228 - val_mae: 0.8229\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 0s 495us/step - loss: 3.1800 - mse: 3.1800 - mae: 1.2669 - val_loss: 1.0551 - val_mse: 1.0551 - val_mae: 0.7932\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 0s 438us/step - loss: 3.1135 - mse: 3.1135 - mae: 1.2373 - val_loss: 1.0146 - val_mse: 1.0146 - val_mae: 0.7700\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 0s 314us/step - loss: 3.0736 - mse: 3.0736 - mae: 1.2222 - val_loss: 0.9937 - val_mse: 0.9937 - val_mae: 0.7582\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 0s 304us/step - loss: 3.0400 - mse: 3.0400 - mae: 1.2112 - val_loss: 0.9836 - val_mse: 0.9836 - val_mae: 0.7532\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 0s 544us/step - loss: 3.0012 - mse: 3.0012 - mae: 1.2031 - val_loss: 0.9809 - val_mse: 0.9809 - val_mae: 0.7577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "113/113 [==============================] - 0s 546us/step - loss: 2.9585 - mse: 2.9585 - mae: 1.1989 - val_loss: 0.9853 - val_mse: 0.9853 - val_mae: 0.7670\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 0s 442us/step - loss: 2.9179 - mse: 2.9179 - mae: 1.1968 - val_loss: 0.9934 - val_mse: 0.9934 - val_mae: 0.7770\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 0s 894us/step - loss: 2.8805 - mse: 2.8805 - mae: 1.1942 - val_loss: 0.9995 - val_mse: 0.9995 - val_mae: 0.7851\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 0s 584us/step - loss: 2.8442 - mse: 2.8442 - mae: 1.1887 - val_loss: 1.0009 - val_mse: 1.0009 - val_mae: 0.7894\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 0s 656us/step - loss: 2.8084 - mse: 2.8084 - mae: 1.1805 - val_loss: 0.9969 - val_mse: 0.9969 - val_mae: 0.7889\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 0s 293us/step - loss: 2.7738 - mse: 2.7738 - mae: 1.1700 - val_loss: 0.9918 - val_mse: 0.9918 - val_mae: 0.7868\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 2.7424 - mse: 2.7424 - mae: 1.1587 - val_loss: 0.9891 - val_mse: 0.9891 - val_mae: 0.7856\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 0s 463us/step - loss: 2.7162 - mse: 2.7162 - mae: 1.1504 - val_loss: 0.9899 - val_mse: 0.9899 - val_mae: 0.7871\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 0s 278us/step - loss: 2.6905 - mse: 2.6905 - mae: 1.1437 - val_loss: 0.9936 - val_mse: 0.9936 - val_mae: 0.7912\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 0s 734us/step - loss: 2.6644 - mse: 2.6644 - mae: 1.1376 - val_loss: 0.9990 - val_mse: 0.9990 - val_mae: 0.7967\n",
      "60\n",
      "[60]\n",
      "Train on 124 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 4.8996 - mse: 4.8996 - mae: 1.7213 - val_loss: 3.4438 - val_mse: 3.4438 - val_mae: 1.5769\n",
      "Epoch 2/100\n",
      "124/124 [==============================] - 0s 764us/step - loss: 3.4963 - mse: 3.4963 - mae: 1.3562 - val_loss: 2.2444 - val_mse: 2.2444 - val_mae: 1.2459\n",
      "Epoch 3/100\n",
      "124/124 [==============================] - 0s 774us/step - loss: 2.9602 - mse: 2.9602 - mae: 1.2396 - val_loss: 1.9127 - val_mse: 1.9127 - val_mae: 1.1307\n",
      "Epoch 4/100\n",
      "124/124 [==============================] - 0s 448us/step - loss: 2.9984 - mse: 2.9984 - mae: 1.3107 - val_loss: 1.9227 - val_mse: 1.9227 - val_mae: 1.1224\n",
      "Epoch 5/100\n",
      "124/124 [==============================] - 0s 423us/step - loss: 3.0269 - mse: 3.0269 - mae: 1.3407 - val_loss: 1.8578 - val_mse: 1.8578 - val_mae: 1.0903\n",
      "Epoch 6/100\n",
      "124/124 [==============================] - 0s 522us/step - loss: 2.8828 - mse: 2.8828 - mae: 1.3068 - val_loss: 1.8008 - val_mse: 1.8008 - val_mae: 1.0773\n",
      "Epoch 7/100\n",
      "124/124 [==============================] - 0s 443us/step - loss: 2.7330 - mse: 2.7330 - mae: 1.2583 - val_loss: 1.8147 - val_mse: 1.8147 - val_mae: 1.0900\n",
      "Epoch 8/100\n",
      "124/124 [==============================] - 0s 404us/step - loss: 2.6443 - mse: 2.6443 - mae: 1.2283 - val_loss: 1.8453 - val_mse: 1.8453 - val_mae: 1.0936\n",
      "Epoch 9/100\n",
      "124/124 [==============================] - 0s 730us/step - loss: 2.5918 - mse: 2.5918 - mae: 1.2132 - val_loss: 1.8488 - val_mse: 1.8488 - val_mae: 1.0840\n",
      "Epoch 10/100\n",
      "124/124 [==============================] - 0s 328us/step - loss: 2.5505 - mse: 2.5505 - mae: 1.2080 - val_loss: 1.8323 - val_mse: 1.8323 - val_mae: 1.0657\n",
      "Epoch 11/100\n",
      "124/124 [==============================] - 0s 671us/step - loss: 2.5179 - mse: 2.5179 - mae: 1.2097 - val_loss: 1.8135 - val_mse: 1.8135 - val_mae: 1.0413\n",
      "Epoch 12/100\n",
      "124/124 [==============================] - 0s 646us/step - loss: 2.4945 - mse: 2.4945 - mae: 1.2117 - val_loss: 1.8040 - val_mse: 1.8040 - val_mae: 1.0209\n",
      "Epoch 13/100\n",
      "124/124 [==============================] - 0s 759us/step - loss: 2.4751 - mse: 2.4751 - mae: 1.2101 - val_loss: 1.8000 - val_mse: 1.8000 - val_mae: 1.0061\n",
      "Epoch 14/100\n",
      "124/124 [==============================] - 0s 721us/step - loss: 2.4521 - mse: 2.4521 - mae: 1.2042 - val_loss: 1.8012 - val_mse: 1.8012 - val_mae: 1.0015\n",
      "Epoch 15/100\n",
      "124/124 [==============================] - 0s 694us/step - loss: 2.4264 - mse: 2.4264 - mae: 1.1957 - val_loss: 1.8029 - val_mse: 1.8029 - val_mae: 1.0015\n",
      "Epoch 16/100\n",
      "124/124 [==============================] - 0s 543us/step - loss: 2.4014 - mse: 2.4014 - mae: 1.1868 - val_loss: 1.8029 - val_mse: 1.8029 - val_mae: 1.0011\n",
      "Epoch 17/100\n",
      "124/124 [==============================] - 0s 451us/step - loss: 2.3861 - mse: 2.3861 - mae: 1.1800 - val_loss: 1.7927 - val_mse: 1.7927 - val_mae: 0.9977\n",
      "Epoch 18/100\n",
      "124/124 [==============================] - 0s 335us/step - loss: 2.3709 - mse: 2.3709 - mae: 1.1741 - val_loss: 1.7811 - val_mse: 1.7811 - val_mae: 0.9918\n",
      "Epoch 19/100\n",
      "124/124 [==============================] - 0s 781us/step - loss: 2.3570 - mse: 2.3570 - mae: 1.1692 - val_loss: 1.7732 - val_mse: 1.7732 - val_mae: 0.9856\n",
      "Epoch 20/100\n",
      "124/124 [==============================] - 0s 313us/step - loss: 2.3424 - mse: 2.3424 - mae: 1.1646 - val_loss: 1.7686 - val_mse: 1.7686 - val_mae: 0.9804\n",
      "Epoch 21/100\n",
      "124/124 [==============================] - 0s 295us/step - loss: 2.3285 - mse: 2.3285 - mae: 1.1600 - val_loss: 1.7656 - val_mse: 1.7656 - val_mae: 0.9768\n",
      "Epoch 22/100\n",
      "124/124 [==============================] - 0s 338us/step - loss: 2.3147 - mse: 2.3147 - mae: 1.1551 - val_loss: 1.7616 - val_mse: 1.7616 - val_mae: 0.9741\n",
      "Epoch 23/100\n",
      "124/124 [==============================] - 0s 542us/step - loss: 2.3012 - mse: 2.3012 - mae: 1.1502 - val_loss: 1.7588 - val_mse: 1.7588 - val_mae: 0.9723\n",
      "Epoch 24/100\n",
      "124/124 [==============================] - 0s 542us/step - loss: 2.2884 - mse: 2.2884 - mae: 1.1453 - val_loss: 1.7565 - val_mse: 1.7565 - val_mae: 0.9701\n",
      "Epoch 25/100\n",
      "124/124 [==============================] - 0s 574us/step - loss: 2.2764 - mse: 2.2764 - mae: 1.1407 - val_loss: 1.7504 - val_mse: 1.7504 - val_mae: 0.9658\n",
      "Epoch 26/100\n",
      "124/124 [==============================] - 0s 624us/step - loss: 2.2646 - mse: 2.2646 - mae: 1.1360 - val_loss: 1.7468 - val_mse: 1.7468 - val_mae: 0.9620\n",
      "Epoch 27/100\n",
      "124/124 [==============================] - 0s 567us/step - loss: 2.2532 - mse: 2.2532 - mae: 1.1316 - val_loss: 1.7468 - val_mse: 1.7468 - val_mae: 0.9594\n",
      "Epoch 28/100\n",
      "124/124 [==============================] - 0s 971us/step - loss: 2.2419 - mse: 2.2419 - mae: 1.1273 - val_loss: 1.7490 - val_mse: 1.7490 - val_mae: 0.9575\n",
      "Epoch 29/100\n",
      "124/124 [==============================] - 0s 456us/step - loss: 2.2306 - mse: 2.2306 - mae: 1.1234 - val_loss: 1.7525 - val_mse: 1.7525 - val_mae: 0.9569\n",
      "Epoch 30/100\n",
      "124/124 [==============================] - 0s 597us/step - loss: 2.2196 - mse: 2.2196 - mae: 1.1197 - val_loss: 1.7513 - val_mse: 1.7513 - val_mae: 0.9557\n",
      "Epoch 31/100\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.2087 - mse: 2.2087 - mae: 1.1155 - val_loss: 1.7474 - val_mse: 1.7474 - val_mae: 0.9535\n",
      "Epoch 32/100\n",
      "124/124 [==============================] - 0s 848us/step - loss: 2.1981 - mse: 2.1981 - mae: 1.1112 - val_loss: 1.7471 - val_mse: 1.7471 - val_mae: 0.9528\n",
      "Epoch 33/100\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.1877 - mse: 2.1877 - mae: 1.1076 - val_loss: 1.7473 - val_mse: 1.7473 - val_mae: 0.9517\n",
      "Epoch 34/100\n",
      "124/124 [==============================] - 0s 373us/step - loss: 2.1773 - mse: 2.1773 - mae: 1.1047 - val_loss: 1.7450 - val_mse: 1.7450 - val_mae: 0.9494\n",
      "Epoch 35/100\n",
      "124/124 [==============================] - 0s 424us/step - loss: 2.1676 - mse: 2.1676 - mae: 1.1017 - val_loss: 1.7430 - val_mse: 1.7430 - val_mae: 0.9476\n",
      "Epoch 36/100\n",
      "124/124 [==============================] - 0s 555us/step - loss: 2.1579 - mse: 2.1579 - mae: 1.0983 - val_loss: 1.7415 - val_mse: 1.7415 - val_mae: 0.9465\n",
      "Epoch 37/100\n",
      "124/124 [==============================] - 0s 756us/step - loss: 2.1484 - mse: 2.1484 - mae: 1.0946 - val_loss: 1.7406 - val_mse: 1.7406 - val_mae: 0.9461\n",
      "Epoch 38/100\n",
      "124/124 [==============================] - 0s 608us/step - loss: 2.1394 - mse: 2.1394 - mae: 1.0912 - val_loss: 1.7418 - val_mse: 1.7418 - val_mae: 0.9451\n",
      "Epoch 39/100\n",
      "124/124 [==============================] - 0s 636us/step - loss: 2.1305 - mse: 2.1305 - mae: 1.0887 - val_loss: 1.7387 - val_mse: 1.7387 - val_mae: 0.9424\n",
      "Epoch 40/100\n",
      "124/124 [==============================] - 0s 633us/step - loss: 2.1219 - mse: 2.1219 - mae: 1.0859 - val_loss: 1.7359 - val_mse: 1.7359 - val_mae: 0.9406\n",
      "Epoch 41/100\n",
      "124/124 [==============================] - 0s 466us/step - loss: 2.1133 - mse: 2.1133 - mae: 1.0828 - val_loss: 1.7394 - val_mse: 1.7394 - val_mae: 0.9400\n",
      "Epoch 42/100\n",
      "124/124 [==============================] - 0s 400us/step - loss: 2.1049 - mse: 2.1049 - mae: 1.0804 - val_loss: 1.7427 - val_mse: 1.7427 - val_mae: 0.9388\n",
      "Epoch 43/100\n",
      "124/124 [==============================] - 0s 559us/step - loss: 2.0964 - mse: 2.0964 - mae: 1.0782 - val_loss: 1.7438 - val_mse: 1.7438 - val_mae: 0.9377\n",
      "Epoch 44/100\n",
      "124/124 [==============================] - 0s 377us/step - loss: 2.0877 - mse: 2.0877 - mae: 1.0756 - val_loss: 1.7464 - val_mse: 1.7464 - val_mae: 0.9369\n",
      "Epoch 45/100\n",
      "124/124 [==============================] - 0s 503us/step - loss: 2.0788 - mse: 2.0788 - mae: 1.0729 - val_loss: 1.7502 - val_mse: 1.7502 - val_mae: 0.9364\n",
      "Epoch 46/100\n",
      "124/124 [==============================] - 0s 429us/step - loss: 2.0699 - mse: 2.0699 - mae: 1.0707 - val_loss: 1.7552 - val_mse: 1.7552 - val_mae: 0.9363\n",
      "Epoch 47/100\n",
      "124/124 [==============================] - 0s 488us/step - loss: 2.0605 - mse: 2.0605 - mae: 1.0681 - val_loss: 1.7551 - val_mse: 1.7551 - val_mae: 0.9354\n",
      "Epoch 48/100\n",
      "124/124 [==============================] - 0s 618us/step - loss: 2.0512 - mse: 2.0512 - mae: 1.0650 - val_loss: 1.7534 - val_mse: 1.7534 - val_mae: 0.9345\n",
      "Epoch 49/100\n",
      "124/124 [==============================] - 0s 666us/step - loss: 2.0419 - mse: 2.0419 - mae: 1.0617 - val_loss: 1.7542 - val_mse: 1.7542 - val_mae: 0.9334\n",
      "Epoch 50/100\n",
      "124/124 [==============================] - 0s 695us/step - loss: 2.0340 - mse: 2.0340 - mae: 1.0598 - val_loss: 1.7527 - val_mse: 1.7527 - val_mae: 0.9316\n",
      "61\n",
      "[61]\n",
      "Train on 83 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 2s 23ms/step - loss: 4.3304 - mse: 4.3304 - mae: 1.9103 - val_loss: 2.3509 - val_mse: 2.3509 - val_mae: 1.4786\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 419us/step - loss: 3.7940 - mse: 3.7940 - mae: 1.7647 - val_loss: 1.8935 - val_mse: 1.8935 - val_mae: 1.3208\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 583us/step - loss: 3.2633 - mse: 3.2633 - mae: 1.6089 - val_loss: 1.5139 - val_mse: 1.5139 - val_mae: 1.1730\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 470us/step - loss: 2.8113 - mse: 2.8113 - mae: 1.4636 - val_loss: 1.2154 - val_mse: 1.2154 - val_mae: 1.0401\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 431us/step - loss: 2.4710 - mse: 2.4710 - mae: 1.3381 - val_loss: 0.9926 - val_mse: 0.9926 - val_mae: 0.9300\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 356us/step - loss: 2.2037 - mse: 2.2037 - mae: 1.2303 - val_loss: 0.8257 - val_mse: 0.8257 - val_mae: 0.8343\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 463us/step - loss: 1.9901 - mse: 1.9901 - mae: 1.1359 - val_loss: 0.6896 - val_mse: 0.6896 - val_mae: 0.7471\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 430us/step - loss: 1.8076 - mse: 1.8076 - mae: 1.0505 - val_loss: 0.5698 - val_mse: 0.5698 - val_mae: 0.6657\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 413us/step - loss: 1.6454 - mse: 1.6454 - mae: 0.9672 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5805\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 598us/step - loss: 1.4952 - mse: 1.4952 - mae: 0.8865 - val_loss: 0.3627 - val_mse: 0.3627 - val_mae: 0.4984\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 383us/step - loss: 1.3551 - mse: 1.3551 - mae: 0.8095 - val_loss: 0.2809 - val_mse: 0.2809 - val_mae: 0.4312\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 588us/step - loss: 1.2292 - mse: 1.2292 - mae: 0.7475 - val_loss: 0.2172 - val_mse: 0.2172 - val_mae: 0.3694\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 374us/step - loss: 1.1194 - mse: 1.1194 - mae: 0.7019 - val_loss: 0.1722 - val_mse: 0.1722 - val_mae: 0.3329\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 351us/step - loss: 1.0250 - mse: 1.0250 - mae: 0.6681 - val_loss: 0.1458 - val_mse: 0.1458 - val_mae: 0.3040\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 483us/step - loss: 0.9473 - mse: 0.9473 - mae: 0.6461 - val_loss: 0.1365 - val_mse: 0.1365 - val_mae: 0.2874\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.8848 - mse: 0.8848 - mae: 0.6344 - val_loss: 0.1443 - val_mse: 0.1443 - val_mae: 0.2943\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 439us/step - loss: 0.8386 - mse: 0.8386 - mae: 0.6306 - val_loss: 0.1659 - val_mse: 0.1659 - val_mae: 0.3111\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 625us/step - loss: 0.8071 - mse: 0.8071 - mae: 0.6364 - val_loss: 0.1972 - val_mse: 0.1972 - val_mae: 0.3406\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 831us/step - loss: 0.7878 - mse: 0.7878 - mae: 0.6462 - val_loss: 0.2328 - val_mse: 0.2328 - val_mae: 0.3660\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 386us/step - loss: 0.7780 - mse: 0.7780 - mae: 0.6549 - val_loss: 0.2670 - val_mse: 0.2670 - val_mae: 0.3880\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 475us/step - loss: 0.7740 - mse: 0.7740 - mae: 0.6625 - val_loss: 0.2958 - val_mse: 0.2958 - val_mae: 0.4068\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 565us/step - loss: 0.7723 - mse: 0.7723 - mae: 0.6692 - val_loss: 0.3163 - val_mse: 0.3163 - val_mae: 0.4220\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 351us/step - loss: 0.7709 - mse: 0.7709 - mae: 0.6726 - val_loss: 0.3279 - val_mse: 0.3279 - val_mae: 0.4299\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 381us/step - loss: 0.7687 - mse: 0.7687 - mae: 0.6733 - val_loss: 0.3318 - val_mse: 0.3318 - val_mae: 0.4315\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 525us/step - loss: 0.7656 - mse: 0.7656 - mae: 0.6718 - val_loss: 0.3294 - val_mse: 0.3294 - val_mae: 0.4285\n",
      "62\n",
      "[62]\n",
      "Train on 109 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 8.3800 - mse: 8.3800 - mae: 2.4411 - val_loss: 4.6325 - val_mse: 4.6325 - val_mae: 1.8873\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 0s 301us/step - loss: 6.3535 - mse: 6.3535 - mae: 2.0161 - val_loss: 3.4831 - val_mse: 3.4831 - val_mae: 1.5688\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 0s 384us/step - loss: 4.9437 - mse: 4.9437 - mae: 1.6784 - val_loss: 2.6130 - val_mse: 2.6130 - val_mae: 1.3158\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 0s 579us/step - loss: 4.0256 - mse: 4.0256 - mae: 1.4693 - val_loss: 1.9781 - val_mse: 1.9781 - val_mae: 1.1101\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 315us/step - loss: 3.4299 - mse: 3.4299 - mae: 1.3360 - val_loss: 1.5788 - val_mse: 1.5788 - val_mae: 0.9631\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 323us/step - loss: 3.0564 - mse: 3.0564 - mae: 1.2546 - val_loss: 1.3595 - val_mse: 1.3595 - val_mae: 0.8928\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 0s 352us/step - loss: 2.8976 - mse: 2.8976 - mae: 1.2512 - val_loss: 1.2822 - val_mse: 1.2822 - val_mae: 0.8646\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 0s 451us/step - loss: 2.8544 - mse: 2.8544 - mae: 1.2696 - val_loss: 1.2649 - val_mse: 1.2649 - val_mae: 0.8669\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 0s 308us/step - loss: 2.8272 - mse: 2.8272 - mae: 1.2750 - val_loss: 1.2559 - val_mse: 1.2559 - val_mae: 0.8686\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 0s 355us/step - loss: 2.7718 - mse: 2.7718 - mae: 1.2669 - val_loss: 1.2408 - val_mse: 1.2408 - val_mae: 0.8662\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 0s 369us/step - loss: 2.6894 - mse: 2.6894 - mae: 1.2479 - val_loss: 1.2214 - val_mse: 1.2214 - val_mae: 0.8617\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 0s 331us/step - loss: 2.6033 - mse: 2.6033 - mae: 1.2253 - val_loss: 1.2101 - val_mse: 1.2101 - val_mae: 0.8614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "109/109 [==============================] - 0s 427us/step - loss: 2.5297 - mse: 2.5297 - mae: 1.2039 - val_loss: 1.2034 - val_mse: 1.2034 - val_mae: 0.8670\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 0s 432us/step - loss: 2.4759 - mse: 2.4759 - mae: 1.1877 - val_loss: 1.2011 - val_mse: 1.2011 - val_mae: 0.8717\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 0s 327us/step - loss: 2.4342 - mse: 2.4342 - mae: 1.1770 - val_loss: 1.1951 - val_mse: 1.1951 - val_mae: 0.8728\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 0s 784us/step - loss: 2.3976 - mse: 2.3976 - mae: 1.1688 - val_loss: 1.1838 - val_mse: 1.1838 - val_mae: 0.8707\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 0s 428us/step - loss: 2.3612 - mse: 2.3612 - mae: 1.1634 - val_loss: 1.1707 - val_mse: 1.1707 - val_mae: 0.8667\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 0s 783us/step - loss: 2.3279 - mse: 2.3279 - mae: 1.1595 - val_loss: 1.1574 - val_mse: 1.1574 - val_mae: 0.8633\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 0s 340us/step - loss: 2.2975 - mse: 2.2975 - mae: 1.1569 - val_loss: 1.1468 - val_mse: 1.1468 - val_mae: 0.8602\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 0s 325us/step - loss: 2.2696 - mse: 2.2696 - mae: 1.1553 - val_loss: 1.1385 - val_mse: 1.1385 - val_mae: 0.8571\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 0s 386us/step - loss: 2.2440 - mse: 2.2440 - mae: 1.1529 - val_loss: 1.1308 - val_mse: 1.1308 - val_mae: 0.8540\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 0s 393us/step - loss: 2.2204 - mse: 2.2204 - mae: 1.1496 - val_loss: 1.1250 - val_mse: 1.1250 - val_mae: 0.8517\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 0s 417us/step - loss: 2.1973 - mse: 2.1973 - mae: 1.1457 - val_loss: 1.1210 - val_mse: 1.1210 - val_mae: 0.8501\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 0s 498us/step - loss: 2.1746 - mse: 2.1746 - mae: 1.1415 - val_loss: 1.1187 - val_mse: 1.1187 - val_mae: 0.8490\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 0s 396us/step - loss: 2.1537 - mse: 2.1537 - mae: 1.1373 - val_loss: 1.1172 - val_mse: 1.1172 - val_mae: 0.8480\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 0s 607us/step - loss: 2.1345 - mse: 2.1345 - mae: 1.1333 - val_loss: 1.1168 - val_mse: 1.1168 - val_mae: 0.8473\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 0s 305us/step - loss: 2.1165 - mse: 2.1165 - mae: 1.1296 - val_loss: 1.1172 - val_mse: 1.1172 - val_mae: 0.8467\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 0s 354us/step - loss: 2.1000 - mse: 2.1000 - mae: 1.1263 - val_loss: 1.1185 - val_mse: 1.1185 - val_mae: 0.8463\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 0s 519us/step - loss: 2.0840 - mse: 2.0840 - mae: 1.1237 - val_loss: 1.1198 - val_mse: 1.1198 - val_mae: 0.8459\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 0s 289us/step - loss: 2.0689 - mse: 2.0689 - mae: 1.1215 - val_loss: 1.1206 - val_mse: 1.1206 - val_mae: 0.8451\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 0s 459us/step - loss: 2.0540 - mse: 2.0540 - mae: 1.1192 - val_loss: 1.1203 - val_mse: 1.1203 - val_mae: 0.8437\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 0s 359us/step - loss: 2.0388 - mse: 2.0388 - mae: 1.1171 - val_loss: 1.1203 - val_mse: 1.1203 - val_mae: 0.8422\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 0s 435us/step - loss: 2.0242 - mse: 2.0242 - mae: 1.1151 - val_loss: 1.1208 - val_mse: 1.1208 - val_mae: 0.8411\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 0s 297us/step - loss: 2.0087 - mse: 2.0087 - mae: 1.1124 - val_loss: 1.1218 - val_mse: 1.1218 - val_mae: 0.8402\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 0s 667us/step - loss: 1.9933 - mse: 1.9933 - mae: 1.1094 - val_loss: 1.1231 - val_mse: 1.1231 - val_mae: 0.8399\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 0s 441us/step - loss: 1.9786 - mse: 1.9786 - mae: 1.1062 - val_loss: 1.1239 - val_mse: 1.1239 - val_mae: 0.8395\n",
      "63\n",
      "[63]\n",
      "Train on 104 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 2.4008 - mse: 2.4008 - mae: 1.1882 - val_loss: 2.0335 - val_mse: 2.0335 - val_mae: 1.0623\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 0s 598us/step - loss: 2.2456 - mse: 2.2456 - mae: 1.1870 - val_loss: 2.0771 - val_mse: 2.0771 - val_mae: 1.1460\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 0s 340us/step - loss: 2.2074 - mse: 2.2074 - mae: 1.1993 - val_loss: 2.0478 - val_mse: 2.0478 - val_mae: 1.1492\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 0s 471us/step - loss: 2.1269 - mse: 2.1269 - mae: 1.1811 - val_loss: 1.9503 - val_mse: 1.9503 - val_mae: 1.0989\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 0s 471us/step - loss: 2.0202 - mse: 2.0202 - mae: 1.1394 - val_loss: 1.8571 - val_mse: 1.8571 - val_mae: 1.0437\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 0s 300us/step - loss: 1.9335 - mse: 1.9335 - mae: 1.1023 - val_loss: 1.8022 - val_mse: 1.8022 - val_mae: 1.0157\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 0s 598us/step - loss: 1.8676 - mse: 1.8676 - mae: 1.0780 - val_loss: 1.7848 - val_mse: 1.7848 - val_mae: 1.0169\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 0s 461us/step - loss: 1.8129 - mse: 1.8129 - mae: 1.0655 - val_loss: 1.7872 - val_mse: 1.7872 - val_mae: 1.0329\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 0s 357us/step - loss: 1.7696 - mse: 1.7696 - mae: 1.0589 - val_loss: 1.7823 - val_mse: 1.7823 - val_mae: 1.0473\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 0s 345us/step - loss: 1.7342 - mse: 1.7342 - mae: 1.0522 - val_loss: 1.7599 - val_mse: 1.7599 - val_mae: 1.0451\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 0s 539us/step - loss: 1.6991 - mse: 1.6991 - mae: 1.0401 - val_loss: 1.7236 - val_mse: 1.7236 - val_mae: 1.0288\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 0s 622us/step - loss: 1.6657 - mse: 1.6657 - mae: 1.0241 - val_loss: 1.6842 - val_mse: 1.6842 - val_mae: 1.0061\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 0s 523us/step - loss: 1.6353 - mse: 1.6353 - mae: 1.0087 - val_loss: 1.6525 - val_mse: 1.6525 - val_mae: 0.9853\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 0s 625us/step - loss: 1.6094 - mse: 1.6094 - mae: 0.9976 - val_loss: 1.6302 - val_mse: 1.6302 - val_mae: 0.9719\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 0s 538us/step - loss: 1.5869 - mse: 1.5869 - mae: 0.9908 - val_loss: 1.6168 - val_mse: 1.6168 - val_mae: 0.9651\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 0s 596us/step - loss: 1.5675 - mse: 1.5675 - mae: 0.9868 - val_loss: 1.6058 - val_mse: 1.6058 - val_mae: 0.9607\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 0s 708us/step - loss: 1.5511 - mse: 1.5511 - mae: 0.9839 - val_loss: 1.5906 - val_mse: 1.5906 - val_mae: 0.9547\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 0s 760us/step - loss: 1.5354 - mse: 1.5354 - mae: 0.9805 - val_loss: 1.5677 - val_mse: 1.5677 - val_mae: 0.9455\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 0s 668us/step - loss: 1.5191 - mse: 1.5191 - mae: 0.9758 - val_loss: 1.5445 - val_mse: 1.5445 - val_mae: 0.9355\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 0s 704us/step - loss: 1.5038 - mse: 1.5038 - mae: 0.9710 - val_loss: 1.5259 - val_mse: 1.5259 - val_mae: 0.9284\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 0s 693us/step - loss: 1.4878 - mse: 1.4878 - mae: 0.9661 - val_loss: 1.5130 - val_mse: 1.5130 - val_mae: 0.9251\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 0s 692us/step - loss: 1.4719 - mse: 1.4719 - mae: 0.9621 - val_loss: 1.5012 - val_mse: 1.5012 - val_mae: 0.9214\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 0s 536us/step - loss: 1.4572 - mse: 1.4572 - mae: 0.9584 - val_loss: 1.4885 - val_mse: 1.4885 - val_mae: 0.9149\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 0s 766us/step - loss: 1.4444 - mse: 1.4444 - mae: 0.9545 - val_loss: 1.4794 - val_mse: 1.4794 - val_mae: 0.9096\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 0s 395us/step - loss: 1.4322 - mse: 1.4322 - mae: 0.9511 - val_loss: 1.4820 - val_mse: 1.4820 - val_mae: 0.9117\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 0s 589us/step - loss: 1.4210 - mse: 1.4210 - mae: 0.9491 - val_loss: 1.4904 - val_mse: 1.4904 - val_mae: 0.9170\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 0s 333us/step - loss: 1.4113 - mse: 1.4113 - mae: 0.9477 - val_loss: 1.4976 - val_mse: 1.4976 - val_mae: 0.9203\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 0s 355us/step - loss: 1.4027 - mse: 1.4027 - mae: 0.9456 - val_loss: 1.4994 - val_mse: 1.4994 - val_mae: 0.9188\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 0s 471us/step - loss: 1.3930 - mse: 1.3930 - mae: 0.9422 - val_loss: 1.4994 - val_mse: 1.4994 - val_mae: 0.9164\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 0s 557us/step - loss: 1.3834 - mse: 1.3834 - mae: 0.9391 - val_loss: 1.5049 - val_mse: 1.5049 - val_mae: 0.9190\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 0s 586us/step - loss: 1.3751 - mse: 1.3751 - mae: 0.9376 - val_loss: 1.5142 - val_mse: 1.5142 - val_mae: 0.9252\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.3686 - mse: 1.3686 - mae: 0.9370 - val_loss: 1.5190 - val_mse: 1.5190 - val_mae: 0.9276\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 0s 375us/step - loss: 1.3607 - mse: 1.3607 - mae: 0.9351 - val_loss: 1.5212 - val_mse: 1.5212 - val_mae: 0.9264\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 0s 448us/step - loss: 1.3523 - mse: 1.3523 - mae: 0.9319 - val_loss: 1.5209 - val_mse: 1.5209 - val_mae: 0.9231\n",
      "64\n",
      "[64]\n",
      "Train on 88 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 5.4449 - mse: 5.4449 - mae: 2.0675 - val_loss: 2.3268 - val_mse: 2.3268 - val_mae: 1.3858\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 665us/step - loss: 5.1825 - mse: 5.1825 - mae: 2.0046 - val_loss: 2.2133 - val_mse: 2.2133 - val_mae: 1.3463\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 385us/step - loss: 4.8997 - mse: 4.8997 - mae: 1.9331 - val_loss: 2.0848 - val_mse: 2.0848 - val_mae: 1.2961\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 401us/step - loss: 4.5792 - mse: 4.5792 - mae: 1.8441 - val_loss: 1.9240 - val_mse: 1.9240 - val_mae: 1.2327\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 435us/step - loss: 4.2170 - mse: 4.2170 - mae: 1.7351 - val_loss: 1.6840 - val_mse: 1.6840 - val_mae: 1.1320\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 409us/step - loss: 3.8089 - mse: 3.8089 - mae: 1.6011 - val_loss: 1.4160 - val_mse: 1.4160 - val_mae: 1.0089\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 663us/step - loss: 3.4009 - mse: 3.4009 - mae: 1.4547 - val_loss: 1.1780 - val_mse: 1.1780 - val_mae: 0.8839\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 463us/step - loss: 3.0137 - mse: 3.0137 - mae: 1.3138 - val_loss: 0.9624 - val_mse: 0.9624 - val_mae: 0.7534\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 492us/step - loss: 2.6379 - mse: 2.6379 - mae: 1.1854 - val_loss: 0.7793 - val_mse: 0.7793 - val_mae: 0.6292\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2.3017 - mse: 2.3017 - mae: 1.0654 - val_loss: 0.6365 - val_mse: 0.6365 - val_mae: 0.5278\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 773us/step - loss: 2.0255 - mse: 2.0255 - mae: 0.9780 - val_loss: 0.5301 - val_mse: 0.5301 - val_mae: 0.4571\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 383us/step - loss: 1.8027 - mse: 1.8027 - mae: 0.9154 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4183\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 574us/step - loss: 1.6424 - mse: 1.6424 - mae: 0.8818 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4071\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 391us/step - loss: 1.5399 - mse: 1.5399 - mae: 0.8629 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4266\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.5865 - mse: 0.5865 - mae: 0.507 - 0s 760us/step - loss: 1.4847 - mse: 1.4847 - mae: 0.8590 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4612\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 401us/step - loss: 1.4597 - mse: 1.4597 - mae: 0.8680 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.5024\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 889us/step - loss: 1.4517 - mse: 1.4517 - mae: 0.8807 - val_loss: 0.4368 - val_mse: 0.4368 - val_mae: 0.5323\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 409us/step - loss: 1.4485 - mse: 1.4485 - mae: 0.8932 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.5497\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.4418 - mse: 1.4418 - mae: 0.8994 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.5560\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 741us/step - loss: 1.4291 - mse: 1.4291 - mae: 0.8974 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.5533\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.5018 - mse: 0.5018 - mae: 0.565 - 0s 1ms/step - loss: 1.4121 - mse: 1.4121 - mae: 0.8895 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.5444\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 654us/step - loss: 1.3930 - mse: 1.3930 - mae: 0.8779 - val_loss: 0.4333 - val_mse: 0.4333 - val_mae: 0.5318\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 819us/step - loss: 1.3742 - mse: 1.3742 - mae: 0.8655 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.5179\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 545us/step - loss: 1.3579 - mse: 1.3579 - mae: 0.8531 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.5044\n",
      "65\n",
      "[65]\n",
      "Train on 111 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 21.6531 - mse: 21.6531 - mae: 4.3276 - val_loss: 10.4308 - val_mse: 10.4308 - val_mae: 3.1388\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 0s 778us/step - loss: 17.9607 - mse: 17.9607 - mae: 3.9050 - val_loss: 8.6884 - val_mse: 8.6884 - val_mae: 2.8532\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 0s 418us/step - loss: 15.0237 - mse: 15.0237 - mae: 3.5303 - val_loss: 7.3753 - val_mse: 7.3753 - val_mae: 2.6226\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 0s 737us/step - loss: 12.8685 - mse: 12.8685 - mae: 3.2210 - val_loss: 6.4247 - val_mse: 6.4247 - val_mae: 2.4408\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 0s 526us/step - loss: 11.3011 - mse: 11.3011 - mae: 2.9726 - val_loss: 5.6606 - val_mse: 5.6606 - val_mae: 2.2822\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 0s 342us/step - loss: 10.0047 - mse: 10.0047 - mae: 2.7459 - val_loss: 4.9295 - val_mse: 4.9295 - val_mae: 2.1193\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 0s 606us/step - loss: 8.8354 - mse: 8.8354 - mae: 2.5245 - val_loss: 4.2035 - val_mse: 4.2035 - val_mae: 1.9418\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 0s 788us/step - loss: 7.7766 - mse: 7.7766 - mae: 2.3056 - val_loss: 3.5241 - val_mse: 3.5241 - val_mae: 1.7582\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 6.8226 - mse: 6.8226 - mae: 2.0935 - val_loss: 2.8895 - val_mse: 2.8895 - val_mae: 1.5691\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 0s 307us/step - loss: 5.9480 - mse: 5.9480 - mae: 1.8952 - val_loss: 2.3278 - val_mse: 2.3278 - val_mae: 1.3790\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 0s 323us/step - loss: 5.1791 - mse: 5.1791 - mae: 1.7186 - val_loss: 1.8449 - val_mse: 1.8449 - val_mae: 1.1923\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 0s 621us/step - loss: 4.5421 - mse: 4.5421 - mae: 1.5610 - val_loss: 1.4420 - val_mse: 1.4420 - val_mae: 1.0123\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 0s 598us/step - loss: 4.0408 - mse: 4.0408 - mae: 1.4406 - val_loss: 1.1190 - val_mse: 1.1190 - val_mae: 0.8584\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 0s 976us/step - loss: 3.6477 - mse: 3.6477 - mae: 1.3458 - val_loss: 0.8649 - val_mse: 0.8649 - val_mae: 0.7512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "111/111 [==============================] - 0s 489us/step - loss: 3.3653 - mse: 3.3653 - mae: 1.2798 - val_loss: 0.6765 - val_mse: 0.6765 - val_mae: 0.6582\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 0s 642us/step - loss: 3.1821 - mse: 3.1821 - mae: 1.2415 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5992\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 0s 701us/step - loss: 3.0843 - mse: 3.0843 - mae: 1.2324 - val_loss: 0.4833 - val_mse: 0.4833 - val_mae: 0.5614\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 0s 772us/step - loss: 3.0526 - mse: 3.0526 - mae: 1.2359 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.5453\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - ETA: 0s - loss: 6.6524 - mse: 6.6524 - mae: 1.794 - 0s 541us/step - loss: 3.0502 - mse: 3.0502 - mae: 1.2427 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.5378\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 0s 492us/step - loss: 3.0452 - mse: 3.0452 - mae: 1.2468 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.5366\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 0s 551us/step - loss: 3.0276 - mse: 3.0276 - mae: 1.2464 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.5366\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 0s 365us/step - loss: 2.9989 - mse: 2.9989 - mae: 1.2417 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.5369\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 0s 395us/step - loss: 2.9655 - mse: 2.9655 - mae: 1.2350 - val_loss: 0.4377 - val_mse: 0.4377 - val_mae: 0.5378\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 0s 401us/step - loss: 2.9350 - mse: 2.9350 - mae: 1.2281 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.5398\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 0s 544us/step - loss: 2.9093 - mse: 2.9093 - mae: 1.2216 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.5411\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 0s 281us/step - loss: 2.8883 - mse: 2.8883 - mae: 1.2161 - val_loss: 0.4460 - val_mse: 0.4460 - val_mae: 0.5410\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 0s 475us/step - loss: 2.8681 - mse: 2.8681 - mae: 1.2115 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.5399\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 0s 567us/step - loss: 2.8486 - mse: 2.8486 - mae: 1.2073 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.5378\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 0s 918us/step - loss: 2.8296 - mse: 2.8296 - mae: 1.2034 - val_loss: 0.4397 - val_mse: 0.4397 - val_mae: 0.5346\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 0s 421us/step - loss: 2.8112 - mse: 2.8112 - mae: 1.1998 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.5314\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 0s 309us/step - loss: 2.7951 - mse: 2.7951 - mae: 1.1968 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.5291\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 0s 949us/step - loss: 2.7775 - mse: 2.7775 - mae: 1.1934 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.5271\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 0s 603us/step - loss: 2.7605 - mse: 2.7605 - mae: 1.1900 - val_loss: 0.4293 - val_mse: 0.4293 - val_mae: 0.5248\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 0s 412us/step - loss: 2.7452 - mse: 2.7452 - mae: 1.1869 - val_loss: 0.4274 - val_mse: 0.4274 - val_mae: 0.5224\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 0s 683us/step - loss: 2.7304 - mse: 2.7304 - mae: 1.1841 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.5207\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 0s 451us/step - loss: 2.7167 - mse: 2.7167 - mae: 1.1818 - val_loss: 0.4255 - val_mse: 0.4255 - val_mae: 0.5195\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 0s 703us/step - loss: 2.7031 - mse: 2.7031 - mae: 1.1792 - val_loss: 0.4255 - val_mse: 0.4255 - val_mae: 0.5186\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 0s 628us/step - loss: 2.6899 - mse: 2.6899 - mae: 1.1765 - val_loss: 0.4257 - val_mse: 0.4257 - val_mae: 0.5177\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 0s 420us/step - loss: 2.6779 - mse: 2.6779 - mae: 1.1741 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.5172\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 0s 916us/step - loss: 2.6643 - mse: 2.6643 - mae: 1.1711 - val_loss: 0.4270 - val_mse: 0.4270 - val_mae: 0.5167\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 0s 598us/step - loss: 2.6519 - mse: 2.6519 - mae: 1.1683 - val_loss: 0.4272 - val_mse: 0.4272 - val_mae: 0.5161\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 0s 641us/step - loss: 2.6396 - mse: 2.6396 - mae: 1.1656 - val_loss: 0.4270 - val_mse: 0.4270 - val_mae: 0.5156\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 0s 769us/step - loss: 2.6278 - mse: 2.6278 - mae: 1.1632 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.5154\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 0s 528us/step - loss: 2.6164 - mse: 2.6164 - mae: 1.1609 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.5153\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 0s 649us/step - loss: 2.6058 - mse: 2.6058 - mae: 1.1589 - val_loss: 0.4273 - val_mse: 0.4273 - val_mae: 0.5158\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 0s 525us/step - loss: 2.5949 - mse: 2.5949 - mae: 1.1563 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.5162\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 0s 961us/step - loss: 2.5844 - mse: 2.5844 - mae: 1.1541 - val_loss: 0.4278 - val_mse: 0.4278 - val_mae: 0.5164\n",
      "66\n",
      "[66]\n",
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 15.0570 - mse: 15.0570 - mae: 3.4932 - val_loss: 13.5481 - val_mse: 13.5481 - val_mae: 3.4913\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 588us/step - loss: 12.9224 - mse: 12.9224 - mae: 3.1802 - val_loss: 11.7844 - val_mse: 11.7844 - val_mae: 3.2386\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 606us/step - loss: 11.1154 - mse: 11.1154 - mae: 2.8923 - val_loss: 10.2039 - val_mse: 10.2039 - val_mae: 2.9940\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 451us/step - loss: 9.5973 - mse: 9.5973 - mae: 2.6302 - val_loss: 8.6544 - val_mse: 8.6544 - val_mae: 2.7351\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 407us/step - loss: 8.2865 - mse: 8.2865 - mae: 2.3936 - val_loss: 7.2293 - val_mse: 7.2293 - val_mae: 2.4807\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 538us/step - loss: 7.1886 - mse: 7.1886 - mae: 2.1857 - val_loss: 6.0745 - val_mse: 6.0745 - val_mae: 2.2483\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 557us/step - loss: 6.2454 - mse: 6.2454 - mae: 1.9989 - val_loss: 5.1360 - val_mse: 5.1360 - val_mae: 2.0346\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 354us/step - loss: 5.4278 - mse: 5.4278 - mae: 1.8328 - val_loss: 4.2964 - val_mse: 4.2964 - val_mae: 1.8177\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 454us/step - loss: 4.6918 - mse: 4.6918 - mae: 1.6708 - val_loss: 3.4755 - val_mse: 3.4755 - val_mae: 1.6073\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 455us/step - loss: 4.0304 - mse: 4.0304 - mae: 1.5210 - val_loss: 2.7418 - val_mse: 2.7418 - val_mae: 1.4167\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 390us/step - loss: 3.4561 - mse: 3.4561 - mae: 1.3867 - val_loss: 2.1358 - val_mse: 2.1358 - val_mae: 1.2537\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 302us/step - loss: 2.9984 - mse: 2.9984 - mae: 1.2888 - val_loss: 1.6672 - val_mse: 1.6672 - val_mae: 1.1005\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 638us/step - loss: 2.6672 - mse: 2.6672 - mae: 1.2250 - val_loss: 1.3288 - val_mse: 1.3288 - val_mae: 0.9666\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 385us/step - loss: 2.4631 - mse: 2.4631 - mae: 1.1971 - val_loss: 1.1101 - val_mse: 1.1101 - val_mae: 0.8594\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 475us/step - loss: 2.3651 - mse: 2.3651 - mae: 1.1942 - val_loss: 0.9839 - val_mse: 0.9839 - val_mae: 0.7829\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 495us/step - loss: 2.3396 - mse: 2.3396 - mae: 1.2006 - val_loss: 0.9215 - val_mse: 0.9215 - val_mae: 0.7414\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 411us/step - loss: 2.3474 - mse: 2.3474 - mae: 1.2117 - val_loss: 0.8961 - val_mse: 0.8961 - val_mae: 0.7319\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 629us/step - loss: 2.3607 - mse: 2.3607 - mae: 1.2213 - val_loss: 0.8875 - val_mse: 0.8875 - val_mae: 0.7321\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 582us/step - loss: 2.3642 - mse: 2.3642 - mae: 1.2253 - val_loss: 0.8859 - val_mse: 0.8859 - val_mae: 0.7340\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 446us/step - loss: 2.3527 - mse: 2.3527 - mae: 1.2237 - val_loss: 0.8875 - val_mse: 0.8875 - val_mae: 0.7343\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 672us/step - loss: 2.3302 - mse: 2.3302 - mae: 1.2178 - val_loss: 0.8920 - val_mse: 0.8920 - val_mae: 0.7360\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 542us/step - loss: 2.3036 - mse: 2.3036 - mae: 1.2105 - val_loss: 0.8995 - val_mse: 0.8995 - val_mae: 0.7382\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 2.2770 - mse: 2.2770 - mae: 1.2031 - val_loss: 0.9092 - val_mse: 0.9092 - val_mae: 0.7417\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 579us/step - loss: 2.2529 - mse: 2.2529 - mae: 1.1959 - val_loss: 0.9192 - val_mse: 0.9192 - val_mae: 0.7467\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 520us/step - loss: 2.2318 - mse: 2.2318 - mae: 1.1900 - val_loss: 0.9284 - val_mse: 0.9284 - val_mae: 0.7521\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 365us/step - loss: 2.2140 - mse: 2.2140 - mae: 1.1850 - val_loss: 0.9354 - val_mse: 0.9354 - val_mae: 0.7560\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 604us/step - loss: 2.1973 - mse: 2.1973 - mae: 1.1805 - val_loss: 0.9401 - val_mse: 0.9401 - val_mae: 0.7600\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 596us/step - loss: 2.1824 - mse: 2.1824 - mae: 1.1768 - val_loss: 0.9422 - val_mse: 0.9422 - val_mae: 0.7604\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 621us/step - loss: 2.1690 - mse: 2.1690 - mae: 1.1737 - val_loss: 0.9430 - val_mse: 0.9430 - val_mae: 0.7594\n",
      "67\n",
      "[67]\n",
      "Train on 109 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 7.7368 - mse: 7.7368 - mae: 2.2652 - val_loss: 9.9274 - val_mse: 9.9274 - val_mae: 2.6265\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 0s 514us/step - loss: 6.2371 - mse: 6.2371 - mae: 1.9592 - val_loss: 7.5869 - val_mse: 7.5869 - val_mae: 2.2653\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 0s 459us/step - loss: 4.9420 - mse: 4.9420 - mae: 1.6840 - val_loss: 5.7804 - val_mse: 5.7804 - val_mae: 1.9516\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 0s 784us/step - loss: 3.9071 - mse: 3.9071 - mae: 1.4458 - val_loss: 4.4375 - val_mse: 4.4375 - val_mae: 1.6869\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 595us/step - loss: 3.1887 - mse: 3.1887 - mae: 1.2790 - val_loss: 3.4410 - val_mse: 3.4410 - val_mae: 1.4693\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 797us/step - loss: 2.7444 - mse: 2.7444 - mae: 1.1784 - val_loss: 2.7850 - val_mse: 2.7850 - val_mae: 1.3071\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 2.5356 - mse: 2.5356 - mae: 1.1383 - val_loss: 2.4031 - val_mse: 2.4031 - val_mae: 1.2101\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 0s 679us/step - loss: 2.4705 - mse: 2.4705 - mae: 1.1478 - val_loss: 2.2121 - val_mse: 2.2121 - val_mae: 1.1727\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 0s 880us/step - loss: 2.4526 - mse: 2.4526 - mae: 1.1611 - val_loss: 2.1283 - val_mse: 2.1283 - val_mae: 1.1517\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 0s 610us/step - loss: 2.4258 - mse: 2.4258 - mae: 1.1628 - val_loss: 2.1032 - val_mse: 2.1032 - val_mae: 1.1450\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 0s 438us/step - loss: 2.3776 - mse: 2.3776 - mae: 1.1504 - val_loss: 2.1213 - val_mse: 2.1213 - val_mae: 1.1495\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 0s 506us/step - loss: 2.3155 - mse: 2.3155 - mae: 1.1265 - val_loss: 2.1727 - val_mse: 2.1727 - val_mae: 1.1591\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 0s 570us/step - loss: 2.2620 - mse: 2.2620 - mae: 1.1028 - val_loss: 2.2368 - val_mse: 2.2368 - val_mae: 1.1722\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 0s 531us/step - loss: 2.2218 - mse: 2.2218 - mae: 1.0845 - val_loss: 2.2938 - val_mse: 2.2938 - val_mae: 1.1976\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 2.1916 - mse: 2.1916 - mae: 1.0694 - val_loss: 2.3277 - val_mse: 2.3277 - val_mae: 1.2129\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 0s 528us/step - loss: 2.1652 - mse: 2.1652 - mae: 1.0569 - val_loss: 2.3334 - val_mse: 2.3334 - val_mae: 1.2185\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 0s 604us/step - loss: 2.1407 - mse: 2.1407 - mae: 1.0475 - val_loss: 2.3133 - val_mse: 2.3133 - val_mae: 1.2166\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 0s 361us/step - loss: 2.1170 - mse: 2.1170 - mae: 1.0406 - val_loss: 2.2721 - val_mse: 2.2721 - val_mae: 1.2070\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 0s 349us/step - loss: 2.0935 - mse: 2.0935 - mae: 1.0364 - val_loss: 2.2215 - val_mse: 2.2215 - val_mae: 1.1933\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 2.0712 - mse: 2.0712 - mae: 1.0335 - val_loss: 2.1720 - val_mse: 2.1720 - val_mae: 1.1797\n",
      "68\n",
      "[68]\n",
      "Train on 80 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 8.8884 - mse: 8.8884 - mae: 2.5759 - val_loss: 7.4420 - val_mse: 7.4420 - val_mae: 2.5255\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.1675 - mse: 8.1675 - mae: 2.4366 - val_loss: 6.8092 - val_mse: 6.8092 - val_mae: 2.3992\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 668us/step - loss: 7.5571 - mse: 7.5571 - mae: 2.3106 - val_loss: 6.2857 - val_mse: 6.2857 - val_mae: 2.2888\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 989us/step - loss: 7.0649 - mse: 7.0649 - mae: 2.2060 - val_loss: 5.8585 - val_mse: 5.8585 - val_mae: 2.1950\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 587us/step - loss: 6.6518 - mse: 6.6518 - mae: 2.1147 - val_loss: 5.5036 - val_mse: 5.5036 - val_mae: 2.1122\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 374us/step - loss: 6.3030 - mse: 6.3030 - mae: 2.0346 - val_loss: 5.2178 - val_mse: 5.2178 - val_mae: 2.0447\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 654us/step - loss: 6.0195 - mse: 6.0195 - mae: 1.9616 - val_loss: 4.9357 - val_mse: 4.9357 - val_mae: 1.9739\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 459us/step - loss: 5.7822 - mse: 5.7822 - mae: 1.8932 - val_loss: 4.6654 - val_mse: 4.6654 - val_mae: 1.9002\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 716us/step - loss: 5.5516 - mse: 5.5516 - mae: 1.8224 - val_loss: 4.4000 - val_mse: 4.4000 - val_mae: 1.8237\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 356us/step - loss: 5.3060 - mse: 5.3060 - mae: 1.7477 - val_loss: 4.1142 - val_mse: 4.1142 - val_mae: 1.7403\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0292 - mse: 5.0292 - mae: 1.6643 - val_loss: 3.8089 - val_mse: 3.8089 - val_mae: 1.6458\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 449us/step - loss: 4.7391 - mse: 4.7391 - mae: 1.5771 - val_loss: 3.4806 - val_mse: 3.4806 - val_mae: 1.5382\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 534us/step - loss: 4.4344 - mse: 4.4344 - mae: 1.4828 - val_loss: 3.1367 - val_mse: 3.1367 - val_mae: 1.4178\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 373us/step - loss: 4.1240 - mse: 4.1240 - mae: 1.3920 - val_loss: 2.8075 - val_mse: 2.8075 - val_mae: 1.2909\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 362us/step - loss: 3.8264 - mse: 3.8264 - mae: 1.3064 - val_loss: 2.5033 - val_mse: 2.5033 - val_mae: 1.1607\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 911us/step - loss: 3.5416 - mse: 3.5416 - mae: 1.2408 - val_loss: 2.2309 - val_mse: 2.2309 - val_mae: 1.0289\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 426us/step - loss: 3.2882 - mse: 3.2882 - mae: 1.1890 - val_loss: 1.9955 - val_mse: 1.9955 - val_mae: 0.9186\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 744us/step - loss: 3.0714 - mse: 3.0714 - mae: 1.1438 - val_loss: 1.7970 - val_mse: 1.7970 - val_mae: 0.8414\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8941 - mse: 2.8941 - mae: 1.1186 - val_loss: 1.6387 - val_mse: 1.6387 - val_mae: 0.7943\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 744us/step - loss: 2.7552 - mse: 2.7552 - mae: 1.1120 - val_loss: 1.5199 - val_mse: 1.5199 - val_mae: 0.7724\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 430us/step - loss: 2.6526 - mse: 2.6526 - mae: 1.1111 - val_loss: 1.4333 - val_mse: 1.4333 - val_mae: 0.7609\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 958us/step - loss: 2.5795 - mse: 2.5795 - mae: 1.1142 - val_loss: 1.3730 - val_mse: 1.3730 - val_mae: 0.7500\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 730us/step - loss: 2.5304 - mse: 2.5304 - mae: 1.1211 - val_loss: 1.3339 - val_mse: 1.3339 - val_mae: 0.7400\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 492us/step - loss: 2.4970 - mse: 2.4970 - mae: 1.1273 - val_loss: 1.3077 - val_mse: 1.3077 - val_mae: 0.7364\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 672us/step - loss: 2.4733 - mse: 2.4733 - mae: 1.1320 - val_loss: 1.2899 - val_mse: 1.2899 - val_mae: 0.7388\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 508us/step - loss: 2.4533 - mse: 2.4533 - mae: 1.1350 - val_loss: 1.2769 - val_mse: 1.2769 - val_mae: 0.7377\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4336 - mse: 2.4336 - mae: 1.1339 - val_loss: 1.2666 - val_mse: 1.2666 - val_mae: 0.7337\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 374us/step - loss: 2.4136 - mse: 2.4136 - mae: 1.1295 - val_loss: 1.2583 - val_mse: 1.2583 - val_mae: 0.7277\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 798us/step - loss: 2.3943 - mse: 2.3943 - mae: 1.1231 - val_loss: 1.2513 - val_mse: 1.2513 - val_mae: 0.7201\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 644us/step - loss: 2.3755 - mse: 2.3755 - mae: 1.1152 - val_loss: 1.2451 - val_mse: 1.2451 - val_mae: 0.7131\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 601us/step - loss: 2.3576 - mse: 2.3576 - mae: 1.1066 - val_loss: 1.2401 - val_mse: 1.2401 - val_mae: 0.7070\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 682us/step - loss: 2.3408 - mse: 2.3408 - mae: 1.0978 - val_loss: 1.2359 - val_mse: 1.2359 - val_mae: 0.7012\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 448us/step - loss: 2.3248 - mse: 2.3248 - mae: 1.0891 - val_loss: 1.2311 - val_mse: 1.2311 - val_mae: 0.6961\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 382us/step - loss: 2.3098 - mse: 2.3098 - mae: 1.0812 - val_loss: 1.2264 - val_mse: 1.2264 - val_mae: 0.6915\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 799us/step - loss: 2.2956 - mse: 2.2956 - mae: 1.0746 - val_loss: 1.2215 - val_mse: 1.2215 - val_mae: 0.6874\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2819 - mse: 2.2819 - mae: 1.0691 - val_loss: 1.2162 - val_mse: 1.2162 - val_mae: 0.6841\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 700us/step - loss: 2.2683 - mse: 2.2683 - mae: 1.0640 - val_loss: 1.2104 - val_mse: 1.2104 - val_mae: 0.6815\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 573us/step - loss: 2.2549 - mse: 2.2549 - mae: 1.0593 - val_loss: 1.2042 - val_mse: 1.2042 - val_mae: 0.6791\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 756us/step - loss: 2.2417 - mse: 2.2417 - mae: 1.0551 - val_loss: 1.1976 - val_mse: 1.1976 - val_mae: 0.6767\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 410us/step - loss: 2.2287 - mse: 2.2287 - mae: 1.0512 - val_loss: 1.1910 - val_mse: 1.1910 - val_mae: 0.6746\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2159 - mse: 2.2159 - mae: 1.0476 - val_loss: 1.1847 - val_mse: 1.1847 - val_mae: 0.6725\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 2.2035 - mse: 2.2035 - mae: 1.0444 - val_loss: 1.1787 - val_mse: 1.1787 - val_mae: 0.6707\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 407us/step - loss: 2.1917 - mse: 2.1917 - mae: 1.0414 - val_loss: 1.1733 - val_mse: 1.1733 - val_mae: 0.6697\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 494us/step - loss: 2.1818 - mse: 2.1818 - mae: 1.0386 - val_loss: 1.1682 - val_mse: 1.1682 - val_mae: 0.6689\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 422us/step - loss: 2.1716 - mse: 2.1716 - mae: 1.0360 - val_loss: 1.1635 - val_mse: 1.1635 - val_mae: 0.6681\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 503us/step - loss: 2.1612 - mse: 2.1612 - mae: 1.0334 - val_loss: 1.1591 - val_mse: 1.1591 - val_mae: 0.6673\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 436us/step - loss: 2.1508 - mse: 2.1508 - mae: 1.0311 - val_loss: 1.1551 - val_mse: 1.1551 - val_mae: 0.6675\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 380us/step - loss: 2.1419 - mse: 2.1419 - mae: 1.0288 - val_loss: 1.1514 - val_mse: 1.1514 - val_mae: 0.6678\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 746us/step - loss: 2.1333 - mse: 2.1333 - mae: 1.0264 - val_loss: 1.1481 - val_mse: 1.1481 - val_mae: 0.6679\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 740us/step - loss: 2.1247 - mse: 2.1247 - mae: 1.0240 - val_loss: 1.1450 - val_mse: 1.1450 - val_mae: 0.6678\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 375us/step - loss: 2.1162 - mse: 2.1162 - mae: 1.0215 - val_loss: 1.1422 - val_mse: 1.1422 - val_mae: 0.6675\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 962us/step - loss: 2.1078 - mse: 2.1078 - mae: 1.0189 - val_loss: 1.1395 - val_mse: 1.1395 - val_mae: 0.6671\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0995 - mse: 2.0995 - mae: 1.0163 - val_loss: 1.1368 - val_mse: 1.1368 - val_mae: 0.6664\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0916 - mse: 2.0916 - mae: 1.0137 - val_loss: 1.1340 - val_mse: 1.1340 - val_mae: 0.6657\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0840 - mse: 2.0840 - mae: 1.0113 - val_loss: 1.1315 - val_mse: 1.1315 - val_mae: 0.6651\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0764 - mse: 2.0764 - mae: 1.0091 - val_loss: 1.1293 - val_mse: 1.1293 - val_mae: 0.6648\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 835us/step - loss: 2.0692 - mse: 2.0692 - mae: 1.0069 - val_loss: 1.1270 - val_mse: 1.1270 - val_mae: 0.6641\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 521us/step - loss: 2.0618 - mse: 2.0618 - mae: 1.0046 - val_loss: 1.1244 - val_mse: 1.1244 - val_mae: 0.6632\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 455us/step - loss: 2.0551 - mse: 2.0551 - mae: 1.0023 - val_loss: 1.1219 - val_mse: 1.1219 - val_mae: 0.6624\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 439us/step - loss: 2.0483 - mse: 2.0483 - mae: 1.0002 - val_loss: 1.1196 - val_mse: 1.1196 - val_mae: 0.6628\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 691us/step - loss: 2.0413 - mse: 2.0413 - mae: 0.9982 - val_loss: 1.1173 - val_mse: 1.1173 - val_mae: 0.6636\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 740us/step - loss: 2.0341 - mse: 2.0341 - mae: 0.9964 - val_loss: 1.1150 - val_mse: 1.1150 - val_mae: 0.6644\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 908us/step - loss: 2.0274 - mse: 2.0274 - mae: 0.9948 - val_loss: 1.1123 - val_mse: 1.1123 - val_mae: 0.6646\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 612us/step - loss: 2.0202 - mse: 2.0202 - mae: 0.9928 - val_loss: 1.1093 - val_mse: 1.1093 - val_mae: 0.6644\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 694us/step - loss: 2.0129 - mse: 2.0129 - mae: 0.9907 - val_loss: 1.1065 - val_mse: 1.1065 - val_mae: 0.6644\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 720us/step - loss: 2.0058 - mse: 2.0058 - mae: 0.9886 - val_loss: 1.1039 - val_mse: 1.1039 - val_mae: 0.6648\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.4138 - mse: 3.4138 - mae: 1.302 - 0s 818us/step - loss: 1.9985 - mse: 1.9985 - mae: 0.9865 - val_loss: 1.1015 - val_mse: 1.1015 - val_mae: 0.6655\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 593us/step - loss: 1.9911 - mse: 1.9911 - mae: 0.9845 - val_loss: 1.0990 - val_mse: 1.0990 - val_mae: 0.6658\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 630us/step - loss: 1.9844 - mse: 1.9844 - mae: 0.9824 - val_loss: 1.0974 - val_mse: 1.0974 - val_mae: 0.6663\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 740us/step - loss: 1.9782 - mse: 1.9782 - mae: 0.9806 - val_loss: 1.0938 - val_mse: 1.0938 - val_mae: 0.6672\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 676us/step - loss: 1.9726 - mse: 1.9726 - mae: 0.9794 - val_loss: 1.0921 - val_mse: 1.0921 - val_mae: 0.6680\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 700us/step - loss: 1.9665 - mse: 1.9665 - mae: 0.9778 - val_loss: 1.0916 - val_mse: 1.0916 - val_mae: 0.6686\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 476us/step - loss: 1.9614 - mse: 1.9614 - mae: 0.9764 - val_loss: 1.0903 - val_mse: 1.0903 - val_mae: 0.6694\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9562 - mse: 1.9562 - mae: 0.9753 - val_loss: 1.0885 - val_mse: 1.0885 - val_mae: 0.6704\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 821us/step - loss: 1.9505 - mse: 1.9505 - mae: 0.9741 - val_loss: 1.0877 - val_mse: 1.0877 - val_mae: 0.6714\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9449 - mse: 1.9449 - mae: 0.9729 - val_loss: 1.0865 - val_mse: 1.0865 - val_mae: 0.6725\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 682us/step - loss: 1.9394 - mse: 1.9394 - mae: 0.9717 - val_loss: 1.0861 - val_mse: 1.0861 - val_mae: 0.6735\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 943us/step - loss: 1.9345 - mse: 1.9345 - mae: 0.9705 - val_loss: 1.0852 - val_mse: 1.0852 - val_mae: 0.6745\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 608us/step - loss: 1.9296 - mse: 1.9296 - mae: 0.9693 - val_loss: 1.0837 - val_mse: 1.0837 - val_mae: 0.6752\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 1.9246 - mse: 1.9246 - mae: 0.9681 - val_loss: 1.0839 - val_mse: 1.0839 - val_mae: 0.6756\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 530us/step - loss: 1.9196 - mse: 1.9196 - mae: 0.9664 - val_loss: 1.0846 - val_mse: 1.0846 - val_mae: 0.6758\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 404us/step - loss: 1.9157 - mse: 1.9157 - mae: 0.9649 - val_loss: 1.0830 - val_mse: 1.0830 - val_mae: 0.6762\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 361us/step - loss: 1.9108 - mse: 1.9108 - mae: 0.9638 - val_loss: 1.0814 - val_mse: 1.0814 - val_mae: 0.6769\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 481us/step - loss: 1.9069 - mse: 1.9069 - mae: 0.9627 - val_loss: 1.0819 - val_mse: 1.0819 - val_mae: 0.6774\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 576us/step - loss: 1.9023 - mse: 1.9023 - mae: 0.9612 - val_loss: 1.0840 - val_mse: 1.0840 - val_mae: 0.6778\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 459us/step - loss: 1.8983 - mse: 1.8983 - mae: 0.9597 - val_loss: 1.0836 - val_mse: 1.0836 - val_mae: 0.6787\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 502us/step - loss: 1.8940 - mse: 1.8940 - mae: 0.9587 - val_loss: 1.0825 - val_mse: 1.0825 - val_mae: 0.6795\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 445us/step - loss: 1.8900 - mse: 1.8900 - mae: 0.9578 - val_loss: 1.0834 - val_mse: 1.0834 - val_mae: 0.6801\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 990us/step - loss: 1.8858 - mse: 1.8858 - mae: 0.9565 - val_loss: 1.0849 - val_mse: 1.0849 - val_mae: 0.6809\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 506us/step - loss: 1.8823 - mse: 1.8823 - mae: 0.9553 - val_loss: 1.0842 - val_mse: 1.0842 - val_mae: 0.6820\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8781 - mse: 1.8781 - mae: 0.9545 - val_loss: 1.0846 - val_mse: 1.0846 - val_mae: 0.6831\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8741 - mse: 1.8741 - mae: 0.9535 - val_loss: 1.0856 - val_mse: 1.0856 - val_mae: 0.6839\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 568us/step - loss: 1.8706 - mse: 1.8706 - mae: 0.9523 - val_loss: 1.0856 - val_mse: 1.0856 - val_mae: 0.6846\n",
      "69\n",
      "[69]\n",
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 5.2626 - mse: 5.2626 - mae: 1.7956 - val_loss: 3.2513 - val_mse: 3.2513 - val_mae: 1.5631\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 651us/step - loss: 4.1196 - mse: 4.1196 - mae: 1.5222 - val_loss: 2.3930 - val_mse: 2.3930 - val_mae: 1.3184\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 500us/step - loss: 3.3008 - mse: 3.3008 - mae: 1.3227 - val_loss: 1.7742 - val_mse: 1.7742 - val_mae: 1.1265\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 363us/step - loss: 2.7604 - mse: 2.7604 - mae: 1.2050 - val_loss: 1.3597 - val_mse: 1.3597 - val_mae: 0.9802\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 316us/step - loss: 2.4544 - mse: 2.4544 - mae: 1.1581 - val_loss: 1.1238 - val_mse: 1.1238 - val_mae: 0.8606\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 522us/step - loss: 2.3218 - mse: 2.3218 - mae: 1.1542 - val_loss: 1.0138 - val_mse: 1.0138 - val_mae: 0.7914\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 698us/step - loss: 2.2975 - mse: 2.2975 - mae: 1.1754 - val_loss: 0.9774 - val_mse: 0.9774 - val_mae: 0.7705\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 472us/step - loss: 2.3168 - mse: 2.3168 - mae: 1.1946 - val_loss: 0.9725 - val_mse: 0.9725 - val_mae: 0.7726\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 507us/step - loss: 2.3301 - mse: 2.3301 - mae: 1.2035 - val_loss: 0.9659 - val_mse: 0.9659 - val_mae: 0.7735\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 564us/step - loss: 2.3196 - mse: 2.3196 - mae: 1.2024 - val_loss: 0.9514 - val_mse: 0.9514 - val_mae: 0.7661\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 480us/step - loss: 2.2888 - mse: 2.2888 - mae: 1.1933 - val_loss: 0.9338 - val_mse: 0.9338 - val_mae: 0.7534\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 614us/step - loss: 2.2492 - mse: 2.2492 - mae: 1.1798 - val_loss: 0.9194 - val_mse: 0.9194 - val_mae: 0.7417\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 638us/step - loss: 2.2116 - mse: 2.2116 - mae: 1.1656 - val_loss: 0.9113 - val_mse: 0.9113 - val_mae: 0.7394\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 536us/step - loss: 2.1819 - mse: 2.1819 - mae: 1.1531 - val_loss: 0.9075 - val_mse: 0.9075 - val_mae: 0.7411\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 634us/step - loss: 2.1591 - mse: 2.1591 - mae: 1.1419 - val_loss: 0.9043 - val_mse: 0.9043 - val_mae: 0.7446\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 593us/step - loss: 2.1404 - mse: 2.1404 - mae: 1.1326 - val_loss: 0.8993 - val_mse: 0.8993 - val_mae: 0.7443\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 553us/step - loss: 2.1240 - mse: 2.1240 - mae: 1.1255 - val_loss: 0.8917 - val_mse: 0.8917 - val_mae: 0.7406\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 561us/step - loss: 2.1090 - mse: 2.1090 - mae: 1.1202 - val_loss: 0.8824 - val_mse: 0.8824 - val_mae: 0.7348\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 670us/step - loss: 2.0952 - mse: 2.0952 - mae: 1.1163 - val_loss: 0.8728 - val_mse: 0.8728 - val_mae: 0.7285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 456us/step - loss: 2.0835 - mse: 2.0835 - mae: 1.1132 - val_loss: 0.8637 - val_mse: 0.8637 - val_mae: 0.7237\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 552us/step - loss: 2.0738 - mse: 2.0738 - mae: 1.1108 - val_loss: 0.8555 - val_mse: 0.8555 - val_mae: 0.7203\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 438us/step - loss: 2.0645 - mse: 2.0645 - mae: 1.1082 - val_loss: 0.8480 - val_mse: 0.8480 - val_mae: 0.7174\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 500us/step - loss: 2.0547 - mse: 2.0547 - mae: 1.1050 - val_loss: 0.8414 - val_mse: 0.8414 - val_mae: 0.7147\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 702us/step - loss: 2.0449 - mse: 2.0449 - mae: 1.1016 - val_loss: 0.8354 - val_mse: 0.8354 - val_mae: 0.7119\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 612us/step - loss: 2.0350 - mse: 2.0350 - mae: 1.0979 - val_loss: 0.8292 - val_mse: 0.8292 - val_mae: 0.7093\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 604us/step - loss: 2.0244 - mse: 2.0244 - mae: 1.0939 - val_loss: 0.8239 - val_mse: 0.8239 - val_mae: 0.7087\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 342us/step - loss: 2.0132 - mse: 2.0132 - mae: 1.0894 - val_loss: 0.8180 - val_mse: 0.8180 - val_mae: 0.7080\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 664us/step - loss: 2.0022 - mse: 2.0022 - mae: 1.0851 - val_loss: 0.8123 - val_mse: 0.8123 - val_mae: 0.7064\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 828us/step - loss: 1.9921 - mse: 1.9921 - mae: 1.0814 - val_loss: 0.8068 - val_mse: 0.8068 - val_mae: 0.7045\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 659us/step - loss: 1.9821 - mse: 1.9821 - mae: 1.0780 - val_loss: 0.8011 - val_mse: 0.8011 - val_mae: 0.7023\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 559us/step - loss: 1.9721 - mse: 1.9721 - mae: 1.0746 - val_loss: 0.7957 - val_mse: 0.7957 - val_mae: 0.7005\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 708us/step - loss: 1.9622 - mse: 1.9622 - mae: 1.0710 - val_loss: 0.7907 - val_mse: 0.7907 - val_mae: 0.6989\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 725us/step - loss: 1.9537 - mse: 1.9537 - mae: 1.0676 - val_loss: 0.7860 - val_mse: 0.7860 - val_mae: 0.6968\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 566us/step - loss: 1.9451 - mse: 1.9451 - mae: 1.0647 - val_loss: 0.7815 - val_mse: 0.7815 - val_mae: 0.6948\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 583us/step - loss: 1.9369 - mse: 1.9369 - mae: 1.0620 - val_loss: 0.7770 - val_mse: 0.7770 - val_mae: 0.6928\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 633us/step - loss: 1.9281 - mse: 1.9281 - mae: 1.0590 - val_loss: 0.7727 - val_mse: 0.7727 - val_mae: 0.6909\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 541us/step - loss: 1.9196 - mse: 1.9196 - mae: 1.0560 - val_loss: 0.7688 - val_mse: 0.7688 - val_mae: 0.6890\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 739us/step - loss: 1.9114 - mse: 1.9114 - mae: 1.0530 - val_loss: 0.7657 - val_mse: 0.7657 - val_mae: 0.6874\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 633us/step - loss: 1.9033 - mse: 1.9033 - mae: 1.0499 - val_loss: 0.7625 - val_mse: 0.7625 - val_mae: 0.6858\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 482us/step - loss: 1.8945 - mse: 1.8945 - mae: 1.0467 - val_loss: 0.7606 - val_mse: 0.7606 - val_mae: 0.6847\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 550us/step - loss: 1.8860 - mse: 1.8860 - mae: 1.0433 - val_loss: 0.7594 - val_mse: 0.7594 - val_mae: 0.6838\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 589us/step - loss: 1.8778 - mse: 1.8778 - mae: 1.0403 - val_loss: 0.7582 - val_mse: 0.7582 - val_mae: 0.6828\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 608us/step - loss: 1.8704 - mse: 1.8704 - mae: 1.0375 - val_loss: 0.7554 - val_mse: 0.7554 - val_mae: 0.6813\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 576us/step - loss: 1.8629 - mse: 1.8629 - mae: 1.0351 - val_loss: 0.7531 - val_mse: 0.7531 - val_mae: 0.6800\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 536us/step - loss: 1.8555 - mse: 1.8555 - mae: 1.0327 - val_loss: 0.7514 - val_mse: 0.7514 - val_mae: 0.6789\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 525us/step - loss: 1.8483 - mse: 1.8483 - mae: 1.0302 - val_loss: 0.7501 - val_mse: 0.7501 - val_mae: 0.6779\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 656us/step - loss: 1.8409 - mse: 1.8409 - mae: 1.0274 - val_loss: 0.7489 - val_mse: 0.7489 - val_mae: 0.6770\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 491us/step - loss: 1.8338 - mse: 1.8338 - mae: 1.0249 - val_loss: 0.7462 - val_mse: 0.7462 - val_mae: 0.6751\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 574us/step - loss: 1.8266 - mse: 1.8266 - mae: 1.0225 - val_loss: 0.7462 - val_mse: 0.7462 - val_mae: 0.6748\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.8195 - mse: 1.8195 - mae: 1.0195 - val_loss: 0.7473 - val_mse: 0.7473 - val_mae: 0.6751\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 881us/step - loss: 1.8134 - mse: 1.8134 - mae: 1.0167 - val_loss: 0.7457 - val_mse: 0.7457 - val_mae: 0.6738\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 350us/step - loss: 1.8069 - mse: 1.8069 - mae: 1.0146 - val_loss: 0.7429 - val_mse: 0.7429 - val_mae: 0.6720\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 453us/step - loss: 1.8004 - mse: 1.8004 - mae: 1.0129 - val_loss: 0.7424 - val_mse: 0.7424 - val_mae: 0.6714\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 434us/step - loss: 1.7938 - mse: 1.7938 - mae: 1.0108 - val_loss: 0.7428 - val_mse: 0.7428 - val_mae: 0.6712\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 548us/step - loss: 1.7878 - mse: 1.7878 - mae: 1.0088 - val_loss: 0.7408 - val_mse: 0.7408 - val_mae: 0.6696\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 637us/step - loss: 1.7816 - mse: 1.7816 - mae: 1.0071 - val_loss: 0.7392 - val_mse: 0.7392 - val_mae: 0.6682\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 589us/step - loss: 1.7749 - mse: 1.7749 - mae: 1.0048 - val_loss: 0.7399 - val_mse: 0.7399 - val_mae: 0.6679\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 441us/step - loss: 1.7685 - mse: 1.7685 - mae: 1.0022 - val_loss: 0.7385 - val_mse: 0.7385 - val_mae: 0.6665\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 504us/step - loss: 1.7621 - mse: 1.7621 - mae: 1.0001 - val_loss: 0.7376 - val_mse: 0.7376 - val_mae: 0.6653\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 422us/step - loss: 1.7558 - mse: 1.7558 - mae: 0.9982 - val_loss: 0.7370 - val_mse: 0.7370 - val_mae: 0.6643\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 585us/step - loss: 1.7495 - mse: 1.7495 - mae: 0.9962 - val_loss: 0.7360 - val_mse: 0.7360 - val_mae: 0.6630\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 460us/step - loss: 1.7434 - mse: 1.7434 - mae: 0.9945 - val_loss: 0.7347 - val_mse: 0.7347 - val_mae: 0.6617\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 517us/step - loss: 1.7370 - mse: 1.7370 - mae: 0.9928 - val_loss: 0.7352 - val_mse: 0.7352 - val_mae: 0.6614\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 530us/step - loss: 1.7315 - mse: 1.7315 - mae: 0.9911 - val_loss: 0.7337 - val_mse: 0.7337 - val_mae: 0.6602\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 496us/step - loss: 1.7256 - mse: 1.7256 - mae: 0.9897 - val_loss: 0.7321 - val_mse: 0.7321 - val_mae: 0.6589\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 497us/step - loss: 1.7202 - mse: 1.7203 - mae: 0.9885 - val_loss: 0.7309 - val_mse: 0.7309 - val_mae: 0.6577\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 860us/step - loss: 1.7143 - mse: 1.7143 - mae: 0.9868 - val_loss: 0.7324 - val_mse: 0.7324 - val_mae: 0.6579\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 574us/step - loss: 1.7088 - mse: 1.7088 - mae: 0.9848 - val_loss: 0.7337 - val_mse: 0.7337 - val_mae: 0.6578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 802us/step - loss: 1.7036 - mse: 1.7036 - mae: 0.9832 - val_loss: 0.7309 - val_mse: 0.7309 - val_mae: 0.6559\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 826us/step - loss: 1.6975 - mse: 1.6975 - mae: 0.9821 - val_loss: 0.7312 - val_mse: 0.7312 - val_mae: 0.6554\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 409us/step - loss: 1.6913 - mse: 1.6913 - mae: 0.9799 - val_loss: 0.7309 - val_mse: 0.7309 - val_mae: 0.6547\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 492us/step - loss: 1.6853 - mse: 1.6853 - mae: 0.9778 - val_loss: 0.7309 - val_mse: 0.7309 - val_mae: 0.6542\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 785us/step - loss: 1.6799 - mse: 1.6799 - mae: 0.9763 - val_loss: 0.7290 - val_mse: 0.7290 - val_mae: 0.6527\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 671us/step - loss: 1.6741 - mse: 1.6741 - mae: 0.9749 - val_loss: 0.7298 - val_mse: 0.7298 - val_mae: 0.6523\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.6684 - mse: 1.6684 - mae: 0.9729 - val_loss: 0.7300 - val_mse: 0.7300 - val_mae: 0.6517\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6634 - mse: 1.6634 - mae: 0.9714 - val_loss: 0.7256 - val_mse: 0.7256 - val_mae: 0.6493\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 932us/step - loss: 1.6577 - mse: 1.6577 - mae: 0.9703 - val_loss: 0.7254 - val_mse: 0.7254 - val_mae: 0.6483\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 627us/step - loss: 1.6516 - mse: 1.6516 - mae: 0.9681 - val_loss: 0.7265 - val_mse: 0.7265 - val_mae: 0.6480\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 588us/step - loss: 1.6465 - mse: 1.6465 - mae: 0.9660 - val_loss: 0.7218 - val_mse: 0.7218 - val_mae: 0.6453\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 600us/step - loss: 1.6411 - mse: 1.6411 - mae: 0.9654 - val_loss: 0.7185 - val_mse: 0.7185 - val_mae: 0.6431\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 337us/step - loss: 1.6355 - mse: 1.6355 - mae: 0.9639 - val_loss: 0.7195 - val_mse: 0.7195 - val_mae: 0.6430\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 734us/step - loss: 1.6295 - mse: 1.6295 - mae: 0.9613 - val_loss: 0.7220 - val_mse: 0.7220 - val_mae: 0.6439\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 594us/step - loss: 1.6247 - mse: 1.6247 - mae: 0.9591 - val_loss: 0.7209 - val_mse: 0.7209 - val_mae: 0.6438\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 668us/step - loss: 1.6190 - mse: 1.6190 - mae: 0.9582 - val_loss: 0.7191 - val_mse: 0.7191 - val_mae: 0.6433\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 524us/step - loss: 1.6138 - mse: 1.6138 - mae: 0.9569 - val_loss: 0.7198 - val_mse: 0.7198 - val_mae: 0.6435\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 409us/step - loss: 1.6081 - mse: 1.6081 - mae: 0.9546 - val_loss: 0.7168 - val_mse: 0.7168 - val_mae: 0.6419\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 550us/step - loss: 1.6028 - mse: 1.6028 - mae: 0.9529 - val_loss: 0.7156 - val_mse: 0.7156 - val_mae: 0.6407\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 740us/step - loss: 1.5972 - mse: 1.5972 - mae: 0.9506 - val_loss: 0.7158 - val_mse: 0.7158 - val_mae: 0.6405\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 908us/step - loss: 1.5913 - mse: 1.5913 - mae: 0.9480 - val_loss: 0.7191 - val_mse: 0.7191 - val_mae: 0.6422\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 573us/step - loss: 1.5862 - mse: 1.5862 - mae: 0.9458 - val_loss: 0.7172 - val_mse: 0.7172 - val_mae: 0.6421\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.5808 - mse: 1.5808 - mae: 0.9447 - val_loss: 0.7163 - val_mse: 0.7163 - val_mae: 0.6421\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 767us/step - loss: 1.5755 - mse: 1.5755 - mae: 0.9428 - val_loss: 0.7178 - val_mse: 0.7178 - val_mae: 0.6423\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 650us/step - loss: 1.5704 - mse: 1.5704 - mae: 0.9407 - val_loss: 0.7133 - val_mse: 0.7133 - val_mae: 0.6399\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 555us/step - loss: 1.5657 - mse: 1.5657 - mae: 0.9393 - val_loss: 0.7160 - val_mse: 0.7160 - val_mae: 0.6403\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 649us/step - loss: 1.5594 - mse: 1.5594 - mae: 0.9358 - val_loss: 0.7195 - val_mse: 0.7195 - val_mae: 0.6417\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 904us/step - loss: 1.5544 - mse: 1.5544 - mae: 0.9333 - val_loss: 0.7147 - val_mse: 0.7147 - val_mae: 0.6410\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 881us/step - loss: 1.5487 - mse: 1.5487 - mae: 0.9329 - val_loss: 0.7143 - val_mse: 0.7143 - val_mae: 0.6414\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 684us/step - loss: 1.5434 - mse: 1.5434 - mae: 0.9311 - val_loss: 0.7168 - val_mse: 0.7168 - val_mae: 0.6422\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 524us/step - loss: 1.5376 - mse: 1.5376 - mae: 0.9284 - val_loss: 0.7145 - val_mse: 0.7145 - val_mae: 0.6415\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 940us/step - loss: 1.5317 - mse: 1.5317 - mae: 0.9266 - val_loss: 0.7178 - val_mse: 0.7178 - val_mae: 0.6428\n",
      "70\n",
      "[70]\n",
      "Train on 100 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 5.0231 - mse: 5.0231 - mae: 1.9579 - val_loss: 1.2372 - val_mse: 1.2372 - val_mae: 1.0464\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 841us/step - loss: 3.8419 - mse: 3.8419 - mae: 1.6640 - val_loss: 0.8231 - val_mse: 0.8231 - val_mae: 0.8330\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 534us/step - loss: 2.9138 - mse: 2.9138 - mae: 1.4071 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.6341\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 363us/step - loss: 2.2520 - mse: 2.2520 - mae: 1.2069 - val_loss: 0.3069 - val_mse: 0.3069 - val_mae: 0.4776\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 712us/step - loss: 1.8318 - mse: 1.8318 - mae: 1.0663 - val_loss: 0.1973 - val_mse: 0.1973 - val_mae: 0.3538\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 587us/step - loss: 1.6056 - mse: 1.6056 - mae: 0.9769 - val_loss: 0.1560 - val_mse: 0.1560 - val_mae: 0.2715\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 488us/step - loss: 1.5201 - mse: 1.5201 - mae: 0.9403 - val_loss: 0.1548 - val_mse: 0.1548 - val_mae: 0.2566\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 476us/step - loss: 1.5116 - mse: 1.5116 - mae: 0.9433 - val_loss: 0.1682 - val_mse: 0.1682 - val_mae: 0.2799\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 565us/step - loss: 1.5230 - mse: 1.5230 - mae: 0.9496 - val_loss: 0.1780 - val_mse: 0.1780 - val_mae: 0.2948\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 548us/step - loss: 1.5218 - mse: 1.5218 - mae: 0.9507 - val_loss: 0.1772 - val_mse: 0.1772 - val_mae: 0.2953\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 490us/step - loss: 1.4986 - mse: 1.4986 - mae: 0.9438 - val_loss: 0.1676 - val_mse: 0.1676 - val_mae: 0.2831\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.4603 - mse: 1.4603 - mae: 0.9323 - val_loss: 0.1544 - val_mse: 0.1544 - val_mae: 0.2651\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 812us/step - loss: 1.4183 - mse: 1.4183 - mae: 0.9202 - val_loss: 0.1418 - val_mse: 0.1418 - val_mae: 0.2465\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 511us/step - loss: 1.3808 - mse: 1.3808 - mae: 0.9102 - val_loss: 0.1320 - val_mse: 0.1320 - val_mae: 0.2304\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 554us/step - loss: 1.3500 - mse: 1.3500 - mae: 0.9030 - val_loss: 0.1246 - val_mse: 0.1246 - val_mae: 0.2171\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 374us/step - loss: 1.3251 - mse: 1.3251 - mae: 0.8963 - val_loss: 0.1195 - val_mse: 0.1195 - val_mae: 0.2091\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 354us/step - loss: 1.3033 - mse: 1.3033 - mae: 0.8898 - val_loss: 0.1164 - val_mse: 0.1164 - val_mae: 0.2057\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 502us/step - loss: 1.2854 - mse: 1.2854 - mae: 0.8844 - val_loss: 0.1142 - val_mse: 0.1142 - val_mae: 0.2044\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 513us/step - loss: 1.2697 - mse: 1.2697 - mae: 0.8797 - val_loss: 0.1128 - val_mse: 0.1128 - val_mae: 0.2043\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 514us/step - loss: 1.2556 - mse: 1.2556 - mae: 0.8754 - val_loss: 0.1119 - val_mse: 0.1119 - val_mae: 0.2052\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 605us/step - loss: 1.2425 - mse: 1.2425 - mae: 0.8713 - val_loss: 0.1115 - val_mse: 0.1115 - val_mae: 0.2072\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 501us/step - loss: 1.2299 - mse: 1.2299 - mae: 0.8672 - val_loss: 0.1112 - val_mse: 0.1112 - val_mae: 0.2090\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 434us/step - loss: 1.2180 - mse: 1.2180 - mae: 0.8639 - val_loss: 0.1107 - val_mse: 0.1107 - val_mae: 0.2103\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 480us/step - loss: 1.2053 - mse: 1.2053 - mae: 0.8602 - val_loss: 0.1101 - val_mse: 0.1101 - val_mae: 0.2112\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 389us/step - loss: 1.1927 - mse: 1.1927 - mae: 0.8566 - val_loss: 0.1090 - val_mse: 0.1090 - val_mae: 0.2116\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 417us/step - loss: 1.1794 - mse: 1.1794 - mae: 0.8533 - val_loss: 0.1079 - val_mse: 0.1079 - val_mae: 0.2118\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 657us/step - loss: 1.1661 - mse: 1.1661 - mae: 0.8502 - val_loss: 0.1069 - val_mse: 0.1069 - val_mae: 0.2129\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 985us/step - loss: 1.1533 - mse: 1.1533 - mae: 0.8470 - val_loss: 0.1057 - val_mse: 0.1057 - val_mae: 0.2138\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 889us/step - loss: 1.1402 - mse: 1.1402 - mae: 0.8435 - val_loss: 0.1047 - val_mse: 0.1047 - val_mae: 0.2153\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 398us/step - loss: 1.1269 - mse: 1.1269 - mae: 0.8396 - val_loss: 0.1039 - val_mse: 0.1039 - val_mae: 0.2172\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 575us/step - loss: 1.1139 - mse: 1.1139 - mae: 0.8355 - val_loss: 0.1028 - val_mse: 0.1028 - val_mae: 0.2186\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 827us/step - loss: 1.1016 - mse: 1.1016 - mae: 0.8316 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2199\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0894 - mse: 1.0894 - mae: 0.8273 - val_loss: 0.0996 - val_mse: 0.0996 - val_mae: 0.2204\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 771us/step - loss: 1.0779 - mse: 1.0779 - mae: 0.8234 - val_loss: 0.0980 - val_mse: 0.0980 - val_mae: 0.2207\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0670 - mse: 1.0670 - mae: 0.8193 - val_loss: 0.0968 - val_mse: 0.0968 - val_mae: 0.2218\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 720us/step - loss: 1.0569 - mse: 1.0569 - mae: 0.8151 - val_loss: 0.0961 - val_mse: 0.0961 - val_mae: 0.2237\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 349us/step - loss: 1.0470 - mse: 1.0470 - mae: 0.8111 - val_loss: 0.0960 - val_mse: 0.0960 - val_mae: 0.2258\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1000us/step - loss: 1.0373 - mse: 1.0373 - mae: 0.8073 - val_loss: 0.0961 - val_mse: 0.0961 - val_mae: 0.2292\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 613us/step - loss: 1.0285 - mse: 1.0285 - mae: 0.8040 - val_loss: 0.0960 - val_mse: 0.0960 - val_mae: 0.2318\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0201 - mse: 1.0201 - mae: 0.8004 - val_loss: 0.0955 - val_mse: 0.0955 - val_mae: 0.2339\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 783us/step - loss: 1.0129 - mse: 1.0129 - mae: 0.7972 - val_loss: 0.0949 - val_mse: 0.0949 - val_mae: 0.2352\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 505us/step - loss: 1.0058 - mse: 1.0058 - mae: 0.7945 - val_loss: 0.0942 - val_mse: 0.0942 - val_mae: 0.2357\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9985 - mse: 0.9985 - mae: 0.7922 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.2354\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.9912 - mse: 0.9912 - mae: 0.7897 - val_loss: 0.0927 - val_mse: 0.0927 - val_mae: 0.2346\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9841 - mse: 0.9841 - mae: 0.7873 - val_loss: 0.0917 - val_mse: 0.0917 - val_mae: 0.2333\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.9768 - mse: 0.9768 - mae: 0.7844 - val_loss: 0.0913 - val_mse: 0.0913 - val_mae: 0.2340\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.9702 - mse: 0.9702 - mae: 0.7817 - val_loss: 0.0913 - val_mse: 0.0913 - val_mae: 0.2357\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 621us/step - loss: 0.9642 - mse: 0.9642 - mae: 0.7792 - val_loss: 0.0915 - val_mse: 0.0915 - val_mae: 0.2379\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 893us/step - loss: 0.9590 - mse: 0.9590 - mae: 0.7770 - val_loss: 0.0914 - val_mse: 0.0914 - val_mae: 0.2394\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 837us/step - loss: 0.9529 - mse: 0.9529 - mae: 0.7744 - val_loss: 0.0914 - val_mse: 0.0914 - val_mae: 0.2409\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 633us/step - loss: 0.9473 - mse: 0.9473 - mae: 0.7726 - val_loss: 0.0911 - val_mse: 0.0911 - val_mae: 0.2410\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 542us/step - loss: 0.9408 - mse: 0.9408 - mae: 0.7704 - val_loss: 0.0914 - val_mse: 0.0914 - val_mae: 0.2425\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.9348 - mse: 0.9348 - mae: 0.7683 - val_loss: 0.0919 - val_mse: 0.0919 - val_mae: 0.2446\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.9292 - mse: 0.9292 - mae: 0.7663 - val_loss: 0.0920 - val_mse: 0.0920 - val_mae: 0.2461\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 815us/step - loss: 0.9237 - mse: 0.9237 - mae: 0.7642 - val_loss: 0.0918 - val_mse: 0.0918 - val_mae: 0.2469\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 782us/step - loss: 0.9181 - mse: 0.9181 - mae: 0.7619 - val_loss: 0.0920 - val_mse: 0.0920 - val_mae: 0.2487\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9128 - mse: 0.9128 - mae: 0.7598 - val_loss: 0.0925 - val_mse: 0.0925 - val_mae: 0.2506\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 716us/step - loss: 0.9076 - mse: 0.9076 - mae: 0.7578 - val_loss: 0.0928 - val_mse: 0.0928 - val_mae: 0.2521\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 551us/step - loss: 0.9024 - mse: 0.9024 - mae: 0.7560 - val_loss: 0.0922 - val_mse: 0.0922 - val_mae: 0.2517\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8964 - mse: 0.8964 - mae: 0.7535 - val_loss: 0.0926 - val_mse: 0.0926 - val_mae: 0.2532\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 691us/step - loss: 0.8903 - mse: 0.8903 - mae: 0.7504 - val_loss: 0.0939 - val_mse: 0.0939 - val_mae: 0.2569\n",
      "71\n",
      "[71]\n",
      "Train on 100 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.4885 - mse: 0.4885 - mae: 0.4774 - val_loss: 0.2804 - val_mse: 0.2804 - val_mae: 0.4639\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 498us/step - loss: 0.4109 - mse: 0.4109 - mae: 0.4165 - val_loss: 0.2082 - val_mse: 0.2082 - val_mae: 0.3950\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 541us/step - loss: 0.3614 - mse: 0.3614 - mae: 0.3860 - val_loss: 0.1624 - val_mse: 0.1624 - val_mae: 0.3419\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 477us/step - loss: 0.3379 - mse: 0.3379 - mae: 0.3753 - val_loss: 0.1366 - val_mse: 0.1366 - val_mae: 0.3027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 560us/step - loss: 0.3319 - mse: 0.3319 - mae: 0.3798 - val_loss: 0.1252 - val_mse: 0.1252 - val_mae: 0.2782\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 553us/step - loss: 0.3308 - mse: 0.3308 - mae: 0.3846 - val_loss: 0.1206 - val_mse: 0.1206 - val_mae: 0.2685\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 545us/step - loss: 0.3276 - mse: 0.3276 - mae: 0.3827 - val_loss: 0.1192 - val_mse: 0.1192 - val_mae: 0.2693\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.3218 - mse: 0.3218 - mae: 0.3759 - val_loss: 0.1201 - val_mse: 0.1201 - val_mae: 0.2772\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 480us/step - loss: 0.3160 - mse: 0.3160 - mae: 0.3679 - val_loss: 0.1223 - val_mse: 0.1223 - val_mae: 0.2860\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 570us/step - loss: 0.3117 - mse: 0.3117 - mae: 0.3603 - val_loss: 0.1246 - val_mse: 0.1246 - val_mae: 0.2929\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 544us/step - loss: 0.3086 - mse: 0.3086 - mae: 0.3543 - val_loss: 0.1256 - val_mse: 0.1256 - val_mae: 0.2961\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 468us/step - loss: 0.3057 - mse: 0.3057 - mae: 0.3503 - val_loss: 0.1244 - val_mse: 0.1244 - val_mae: 0.2952\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.3025 - mse: 0.3025 - mae: 0.3472 - val_loss: 0.1214 - val_mse: 0.1214 - val_mae: 0.2909\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 671us/step - loss: 0.2993 - mse: 0.2993 - mae: 0.3450 - val_loss: 0.1177 - val_mse: 0.1177 - val_mae: 0.2850\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.2962 - mse: 0.2962 - mae: 0.3435 - val_loss: 0.1143 - val_mse: 0.1143 - val_mae: 0.2790\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.2933 - mse: 0.2933 - mae: 0.3422 - val_loss: 0.1115 - val_mse: 0.1115 - val_mae: 0.2740\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2907 - mse: 0.2907 - mae: 0.3407 - val_loss: 0.1094 - val_mse: 0.1094 - val_mae: 0.2703\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.2882 - mse: 0.2882 - mae: 0.3387 - val_loss: 0.1077 - val_mse: 0.1077 - val_mae: 0.2676\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 906us/step - loss: 0.2860 - mse: 0.2860 - mae: 0.3365 - val_loss: 0.1064 - val_mse: 0.1064 - val_mae: 0.2659\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 943us/step - loss: 0.2839 - mse: 0.2839 - mae: 0.3344 - val_loss: 0.1054 - val_mse: 0.1054 - val_mae: 0.2647\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 966us/step - loss: 0.2820 - mse: 0.2820 - mae: 0.3322 - val_loss: 0.1045 - val_mse: 0.1045 - val_mae: 0.2635\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 751us/step - loss: 0.2799 - mse: 0.2799 - mae: 0.3299 - val_loss: 0.1037 - val_mse: 0.1037 - val_mae: 0.2623\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 885us/step - loss: 0.2780 - mse: 0.2780 - mae: 0.3278 - val_loss: 0.1028 - val_mse: 0.1028 - val_mae: 0.2612\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 731us/step - loss: 0.2761 - mse: 0.2761 - mae: 0.3259 - val_loss: 0.1020 - val_mse: 0.1020 - val_mae: 0.2601\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2742 - mse: 0.2742 - mae: 0.3243 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2590\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 577us/step - loss: 0.2724 - mse: 0.2724 - mae: 0.3230 - val_loss: 0.1006 - val_mse: 0.1006 - val_mae: 0.2579\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2706 - mse: 0.2706 - mae: 0.3216 - val_loss: 0.0999 - val_mse: 0.0999 - val_mae: 0.2572\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.2690 - mse: 0.2690 - mae: 0.3203 - val_loss: 0.0993 - val_mse: 0.0993 - val_mae: 0.2562\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2675 - mse: 0.2675 - mae: 0.3190 - val_loss: 0.0987 - val_mse: 0.0987 - val_mae: 0.2549\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2660 - mse: 0.2660 - mae: 0.3177 - val_loss: 0.0984 - val_mse: 0.0984 - val_mae: 0.2543\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 789us/step - loss: 0.2645 - mse: 0.2645 - mae: 0.3162 - val_loss: 0.0984 - val_mse: 0.0984 - val_mae: 0.2544\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 862us/step - loss: 0.2633 - mse: 0.2633 - mae: 0.3148 - val_loss: 0.0982 - val_mse: 0.0982 - val_mae: 0.2537\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2619 - mse: 0.2619 - mae: 0.3138 - val_loss: 0.0978 - val_mse: 0.0978 - val_mae: 0.2528\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 621us/step - loss: 0.2606 - mse: 0.2606 - mae: 0.3127 - val_loss: 0.0974 - val_mse: 0.0974 - val_mae: 0.2521\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 932us/step - loss: 0.2594 - mse: 0.2594 - mae: 0.3116 - val_loss: 0.0973 - val_mse: 0.0973 - val_mae: 0.2518\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3418 - mse: 0.3418 - mae: 0.351 - 0s 610us/step - loss: 0.2582 - mse: 0.2582 - mae: 0.3105 - val_loss: 0.0970 - val_mse: 0.0970 - val_mae: 0.2511\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.2570 - mse: 0.2570 - mae: 0.3097 - val_loss: 0.0967 - val_mse: 0.0967 - val_mae: 0.2501\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 618us/step - loss: 0.2558 - mse: 0.2558 - mae: 0.3087 - val_loss: 0.0966 - val_mse: 0.0966 - val_mae: 0.2499\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2545 - mse: 0.2545 - mae: 0.3075 - val_loss: 0.0964 - val_mse: 0.0964 - val_mae: 0.2500\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 906us/step - loss: 0.2533 - mse: 0.2533 - mae: 0.3061 - val_loss: 0.0962 - val_mse: 0.0962 - val_mae: 0.2499\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.2520 - mse: 0.2520 - mae: 0.3049 - val_loss: 0.0957 - val_mse: 0.0957 - val_mae: 0.2490\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 596us/step - loss: 0.2506 - mse: 0.2506 - mae: 0.3040 - val_loss: 0.0954 - val_mse: 0.0954 - val_mae: 0.2481\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2493 - mse: 0.2493 - mae: 0.3029 - val_loss: 0.0951 - val_mse: 0.0951 - val_mae: 0.2471\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 738us/step - loss: 0.2480 - mse: 0.2480 - mae: 0.3019 - val_loss: 0.0950 - val_mse: 0.0950 - val_mae: 0.2470\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 761us/step - loss: 0.2468 - mse: 0.2468 - mae: 0.3006 - val_loss: 0.0949 - val_mse: 0.0949 - val_mae: 0.2471\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 470us/step - loss: 0.2456 - mse: 0.2456 - mae: 0.2993 - val_loss: 0.0947 - val_mse: 0.0947 - val_mae: 0.2468\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 733us/step - loss: 0.2444 - mse: 0.2444 - mae: 0.2983 - val_loss: 0.0948 - val_mse: 0.0948 - val_mae: 0.2473\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2432 - mse: 0.2432 - mae: 0.2969 - val_loss: 0.0949 - val_mse: 0.0949 - val_mae: 0.2476\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.2420 - mse: 0.2420 - mae: 0.2959 - val_loss: 0.0946 - val_mse: 0.0946 - val_mae: 0.2467\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 589us/step - loss: 0.2408 - mse: 0.2408 - mae: 0.2951 - val_loss: 0.0941 - val_mse: 0.0941 - val_mae: 0.2455\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 683us/step - loss: 0.2396 - mse: 0.2396 - mae: 0.2945 - val_loss: 0.0940 - val_mse: 0.0940 - val_mae: 0.2451\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2386 - mse: 0.2386 - mae: 0.2937 - val_loss: 0.0941 - val_mse: 0.0941 - val_mae: 0.2449\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 754us/step - loss: 0.2375 - mse: 0.2375 - mae: 0.2930 - val_loss: 0.0940 - val_mse: 0.0940 - val_mae: 0.2444\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.2365 - mse: 0.2365 - mae: 0.2924 - val_loss: 0.0936 - val_mse: 0.0936 - val_mae: 0.2431\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 582us/step - loss: 0.2354 - mse: 0.2354 - mae: 0.2919 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2426\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 550us/step - loss: 0.2344 - mse: 0.2344 - mae: 0.2908 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2424\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 603us/step - loss: 0.2334 - mse: 0.2334 - mae: 0.2898 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2425\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 592us/step - loss: 0.2324 - mse: 0.2324 - mae: 0.2890 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.2428\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 701us/step - loss: 0.2315 - mse: 0.2315 - mae: 0.2881 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.2427\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.2307 - mse: 0.2307 - mae: 0.2876 - val_loss: 0.0936 - val_mse: 0.0936 - val_mae: 0.2422\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3195 - mse: 0.3195 - mae: 0.344 - 0s 617us/step - loss: 0.2299 - mse: 0.2299 - mae: 0.2870 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.2416\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 582us/step - loss: 0.2287 - mse: 0.2287 - mae: 0.2862 - val_loss: 0.0931 - val_mse: 0.0931 - val_mae: 0.2406\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 779us/step - loss: 0.2279 - mse: 0.2279 - mae: 0.2858 - val_loss: 0.0931 - val_mse: 0.0931 - val_mae: 0.2404\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 490us/step - loss: 0.2269 - mse: 0.2269 - mae: 0.2851 - val_loss: 0.0934 - val_mse: 0.0934 - val_mae: 0.2407\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 621us/step - loss: 0.2261 - mse: 0.2261 - mae: 0.2842 - val_loss: 0.0934 - val_mse: 0.0934 - val_mae: 0.2405\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 489us/step - loss: 0.2252 - mse: 0.2252 - mae: 0.2836 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2403\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 651us/step - loss: 0.2244 - mse: 0.2244 - mae: 0.2830 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.2403\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 817us/step - loss: 0.2236 - mse: 0.2236 - mae: 0.2820 - val_loss: 0.0936 - val_mse: 0.0936 - val_mae: 0.2406\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 786us/step - loss: 0.2226 - mse: 0.2226 - mae: 0.2811 - val_loss: 0.0934 - val_mse: 0.0934 - val_mae: 0.2396\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 633us/step - loss: 0.2216 - mse: 0.2216 - mae: 0.2806 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2392\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 762us/step - loss: 0.2209 - mse: 0.2209 - mae: 0.2800 - val_loss: 0.0938 - val_mse: 0.0938 - val_mae: 0.2400\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 811us/step - loss: 0.2202 - mse: 0.2202 - mae: 0.2791 - val_loss: 0.0938 - val_mse: 0.0938 - val_mae: 0.2400\n",
      "72\n",
      "[72]\n",
      "Train on 112 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 9.6244 - mse: 9.6244 - mae: 2.5459 - val_loss: 4.5704 - val_mse: 4.5704 - val_mae: 1.9502\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 422us/step - loss: 8.1972 - mse: 8.1972 - mae: 2.2817 - val_loss: 3.8980 - val_mse: 3.8980 - val_mae: 1.7794\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 926us/step - loss: 7.0632 - mse: 7.0632 - mae: 2.0471 - val_loss: 3.3674 - val_mse: 3.3674 - val_mae: 1.6259\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 326us/step - loss: 6.1043 - mse: 6.1043 - mae: 1.8374 - val_loss: 2.8742 - val_mse: 2.8742 - val_mae: 1.4827\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 5.2912 - mse: 5.2912 - mae: 1.6546 - val_loss: 2.4263 - val_mse: 2.4263 - val_mae: 1.3527\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 617us/step - loss: 4.6322 - mse: 4.6322 - mae: 1.5078 - val_loss: 2.0299 - val_mse: 2.0299 - val_mae: 1.2297\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 773us/step - loss: 4.0913 - mse: 4.0913 - mae: 1.3882 - val_loss: 1.6802 - val_mse: 1.6802 - val_mae: 1.1096\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 670us/step - loss: 3.6630 - mse: 3.6630 - mae: 1.2999 - val_loss: 1.3852 - val_mse: 1.3852 - val_mae: 0.9995\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 592us/step - loss: 3.3482 - mse: 3.3482 - mae: 1.2428 - val_loss: 1.1503 - val_mse: 1.1503 - val_mae: 0.9053\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 760us/step - loss: 3.1306 - mse: 3.1306 - mae: 1.2132 - val_loss: 0.9715 - val_mse: 0.9715 - val_mae: 0.8425\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 2.9956 - mse: 2.9956 - mae: 1.2121 - val_loss: 0.8428 - val_mse: 0.8428 - val_mae: 0.7859\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 651us/step - loss: 2.9196 - mse: 2.9196 - mae: 1.2205 - val_loss: 0.7586 - val_mse: 0.7586 - val_mae: 0.7405\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - ETA: 0s - loss: 2.8083 - mse: 2.8083 - mae: 1.188 - 0s 743us/step - loss: 2.8811 - mse: 2.8811 - mae: 1.2318 - val_loss: 0.7095 - val_mse: 0.7095 - val_mae: 0.7087\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 861us/step - loss: 2.8571 - mse: 2.8571 - mae: 1.2389 - val_loss: 0.6836 - val_mse: 0.6836 - val_mae: 0.6895\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 589us/step - loss: 2.8344 - mse: 2.8344 - mae: 1.2401 - val_loss: 0.6720 - val_mse: 0.6720 - val_mae: 0.6807\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 608us/step - loss: 2.8073 - mse: 2.8073 - mae: 1.2369 - val_loss: 0.6702 - val_mse: 0.6702 - val_mae: 0.6800\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 564us/step - loss: 2.7749 - mse: 2.7749 - mae: 1.2295 - val_loss: 0.6760 - val_mse: 0.6760 - val_mae: 0.6856\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 353us/step - loss: 2.7432 - mse: 2.7432 - mae: 1.2204 - val_loss: 0.6871 - val_mse: 0.6871 - val_mae: 0.6952\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 635us/step - loss: 2.7125 - mse: 2.7125 - mae: 1.2097 - val_loss: 0.7087 - val_mse: 0.7087 - val_mae: 0.7104\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 649us/step - loss: 2.6780 - mse: 2.6780 - mae: 1.1962 - val_loss: 0.7387 - val_mse: 0.7387 - val_mae: 0.7296\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 561us/step - loss: 2.6512 - mse: 2.6512 - mae: 1.1836 - val_loss: 0.7703 - val_mse: 0.7703 - val_mae: 0.7493\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 456us/step - loss: 2.6261 - mse: 2.6261 - mae: 1.1726 - val_loss: 0.7972 - val_mse: 0.7972 - val_mae: 0.7650\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 411us/step - loss: 2.6000 - mse: 2.6000 - mae: 1.1623 - val_loss: 0.8098 - val_mse: 0.8098 - val_mae: 0.7718\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 434us/step - loss: 2.5749 - mse: 2.5749 - mae: 1.1542 - val_loss: 0.8111 - val_mse: 0.8111 - val_mae: 0.7722\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 783us/step - loss: 2.5491 - mse: 2.5491 - mae: 1.1496 - val_loss: 0.8026 - val_mse: 0.8026 - val_mae: 0.7672\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 561us/step - loss: 2.5240 - mse: 2.5240 - mae: 1.1469 - val_loss: 0.7882 - val_mse: 0.7882 - val_mae: 0.7600\n",
      "73\n",
      "[73]\n",
      "Train on 81 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 11.6163 - mse: 11.6163 - mae: 3.1127 - val_loss: 6.4785 - val_mse: 6.4785 - val_mae: 2.1246\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 0s 545us/step - loss: 9.6742 - mse: 9.6742 - mae: 2.7996 - val_loss: 5.3682 - val_mse: 5.3682 - val_mae: 1.8382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "81/81 [==============================] - 0s 432us/step - loss: 8.0380 - mse: 8.0380 - mae: 2.5077 - val_loss: 4.5718 - val_mse: 4.5718 - val_mae: 1.5946\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 0s 463us/step - loss: 6.8231 - mse: 6.8231 - mae: 2.2637 - val_loss: 4.0031 - val_mse: 4.0031 - val_mae: 1.4234\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 0s 819us/step - loss: 5.9061 - mse: 5.9061 - mae: 2.0465 - val_loss: 3.5731 - val_mse: 3.5731 - val_mae: 1.2913\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 0s 740us/step - loss: 5.1313 - mse: 5.1313 - mae: 1.8453 - val_loss: 3.1991 - val_mse: 3.1991 - val_mae: 1.1785\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 0s 416us/step - loss: 4.4102 - mse: 4.4102 - mae: 1.6539 - val_loss: 2.8795 - val_mse: 2.8795 - val_mae: 1.0710\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 0s 593us/step - loss: 3.7637 - mse: 3.7637 - mae: 1.4895 - val_loss: 2.6497 - val_mse: 2.6497 - val_mae: 1.0276\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 0s 687us/step - loss: 3.2065 - mse: 3.2065 - mae: 1.3371 - val_loss: 2.4970 - val_mse: 2.4970 - val_mae: 0.9838\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 0s 946us/step - loss: 2.7239 - mse: 2.7239 - mae: 1.2198 - val_loss: 2.4112 - val_mse: 2.4112 - val_mae: 0.9446\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 0s 470us/step - loss: 2.3302 - mse: 2.3302 - mae: 1.1319 - val_loss: 2.3697 - val_mse: 2.3697 - val_mae: 0.9784\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 0s 661us/step - loss: 2.0443 - mse: 2.0443 - mae: 1.0728 - val_loss: 2.4176 - val_mse: 2.4176 - val_mae: 1.0534\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 0s 903us/step - loss: 1.8764 - mse: 1.8764 - mae: 1.0410 - val_loss: 2.5281 - val_mse: 2.5281 - val_mae: 1.1323\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 0s 439us/step - loss: 1.8025 - mse: 1.8025 - mae: 1.0347 - val_loss: 2.6723 - val_mse: 2.6723 - val_mae: 1.2141\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 0s 479us/step - loss: 1.7961 - mse: 1.7961 - mae: 1.0510 - val_loss: 2.8179 - val_mse: 2.8179 - val_mae: 1.2906\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 0s 657us/step - loss: 1.8216 - mse: 1.8216 - mae: 1.0691 - val_loss: 2.9248 - val_mse: 2.9248 - val_mae: 1.3447\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 0s 549us/step - loss: 1.8490 - mse: 1.8490 - mae: 1.0840 - val_loss: 2.9784 - val_mse: 2.9784 - val_mae: 1.3712\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 0s 494us/step - loss: 1.8601 - mse: 1.8601 - mae: 1.0905 - val_loss: 2.9773 - val_mse: 2.9773 - val_mae: 1.3736\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 0s 756us/step - loss: 1.8503 - mse: 1.8503 - mae: 1.0877 - val_loss: 2.9323 - val_mse: 2.9323 - val_mae: 1.3572\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 0s 689us/step - loss: 1.8247 - mse: 1.8247 - mae: 1.0786 - val_loss: 2.8603 - val_mse: 2.8603 - val_mae: 1.3279\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 0s 600us/step - loss: 1.7927 - mse: 1.7927 - mae: 1.0675 - val_loss: 2.7789 - val_mse: 2.7789 - val_mae: 1.2927\n",
      "74\n",
      "[74]\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 2.4009 - mse: 2.4009 - mae: 1.0964 - val_loss: 3.8644 - val_mse: 3.8644 - val_mae: 1.7942\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 2.0823 - mse: 2.0823 - mae: 1.0383 - val_loss: 2.9940 - val_mse: 2.9940 - val_mae: 1.5493\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 490us/step - loss: 1.8932 - mse: 1.8932 - mae: 1.0137 - val_loss: 2.3363 - val_mse: 2.3363 - val_mae: 1.3259\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8114 - mse: 1.8114 - mae: 1.0109 - val_loss: 1.9173 - val_mse: 1.9173 - val_mae: 1.1675\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 721us/step - loss: 1.7924 - mse: 1.7924 - mae: 1.0178 - val_loss: 1.7051 - val_mse: 1.7051 - val_mae: 1.0812\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7826 - mse: 1.7826 - mae: 1.0199 - val_loss: 1.6350 - val_mse: 1.6350 - val_mae: 1.0528\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7589 - mse: 1.7589 - mae: 1.0135 - val_loss: 1.6641 - val_mse: 1.6641 - val_mae: 1.0703\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 972us/step - loss: 1.7257 - mse: 1.7257 - mae: 1.0021 - val_loss: 1.7620 - val_mse: 1.7620 - val_mae: 1.1169\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 706us/step - loss: 1.6905 - mse: 1.6905 - mae: 0.9877 - val_loss: 1.8877 - val_mse: 1.8877 - val_mae: 1.1698\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 745us/step - loss: 1.6625 - mse: 1.6625 - mae: 0.9760 - val_loss: 2.0070 - val_mse: 2.0070 - val_mae: 1.2193\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 609us/step - loss: 1.6440 - mse: 1.6440 - mae: 0.9660 - val_loss: 2.0977 - val_mse: 2.0977 - val_mae: 1.2561\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 885us/step - loss: 1.6286 - mse: 1.6286 - mae: 0.9573 - val_loss: 2.1397 - val_mse: 2.1397 - val_mae: 1.2745\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 769us/step - loss: 1.6124 - mse: 1.6124 - mae: 0.9506 - val_loss: 2.1274 - val_mse: 2.1274 - val_mae: 1.2745\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 681us/step - loss: 1.5931 - mse: 1.5931 - mae: 0.9452 - val_loss: 2.0766 - val_mse: 2.0766 - val_mae: 1.2606\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 850us/step - loss: 1.5722 - mse: 1.5722 - mae: 0.9413 - val_loss: 2.0061 - val_mse: 2.0061 - val_mae: 1.2389\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 684us/step - loss: 1.5509 - mse: 1.5509 - mae: 0.9379 - val_loss: 1.9331 - val_mse: 1.9331 - val_mae: 1.2150\n",
      "75\n",
      "[75]\n",
      "Train on 104 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "104/104 [==============================] - 3s 29ms/step - loss: 6.9361 - mse: 6.9361 - mae: 2.1480 - val_loss: 3.1478 - val_mse: 3.1478 - val_mae: 1.6208\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 0s 570us/step - loss: 5.6083 - mse: 5.6083 - mae: 1.8462 - val_loss: 2.3730 - val_mse: 2.3730 - val_mae: 1.3866\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 0s 658us/step - loss: 4.5473 - mse: 4.5473 - mae: 1.5728 - val_loss: 1.7913 - val_mse: 1.7913 - val_mae: 1.1794\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 0s 558us/step - loss: 3.7866 - mse: 3.7866 - mae: 1.3691 - val_loss: 1.3520 - val_mse: 1.3520 - val_mae: 0.9758\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 0s 398us/step - loss: 3.2911 - mse: 3.2911 - mae: 1.2612 - val_loss: 1.0507 - val_mse: 1.0507 - val_mae: 0.7999\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 0s 462us/step - loss: 3.0338 - mse: 3.0338 - mae: 1.2151 - val_loss: 0.8997 - val_mse: 0.8997 - val_mae: 0.6847\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 0s 794us/step - loss: 2.9471 - mse: 2.9471 - mae: 1.2118 - val_loss: 0.8375 - val_mse: 0.8375 - val_mae: 0.6135\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 0s 760us/step - loss: 2.9444 - mse: 2.9444 - mae: 1.2261 - val_loss: 0.8183 - val_mse: 0.8183 - val_mae: 0.5839\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 0s 454us/step - loss: 2.9363 - mse: 2.9363 - mae: 1.2309 - val_loss: 0.8055 - val_mse: 0.8055 - val_mae: 0.5827\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 0s 397us/step - loss: 2.8870 - mse: 2.8870 - mae: 1.2200 - val_loss: 0.7916 - val_mse: 0.7916 - val_mae: 0.5822\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 0s 825us/step - loss: 2.8126 - mse: 2.8126 - mae: 1.2002 - val_loss: 0.7813 - val_mse: 0.7813 - val_mae: 0.5984\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 0s 478us/step - loss: 2.7438 - mse: 2.7438 - mae: 1.1826 - val_loss: 0.7793 - val_mse: 0.7793 - val_mae: 0.6165\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 0s 586us/step - loss: 2.6855 - mse: 2.6855 - mae: 1.1667 - val_loss: 0.7750 - val_mse: 0.7750 - val_mae: 0.6280\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 0s 696us/step - loss: 2.6397 - mse: 2.6397 - mae: 1.1531 - val_loss: 0.7706 - val_mse: 0.7706 - val_mae: 0.6342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "104/104 [==============================] - 0s 632us/step - loss: 2.6011 - mse: 2.6011 - mae: 1.1416 - val_loss: 0.7575 - val_mse: 0.7575 - val_mae: 0.6334\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 0s 914us/step - loss: 2.5619 - mse: 2.5619 - mae: 1.1312 - val_loss: 0.7436 - val_mse: 0.7436 - val_mae: 0.6273\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 0s 865us/step - loss: 2.5249 - mse: 2.5249 - mae: 1.1227 - val_loss: 0.7303 - val_mse: 0.7303 - val_mae: 0.6180\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 0s 369us/step - loss: 2.4899 - mse: 2.4899 - mae: 1.1158 - val_loss: 0.7178 - val_mse: 0.7178 - val_mae: 0.6070\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 0s 486us/step - loss: 2.4572 - mse: 2.4572 - mae: 1.1096 - val_loss: 0.7059 - val_mse: 0.7059 - val_mae: 0.6010\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 0s 368us/step - loss: 2.4261 - mse: 2.4261 - mae: 1.1038 - val_loss: 0.6942 - val_mse: 0.6942 - val_mae: 0.5988\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 0s 494us/step - loss: 2.3956 - mse: 2.3956 - mae: 1.0986 - val_loss: 0.6825 - val_mse: 0.6825 - val_mae: 0.5967\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 0s 597us/step - loss: 2.3658 - mse: 2.3658 - mae: 1.0929 - val_loss: 0.6714 - val_mse: 0.6714 - val_mae: 0.5948\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 0s 521us/step - loss: 2.3369 - mse: 2.3369 - mae: 1.0869 - val_loss: 0.6614 - val_mse: 0.6614 - val_mae: 0.5927\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 0s 492us/step - loss: 2.3114 - mse: 2.3114 - mae: 1.0815 - val_loss: 0.6526 - val_mse: 0.6526 - val_mae: 0.5909\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 0s 529us/step - loss: 2.2878 - mse: 2.2878 - mae: 1.0769 - val_loss: 0.6447 - val_mse: 0.6447 - val_mae: 0.5892\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 0s 510us/step - loss: 2.2657 - mse: 2.2657 - mae: 1.0729 - val_loss: 0.6384 - val_mse: 0.6384 - val_mae: 0.5884\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 0s 667us/step - loss: 2.2454 - mse: 2.2454 - mae: 1.0693 - val_loss: 0.6332 - val_mse: 0.6332 - val_mae: 0.5877\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 0s 512us/step - loss: 2.2265 - mse: 2.2265 - mae: 1.0653 - val_loss: 0.6280 - val_mse: 0.6280 - val_mae: 0.5871\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 0s 441us/step - loss: 2.2076 - mse: 2.2076 - mae: 1.0604 - val_loss: 0.6231 - val_mse: 0.6231 - val_mae: 0.5864\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 0s 706us/step - loss: 2.1899 - mse: 2.1899 - mae: 1.0552 - val_loss: 0.6187 - val_mse: 0.6187 - val_mae: 0.5854\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 0s 703us/step - loss: 2.1740 - mse: 2.1740 - mae: 1.0506 - val_loss: 0.6150 - val_mse: 0.6150 - val_mae: 0.5844\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 0s 480us/step - loss: 2.1591 - mse: 2.1591 - mae: 1.0465 - val_loss: 0.6118 - val_mse: 0.6118 - val_mae: 0.5834\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 0s 651us/step - loss: 2.1453 - mse: 2.1453 - mae: 1.0431 - val_loss: 0.6090 - val_mse: 0.6090 - val_mae: 0.5825\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 0s 494us/step - loss: 2.1322 - mse: 2.1322 - mae: 1.0404 - val_loss: 0.6061 - val_mse: 0.6061 - val_mae: 0.5816\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 0s 574us/step - loss: 2.1181 - mse: 2.1181 - mae: 1.0372 - val_loss: 0.6031 - val_mse: 0.6031 - val_mae: 0.5811\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 0s 468us/step - loss: 2.1036 - mse: 2.1036 - mae: 1.0332 - val_loss: 0.6005 - val_mse: 0.6005 - val_mae: 0.5806\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 0s 980us/step - loss: 2.0899 - mse: 2.0899 - mae: 1.0295 - val_loss: 0.5981 - val_mse: 0.5981 - val_mae: 0.5799\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 0s 548us/step - loss: 2.0769 - mse: 2.0769 - mae: 1.0263 - val_loss: 0.5959 - val_mse: 0.5959 - val_mae: 0.5792\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 2.0652 - mse: 2.0652 - mae: 1.0237 - val_loss: 0.5937 - val_mse: 0.5937 - val_mae: 0.5783\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 0s 704us/step - loss: 2.0551 - mse: 2.0551 - mae: 1.0221 - val_loss: 0.5911 - val_mse: 0.5911 - val_mae: 0.5773\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 0s 596us/step - loss: 2.0438 - mse: 2.0438 - mae: 1.0199 - val_loss: 0.5880 - val_mse: 0.5880 - val_mae: 0.5762\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 0s 516us/step - loss: 2.0315 - mse: 2.0315 - mae: 1.0164 - val_loss: 0.5853 - val_mse: 0.5853 - val_mae: 0.5752\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 0s 477us/step - loss: 2.0199 - mse: 2.0199 - mae: 1.0131 - val_loss: 0.5830 - val_mse: 0.5830 - val_mae: 0.5742\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 0s 455us/step - loss: 2.0084 - mse: 2.0084 - mae: 1.0103 - val_loss: 0.5808 - val_mse: 0.5808 - val_mae: 0.5731\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 0s 326us/step - loss: 1.9986 - mse: 1.9986 - mae: 1.0082 - val_loss: 0.5786 - val_mse: 0.5786 - val_mae: 0.5722\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 0s 634us/step - loss: 1.9865 - mse: 1.9865 - mae: 1.0050 - val_loss: 0.5755 - val_mse: 0.5755 - val_mae: 0.5695\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 0s 643us/step - loss: 1.9749 - mse: 1.9749 - mae: 1.0011 - val_loss: 0.5725 - val_mse: 0.5725 - val_mae: 0.5672\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 0s 513us/step - loss: 1.9641 - mse: 1.9641 - mae: 0.9981 - val_loss: 0.5703 - val_mse: 0.5703 - val_mae: 0.5657\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 0s 452us/step - loss: 1.9537 - mse: 1.9537 - mae: 0.9959 - val_loss: 0.5691 - val_mse: 0.5691 - val_mae: 0.5648\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 0s 804us/step - loss: 1.9449 - mse: 1.9449 - mae: 0.9942 - val_loss: 0.5670 - val_mse: 0.5670 - val_mae: 0.5632\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 0s 371us/step - loss: 1.9344 - mse: 1.9344 - mae: 0.9919 - val_loss: 0.5638 - val_mse: 0.5638 - val_mae: 0.5604\n",
      "Epoch 52/100\n",
      "104/104 [==============================] - 0s 687us/step - loss: 1.9226 - mse: 1.9226 - mae: 0.9882 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.5578\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 0s 876us/step - loss: 1.9112 - mse: 1.9112 - mae: 0.9848 - val_loss: 0.5593 - val_mse: 0.5593 - val_mae: 0.5569\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 0s 988us/step - loss: 1.9022 - mse: 1.9022 - mae: 0.9829 - val_loss: 0.5583 - val_mse: 0.5583 - val_mae: 0.5561\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 0s 417us/step - loss: 1.8922 - mse: 1.8922 - mae: 0.9806 - val_loss: 0.5561 - val_mse: 0.5561 - val_mae: 0.5543\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 0s 413us/step - loss: 1.8818 - mse: 1.8818 - mae: 0.9777 - val_loss: 0.5547 - val_mse: 0.5547 - val_mae: 0.5531\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 0s 943us/step - loss: 1.8720 - mse: 1.8720 - mae: 0.9747 - val_loss: 0.5545 - val_mse: 0.5545 - val_mae: 0.5532\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 0s 696us/step - loss: 1.8628 - mse: 1.8628 - mae: 0.9723 - val_loss: 0.5539 - val_mse: 0.5539 - val_mae: 0.5530\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 0s 878us/step - loss: 1.8539 - mse: 1.8539 - mae: 0.9703 - val_loss: 0.5528 - val_mse: 0.5528 - val_mae: 0.5523\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 0s 845us/step - loss: 1.8451 - mse: 1.8451 - mae: 0.9681 - val_loss: 0.5513 - val_mse: 0.5513 - val_mae: 0.5511\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.8349 - mse: 1.8349 - mae: 0.9651 - val_loss: 0.5510 - val_mse: 0.5510 - val_mae: 0.5506\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 0s 682us/step - loss: 1.8264 - mse: 1.8264 - mae: 0.9628 - val_loss: 0.5505 - val_mse: 0.5505 - val_mae: 0.5502\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.8174 - mse: 1.8174 - mae: 0.9604 - val_loss: 0.5496 - val_mse: 0.5496 - val_mae: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "104/104 [==============================] - 0s 346us/step - loss: 1.8082 - mse: 1.8082 - mae: 0.9580 - val_loss: 0.5485 - val_mse: 0.5485 - val_mae: 0.5496\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 0s 372us/step - loss: 1.7992 - mse: 1.7992 - mae: 0.9556 - val_loss: 0.5474 - val_mse: 0.5474 - val_mae: 0.5491\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 0s 352us/step - loss: 1.7909 - mse: 1.7909 - mae: 0.9532 - val_loss: 0.5463 - val_mse: 0.5463 - val_mae: 0.5486\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 0s 935us/step - loss: 1.7826 - mse: 1.7826 - mae: 0.9507 - val_loss: 0.5459 - val_mse: 0.5459 - val_mae: 0.5487\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 0s 858us/step - loss: 1.7738 - mse: 1.7738 - mae: 0.9476 - val_loss: 0.5475 - val_mse: 0.5475 - val_mae: 0.5502\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 0s 370us/step - loss: 1.7664 - mse: 1.7664 - mae: 0.9461 - val_loss: 0.5485 - val_mse: 0.5485 - val_mae: 0.5514\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 0s 592us/step - loss: 1.7585 - mse: 1.7585 - mae: 0.9443 - val_loss: 0.5468 - val_mse: 0.5468 - val_mae: 0.5504\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 0s 386us/step - loss: 1.7490 - mse: 1.7490 - mae: 0.9412 - val_loss: 0.5448 - val_mse: 0.5448 - val_mae: 0.5489\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 0s 924us/step - loss: 1.7394 - mse: 1.7394 - mae: 0.9379 - val_loss: 0.5438 - val_mse: 0.5438 - val_mae: 0.5480\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 0s 529us/step - loss: 1.7311 - mse: 1.7311 - mae: 0.9349 - val_loss: 0.5445 - val_mse: 0.5445 - val_mae: 0.5483\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 0s 407us/step - loss: 1.7222 - mse: 1.7222 - mae: 0.9325 - val_loss: 0.5448 - val_mse: 0.5448 - val_mae: 0.5488\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 0s 748us/step - loss: 1.7139 - mse: 1.7139 - mae: 0.9302 - val_loss: 0.5447 - val_mse: 0.5447 - val_mae: 0.5486\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.7051 - mse: 1.7051 - mae: 0.9273 - val_loss: 0.5448 - val_mse: 0.5448 - val_mae: 0.5483\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 0s 663us/step - loss: 1.6961 - mse: 1.6961 - mae: 0.9244 - val_loss: 0.5453 - val_mse: 0.5453 - val_mae: 0.5483\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 0s 814us/step - loss: 1.6871 - mse: 1.6871 - mae: 0.9216 - val_loss: 0.5457 - val_mse: 0.5457 - val_mae: 0.5479\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 0s 882us/step - loss: 1.6781 - mse: 1.6781 - mae: 0.9188 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5476\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 0s 722us/step - loss: 1.6689 - mse: 1.6689 - mae: 0.9161 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5477\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.6611 - mse: 1.6611 - mae: 0.9140 - val_loss: 0.5461 - val_mse: 0.5461 - val_mae: 0.5483\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 0s 392us/step - loss: 1.6529 - mse: 1.6529 - mae: 0.9120 - val_loss: 0.5469 - val_mse: 0.5469 - val_mae: 0.5487\n",
      "76\n",
      "[76]\n",
      "Train on 115 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 10.8241 - mse: 10.8241 - mae: 2.7921 - val_loss: 13.8070 - val_mse: 13.8070 - val_mae: 3.2523\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 0s 375us/step - loss: 6.6854 - mse: 6.6854 - mae: 2.0725 - val_loss: 7.4505 - val_mse: 7.4505 - val_mae: 2.2172\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 0s 371us/step - loss: 4.2201 - mse: 4.2201 - mae: 1.5893 - val_loss: 3.9106 - val_mse: 3.9106 - val_mae: 1.5939\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 0s 638us/step - loss: 3.3579 - mse: 3.3579 - mae: 1.5023 - val_loss: 2.6699 - val_mse: 2.6699 - val_mae: 1.3299\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 0s 336us/step - loss: 3.3954 - mse: 3.3954 - mae: 1.5124 - val_loss: 2.4676 - val_mse: 2.4676 - val_mae: 1.2497\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 0s 385us/step - loss: 3.4530 - mse: 3.4530 - mae: 1.5187 - val_loss: 2.3525 - val_mse: 2.3525 - val_mae: 1.2082\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 0s 447us/step - loss: 3.2111 - mse: 3.2111 - mae: 1.4566 - val_loss: 2.2001 - val_mse: 2.2001 - val_mae: 1.1836\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 0s 455us/step - loss: 2.8605 - mse: 2.8605 - mae: 1.3607 - val_loss: 2.1866 - val_mse: 2.1866 - val_mae: 1.2128\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 0s 394us/step - loss: 2.6108 - mse: 2.6108 - mae: 1.2849 - val_loss: 2.3143 - val_mse: 2.3143 - val_mae: 1.2511\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 0s 408us/step - loss: 2.4914 - mse: 2.4914 - mae: 1.2327 - val_loss: 2.4203 - val_mse: 2.4203 - val_mae: 1.2965\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 0s 627us/step - loss: 2.4204 - mse: 2.4204 - mae: 1.2001 - val_loss: 2.3776 - val_mse: 2.3776 - val_mae: 1.2886\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 0s 404us/step - loss: 2.3373 - mse: 2.3373 - mae: 1.1776 - val_loss: 2.2048 - val_mse: 2.2048 - val_mae: 1.2384\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 0s 430us/step - loss: 2.2431 - mse: 2.2431 - mae: 1.1581 - val_loss: 1.9944 - val_mse: 1.9944 - val_mae: 1.1773\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 0s 533us/step - loss: 2.1640 - mse: 2.1640 - mae: 1.1455 - val_loss: 1.8275 - val_mse: 1.8275 - val_mae: 1.1252\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 0s 655us/step - loss: 2.1066 - mse: 2.1066 - mae: 1.1363 - val_loss: 1.7269 - val_mse: 1.7269 - val_mae: 1.0901\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 0s 518us/step - loss: 2.0580 - mse: 2.0580 - mae: 1.1216 - val_loss: 1.6781 - val_mse: 1.6781 - val_mae: 1.0724\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 0s 621us/step - loss: 2.0090 - mse: 2.0090 - mae: 1.1022 - val_loss: 1.6639 - val_mse: 1.6639 - val_mae: 1.0691\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 0s 659us/step - loss: 1.9624 - mse: 1.9624 - mae: 1.0824 - val_loss: 1.6686 - val_mse: 1.6686 - val_mae: 1.0756\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 0s 471us/step - loss: 1.9243 - mse: 1.9243 - mae: 1.0648 - val_loss: 1.6706 - val_mse: 1.6706 - val_mae: 1.0804\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 0s 629us/step - loss: 1.8942 - mse: 1.8942 - mae: 1.0501 - val_loss: 1.6566 - val_mse: 1.6566 - val_mae: 1.0796\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 0s 427us/step - loss: 1.8680 - mse: 1.8680 - mae: 1.0385 - val_loss: 1.6256 - val_mse: 1.6256 - val_mae: 1.0713\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 0s 373us/step - loss: 1.8447 - mse: 1.8447 - mae: 1.0294 - val_loss: 1.5903 - val_mse: 1.5903 - val_mae: 1.0596\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 0s 481us/step - loss: 1.8238 - mse: 1.8238 - mae: 1.0221 - val_loss: 1.5623 - val_mse: 1.5623 - val_mae: 1.0500\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 0s 602us/step - loss: 1.8063 - mse: 1.8063 - mae: 1.0147 - val_loss: 1.5463 - val_mse: 1.5463 - val_mae: 1.0454\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 0s 617us/step - loss: 1.7908 - mse: 1.7908 - mae: 1.0064 - val_loss: 1.5424 - val_mse: 1.5424 - val_mae: 1.0468\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 0s 645us/step - loss: 1.7767 - mse: 1.7767 - mae: 0.9977 - val_loss: 1.5446 - val_mse: 1.5446 - val_mae: 1.0528\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 0s 498us/step - loss: 1.7637 - mse: 1.7637 - mae: 0.9893 - val_loss: 1.5453 - val_mse: 1.5453 - val_mae: 1.0573\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 0s 543us/step - loss: 1.7519 - mse: 1.7519 - mae: 0.9823 - val_loss: 1.5412 - val_mse: 1.5412 - val_mae: 1.0586\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 0s 457us/step - loss: 1.7410 - mse: 1.7410 - mae: 0.9765 - val_loss: 1.5339 - val_mse: 1.5339 - val_mae: 1.0577\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 0s 531us/step - loss: 1.7307 - mse: 1.7307 - mae: 0.9719 - val_loss: 1.5277 - val_mse: 1.5277 - val_mae: 1.0569\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 0s 489us/step - loss: 1.7208 - mse: 1.7208 - mae: 0.9675 - val_loss: 1.5244 - val_mse: 1.5244 - val_mae: 1.0576\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 0s 654us/step - loss: 1.7118 - mse: 1.7118 - mae: 0.9634 - val_loss: 1.5239 - val_mse: 1.5239 - val_mae: 1.0596\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 0s 677us/step - loss: 1.7034 - mse: 1.7034 - mae: 0.9593 - val_loss: 1.5246 - val_mse: 1.5246 - val_mae: 1.0622\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 0s 476us/step - loss: 1.6957 - mse: 1.6957 - mae: 0.9557 - val_loss: 1.5261 - val_mse: 1.5261 - val_mae: 1.0650\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 0s 415us/step - loss: 1.6885 - mse: 1.6885 - mae: 0.9522 - val_loss: 1.5274 - val_mse: 1.5274 - val_mae: 1.0672\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 0s 382us/step - loss: 1.6819 - mse: 1.6819 - mae: 0.9491 - val_loss: 1.5279 - val_mse: 1.5279 - val_mae: 1.0684\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 0s 538us/step - loss: 1.6756 - mse: 1.6756 - mae: 0.9469 - val_loss: 1.5253 - val_mse: 1.5253 - val_mae: 1.0676\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - 0s 392us/step - loss: 1.6695 - mse: 1.6695 - mae: 0.9448 - val_loss: 1.5245 - val_mse: 1.5245 - val_mae: 1.0678\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 0s 485us/step - loss: 1.6635 - mse: 1.6635 - mae: 0.9424 - val_loss: 1.5257 - val_mse: 1.5257 - val_mae: 1.0690\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - 0s 406us/step - loss: 1.6577 - mse: 1.6577 - mae: 0.9399 - val_loss: 1.5262 - val_mse: 1.5262 - val_mae: 1.0698\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - 0s 363us/step - loss: 1.6524 - mse: 1.6524 - mae: 0.9382 - val_loss: 1.5249 - val_mse: 1.5249 - val_mae: 1.0693\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - 0s 443us/step - loss: 1.6471 - mse: 1.6471 - mae: 0.9362 - val_loss: 1.5267 - val_mse: 1.5267 - val_mae: 1.0705\n",
      "77\n",
      "[77]\n",
      "Train on 98 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 3.0880 - mse: 3.0880 - mae: 1.4104 - val_loss: 7.2996 - val_mse: 7.2996 - val_mae: 2.3031\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 405us/step - loss: 2.4508 - mse: 2.4508 - mae: 1.1962 - val_loss: 5.6851 - val_mse: 5.6851 - val_mae: 2.0356\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.9432 - mse: 1.9432 - mae: 1.0115 - val_loss: 4.3492 - val_mse: 4.3492 - val_mae: 1.7961\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.5739 - mse: 1.5739 - mae: 0.8953 - val_loss: 3.3087 - val_mse: 3.3087 - val_mae: 1.5764\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 509us/step - loss: 1.3403 - mse: 1.3403 - mae: 0.8326 - val_loss: 2.5789 - val_mse: 2.5789 - val_mae: 1.4039\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1.2307 - mse: 1.2307 - mae: 0.8147 - val_loss: 2.1261 - val_mse: 2.1261 - val_mae: 1.2600\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.2120 - mse: 1.2120 - mae: 0.8146 - val_loss: 1.8820 - val_mse: 1.8820 - val_mae: 1.1577\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 542us/step - loss: 1.2354 - mse: 1.2354 - mae: 0.8391 - val_loss: 1.7685 - val_mse: 1.7685 - val_mae: 1.1303\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 937us/step - loss: 1.2576 - mse: 1.2576 - mae: 0.8571 - val_loss: 1.7171 - val_mse: 1.7171 - val_mae: 1.1135\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.2551 - mse: 1.2551 - mae: 0.8616 - val_loss: 1.6940 - val_mse: 1.6940 - val_mae: 1.1036\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 749us/step - loss: 1.2301 - mse: 1.2301 - mae: 0.8522 - val_loss: 1.6901 - val_mse: 1.6901 - val_mae: 1.0983\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 646us/step - loss: 1.1947 - mse: 1.1947 - mae: 0.8347 - val_loss: 1.7031 - val_mse: 1.7031 - val_mae: 1.0985\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 793us/step - loss: 1.1609 - mse: 1.1609 - mae: 0.8163 - val_loss: 1.7296 - val_mse: 1.7296 - val_mae: 1.1089\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 921us/step - loss: 1.1334 - mse: 1.1334 - mae: 0.8023 - val_loss: 1.7564 - val_mse: 1.7564 - val_mae: 1.1236\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 391us/step - loss: 1.1133 - mse: 1.1133 - mae: 0.7924 - val_loss: 1.7702 - val_mse: 1.7702 - val_mae: 1.1312\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0988 - mse: 1.0988 - mae: 0.7851 - val_loss: 1.7698 - val_mse: 1.7698 - val_mae: 1.1321\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0867 - mse: 1.0867 - mae: 0.7796 - val_loss: 1.7563 - val_mse: 1.7563 - val_mae: 1.1270\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 740us/step - loss: 1.0757 - mse: 1.0757 - mae: 0.7758 - val_loss: 1.7305 - val_mse: 1.7305 - val_mae: 1.1169\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 644us/step - loss: 1.0662 - mse: 1.0662 - mae: 0.7733 - val_loss: 1.6973 - val_mse: 1.6973 - val_mae: 1.1038\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 636us/step - loss: 1.0576 - mse: 1.0576 - mae: 0.7719 - val_loss: 1.6652 - val_mse: 1.6652 - val_mae: 1.0903\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 455us/step - loss: 1.0493 - mse: 1.0493 - mae: 0.7706 - val_loss: 1.6368 - val_mse: 1.6368 - val_mae: 1.0772\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 572us/step - loss: 1.0418 - mse: 1.0418 - mae: 0.7687 - val_loss: 1.6144 - val_mse: 1.6144 - val_mae: 1.0656\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0334 - mse: 1.0334 - mae: 0.7661 - val_loss: 1.6003 - val_mse: 1.6003 - val_mae: 1.0580\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 375us/step - loss: 1.0231 - mse: 1.0231 - mae: 0.7619 - val_loss: 1.5972 - val_mse: 1.5972 - val_mae: 1.0552\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 638us/step - loss: 1.0111 - mse: 1.0111 - mae: 0.7557 - val_loss: 1.5995 - val_mse: 1.5995 - val_mae: 1.0542\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 487us/step - loss: 0.9963 - mse: 0.9963 - mae: 0.7478 - val_loss: 1.5987 - val_mse: 1.5987 - val_mae: 1.0513\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.3815 - mse: 0.3815 - mae: 0.521 - 0s 483us/step - loss: 0.9794 - mse: 0.9794 - mae: 0.7407 - val_loss: 1.5958 - val_mse: 1.5958 - val_mae: 1.0494\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9637 - mse: 0.9637 - mae: 0.7339 - val_loss: 1.5903 - val_mse: 1.5903 - val_mae: 1.0478\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 543us/step - loss: 0.9519 - mse: 0.9519 - mae: 0.7289 - val_loss: 1.5773 - val_mse: 1.5773 - val_mae: 1.0445\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 424us/step - loss: 0.9425 - mse: 0.9425 - mae: 0.7249 - val_loss: 1.5515 - val_mse: 1.5515 - val_mae: 1.0347\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 464us/step - loss: 0.9346 - mse: 0.9346 - mae: 0.7225 - val_loss: 1.5244 - val_mse: 1.5244 - val_mae: 1.0231\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 534us/step - loss: 0.9280 - mse: 0.9280 - mae: 0.7205 - val_loss: 1.5059 - val_mse: 1.5059 - val_mae: 1.0152\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 496us/step - loss: 0.9220 - mse: 0.9220 - mae: 0.7189 - val_loss: 1.4927 - val_mse: 1.4927 - val_mae: 1.0095\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 632us/step - loss: 0.9163 - mse: 0.9163 - mae: 0.7176 - val_loss: 1.4839 - val_mse: 1.4839 - val_mae: 1.0060\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 507us/step - loss: 0.9100 - mse: 0.9100 - mae: 0.7157 - val_loss: 1.4783 - val_mse: 1.4783 - val_mae: 1.0037\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 563us/step - loss: 0.9040 - mse: 0.9040 - mae: 0.7136 - val_loss: 1.4701 - val_mse: 1.4701 - val_mae: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 704us/step - loss: 0.8983 - mse: 0.8983 - mae: 0.7118 - val_loss: 1.4600 - val_mse: 1.4600 - val_mae: 0.9949\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 471us/step - loss: 0.8930 - mse: 0.8930 - mae: 0.7102 - val_loss: 1.4530 - val_mse: 1.4530 - val_mae: 0.9913\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 762us/step - loss: 0.8873 - mse: 0.8873 - mae: 0.7080 - val_loss: 1.4494 - val_mse: 1.4494 - val_mae: 0.9889\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 518us/step - loss: 0.8815 - mse: 0.8815 - mae: 0.7056 - val_loss: 1.4472 - val_mse: 1.4472 - val_mae: 0.9869\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 622us/step - loss: 0.8757 - mse: 0.8757 - mae: 0.7030 - val_loss: 1.4441 - val_mse: 1.4441 - val_mae: 0.9847\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 576us/step - loss: 0.8703 - mse: 0.8703 - mae: 0.7009 - val_loss: 1.4407 - val_mse: 1.4407 - val_mae: 0.9833\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 510us/step - loss: 0.8646 - mse: 0.8646 - mae: 0.6986 - val_loss: 1.4372 - val_mse: 1.4372 - val_mae: 0.9808\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 838us/step - loss: 0.8601 - mse: 0.8601 - mae: 0.6969 - val_loss: 1.4336 - val_mse: 1.4336 - val_mae: 0.9776\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 451us/step - loss: 0.8548 - mse: 0.8548 - mae: 0.6948 - val_loss: 1.4273 - val_mse: 1.4273 - val_mae: 0.9737\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 650us/step - loss: 0.8504 - mse: 0.8504 - mae: 0.6934 - val_loss: 1.4204 - val_mse: 1.4204 - val_mae: 0.9695\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 606us/step - loss: 0.8462 - mse: 0.8462 - mae: 0.6921 - val_loss: 1.4182 - val_mse: 1.4182 - val_mae: 0.9675\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 566us/step - loss: 0.8415 - mse: 0.8415 - mae: 0.6901 - val_loss: 1.4160 - val_mse: 1.4160 - val_mae: 0.9659\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 489us/step - loss: 0.8375 - mse: 0.8375 - mae: 0.6883 - val_loss: 1.4129 - val_mse: 1.4129 - val_mae: 0.9657\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 585us/step - loss: 0.8330 - mse: 0.8330 - mae: 0.6863 - val_loss: 1.4141 - val_mse: 1.4141 - val_mae: 0.9681\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 504us/step - loss: 0.8282 - mse: 0.8282 - mae: 0.6840 - val_loss: 1.4110 - val_mse: 1.4110 - val_mae: 0.9684\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 624us/step - loss: 0.8242 - mse: 0.8242 - mae: 0.6826 - val_loss: 1.4034 - val_mse: 1.4034 - val_mae: 0.9668\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 594us/step - loss: 0.8210 - mse: 0.8210 - mae: 0.6819 - val_loss: 1.4019 - val_mse: 1.4019 - val_mae: 0.9677\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 892us/step - loss: 0.8162 - mse: 0.8162 - mae: 0.6797 - val_loss: 1.4040 - val_mse: 1.4040 - val_mae: 0.9699\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 473us/step - loss: 0.8122 - mse: 0.8122 - mae: 0.6778 - val_loss: 1.4006 - val_mse: 1.4006 - val_mae: 0.9694\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 617us/step - loss: 0.8090 - mse: 0.8090 - mae: 0.6767 - val_loss: 1.3958 - val_mse: 1.3958 - val_mae: 0.9684\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 497us/step - loss: 0.8051 - mse: 0.8051 - mae: 0.6754 - val_loss: 1.3949 - val_mse: 1.3949 - val_mae: 0.9693\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 450us/step - loss: 0.8011 - mse: 0.8011 - mae: 0.6740 - val_loss: 1.3973 - val_mse: 1.3973 - val_mae: 0.9718\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 500us/step - loss: 0.7969 - mse: 0.7969 - mae: 0.6721 - val_loss: 1.3971 - val_mse: 1.3971 - val_mae: 0.9730\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 545us/step - loss: 0.7938 - mse: 0.7938 - mae: 0.6712 - val_loss: 1.3981 - val_mse: 1.3981 - val_mae: 0.9746\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 423us/step - loss: 0.7889 - mse: 0.7889 - mae: 0.6692 - val_loss: 1.4045 - val_mse: 1.4045 - val_mae: 0.9784\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 557us/step - loss: 0.7848 - mse: 0.7848 - mae: 0.6669 - val_loss: 1.4042 - val_mse: 1.4042 - val_mae: 0.9788\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 489us/step - loss: 0.7815 - mse: 0.7815 - mae: 0.6656 - val_loss: 1.3968 - val_mse: 1.3968 - val_mae: 0.9759\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 686us/step - loss: 0.7791 - mse: 0.7791 - mae: 0.6654 - val_loss: 1.3951 - val_mse: 1.3951 - val_mae: 0.9751\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 457us/step - loss: 0.7756 - mse: 0.7756 - mae: 0.6642 - val_loss: 1.4001 - val_mse: 1.4001 - val_mae: 0.9773\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 624us/step - loss: 0.7724 - mse: 0.7724 - mae: 0.6627 - val_loss: 1.4024 - val_mse: 1.4024 - val_mae: 0.9786\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 614us/step - loss: 0.7690 - mse: 0.7690 - mae: 0.6612 - val_loss: 1.4007 - val_mse: 1.4007 - val_mae: 0.9785\n",
      "78\n",
      "[78]\n",
      "Train on 91 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 3s 31ms/step - loss: 4.5484 - mse: 4.5484 - mae: 1.6220 - val_loss: 1.3516 - val_mse: 1.3516 - val_mae: 1.0387\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 661us/step - loss: 4.0924 - mse: 4.0924 - mae: 1.4849 - val_loss: 1.0799 - val_mse: 1.0799 - val_mae: 0.9004\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 615us/step - loss: 3.6548 - mse: 3.6548 - mae: 1.3570 - val_loss: 0.8311 - val_mse: 0.8311 - val_mae: 0.7535\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 626us/step - loss: 3.2430 - mse: 3.2430 - mae: 1.2341 - val_loss: 0.6186 - val_mse: 0.6186 - val_mae: 0.6157\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 598us/step - loss: 2.8673 - mse: 2.8673 - mae: 1.1253 - val_loss: 0.4531 - val_mse: 0.4531 - val_mae: 0.5067\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 512us/step - loss: 2.5565 - mse: 2.5565 - mae: 1.0507 - val_loss: 0.3415 - val_mse: 0.3415 - val_mae: 0.4162\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 2.3215 - mse: 2.3215 - mae: 1.0149 - val_loss: 0.2844 - val_mse: 0.2844 - val_mae: 0.3743\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 2.1650 - mse: 2.1650 - mae: 0.9995 - val_loss: 0.2734 - val_mse: 0.2734 - val_mae: 0.3704\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 2.0775 - mse: 2.0775 - mae: 1.0042 - val_loss: 0.2929 - val_mse: 0.2929 - val_mae: 0.3807\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 410us/step - loss: 2.0390 - mse: 2.0390 - mae: 1.0169 - val_loss: 0.3225 - val_mse: 0.3225 - val_mae: 0.4113\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 594us/step - loss: 2.0226 - mse: 2.0226 - mae: 1.0312 - val_loss: 0.3445 - val_mse: 0.3445 - val_mae: 0.4362\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 584us/step - loss: 2.0081 - mse: 2.0081 - mae: 1.0378 - val_loss: 0.3511 - val_mse: 0.3511 - val_mae: 0.4449\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 970us/step - loss: 1.9863 - mse: 1.9863 - mae: 1.0356 - val_loss: 0.3433 - val_mse: 0.3433 - val_mae: 0.4413\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 422us/step - loss: 1.9589 - mse: 1.9589 - mae: 1.0272 - val_loss: 0.3282 - val_mse: 0.3282 - val_mae: 0.4306\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 491us/step - loss: 1.9314 - mse: 1.9314 - mae: 1.0157 - val_loss: 0.3119 - val_mse: 0.3119 - val_mae: 0.4172\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 625us/step - loss: 1.9075 - mse: 1.9075 - mae: 1.0037 - val_loss: 0.2981 - val_mse: 0.2981 - val_mae: 0.4044\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8876 - mse: 1.8876 - mae: 0.9928 - val_loss: 0.2883 - val_mse: 0.2883 - val_mae: 0.3947\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 829us/step - loss: 1.8706 - mse: 1.8706 - mae: 0.9845 - val_loss: 0.2821 - val_mse: 0.2821 - val_mae: 0.3889\n",
      "79\n",
      "[79]\n",
      "Train on 97 samples, validate on 25 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 3s 28ms/step - loss: 10.6341 - mse: 10.6341 - mae: 3.0852 - val_loss: 7.7563 - val_mse: 7.7563 - val_mae: 2.5676\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 8.6269 - mse: 8.6269 - mae: 2.7555 - val_loss: 6.4061 - val_mse: 6.4061 - val_mae: 2.2932\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 739us/step - loss: 7.0183 - mse: 7.0183 - mae: 2.4596 - val_loss: 5.3003 - val_mse: 5.3003 - val_mae: 2.0423\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 642us/step - loss: 5.7254 - mse: 5.7254 - mae: 2.1941 - val_loss: 4.4457 - val_mse: 4.4457 - val_mae: 1.8327\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 717us/step - loss: 4.7120 - mse: 4.7120 - mae: 1.9642 - val_loss: 3.7928 - val_mse: 3.7928 - val_mae: 1.6605\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 560us/step - loss: 3.9469 - mse: 3.9469 - mae: 1.7733 - val_loss: 3.3172 - val_mse: 3.3172 - val_mae: 1.5297\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 551us/step - loss: 3.4316 - mse: 3.4316 - mae: 1.6294 - val_loss: 2.9535 - val_mse: 2.9535 - val_mae: 1.4162\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 856us/step - loss: 3.0969 - mse: 3.0969 - mae: 1.5252 - val_loss: 2.6443 - val_mse: 2.6443 - val_mae: 1.3175\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 874us/step - loss: 2.8446 - mse: 2.8446 - mae: 1.4415 - val_loss: 2.4096 - val_mse: 2.4096 - val_mae: 1.2348\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 2.6238 - mse: 2.6238 - mae: 1.3652 - val_loss: 2.2075 - val_mse: 2.2075 - val_mae: 1.1551\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 497us/step - loss: 2.4076 - mse: 2.4076 - mae: 1.2853 - val_loss: 2.0189 - val_mse: 2.0189 - val_mae: 1.0737\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 560us/step - loss: 2.1847 - mse: 2.1847 - mae: 1.2034 - val_loss: 1.8332 - val_mse: 1.8332 - val_mae: 0.9841\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 769us/step - loss: 1.9501 - mse: 1.9501 - mae: 1.1232 - val_loss: 1.6639 - val_mse: 1.6639 - val_mae: 0.8983\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 448us/step - loss: 1.7220 - mse: 1.7220 - mae: 1.0461 - val_loss: 1.5188 - val_mse: 1.5188 - val_mae: 0.8216\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.5080 - mse: 1.5080 - mae: 0.9721 - val_loss: 1.3876 - val_mse: 1.3876 - val_mae: 0.7599\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.3231 - mse: 1.3231 - mae: 0.8975 - val_loss: 1.2865 - val_mse: 1.2865 - val_mae: 0.7325\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.1743 - mse: 1.1743 - mae: 0.8329 - val_loss: 1.2122 - val_mse: 1.2122 - val_mae: 0.7100\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.0633 - mse: 1.0633 - mae: 0.7768 - val_loss: 1.1646 - val_mse: 1.1646 - val_mae: 0.7003\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9854 - mse: 0.9854 - mae: 0.7382 - val_loss: 1.1407 - val_mse: 1.1407 - val_mae: 0.6975\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 793us/step - loss: 0.9355 - mse: 0.9355 - mae: 0.7158 - val_loss: 1.1317 - val_mse: 1.1317 - val_mae: 0.6994\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 480us/step - loss: 0.9064 - mse: 0.9064 - mae: 0.7018 - val_loss: 1.1285 - val_mse: 1.1285 - val_mae: 0.7052\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 792us/step - loss: 0.8905 - mse: 0.8905 - mae: 0.6940 - val_loss: 1.1283 - val_mse: 1.1283 - val_mae: 0.7087\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 629us/step - loss: 0.8811 - mse: 0.8811 - mae: 0.6913 - val_loss: 1.1267 - val_mse: 1.1267 - val_mae: 0.7109\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.8726 - mse: 0.8726 - mae: 0.6889 - val_loss: 1.1218 - val_mse: 1.1218 - val_mae: 0.7109\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 519us/step - loss: 0.8636 - mse: 0.8636 - mae: 0.6853 - val_loss: 1.1132 - val_mse: 1.1132 - val_mae: 0.7074\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 541us/step - loss: 0.8538 - mse: 0.8538 - mae: 0.6807 - val_loss: 1.1026 - val_mse: 1.1026 - val_mae: 0.7019\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 884us/step - loss: 0.8433 - mse: 0.8433 - mae: 0.6753 - val_loss: 1.0916 - val_mse: 1.0916 - val_mae: 0.6952\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.8327 - mse: 0.8327 - mae: 0.6700 - val_loss: 1.0810 - val_mse: 1.0810 - val_mae: 0.6881\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 733us/step - loss: 0.8232 - mse: 0.8232 - mae: 0.6652 - val_loss: 1.0717 - val_mse: 1.0717 - val_mae: 0.6814\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 793us/step - loss: 0.8148 - mse: 0.8148 - mae: 0.6605 - val_loss: 1.0639 - val_mse: 1.0639 - val_mae: 0.6754\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 665us/step - loss: 0.8074 - mse: 0.8074 - mae: 0.6563 - val_loss: 1.0579 - val_mse: 1.0579 - val_mae: 0.6706\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 674us/step - loss: 0.8005 - mse: 0.8005 - mae: 0.6526 - val_loss: 1.0533 - val_mse: 1.0533 - val_mae: 0.6678\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 570us/step - loss: 0.7941 - mse: 0.7941 - mae: 0.6493 - val_loss: 1.0499 - val_mse: 1.0499 - val_mae: 0.6660\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 718us/step - loss: 0.7881 - mse: 0.7881 - mae: 0.6463 - val_loss: 1.0470 - val_mse: 1.0470 - val_mae: 0.6647\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 687us/step - loss: 0.7824 - mse: 0.7824 - mae: 0.6434 - val_loss: 1.0448 - val_mse: 1.0448 - val_mae: 0.6640\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 619us/step - loss: 0.7771 - mse: 0.7771 - mae: 0.6405 - val_loss: 1.0440 - val_mse: 1.0440 - val_mae: 0.6642\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 767us/step - loss: 0.7713 - mse: 0.7713 - mae: 0.6375 - val_loss: 1.0444 - val_mse: 1.0444 - val_mae: 0.6651\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 877us/step - loss: 0.7658 - mse: 0.7658 - mae: 0.6346 - val_loss: 1.0450 - val_mse: 1.0450 - val_mae: 0.6657\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 845us/step - loss: 0.7608 - mse: 0.7608 - mae: 0.6324 - val_loss: 1.0454 - val_mse: 1.0454 - val_mae: 0.6660\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 765us/step - loss: 0.7560 - mse: 0.7560 - mae: 0.6304 - val_loss: 1.0457 - val_mse: 1.0457 - val_mae: 0.6660\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 675us/step - loss: 0.7516 - mse: 0.7516 - mae: 0.6283 - val_loss: 1.0462 - val_mse: 1.0462 - val_mae: 0.6658\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 656us/step - loss: 0.7473 - mse: 0.7473 - mae: 0.6261 - val_loss: 1.0473 - val_mse: 1.0473 - val_mae: 0.6657\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 725us/step - loss: 0.7431 - mse: 0.7431 - mae: 0.6241 - val_loss: 1.0487 - val_mse: 1.0487 - val_mae: 0.6658\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 732us/step - loss: 0.7390 - mse: 0.7390 - mae: 0.6220 - val_loss: 1.0508 - val_mse: 1.0508 - val_mae: 0.6661\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 765us/step - loss: 0.7353 - mse: 0.7353 - mae: 0.6201 - val_loss: 1.0530 - val_mse: 1.0530 - val_mae: 0.6667\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 739us/step - loss: 0.7317 - mse: 0.7317 - mae: 0.6185 - val_loss: 1.0544 - val_mse: 1.0544 - val_mae: 0.6669\n",
      "80\n",
      "[80]\n",
      "Train on 99 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 3s 29ms/step - loss: 10.9263 - mse: 10.9263 - mae: 2.7499 - val_loss: 4.6214 - val_mse: 4.6214 - val_mae: 1.8047\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 7.9632 - mse: 7.9632 - mae: 2.2364 - val_loss: 3.3129 - val_mse: 3.3129 - val_mae: 1.4912\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 380us/step - loss: 6.0132 - mse: 6.0132 - mae: 1.8279 - val_loss: 2.3861 - val_mse: 2.3861 - val_mae: 1.2611\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 682us/step - loss: 4.7547 - mse: 4.7547 - mae: 1.5549 - val_loss: 1.7604 - val_mse: 1.7604 - val_mae: 1.0627\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.9745 - mse: 3.9745 - mae: 1.3911 - val_loss: 1.3843 - val_mse: 1.3843 - val_mae: 0.9428\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 516us/step - loss: 3.5367 - mse: 3.5367 - mae: 1.3291 - val_loss: 1.1678 - val_mse: 1.1678 - val_mae: 0.8475\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.3096 - mse: 3.3096 - mae: 1.3128 - val_loss: 1.0834 - val_mse: 1.0834 - val_mae: 0.7861\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 748us/step - loss: 3.2186 - mse: 3.2186 - mae: 1.3169 - val_loss: 1.0550 - val_mse: 1.0550 - val_mae: 0.7501\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 3.1893 - mse: 3.1893 - mae: 1.3196 - val_loss: 1.0481 - val_mse: 1.0481 - val_mae: 0.7335\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 733us/step - loss: 3.1665 - mse: 3.1665 - mae: 1.3150 - val_loss: 1.0442 - val_mse: 1.0442 - val_mae: 0.7343\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 896us/step - loss: 3.1253 - mse: 3.1253 - mae: 1.3007 - val_loss: 1.0370 - val_mse: 1.0370 - val_mae: 0.7321\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 650us/step - loss: 3.0725 - mse: 3.0725 - mae: 1.2806 - val_loss: 1.0307 - val_mse: 1.0307 - val_mae: 0.7305\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 659us/step - loss: 3.0197 - mse: 3.0197 - mae: 1.2576 - val_loss: 1.0265 - val_mse: 1.0265 - val_mae: 0.7393\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 676us/step - loss: 2.9824 - mse: 2.9824 - mae: 1.2369 - val_loss: 1.0262 - val_mse: 1.0262 - val_mae: 0.7486\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 656us/step - loss: 2.9607 - mse: 2.9607 - mae: 1.2210 - val_loss: 1.0260 - val_mse: 1.0260 - val_mae: 0.7542\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 695us/step - loss: 2.9440 - mse: 2.9440 - mae: 1.2091 - val_loss: 1.0241 - val_mse: 1.0241 - val_mae: 0.7556\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 695us/step - loss: 2.9267 - mse: 2.9267 - mae: 1.1996 - val_loss: 1.0186 - val_mse: 1.0186 - val_mae: 0.7523\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 507us/step - loss: 2.9054 - mse: 2.9054 - mae: 1.1906 - val_loss: 1.0123 - val_mse: 1.0123 - val_mae: 0.7474\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 597us/step - loss: 2.8880 - mse: 2.8880 - mae: 1.1828 - val_loss: 1.0060 - val_mse: 1.0060 - val_mae: 0.7423\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 651us/step - loss: 2.8706 - mse: 2.8706 - mae: 1.1755 - val_loss: 1.0000 - val_mse: 1.0000 - val_mae: 0.7372\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 530us/step - loss: 2.8539 - mse: 2.8539 - mae: 1.1686 - val_loss: 0.9944 - val_mse: 0.9944 - val_mae: 0.7322\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 465us/step - loss: 2.8389 - mse: 2.8389 - mae: 1.1634 - val_loss: 0.9893 - val_mse: 0.9893 - val_mae: 0.7268\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 552us/step - loss: 2.8233 - mse: 2.8233 - mae: 1.1585 - val_loss: 0.9846 - val_mse: 0.9846 - val_mae: 0.7220\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 607us/step - loss: 2.8094 - mse: 2.8094 - mae: 1.1536 - val_loss: 0.9805 - val_mse: 0.9805 - val_mae: 0.7185\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 407us/step - loss: 2.7962 - mse: 2.7962 - mae: 1.1483 - val_loss: 0.9783 - val_mse: 0.9783 - val_mae: 0.7166\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 438us/step - loss: 2.7841 - mse: 2.7841 - mae: 1.1432 - val_loss: 0.9749 - val_mse: 0.9749 - val_mae: 0.7140\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 601us/step - loss: 2.7706 - mse: 2.7706 - mae: 1.1378 - val_loss: 0.9720 - val_mse: 0.9720 - val_mae: 0.7122\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 566us/step - loss: 2.7584 - mse: 2.7584 - mae: 1.1323 - val_loss: 0.9696 - val_mse: 0.9696 - val_mae: 0.7111\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 608us/step - loss: 2.7476 - mse: 2.7476 - mae: 1.1273 - val_loss: 0.9678 - val_mse: 0.9678 - val_mae: 0.7094\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 2.7348 - mse: 2.7348 - mae: 1.1231 - val_loss: 0.9660 - val_mse: 0.9660 - val_mae: 0.7078\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 820us/step - loss: 2.7230 - mse: 2.7230 - mae: 1.1191 - val_loss: 0.9644 - val_mse: 0.9644 - val_mae: 0.7067\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 431us/step - loss: 2.7111 - mse: 2.7111 - mae: 1.1147 - val_loss: 0.9631 - val_mse: 0.9631 - val_mae: 0.7061\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 676us/step - loss: 2.7000 - mse: 2.7000 - mae: 1.1103 - val_loss: 0.9623 - val_mse: 0.9623 - val_mae: 0.7054\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 603us/step - loss: 2.6888 - mse: 2.6888 - mae: 1.1071 - val_loss: 0.9609 - val_mse: 0.9609 - val_mae: 0.7036\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 897us/step - loss: 2.6776 - mse: 2.6776 - mae: 1.1045 - val_loss: 0.9594 - val_mse: 0.9594 - val_mae: 0.7017\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 633us/step - loss: 2.6662 - mse: 2.6662 - mae: 1.1019 - val_loss: 0.9585 - val_mse: 0.9585 - val_mae: 0.7014\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 613us/step - loss: 2.6545 - mse: 2.6545 - mae: 1.0989 - val_loss: 0.9575 - val_mse: 0.9575 - val_mae: 0.7006\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 435us/step - loss: 2.6435 - mse: 2.6435 - mae: 1.0958 - val_loss: 0.9573 - val_mse: 0.9573 - val_mae: 0.7004\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 507us/step - loss: 2.6347 - mse: 2.6347 - mae: 1.0935 - val_loss: 0.9566 - val_mse: 0.9566 - val_mae: 0.6988\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 563us/step - loss: 2.6227 - mse: 2.6227 - mae: 1.0920 - val_loss: 0.9558 - val_mse: 0.9558 - val_mae: 0.6973\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 564us/step - loss: 2.6120 - mse: 2.6120 - mae: 1.0906 - val_loss: 0.9558 - val_mse: 0.9558 - val_mae: 0.6967\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 597us/step - loss: 2.6008 - mse: 2.6008 - mae: 1.0884 - val_loss: 0.9553 - val_mse: 0.9553 - val_mae: 0.6962\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 451us/step - loss: 2.5935 - mse: 2.5935 - mae: 1.0864 - val_loss: 0.9547 - val_mse: 0.9547 - val_mae: 0.6952\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 743us/step - loss: 2.5814 - mse: 2.5814 - mae: 1.0850 - val_loss: 0.9538 - val_mse: 0.9538 - val_mae: 0.6944\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 540us/step - loss: 2.5710 - mse: 2.5710 - mae: 1.0825 - val_loss: 0.9525 - val_mse: 0.9525 - val_mae: 0.6938\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 641us/step - loss: 2.5610 - mse: 2.5610 - mae: 1.0798 - val_loss: 0.9525 - val_mse: 0.9525 - val_mae: 0.6934\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 558us/step - loss: 2.5501 - mse: 2.5501 - mae: 1.0773 - val_loss: 0.9531 - val_mse: 0.9531 - val_mae: 0.6931\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 659us/step - loss: 2.5404 - mse: 2.5404 - mae: 1.0750 - val_loss: 0.9530 - val_mse: 0.9530 - val_mae: 0.6922\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 822us/step - loss: 2.5304 - mse: 2.5304 - mae: 1.0733 - val_loss: 0.9518 - val_mse: 0.9518 - val_mae: 0.6912\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 547us/step - loss: 2.5189 - mse: 2.5189 - mae: 1.0696 - val_loss: 0.9504 - val_mse: 0.9504 - val_mae: 0.6904\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 563us/step - loss: 2.5111 - mse: 2.5111 - mae: 1.0667 - val_loss: 0.9502 - val_mse: 0.9502 - val_mae: 0.6895\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 2.4985 - mse: 2.4985 - mae: 1.0654 - val_loss: 0.9513 - val_mse: 0.9513 - val_mae: 0.6894\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 399us/step - loss: 2.4876 - mse: 2.4876 - mae: 1.0639 - val_loss: 0.9517 - val_mse: 0.9517 - val_mae: 0.6890\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 844us/step - loss: 2.4759 - mse: 2.4759 - mae: 1.0608 - val_loss: 0.9519 - val_mse: 0.9519 - val_mae: 0.6894\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 641us/step - loss: 2.4656 - mse: 2.4656 - mae: 1.0587 - val_loss: 0.9519 - val_mse: 0.9519 - val_mae: 0.6890\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 598us/step - loss: 2.4538 - mse: 2.4538 - mae: 1.0571 - val_loss: 0.9516 - val_mse: 0.9516 - val_mae: 0.6892\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 673us/step - loss: 2.4415 - mse: 2.4415 - mae: 1.0537 - val_loss: 0.9512 - val_mse: 0.9512 - val_mae: 0.6894\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 426us/step - loss: 2.4321 - mse: 2.4321 - mae: 1.0522 - val_loss: 0.9533 - val_mse: 0.9533 - val_mae: 0.6898\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 567us/step - loss: 2.4209 - mse: 2.4209 - mae: 1.0518 - val_loss: 0.9513 - val_mse: 0.9513 - val_mae: 0.6901\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 625us/step - loss: 2.4120 - mse: 2.4120 - mae: 1.0495 - val_loss: 0.9515 - val_mse: 0.9515 - val_mae: 0.6902\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 673us/step - loss: 2.3986 - mse: 2.3986 - mae: 1.0487 - val_loss: 0.9528 - val_mse: 0.9528 - val_mae: 0.6907\n",
      "81\n",
      "[81]\n",
      "Train on 103 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "103/103 [==============================] - 4s 37ms/step - loss: 6.1294 - mse: 6.1294 - mae: 1.8232 - val_loss: 0.8274 - val_mse: 0.8274 - val_mae: 0.6524\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 906us/step - loss: 5.7628 - mse: 5.7628 - mae: 1.7690 - val_loss: 0.8235 - val_mse: 0.8235 - val_mae: 0.6483\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 363us/step - loss: 5.5278 - mse: 5.5278 - mae: 1.7330 - val_loss: 0.8288 - val_mse: 0.8288 - val_mae: 0.6453\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 938us/step - loss: 5.3334 - mse: 5.3334 - mae: 1.7012 - val_loss: 0.8265 - val_mse: 0.8265 - val_mae: 0.6359\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 5.1628 - mse: 5.1628 - mae: 1.6750 - val_loss: 0.8154 - val_mse: 0.8154 - val_mae: 0.6218\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 5.0086 - mse: 5.0086 - mae: 1.6508 - val_loss: 0.7943 - val_mse: 0.7943 - val_mae: 0.6056\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 573us/step - loss: 4.8660 - mse: 4.8660 - mae: 1.6270 - val_loss: 0.7719 - val_mse: 0.7719 - val_mae: 0.5891\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 4.7291 - mse: 4.7291 - mae: 1.6038 - val_loss: 0.7466 - val_mse: 0.7466 - val_mae: 0.5740\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 647us/step - loss: 4.6166 - mse: 4.6166 - mae: 1.5828 - val_loss: 0.7240 - val_mse: 0.7240 - val_mae: 0.5676\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 633us/step - loss: 4.5151 - mse: 4.5151 - mae: 1.5636 - val_loss: 0.7045 - val_mse: 0.7045 - val_mae: 0.5583\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 354us/step - loss: 4.4240 - mse: 4.4240 - mae: 1.5446 - val_loss: 0.6873 - val_mse: 0.6873 - val_mae: 0.5494\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 715us/step - loss: 4.3526 - mse: 4.3526 - mae: 1.5276 - val_loss: 0.6739 - val_mse: 0.6739 - val_mae: 0.5433\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 848us/step - loss: 4.2903 - mse: 4.2903 - mae: 1.5130 - val_loss: 0.6653 - val_mse: 0.6653 - val_mae: 0.5426\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 888us/step - loss: 4.2330 - mse: 4.2330 - mae: 1.5003 - val_loss: 0.6617 - val_mse: 0.6617 - val_mae: 0.5436\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 763us/step - loss: 4.1853 - mse: 4.1853 - mae: 1.4894 - val_loss: 0.6609 - val_mse: 0.6609 - val_mae: 0.5447\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 772us/step - loss: 4.1398 - mse: 4.1398 - mae: 1.4795 - val_loss: 0.6629 - val_mse: 0.6629 - val_mae: 0.5467\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 418us/step - loss: 4.0943 - mse: 4.0943 - mae: 1.4706 - val_loss: 0.6679 - val_mse: 0.6679 - val_mae: 0.5499\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 841us/step - loss: 4.0497 - mse: 4.0497 - mae: 1.4619 - val_loss: 0.6740 - val_mse: 0.6740 - val_mae: 0.5533\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 744us/step - loss: 4.0117 - mse: 4.0117 - mae: 1.4544 - val_loss: 0.6771 - val_mse: 0.6771 - val_mae: 0.5534\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 834us/step - loss: 3.9744 - mse: 3.9744 - mae: 1.4480 - val_loss: 0.6772 - val_mse: 0.6772 - val_mae: 0.5509\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 3.9373 - mse: 3.9373 - mae: 1.4419 - val_loss: 0.6774 - val_mse: 0.6774 - val_mae: 0.5478\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 642us/step - loss: 3.9007 - mse: 3.9007 - mae: 1.4361 - val_loss: 0.6789 - val_mse: 0.6789 - val_mae: 0.5457\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 935us/step - loss: 3.8651 - mse: 3.8651 - mae: 1.4302 - val_loss: 0.6822 - val_mse: 0.6822 - val_mae: 0.5441\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 583us/step - loss: 3.8313 - mse: 3.8313 - mae: 1.4246 - val_loss: 0.6873 - val_mse: 0.6873 - val_mae: 0.5438\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 3.7992 - mse: 3.7992 - mae: 1.4183 - val_loss: 0.6932 - val_mse: 0.6932 - val_mae: 0.5452\n",
      "82\n",
      "[82]\n",
      "Train on 80 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 9.3420 - mse: 9.3420 - mae: 2.8300 - val_loss: 8.4969 - val_mse: 8.4969 - val_mae: 2.7406\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 918us/step - loss: 7.0952 - mse: 7.0952 - mae: 2.4009 - val_loss: 6.3449 - val_mse: 6.3449 - val_mae: 2.3321\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 448us/step - loss: 5.4245 - mse: 5.4245 - mae: 2.0275 - val_loss: 4.7786 - val_mse: 4.7786 - val_mae: 2.0022\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 766us/step - loss: 4.2342 - mse: 4.2342 - mae: 1.7372 - val_loss: 3.6504 - val_mse: 3.6504 - val_mae: 1.7205\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 539us/step - loss: 3.3373 - mse: 3.3373 - mae: 1.4973 - val_loss: 2.7891 - val_mse: 2.7891 - val_mae: 1.4817\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6802 - mse: 2.6802 - mae: 1.3038 - val_loss: 2.1251 - val_mse: 2.1251 - val_mae: 1.2702\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2135 - mse: 2.2135 - mae: 1.1585 - val_loss: 1.6263 - val_mse: 1.6263 - val_mae: 1.0953\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 646us/step - loss: 1.8950 - mse: 1.8950 - mae: 1.0554 - val_loss: 1.2697 - val_mse: 1.2697 - val_mae: 0.9468\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 868us/step - loss: 1.6914 - mse: 1.6914 - mae: 0.9754 - val_loss: 1.0296 - val_mse: 1.0296 - val_mae: 0.8300\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 598us/step - loss: 1.5768 - mse: 1.5768 - mae: 0.9310 - val_loss: 0.8815 - val_mse: 0.8815 - val_mae: 0.7653\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5240 - mse: 1.5240 - mae: 0.9275 - val_loss: 0.8032 - val_mse: 0.8032 - val_mae: 0.7336\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 469us/step - loss: 1.5009 - mse: 1.5009 - mae: 0.9325 - val_loss: 0.7683 - val_mse: 0.7683 - val_mae: 0.7275\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 721us/step - loss: 1.4857 - mse: 1.4857 - mae: 0.9365 - val_loss: 0.7563 - val_mse: 0.7563 - val_mae: 0.7273\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 920us/step - loss: 1.4718 - mse: 1.4718 - mae: 0.9370 - val_loss: 0.7552 - val_mse: 0.7552 - val_mae: 0.7325\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4515 - mse: 1.4515 - mae: 0.9330 - val_loss: 0.7616 - val_mse: 0.7616 - val_mae: 0.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 439us/step - loss: 1.4222 - mse: 1.4222 - mae: 0.9230 - val_loss: 0.7727 - val_mse: 0.7727 - val_mae: 0.7496\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 791us/step - loss: 1.3886 - mse: 1.3886 - mae: 0.9101 - val_loss: 0.7883 - val_mse: 0.7883 - val_mae: 0.7593\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 578us/step - loss: 1.3530 - mse: 1.3530 - mae: 0.8957 - val_loss: 0.8100 - val_mse: 0.8100 - val_mae: 0.7702\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 489us/step - loss: 1.3206 - mse: 1.3206 - mae: 0.8821 - val_loss: 0.8362 - val_mse: 0.8362 - val_mae: 0.7831\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 618us/step - loss: 1.2932 - mse: 1.2932 - mae: 0.8703 - val_loss: 0.8576 - val_mse: 0.8576 - val_mae: 0.7924\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 620us/step - loss: 1.2712 - mse: 1.2712 - mae: 0.8588 - val_loss: 0.8757 - val_mse: 0.8757 - val_mae: 0.7986\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.2526 - mse: 1.2526 - mae: 0.8497 - val_loss: 0.8899 - val_mse: 0.8899 - val_mae: 0.8017\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 445us/step - loss: 1.2365 - mse: 1.2365 - mae: 0.8412 - val_loss: 0.8987 - val_mse: 0.8987 - val_mae: 0.8031\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 618us/step - loss: 1.2205 - mse: 1.2205 - mae: 0.8331 - val_loss: 0.9022 - val_mse: 0.9022 - val_mae: 0.8028\n",
      "83\n",
      "[83]\n",
      "Train on 104 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 7.5103 - mse: 7.5103 - mae: 2.5155 - val_loss: 15.4372 - val_mse: 15.4372 - val_mae: 3.7335\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 0s 334us/step - loss: 6.5491 - mse: 6.5491 - mae: 2.3165 - val_loss: 13.2495 - val_mse: 13.2495 - val_mae: 3.4357\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 0s 478us/step - loss: 5.5908 - mse: 5.5908 - mae: 2.0924 - val_loss: 11.3579 - val_mse: 11.3579 - val_mae: 3.1549\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 0s 511us/step - loss: 4.5950 - mse: 4.5950 - mae: 1.8317 - val_loss: 9.4067 - val_mse: 9.4067 - val_mae: 2.8382\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 0s 947us/step - loss: 3.6310 - mse: 3.6310 - mae: 1.5456 - val_loss: 7.4387 - val_mse: 7.4387 - val_mae: 2.4864\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 0s 558us/step - loss: 2.7611 - mse: 2.7611 - mae: 1.2537 - val_loss: 5.3418 - val_mse: 5.3418 - val_mae: 2.0439\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 0s 579us/step - loss: 2.0413 - mse: 2.0413 - mae: 1.0099 - val_loss: 3.6215 - val_mse: 3.6215 - val_mae: 1.6060\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 0s 733us/step - loss: 1.5743 - mse: 1.5743 - mae: 0.8831 - val_loss: 2.4460 - val_mse: 2.4460 - val_mae: 1.3074\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 0s 524us/step - loss: 1.3367 - mse: 1.3367 - mae: 0.8203 - val_loss: 1.7642 - val_mse: 1.7642 - val_mae: 1.1180\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 0s 533us/step - loss: 1.2619 - mse: 1.2619 - mae: 0.8166 - val_loss: 1.4271 - val_mse: 1.4271 - val_mae: 1.0036\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 0s 446us/step - loss: 1.2583 - mse: 1.2583 - mae: 0.8343 - val_loss: 1.2949 - val_mse: 1.2949 - val_mae: 0.9495\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 0s 434us/step - loss: 1.2589 - mse: 1.2589 - mae: 0.8399 - val_loss: 1.2722 - val_mse: 1.2722 - val_mae: 0.9394\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 0s 435us/step - loss: 1.2408 - mse: 1.2408 - mae: 0.8297 - val_loss: 1.3150 - val_mse: 1.3150 - val_mae: 0.9580\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 0s 493us/step - loss: 1.2115 - mse: 1.2115 - mae: 0.8101 - val_loss: 1.4045 - val_mse: 1.4045 - val_mae: 0.9961\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 0s 395us/step - loss: 1.1855 - mse: 1.1855 - mae: 0.7894 - val_loss: 1.5210 - val_mse: 1.5210 - val_mae: 1.0384\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 0s 638us/step - loss: 1.1698 - mse: 1.1698 - mae: 0.7727 - val_loss: 1.6357 - val_mse: 1.6357 - val_mae: 1.0748\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 0s 599us/step - loss: 1.1624 - mse: 1.1624 - mae: 0.7647 - val_loss: 1.7214 - val_mse: 1.7214 - val_mae: 1.0989\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 0s 421us/step - loss: 1.1577 - mse: 1.1577 - mae: 0.7586 - val_loss: 1.7662 - val_mse: 1.7662 - val_mae: 1.1101\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 0s 506us/step - loss: 1.1511 - mse: 1.1511 - mae: 0.7540 - val_loss: 1.7690 - val_mse: 1.7690 - val_mae: 1.1092\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 0s 469us/step - loss: 1.1411 - mse: 1.1411 - mae: 0.7499 - val_loss: 1.7397 - val_mse: 1.7397 - val_mae: 1.0989\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 0s 398us/step - loss: 1.1284 - mse: 1.1284 - mae: 0.7464 - val_loss: 1.6844 - val_mse: 1.6844 - val_mae: 1.0806\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 0s 432us/step - loss: 1.1153 - mse: 1.1153 - mae: 0.7440 - val_loss: 1.6232 - val_mse: 1.6232 - val_mae: 1.0596\n",
      "84\n",
      "[84]\n",
      "Train on 100 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 5.6350 - mse: 5.6350 - mae: 2.1133 - val_loss: 2.0533 - val_mse: 2.0533 - val_mae: 1.2618\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 881us/step - loss: 5.0889 - mse: 5.0889 - mae: 1.9812 - val_loss: 1.8361 - val_mse: 1.8361 - val_mae: 1.1670\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 658us/step - loss: 4.5927 - mse: 4.5927 - mae: 1.8537 - val_loss: 1.6265 - val_mse: 1.6265 - val_mae: 1.0686\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 944us/step - loss: 4.1236 - mse: 4.1236 - mae: 1.7237 - val_loss: 1.4268 - val_mse: 1.4268 - val_mae: 0.9658\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 664us/step - loss: 3.6801 - mse: 3.6801 - mae: 1.5964 - val_loss: 1.2416 - val_mse: 1.2416 - val_mae: 0.8597\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 467us/step - loss: 3.2583 - mse: 3.2583 - mae: 1.4712 - val_loss: 1.0645 - val_mse: 1.0645 - val_mae: 0.7524\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 546us/step - loss: 2.8609 - mse: 2.8609 - mae: 1.3516 - val_loss: 0.9101 - val_mse: 0.9101 - val_mae: 0.6626\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 721us/step - loss: 2.4900 - mse: 2.4900 - mae: 1.2409 - val_loss: 0.7852 - val_mse: 0.7852 - val_mae: 0.6170\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1576 - mse: 2.1576 - mae: 1.1476 - val_loss: 0.6881 - val_mse: 0.6881 - val_mae: 0.6031\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 683us/step - loss: 1.8676 - mse: 1.8676 - mae: 1.0725 - val_loss: 0.6217 - val_mse: 0.6217 - val_mae: 0.5968\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 970us/step - loss: 1.6249 - mse: 1.6249 - mae: 1.0091 - val_loss: 0.5877 - val_mse: 0.5877 - val_mae: 0.5968\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 767us/step - loss: 1.4335 - mse: 1.4335 - mae: 0.9603 - val_loss: 0.5821 - val_mse: 0.5821 - val_mae: 0.6109\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.2954 - mse: 1.2954 - mae: 0.9169 - val_loss: 0.6006 - val_mse: 0.6006 - val_mae: 0.6263\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 727us/step - loss: 1.2082 - mse: 1.2082 - mae: 0.8805 - val_loss: 0.6372 - val_mse: 0.6372 - val_mae: 0.6460\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1644 - mse: 1.1644 - mae: 0.8639 - val_loss: 0.6839 - val_mse: 0.6839 - val_mae: 0.6730\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 1.1529 - mse: 1.1529 - mae: 0.8579 - val_loss: 0.7340 - val_mse: 0.7340 - val_mae: 0.6992\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 433us/step - loss: 1.1611 - mse: 1.1611 - mae: 0.8671 - val_loss: 0.7788 - val_mse: 0.7788 - val_mae: 0.7195\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 664us/step - loss: 1.1768 - mse: 1.1768 - mae: 0.8769 - val_loss: 0.8127 - val_mse: 0.8127 - val_mae: 0.7355\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 714us/step - loss: 1.1912 - mse: 1.1912 - mae: 0.8831 - val_loss: 0.8324 - val_mse: 0.8324 - val_mae: 0.7441\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 574us/step - loss: 1.1996 - mse: 1.1996 - mae: 0.8872 - val_loss: 0.8392 - val_mse: 0.8392 - val_mae: 0.7468\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 398us/step - loss: 1.2010 - mse: 1.2010 - mae: 0.8882 - val_loss: 0.8359 - val_mse: 0.8359 - val_mae: 0.7454\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 546us/step - loss: 1.1965 - mse: 1.1965 - mae: 0.8868 - val_loss: 0.8258 - val_mse: 0.8258 - val_mae: 0.7410\n",
      "85\n",
      "[85]\n",
      "Train on 87 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 13.7960 - mse: 13.7960 - mae: 3.2680 - val_loss: 12.1179 - val_mse: 12.1179 - val_mae: 3.3137\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 572us/step - loss: 11.9615 - mse: 11.9615 - mae: 2.9991 - val_loss: 10.2418 - val_mse: 10.2418 - val_mae: 3.0283\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 489us/step - loss: 10.4463 - mse: 10.4463 - mae: 2.7534 - val_loss: 8.6289 - val_mse: 8.6289 - val_mae: 2.7596\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 678us/step - loss: 9.1381 - mse: 9.1381 - mae: 2.5211 - val_loss: 7.2283 - val_mse: 7.2283 - val_mae: 2.5009\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 455us/step - loss: 7.9778 - mse: 7.9778 - mae: 2.2990 - val_loss: 6.0622 - val_mse: 6.0622 - val_mae: 2.2610\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 652us/step - loss: 6.9960 - mse: 6.9960 - mae: 2.0922 - val_loss: 5.1286 - val_mse: 5.1286 - val_mae: 2.0448\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 923us/step - loss: 6.1484 - mse: 6.1484 - mae: 1.8971 - val_loss: 4.2439 - val_mse: 4.2439 - val_mae: 1.8223\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 435us/step - loss: 5.4159 - mse: 5.4159 - mae: 1.7160 - val_loss: 3.4465 - val_mse: 3.4465 - val_mae: 1.5971\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 805us/step - loss: 4.7926 - mse: 4.7926 - mae: 1.5630 - val_loss: 2.7765 - val_mse: 2.7765 - val_mae: 1.4104\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 784us/step - loss: 4.2712 - mse: 4.2712 - mae: 1.4366 - val_loss: 2.2226 - val_mse: 2.2226 - val_mae: 1.2419\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 805us/step - loss: 3.8329 - mse: 3.8329 - mae: 1.3336 - val_loss: 1.8025 - val_mse: 1.8025 - val_mae: 1.0968\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3.4919 - mse: 3.4919 - mae: 1.2559 - val_loss: 1.4856 - val_mse: 1.4856 - val_mae: 0.9641\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 749us/step - loss: 3.2221 - mse: 3.2221 - mae: 1.1952 - val_loss: 1.2634 - val_mse: 1.2634 - val_mae: 0.8530\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3.0347 - mse: 3.0347 - mae: 1.1622 - val_loss: 1.1221 - val_mse: 1.1221 - val_mae: 0.7868\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 518us/step - loss: 2.8947 - mse: 2.8947 - mae: 1.1428 - val_loss: 1.0351 - val_mse: 1.0351 - val_mae: 0.7467\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 491us/step - loss: 2.7954 - mse: 2.7954 - mae: 1.1377 - val_loss: 0.9857 - val_mse: 0.9857 - val_mae: 0.7219\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 961us/step - loss: 2.7231 - mse: 2.7231 - mae: 1.1363 - val_loss: 0.9614 - val_mse: 0.9614 - val_mae: 0.7176\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 694us/step - loss: 2.6687 - mse: 2.6687 - mae: 1.1333 - val_loss: 0.9524 - val_mse: 0.9524 - val_mae: 0.7172\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 951us/step - loss: 2.6242 - mse: 2.6242 - mae: 1.1286 - val_loss: 0.9494 - val_mse: 0.9494 - val_mae: 0.7184\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 0s 499us/step - loss: 2.5922 - mse: 2.5922 - mae: 1.1253 - val_loss: 0.9477 - val_mse: 0.9477 - val_mae: 0.7190\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 0s 464us/step - loss: 2.5637 - mse: 2.5637 - mae: 1.1238 - val_loss: 0.9443 - val_mse: 0.9443 - val_mae: 0.7180\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 0s 720us/step - loss: 2.5338 - mse: 2.5338 - mae: 1.1206 - val_loss: 0.9385 - val_mse: 0.9385 - val_mae: 0.7158\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 0s 628us/step - loss: 2.5026 - mse: 2.5026 - mae: 1.1154 - val_loss: 0.9312 - val_mse: 0.9312 - val_mae: 0.7126\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 0s 567us/step - loss: 2.4709 - mse: 2.4709 - mae: 1.1087 - val_loss: 0.9244 - val_mse: 0.9244 - val_mae: 0.7094\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 0s 569us/step - loss: 2.4388 - mse: 2.4388 - mae: 1.1009 - val_loss: 0.9185 - val_mse: 0.9185 - val_mae: 0.7061\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 0s 426us/step - loss: 2.4082 - mse: 2.4082 - mae: 1.0925 - val_loss: 0.9135 - val_mse: 0.9135 - val_mae: 0.7028\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 0s 820us/step - loss: 2.3802 - mse: 2.3802 - mae: 1.0840 - val_loss: 0.9116 - val_mse: 0.9116 - val_mae: 0.7018\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 0s 878us/step - loss: 2.3541 - mse: 2.3541 - mae: 1.0758 - val_loss: 0.9142 - val_mse: 0.9142 - val_mae: 0.7020\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 0s 482us/step - loss: 2.3299 - mse: 2.3299 - mae: 1.0682 - val_loss: 0.9173 - val_mse: 0.9173 - val_mae: 0.7023\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 0s 548us/step - loss: 2.3066 - mse: 2.3066 - mae: 1.0609 - val_loss: 0.9188 - val_mse: 0.9188 - val_mae: 0.7018\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 0s 387us/step - loss: 2.2841 - mse: 2.2841 - mae: 1.0539 - val_loss: 0.9199 - val_mse: 0.9199 - val_mae: 0.7012\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 0s 540us/step - loss: 2.2621 - mse: 2.2621 - mae: 1.0474 - val_loss: 0.9211 - val_mse: 0.9211 - val_mae: 0.7005\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 0s 517us/step - loss: 2.2405 - mse: 2.2405 - mae: 1.0411 - val_loss: 0.9228 - val_mse: 0.9228 - val_mae: 0.6997\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 0s 457us/step - loss: 2.2195 - mse: 2.2195 - mae: 1.0351 - val_loss: 0.9243 - val_mse: 0.9243 - val_mae: 0.6987\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - ETA: 0s - loss: 4.1408 - mse: 4.1408 - mae: 1.368 - 0s 689us/step - loss: 2.1991 - mse: 2.1991 - mae: 1.0298 - val_loss: 0.9258 - val_mse: 0.9258 - val_mae: 0.6976\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 0s 590us/step - loss: 2.1792 - mse: 2.1792 - mae: 1.0246 - val_loss: 0.9271 - val_mse: 0.9271 - val_mae: 0.6957\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 0s 467us/step - loss: 2.1596 - mse: 2.1596 - mae: 1.0196 - val_loss: 0.9287 - val_mse: 0.9287 - val_mae: 0.6937\n",
      "86\n",
      "[86]\n",
      "Train on 96 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 3s 35ms/step - loss: 3.8886 - mse: 3.8886 - mae: 1.7687 - val_loss: 2.0539 - val_mse: 2.0539 - val_mae: 1.3030\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 568us/step - loss: 3.6418 - mse: 3.6418 - mae: 1.7000 - val_loss: 1.9509 - val_mse: 1.9509 - val_mae: 1.2569\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 858us/step - loss: 3.4755 - mse: 3.4755 - mae: 1.6527 - val_loss: 1.8503 - val_mse: 1.8503 - val_mae: 1.2128\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 696us/step - loss: 3.3289 - mse: 3.3289 - mae: 1.6090 - val_loss: 1.7357 - val_mse: 1.7357 - val_mae: 1.1630\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 641us/step - loss: 3.1560 - mse: 3.1560 - mae: 1.5536 - val_loss: 1.5865 - val_mse: 1.5865 - val_mae: 1.0975\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.9292 - mse: 2.9292 - mae: 1.4767 - val_loss: 1.3960 - val_mse: 1.3960 - val_mae: 1.0088\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 951us/step - loss: 2.6521 - mse: 2.6521 - mae: 1.3779 - val_loss: 1.2035 - val_mse: 1.2035 - val_mae: 0.9091\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.3578 - mse: 2.3578 - mae: 1.2630 - val_loss: 1.0182 - val_mse: 1.0182 - val_mae: 0.7991\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0530 - mse: 2.0530 - mae: 1.1323 - val_loss: 0.8281 - val_mse: 0.8281 - val_mae: 0.6974\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 495us/step - loss: 1.7532 - mse: 1.7532 - mae: 0.9940 - val_loss: 0.6571 - val_mse: 0.6571 - val_mae: 0.6135\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 672us/step - loss: 1.4647 - mse: 1.4647 - mae: 0.8668 - val_loss: 0.5164 - val_mse: 0.5164 - val_mae: 0.5282\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.2135 - mse: 1.2135 - mae: 0.7909 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4677\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.0315 - mse: 1.0315 - mae: 0.7702 - val_loss: 0.4324 - val_mse: 0.4324 - val_mae: 0.4578\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.9212 - mse: 0.9212 - mae: 0.7651 - val_loss: 0.4701 - val_mse: 0.4701 - val_mae: 0.4787\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 854us/step - loss: 0.8855 - mse: 0.8855 - mae: 0.7658 - val_loss: 0.5061 - val_mse: 0.5061 - val_mae: 0.5178\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 449us/step - loss: 0.8801 - mse: 0.8801 - mae: 0.7690 - val_loss: 0.5056 - val_mse: 0.5056 - val_mae: 0.5345\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 662us/step - loss: 0.8725 - mse: 0.8725 - mae: 0.7650 - val_loss: 0.4716 - val_mse: 0.4716 - val_mae: 0.5189\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 616us/step - loss: 0.8587 - mse: 0.8587 - mae: 0.7551 - val_loss: 0.4274 - val_mse: 0.4274 - val_mae: 0.4882\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 743us/step - loss: 0.8481 - mse: 0.8481 - mae: 0.7453 - val_loss: 0.3925 - val_mse: 0.3925 - val_mae: 0.4595\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 757us/step - loss: 0.8429 - mse: 0.8429 - mae: 0.7382 - val_loss: 0.3727 - val_mse: 0.3727 - val_mae: 0.4413\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 691us/step - loss: 0.8410 - mse: 0.8410 - mae: 0.7341 - val_loss: 0.3624 - val_mse: 0.3624 - val_mae: 0.4315\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.8382 - mse: 0.8382 - mae: 0.7308 - val_loss: 0.3589 - val_mse: 0.3589 - val_mae: 0.4281\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 833us/step - loss: 0.8341 - mse: 0.8341 - mae: 0.7278 - val_loss: 0.3585 - val_mse: 0.3585 - val_mae: 0.4287\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 889us/step - loss: 0.8283 - mse: 0.8283 - mae: 0.7251 - val_loss: 0.3600 - val_mse: 0.3600 - val_mae: 0.4323\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.8216 - mse: 0.8216 - mae: 0.7229 - val_loss: 0.3628 - val_mse: 0.3628 - val_mae: 0.4391\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.8150 - mse: 0.8150 - mae: 0.7212 - val_loss: 0.3660 - val_mse: 0.3660 - val_mae: 0.4456\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.8089 - mse: 0.8089 - mae: 0.7194 - val_loss: 0.3683 - val_mse: 0.3683 - val_mae: 0.4501\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 830us/step - loss: 0.8032 - mse: 0.8032 - mae: 0.7176 - val_loss: 0.3696 - val_mse: 0.3696 - val_mae: 0.4525\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.7982 - mse: 0.7982 - mae: 0.7156 - val_loss: 0.3711 - val_mse: 0.3711 - val_mae: 0.4546\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 772us/step - loss: 0.7936 - mse: 0.7936 - mae: 0.7132 - val_loss: 0.3723 - val_mse: 0.3723 - val_mae: 0.4564\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 817us/step - loss: 0.7893 - mse: 0.7893 - mae: 0.7106 - val_loss: 0.3721 - val_mse: 0.3721 - val_mae: 0.4562\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.7851 - mse: 0.7851 - mae: 0.7083 - val_loss: 0.3713 - val_mse: 0.3713 - val_mae: 0.4551\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.7813 - mse: 0.7813 - mae: 0.7063 - val_loss: 0.3717 - val_mse: 0.3717 - val_mae: 0.4558\n",
      "87\n",
      "[87]\n",
      "Train on 101 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 4s 44ms/step - loss: 5.3484 - mse: 5.3484 - mae: 1.3826 - val_loss: 0.9062 - val_mse: 0.9062 - val_mae: 0.8254\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 969us/step - loss: 4.8802 - mse: 4.8802 - mae: 1.3411 - val_loss: 0.6817 - val_mse: 0.6817 - val_mae: 0.6711\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 536us/step - loss: 4.6464 - mse: 4.6464 - mae: 1.3558 - val_loss: 0.5994 - val_mse: 0.5994 - val_mae: 0.5992\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 702us/step - loss: 4.5036 - mse: 4.5036 - mae: 1.3585 - val_loss: 0.5733 - val_mse: 0.5733 - val_mae: 0.5736\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 568us/step - loss: 4.3739 - mse: 4.3739 - mae: 1.3353 - val_loss: 0.5654 - val_mse: 0.5654 - val_mae: 0.5709\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 882us/step - loss: 4.2530 - mse: 4.2530 - mae: 1.2958 - val_loss: 0.5690 - val_mse: 0.5690 - val_mae: 0.5774\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 773us/step - loss: 4.1558 - mse: 4.1558 - mae: 1.2571 - val_loss: 0.5768 - val_mse: 0.5768 - val_mae: 0.5846\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 644us/step - loss: 4.0849 - mse: 4.0849 - mae: 1.2321 - val_loss: 0.5783 - val_mse: 0.5783 - val_mae: 0.5851\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 919us/step - loss: 4.0230 - mse: 4.0230 - mae: 1.2217 - val_loss: 0.5687 - val_mse: 0.5687 - val_mae: 0.5740\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 815us/step - loss: 3.9593 - mse: 3.9593 - mae: 1.2185 - val_loss: 0.5525 - val_mse: 0.5525 - val_mae: 0.5613\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 496us/step - loss: 3.8991 - mse: 3.8991 - mae: 1.2203 - val_loss: 0.5405 - val_mse: 0.5405 - val_mae: 0.5489\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 602us/step - loss: 3.8475 - mse: 3.8475 - mae: 1.2234 - val_loss: 0.5348 - val_mse: 0.5348 - val_mae: 0.5408\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 537us/step - loss: 3.8037 - mse: 3.8037 - mae: 1.2239 - val_loss: 0.5334 - val_mse: 0.5334 - val_mae: 0.5365\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 840us/step - loss: 3.7660 - mse: 3.7660 - mae: 1.2189 - val_loss: 0.5365 - val_mse: 0.5365 - val_mae: 0.5377\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 721us/step - loss: 3.7300 - mse: 3.7300 - mae: 1.2099 - val_loss: 0.5390 - val_mse: 0.5390 - val_mae: 0.5395\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 3.6984 - mse: 3.6984 - mae: 1.2012 - val_loss: 0.5407 - val_mse: 0.5407 - val_mae: 0.5401\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 469us/step - loss: 3.6684 - mse: 3.6684 - mae: 1.1953 - val_loss: 0.5412 - val_mse: 0.5412 - val_mae: 0.5401\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 685us/step - loss: 3.6387 - mse: 3.6387 - mae: 1.1922 - val_loss: 0.5406 - val_mse: 0.5406 - val_mae: 0.5398\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 453us/step - loss: 3.6091 - mse: 3.6091 - mae: 1.1904 - val_loss: 0.5399 - val_mse: 0.5399 - val_mae: 0.5392\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 531us/step - loss: 3.5832 - mse: 3.5832 - mae: 1.1884 - val_loss: 0.5421 - val_mse: 0.5421 - val_mae: 0.5418\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 530us/step - loss: 3.5568 - mse: 3.5568 - mae: 1.1847 - val_loss: 0.5438 - val_mse: 0.5438 - val_mae: 0.5450\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 497us/step - loss: 3.5338 - mse: 3.5338 - mae: 1.1810 - val_loss: 0.5438 - val_mse: 0.5438 - val_mae: 0.5480\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 717us/step - loss: 3.5090 - mse: 3.5090 - mae: 1.1786 - val_loss: 0.5442 - val_mse: 0.5442 - val_mae: 0.5512\n",
      "88\n",
      "[88]\n",
      "Train on 112 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 4s 34ms/step - loss: 77.6149 - mse: 77.6149 - mae: 8.4055 - val_loss: 35.4055 - val_mse: 35.4055 - val_mae: 5.8430\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 503us/step - loss: 62.7145 - mse: 62.7145 - mae: 7.5161 - val_loss: 28.1590 - val_mse: 28.1590 - val_mae: 5.1902\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 627us/step - loss: 50.0460 - mse: 50.0460 - mae: 6.6648 - val_loss: 22.0480 - val_mse: 22.0480 - val_mae: 4.5668\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 673us/step - loss: 39.3069 - mse: 39.3069 - mae: 5.8477 - val_loss: 16.9435 - val_mse: 16.9435 - val_mae: 3.9716\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 895us/step - loss: 30.2763 - mse: 30.2763 - mae: 5.0596 - val_loss: 12.6955 - val_mse: 12.6955 - val_mae: 3.3964\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 589us/step - loss: 22.8202 - mse: 22.8202 - mae: 4.3010 - val_loss: 9.2030 - val_mse: 9.2030 - val_mae: 2.8346\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 681us/step - loss: 16.7865 - mse: 16.7865 - mae: 3.5710 - val_loss: 6.4833 - val_mse: 6.4833 - val_mae: 2.2972\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 579us/step - loss: 12.1341 - mse: 12.1341 - mae: 2.8954 - val_loss: 4.4757 - val_mse: 4.4757 - val_mae: 1.7953\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 618us/step - loss: 8.7110 - mse: 8.7110 - mae: 2.3010 - val_loss: 3.1016 - val_mse: 3.1016 - val_mae: 1.3685\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 643us/step - loss: 6.3423 - mse: 6.3423 - mae: 1.8770 - val_loss: 2.2566 - val_mse: 2.2566 - val_mae: 1.1714\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 585us/step - loss: 4.8263 - mse: 4.8263 - mae: 1.6297 - val_loss: 1.8059 - val_mse: 1.8059 - val_mae: 1.0874\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 587us/step - loss: 3.9480 - mse: 3.9480 - mae: 1.4802 - val_loss: 1.6154 - val_mse: 1.6154 - val_mae: 1.0295\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 489us/step - loss: 3.4798 - mse: 3.4798 - mae: 1.4222 - val_loss: 1.5635 - val_mse: 1.5635 - val_mae: 0.9933\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 663us/step - loss: 3.2517 - mse: 3.2517 - mae: 1.4254 - val_loss: 1.5816 - val_mse: 1.5816 - val_mae: 0.9816\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 711us/step - loss: 3.1539 - mse: 3.1539 - mae: 1.4351 - val_loss: 1.6076 - val_mse: 1.6076 - val_mae: 0.9842\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 686us/step - loss: 3.1057 - mse: 3.1057 - mae: 1.4425 - val_loss: 1.6290 - val_mse: 1.6290 - val_mae: 0.9919\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 775us/step - loss: 3.0662 - mse: 3.0662 - mae: 1.4401 - val_loss: 1.6315 - val_mse: 1.6315 - val_mae: 0.9948\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 938us/step - loss: 3.0113 - mse: 3.0113 - mae: 1.4276 - val_loss: 1.6148 - val_mse: 1.6148 - val_mae: 0.9933\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 603us/step - loss: 2.9434 - mse: 2.9434 - mae: 1.4084 - val_loss: 1.5817 - val_mse: 1.5817 - val_mae: 0.9881\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 580us/step - loss: 2.8636 - mse: 2.8636 - mae: 1.3831 - val_loss: 1.5441 - val_mse: 1.5441 - val_mae: 0.9816\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 765us/step - loss: 2.7812 - mse: 2.7812 - mae: 1.3544 - val_loss: 1.5091 - val_mse: 1.5091 - val_mae: 0.9733\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 580us/step - loss: 2.6999 - mse: 2.6999 - mae: 1.3224 - val_loss: 1.4763 - val_mse: 1.4763 - val_mae: 0.9643\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 363us/step - loss: 2.6290 - mse: 2.6290 - mae: 1.2927 - val_loss: 1.4486 - val_mse: 1.4486 - val_mae: 0.9599\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 2.5678 - mse: 2.5678 - mae: 1.2709 - val_loss: 1.4258 - val_mse: 1.4258 - val_mae: 0.9552\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 692us/step - loss: 2.5126 - mse: 2.5126 - mae: 1.2534 - val_loss: 1.4038 - val_mse: 1.4038 - val_mae: 0.9488\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 473us/step - loss: 2.4663 - mse: 2.4663 - mae: 1.2399 - val_loss: 1.3842 - val_mse: 1.3842 - val_mae: 0.9441\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 679us/step - loss: 2.4320 - mse: 2.4320 - mae: 1.2308 - val_loss: 1.3645 - val_mse: 1.3645 - val_mae: 0.9376\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 530us/step - loss: 2.4000 - mse: 2.4000 - mae: 1.2238 - val_loss: 1.3451 - val_mse: 1.3451 - val_mae: 0.9298\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 542us/step - loss: 2.3663 - mse: 2.3663 - mae: 1.2178 - val_loss: 1.3276 - val_mse: 1.3276 - val_mae: 0.9223\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 911us/step - loss: 2.3338 - mse: 2.3338 - mae: 1.2131 - val_loss: 1.3123 - val_mse: 1.3123 - val_mae: 0.9151\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 948us/step - loss: 2.3048 - mse: 2.3048 - mae: 1.2091 - val_loss: 1.2993 - val_mse: 1.2993 - val_mae: 0.9094\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 413us/step - loss: 2.2768 - mse: 2.2768 - mae: 1.2052 - val_loss: 1.2857 - val_mse: 1.2857 - val_mae: 0.9038\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 650us/step - loss: 2.2496 - mse: 2.2496 - mae: 1.2005 - val_loss: 1.2738 - val_mse: 1.2738 - val_mae: 0.8995\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 895us/step - loss: 2.2230 - mse: 2.2230 - mae: 1.1950 - val_loss: 1.2581 - val_mse: 1.2581 - val_mae: 0.8951\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 604us/step - loss: 2.1959 - mse: 2.1959 - mae: 1.1878 - val_loss: 1.2418 - val_mse: 1.2418 - val_mae: 0.8911\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 401us/step - loss: 2.1697 - mse: 2.1697 - mae: 1.1798 - val_loss: 1.2272 - val_mse: 1.2272 - val_mae: 0.8873\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 599us/step - loss: 2.1485 - mse: 2.1485 - mae: 1.1727 - val_loss: 1.2143 - val_mse: 1.2143 - val_mae: 0.8838\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 669us/step - loss: 2.1292 - mse: 2.1292 - mae: 1.1665 - val_loss: 1.2040 - val_mse: 1.2040 - val_mae: 0.8811\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 2.1112 - mse: 2.1112 - mae: 1.1617 - val_loss: 1.1958 - val_mse: 1.1958 - val_mae: 0.8781\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 613us/step - loss: 2.0935 - mse: 2.0935 - mae: 1.1580 - val_loss: 1.1892 - val_mse: 1.1892 - val_mae: 0.8751\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 944us/step - loss: 2.0766 - mse: 2.0766 - mae: 1.1559 - val_loss: 1.1836 - val_mse: 1.1836 - val_mae: 0.8721\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 987us/step - loss: 2.0605 - mse: 2.0605 - mae: 1.1541 - val_loss: 1.1783 - val_mse: 1.1783 - val_mae: 0.8693\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 2.0452 - mse: 2.0452 - mae: 1.1523 - val_loss: 1.1742 - val_mse: 1.1742 - val_mae: 0.8667\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 431us/step - loss: 2.0306 - mse: 2.0306 - mae: 1.1504 - val_loss: 1.1706 - val_mse: 1.1706 - val_mae: 0.8644\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 561us/step - loss: 2.0164 - mse: 2.0164 - mae: 1.1482 - val_loss: 1.1672 - val_mse: 1.1672 - val_mae: 0.8625\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 377us/step - loss: 2.0025 - mse: 2.0025 - mae: 1.1457 - val_loss: 1.1639 - val_mse: 1.1639 - val_mae: 0.8610\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 474us/step - loss: 1.9892 - mse: 1.9892 - mae: 1.1424 - val_loss: 1.1586 - val_mse: 1.1586 - val_mae: 0.8599\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 910us/step - loss: 1.9763 - mse: 1.9763 - mae: 1.1384 - val_loss: 1.1536 - val_mse: 1.1536 - val_mae: 0.8589\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 0s 524us/step - loss: 1.9641 - mse: 1.9641 - mae: 1.1348 - val_loss: 1.1496 - val_mse: 1.1496 - val_mae: 0.8574\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 661us/step - loss: 1.9523 - mse: 1.9523 - mae: 1.1321 - val_loss: 1.1466 - val_mse: 1.1466 - val_mae: 0.8556\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.9414 - mse: 1.9414 - mae: 1.1300 - val_loss: 1.1441 - val_mse: 1.1441 - val_mae: 0.8541\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 0s 692us/step - loss: 1.9298 - mse: 1.9298 - mae: 1.1277 - val_loss: 1.1422 - val_mse: 1.1422 - val_mae: 0.8525\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.9186 - mse: 1.9186 - mae: 1.1259 - val_loss: 1.1407 - val_mse: 1.1407 - val_mae: 0.8507\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 0s 789us/step - loss: 1.9086 - mse: 1.9086 - mae: 1.1241 - val_loss: 1.1396 - val_mse: 1.1396 - val_mae: 0.8495\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 864us/step - loss: 1.8977 - mse: 1.8977 - mae: 1.1218 - val_loss: 1.1388 - val_mse: 1.1388 - val_mae: 0.8481\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 0s 858us/step - loss: 1.8877 - mse: 1.8877 - mae: 1.1199 - val_loss: 1.1383 - val_mse: 1.1383 - val_mae: 0.8470\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 0s 594us/step - loss: 1.8780 - mse: 1.8780 - mae: 1.1175 - val_loss: 1.1368 - val_mse: 1.1368 - val_mae: 0.8468\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.8690 - mse: 1.8690 - mae: 1.1145 - val_loss: 1.1360 - val_mse: 1.1360 - val_mae: 0.8478\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 687us/step - loss: 1.8602 - mse: 1.8602 - mae: 1.1121 - val_loss: 1.1349 - val_mse: 1.1349 - val_mae: 0.8476\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.8517 - mse: 1.8517 - mae: 1.1101 - val_loss: 1.1340 - val_mse: 1.1340 - val_mae: 0.8477\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 368us/step - loss: 1.8448 - mse: 1.8448 - mae: 1.1079 - val_loss: 1.1327 - val_mse: 1.1327 - val_mae: 0.8491\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 390us/step - loss: 1.8377 - mse: 1.8377 - mae: 1.1050 - val_loss: 1.1322 - val_mse: 1.1322 - val_mae: 0.8503\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.8298 - mse: 1.8298 - mae: 1.1031 - val_loss: 1.1333 - val_mse: 1.1333 - val_mae: 0.8507\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 756us/step - loss: 1.8224 - mse: 1.8224 - mae: 1.1025 - val_loss: 1.1343 - val_mse: 1.1343 - val_mae: 0.8504\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 417us/step - loss: 1.8149 - mse: 1.8149 - mae: 1.1020 - val_loss: 1.1350 - val_mse: 1.1350 - val_mae: 0.8506\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 856us/step - loss: 1.8093 - mse: 1.8093 - mae: 1.1010 - val_loss: 1.1357 - val_mse: 1.1357 - val_mae: 0.8516\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 646us/step - loss: 1.8025 - mse: 1.8025 - mae: 1.0988 - val_loss: 1.1360 - val_mse: 1.1360 - val_mae: 0.8533\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.7954 - mse: 1.7954 - mae: 1.0960 - val_loss: 1.1367 - val_mse: 1.1367 - val_mae: 0.8546\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.7890 - mse: 1.7890 - mae: 1.0943 - val_loss: 1.1387 - val_mse: 1.1387 - val_mae: 0.8551\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 825us/step - loss: 1.7830 - mse: 1.7830 - mae: 1.0933 - val_loss: 1.1403 - val_mse: 1.1403 - val_mae: 0.8562\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 380us/step - loss: 1.7770 - mse: 1.7770 - mae: 1.0916 - val_loss: 1.1413 - val_mse: 1.1413 - val_mae: 0.8575\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 1.7708 - mse: 1.7708 - mae: 1.0898 - val_loss: 1.1427 - val_mse: 1.1427 - val_mae: 0.8582\n",
      "89\n",
      "[89]\n",
      "Train on 138 samples, validate on 35 samples\n",
      "Epoch 1/100\n",
      "138/138 [==============================] - 3s 24ms/step - loss: 12.3064 - mse: 12.3064 - mae: 3.1178 - val_loss: 8.4025 - val_mse: 8.4025 - val_mae: 2.6349\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 0s 889us/step - loss: 9.1045 - mse: 9.1045 - mae: 2.5592 - val_loss: 6.0105 - val_mse: 6.0105 - val_mae: 2.1470\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 0s 728us/step - loss: 6.5622 - mse: 6.5622 - mae: 2.1011 - val_loss: 4.2490 - val_mse: 4.2490 - val_mae: 1.7488\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - 0s 422us/step - loss: 4.7869 - mse: 4.7869 - mae: 1.7296 - val_loss: 3.0284 - val_mse: 3.0284 - val_mae: 1.4594\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - 0s 542us/step - loss: 3.6669 - mse: 3.6669 - mae: 1.4661 - val_loss: 2.3108 - val_mse: 2.3108 - val_mae: 1.2529\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - 0s 656us/step - loss: 3.0782 - mse: 3.0782 - mae: 1.3309 - val_loss: 1.9602 - val_mse: 1.9602 - val_mae: 1.1600\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - 0s 933us/step - loss: 2.8171 - mse: 2.8171 - mae: 1.2892 - val_loss: 1.8106 - val_mse: 1.8106 - val_mae: 1.1094\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - 0s 640us/step - loss: 2.6856 - mse: 2.6856 - mae: 1.2737 - val_loss: 1.7495 - val_mse: 1.7495 - val_mae: 1.0768\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - 0s 614us/step - loss: 2.5917 - mse: 2.5917 - mae: 1.2576 - val_loss: 1.7153 - val_mse: 1.7153 - val_mae: 1.0616\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - 0s 382us/step - loss: 2.4963 - mse: 2.4963 - mae: 1.2319 - val_loss: 1.6964 - val_mse: 1.6964 - val_mae: 1.0557\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - 0s 508us/step - loss: 2.4060 - mse: 2.4060 - mae: 1.2026 - val_loss: 1.6954 - val_mse: 1.6954 - val_mae: 1.0550\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - 0s 586us/step - loss: 2.3336 - mse: 2.3336 - mae: 1.1770 - val_loss: 1.7082 - val_mse: 1.7082 - val_mae: 1.0567\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - 0s 723us/step - loss: 2.2742 - mse: 2.2742 - mae: 1.1575 - val_loss: 1.7247 - val_mse: 1.7247 - val_mae: 1.0635\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 2.2277 - mse: 2.2277 - mae: 1.1419 - val_loss: 1.7368 - val_mse: 1.7368 - val_mae: 1.0691\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - 0s 676us/step - loss: 2.1883 - mse: 2.1883 - mae: 1.1289 - val_loss: 1.7385 - val_mse: 1.7385 - val_mae: 1.0708\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - 0s 966us/step - loss: 2.1509 - mse: 2.1509 - mae: 1.1181 - val_loss: 1.7298 - val_mse: 1.7298 - val_mae: 1.0684\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - 0s 710us/step - loss: 2.1140 - mse: 2.1140 - mae: 1.1086 - val_loss: 1.7152 - val_mse: 1.7152 - val_mae: 1.0635\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - 0s 817us/step - loss: 2.0780 - mse: 2.0780 - mae: 1.1003 - val_loss: 1.7002 - val_mse: 1.7002 - val_mae: 1.0578\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - 0s 705us/step - loss: 2.0435 - mse: 2.0435 - mae: 1.0924 - val_loss: 1.6870 - val_mse: 1.6870 - val_mae: 1.0525\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - 0s 673us/step - loss: 2.0106 - mse: 2.0106 - mae: 1.0843 - val_loss: 1.6767 - val_mse: 1.6767 - val_mae: 1.0481\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - 0s 682us/step - loss: 1.9799 - mse: 1.9799 - mae: 1.0765 - val_loss: 1.6676 - val_mse: 1.6676 - val_mae: 1.0438\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - 0s 474us/step - loss: 1.9511 - mse: 1.9511 - mae: 1.0688 - val_loss: 1.6593 - val_mse: 1.6593 - val_mae: 1.0401\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - 0s 676us/step - loss: 1.9233 - mse: 1.9233 - mae: 1.0607 - val_loss: 1.6524 - val_mse: 1.6524 - val_mae: 1.0372\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - 0s 751us/step - loss: 1.8964 - mse: 1.8964 - mae: 1.0532 - val_loss: 1.6463 - val_mse: 1.6463 - val_mae: 1.0346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "138/138 [==============================] - 0s 721us/step - loss: 1.8709 - mse: 1.8709 - mae: 1.0463 - val_loss: 1.6404 - val_mse: 1.6404 - val_mae: 1.0321\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - 0s 535us/step - loss: 1.8463 - mse: 1.8463 - mae: 1.0396 - val_loss: 1.6345 - val_mse: 1.6345 - val_mae: 1.0293\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - 0s 963us/step - loss: 1.8232 - mse: 1.8232 - mae: 1.0335 - val_loss: 1.6282 - val_mse: 1.6282 - val_mae: 1.0258\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 1.8008 - mse: 1.8008 - mae: 1.0278 - val_loss: 1.6230 - val_mse: 1.6230 - val_mae: 1.0234\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - 0s 651us/step - loss: 1.7789 - mse: 1.7789 - mae: 1.0227 - val_loss: 1.6184 - val_mse: 1.6184 - val_mae: 1.0214\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - 0s 680us/step - loss: 1.7570 - mse: 1.7570 - mae: 1.0178 - val_loss: 1.6146 - val_mse: 1.6146 - val_mae: 1.0194\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - 0s 442us/step - loss: 1.7359 - mse: 1.7359 - mae: 1.0136 - val_loss: 1.6112 - val_mse: 1.6112 - val_mae: 1.0173\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - 0s 656us/step - loss: 1.7157 - mse: 1.7157 - mae: 1.0099 - val_loss: 1.6075 - val_mse: 1.6075 - val_mae: 1.0150\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - 0s 726us/step - loss: 1.6971 - mse: 1.6971 - mae: 1.0062 - val_loss: 1.6011 - val_mse: 1.6011 - val_mae: 1.0119\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - 0s 582us/step - loss: 1.6787 - mse: 1.6787 - mae: 1.0022 - val_loss: 1.5946 - val_mse: 1.5946 - val_mae: 1.0092\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - 0s 657us/step - loss: 1.6610 - mse: 1.6610 - mae: 0.9978 - val_loss: 1.5860 - val_mse: 1.5860 - val_mae: 1.0062\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - 0s 624us/step - loss: 1.6429 - mse: 1.6429 - mae: 0.9931 - val_loss: 1.5762 - val_mse: 1.5762 - val_mae: 1.0026\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - 0s 801us/step - loss: 1.6250 - mse: 1.6250 - mae: 0.9888 - val_loss: 1.5670 - val_mse: 1.5670 - val_mae: 0.9990\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - 0s 664us/step - loss: 1.6069 - mse: 1.6069 - mae: 0.9849 - val_loss: 1.5579 - val_mse: 1.5579 - val_mae: 0.9955\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - 0s 603us/step - loss: 1.5904 - mse: 1.5904 - mae: 0.9812 - val_loss: 1.5509 - val_mse: 1.5509 - val_mae: 0.9934\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - 0s 508us/step - loss: 1.5750 - mse: 1.5750 - mae: 0.9772 - val_loss: 1.5425 - val_mse: 1.5425 - val_mae: 0.9904\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - 0s 565us/step - loss: 1.5601 - mse: 1.5601 - mae: 0.9728 - val_loss: 1.5324 - val_mse: 1.5324 - val_mae: 0.9864\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - 0s 414us/step - loss: 1.5445 - mse: 1.5445 - mae: 0.9688 - val_loss: 1.5204 - val_mse: 1.5204 - val_mae: 0.9807\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - 0s 421us/step - loss: 1.5303 - mse: 1.5303 - mae: 0.9655 - val_loss: 1.5117 - val_mse: 1.5117 - val_mae: 0.9763\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - 0s 633us/step - loss: 1.5171 - mse: 1.5171 - mae: 0.9622 - val_loss: 1.5068 - val_mse: 1.5068 - val_mae: 0.9737\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - 0s 540us/step - loss: 1.5050 - mse: 1.5050 - mae: 0.9590 - val_loss: 1.5040 - val_mse: 1.5040 - val_mae: 0.9725\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - 0s 599us/step - loss: 1.4939 - mse: 1.4939 - mae: 0.9554 - val_loss: 1.5026 - val_mse: 1.5026 - val_mae: 0.9719\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - 0s 611us/step - loss: 1.4833 - mse: 1.4833 - mae: 0.9517 - val_loss: 1.5008 - val_mse: 1.5008 - val_mae: 0.9712\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - 0s 407us/step - loss: 1.4734 - mse: 1.4734 - mae: 0.9486 - val_loss: 1.4982 - val_mse: 1.4982 - val_mae: 0.9706\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - 0s 383us/step - loss: 1.4635 - mse: 1.4635 - mae: 0.9455 - val_loss: 1.4946 - val_mse: 1.4946 - val_mae: 0.9696\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - 0s 403us/step - loss: 1.4542 - mse: 1.4542 - mae: 0.9425 - val_loss: 1.4910 - val_mse: 1.4910 - val_mae: 0.9685\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - 0s 440us/step - loss: 1.4453 - mse: 1.4453 - mae: 0.9397 - val_loss: 1.4870 - val_mse: 1.4870 - val_mae: 0.9672\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - 0s 397us/step - loss: 1.4368 - mse: 1.4368 - mae: 0.9368 - val_loss: 1.4836 - val_mse: 1.4836 - val_mae: 0.9663\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - 0s 804us/step - loss: 1.4284 - mse: 1.4284 - mae: 0.9338 - val_loss: 1.4806 - val_mse: 1.4806 - val_mae: 0.9655\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - 0s 679us/step - loss: 1.4201 - mse: 1.4201 - mae: 0.9307 - val_loss: 1.4780 - val_mse: 1.4780 - val_mae: 0.9647\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - 0s 633us/step - loss: 1.4120 - mse: 1.4120 - mae: 0.9277 - val_loss: 1.4756 - val_mse: 1.4756 - val_mae: 0.9640\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - 0s 459us/step - loss: 1.4041 - mse: 1.4041 - mae: 0.9249 - val_loss: 1.4739 - val_mse: 1.4739 - val_mae: 0.9635\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - 0s 495us/step - loss: 1.3964 - mse: 1.3964 - mae: 0.9220 - val_loss: 1.4715 - val_mse: 1.4715 - val_mae: 0.9627\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - 0s 536us/step - loss: 1.3890 - mse: 1.3890 - mae: 0.9190 - val_loss: 1.4692 - val_mse: 1.4692 - val_mae: 0.9621\n",
      "Epoch 59/100\n",
      "138/138 [==============================] - 0s 590us/step - loss: 1.3814 - mse: 1.3814 - mae: 0.9161 - val_loss: 1.4669 - val_mse: 1.4669 - val_mae: 0.9613\n",
      "Epoch 60/100\n",
      "138/138 [==============================] - 0s 565us/step - loss: 1.3742 - mse: 1.3742 - mae: 0.9130 - val_loss: 1.4650 - val_mse: 1.4650 - val_mae: 0.9606\n",
      "Epoch 61/100\n",
      "138/138 [==============================] - 0s 574us/step - loss: 1.3671 - mse: 1.3671 - mae: 0.9099 - val_loss: 1.4641 - val_mse: 1.4641 - val_mae: 0.9600\n",
      "Epoch 62/100\n",
      "138/138 [==============================] - 0s 538us/step - loss: 1.3602 - mse: 1.3602 - mae: 0.9069 - val_loss: 1.4644 - val_mse: 1.4644 - val_mae: 0.9600\n",
      "Epoch 63/100\n",
      "138/138 [==============================] - 0s 494us/step - loss: 1.3535 - mse: 1.3535 - mae: 0.9038 - val_loss: 1.4638 - val_mse: 1.4638 - val_mae: 0.9596\n",
      "Epoch 64/100\n",
      "138/138 [==============================] - 0s 554us/step - loss: 1.3469 - mse: 1.3469 - mae: 0.9006 - val_loss: 1.4634 - val_mse: 1.4634 - val_mae: 0.9594\n",
      "Epoch 65/100\n",
      "138/138 [==============================] - 0s 545us/step - loss: 1.3407 - mse: 1.3407 - mae: 0.8977 - val_loss: 1.4626 - val_mse: 1.4626 - val_mae: 0.9589\n",
      "Epoch 66/100\n",
      "138/138 [==============================] - 0s 536us/step - loss: 1.3346 - mse: 1.3346 - mae: 0.8949 - val_loss: 1.4608 - val_mse: 1.4608 - val_mae: 0.9580\n",
      "Epoch 67/100\n",
      "138/138 [==============================] - 0s 886us/step - loss: 1.3286 - mse: 1.3286 - mae: 0.8923 - val_loss: 1.4605 - val_mse: 1.4605 - val_mae: 0.9576\n",
      "Epoch 68/100\n",
      "138/138 [==============================] - 0s 521us/step - loss: 1.3227 - mse: 1.3227 - mae: 0.8897 - val_loss: 1.4605 - val_mse: 1.4605 - val_mae: 0.9573\n",
      "Epoch 69/100\n",
      "138/138 [==============================] - 0s 857us/step - loss: 1.3171 - mse: 1.3171 - mae: 0.8869 - val_loss: 1.4600 - val_mse: 1.4600 - val_mae: 0.9568\n",
      "Epoch 70/100\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 1.3115 - mse: 1.3115 - mae: 0.8844 - val_loss: 1.4605 - val_mse: 1.4605 - val_mae: 0.9564\n",
      "Epoch 71/100\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 1.3059 - mse: 1.3059 - mae: 0.8821 - val_loss: 1.4607 - val_mse: 1.4607 - val_mae: 0.9559\n",
      "Epoch 72/100\n",
      "138/138 [==============================] - 0s 663us/step - loss: 1.3004 - mse: 1.3004 - mae: 0.8795 - val_loss: 1.4614 - val_mse: 1.4614 - val_mae: 0.9558\n",
      "Epoch 73/100\n",
      "138/138 [==============================] - 0s 419us/step - loss: 1.2951 - mse: 1.2951 - mae: 0.8768 - val_loss: 1.4622 - val_mse: 1.4622 - val_mae: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "138/138 [==============================] - 0s 745us/step - loss: 1.2898 - mse: 1.2898 - mae: 0.8740 - val_loss: 1.4627 - val_mse: 1.4627 - val_mae: 0.9550\n",
      "Epoch 75/100\n",
      "138/138 [==============================] - 0s 424us/step - loss: 1.2843 - mse: 1.2843 - mae: 0.8714 - val_loss: 1.4644 - val_mse: 1.4644 - val_mae: 0.9550\n",
      "Epoch 76/100\n",
      "138/138 [==============================] - 0s 568us/step - loss: 1.2788 - mse: 1.2788 - mae: 0.8685 - val_loss: 1.4656 - val_mse: 1.4656 - val_mae: 0.9551\n",
      "Epoch 77/100\n",
      "138/138 [==============================] - 0s 442us/step - loss: 1.2737 - mse: 1.2737 - mae: 0.8662 - val_loss: 1.4660 - val_mse: 1.4660 - val_mae: 0.9547\n",
      "Epoch 78/100\n",
      "138/138 [==============================] - 0s 406us/step - loss: 1.2687 - mse: 1.2687 - mae: 0.8643 - val_loss: 1.4657 - val_mse: 1.4657 - val_mae: 0.9540\n",
      "Epoch 79/100\n",
      "138/138 [==============================] - 0s 659us/step - loss: 1.2642 - mse: 1.2642 - mae: 0.8624 - val_loss: 1.4661 - val_mse: 1.4661 - val_mae: 0.9535\n",
      "90\n",
      "[90]\n",
      "Train on 85 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 8.9260 - mse: 8.9260 - mae: 2.5431 - val_loss: 4.6608 - val_mse: 4.6608 - val_mae: 1.8266\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 529us/step - loss: 7.6068 - mse: 7.6068 - mae: 2.2779 - val_loss: 3.8848 - val_mse: 3.8848 - val_mae: 1.5983\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 817us/step - loss: 6.5368 - mse: 6.5368 - mae: 2.0430 - val_loss: 3.2780 - val_mse: 3.2780 - val_mae: 1.3938\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 706us/step - loss: 5.6794 - mse: 5.6794 - mae: 1.8328 - val_loss: 2.8145 - val_mse: 2.8145 - val_mae: 1.2079\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 526us/step - loss: 4.9667 - mse: 4.9667 - mae: 1.6459 - val_loss: 2.4411 - val_mse: 2.4411 - val_mae: 1.0622\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 536us/step - loss: 4.3876 - mse: 4.3876 - mae: 1.4814 - val_loss: 2.1535 - val_mse: 2.1535 - val_mae: 0.9723\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 643us/step - loss: 3.9051 - mse: 3.9051 - mae: 1.3568 - val_loss: 1.9277 - val_mse: 1.9277 - val_mae: 0.8948\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 595us/step - loss: 3.5237 - mse: 3.5237 - mae: 1.2721 - val_loss: 1.7511 - val_mse: 1.7511 - val_mae: 0.8606\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 945us/step - loss: 3.2244 - mse: 3.2244 - mae: 1.2123 - val_loss: 1.6172 - val_mse: 1.6172 - val_mae: 0.8362\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 840us/step - loss: 2.9852 - mse: 2.9852 - mae: 1.1733 - val_loss: 1.5235 - val_mse: 1.5235 - val_mae: 0.8288\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 695us/step - loss: 2.7971 - mse: 2.7971 - mae: 1.1407 - val_loss: 1.4560 - val_mse: 1.4560 - val_mae: 0.8380\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6606 - mse: 2.6606 - mae: 1.1164 - val_loss: 1.4090 - val_mse: 1.4090 - val_mae: 0.8529\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 535us/step - loss: 2.5588 - mse: 2.5588 - mae: 1.0984 - val_loss: 1.3800 - val_mse: 1.3800 - val_mae: 0.8659\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 547us/step - loss: 2.4856 - mse: 2.4856 - mae: 1.0845 - val_loss: 1.3688 - val_mse: 1.3688 - val_mae: 0.8814\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 866us/step - loss: 2.4332 - mse: 2.4332 - mae: 1.0767 - val_loss: 1.3671 - val_mse: 1.3671 - val_mae: 0.9013\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.1333 - mse: 4.1333 - mae: 1.207 - 0s 501us/step - loss: 2.3984 - mse: 2.3984 - mae: 1.0743 - val_loss: 1.3693 - val_mse: 1.3693 - val_mae: 0.9184\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 435us/step - loss: 2.3762 - mse: 2.3762 - mae: 1.0744 - val_loss: 1.3734 - val_mse: 1.3734 - val_mae: 0.9309\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 398us/step - loss: 2.3622 - mse: 2.3622 - mae: 1.0765 - val_loss: 1.3764 - val_mse: 1.3764 - val_mae: 0.9395\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 483us/step - loss: 2.3523 - mse: 2.3523 - mae: 1.0768 - val_loss: 1.3759 - val_mse: 1.3759 - val_mae: 0.9443\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 463us/step - loss: 2.3438 - mse: 2.3438 - mae: 1.0755 - val_loss: 1.3750 - val_mse: 1.3750 - val_mae: 0.9463\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 848us/step - loss: 2.3360 - mse: 2.3360 - mae: 1.0736 - val_loss: 1.3708 - val_mse: 1.3708 - val_mae: 0.9454\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 851us/step - loss: 2.3285 - mse: 2.3285 - mae: 1.0709 - val_loss: 1.3633 - val_mse: 1.3633 - val_mae: 0.9423\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.3203 - mse: 2.3203 - mae: 1.0672 - val_loss: 1.3546 - val_mse: 1.3546 - val_mae: 0.9382\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 770us/step - loss: 2.3115 - mse: 2.3115 - mae: 1.0627 - val_loss: 1.3447 - val_mse: 1.3447 - val_mae: 0.9333\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.3025 - mse: 2.3025 - mae: 1.0576 - val_loss: 1.3341 - val_mse: 1.3341 - val_mae: 0.9278\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 665us/step - loss: 2.2938 - mse: 2.2938 - mae: 1.0522 - val_loss: 1.3251 - val_mse: 1.3251 - val_mae: 0.9228\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 434us/step - loss: 2.2857 - mse: 2.2857 - mae: 1.0471 - val_loss: 1.3176 - val_mse: 1.3176 - val_mae: 0.9183\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.2779 - mse: 2.2779 - mae: 1.0427 - val_loss: 1.3117 - val_mse: 1.3117 - val_mae: 0.9147\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.2704 - mse: 2.2704 - mae: 1.0389 - val_loss: 1.3072 - val_mse: 1.3072 - val_mae: 0.9117\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.2630 - mse: 2.2630 - mae: 1.0355 - val_loss: 1.3037 - val_mse: 1.3037 - val_mae: 0.9095\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.2555 - mse: 2.2555 - mae: 1.0323 - val_loss: 1.3014 - val_mse: 1.3014 - val_mae: 0.9079\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 439us/step - loss: 2.2484 - mse: 2.2484 - mae: 1.0293 - val_loss: 1.2992 - val_mse: 1.2992 - val_mae: 0.9066\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.2412 - mse: 2.2412 - mae: 1.0262 - val_loss: 1.2975 - val_mse: 1.2975 - val_mae: 0.9057\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 862us/step - loss: 2.2345 - mse: 2.2345 - mae: 1.0234 - val_loss: 1.2963 - val_mse: 1.2963 - val_mae: 0.9051\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 531us/step - loss: 2.2280 - mse: 2.2280 - mae: 1.0208 - val_loss: 1.2955 - val_mse: 1.2955 - val_mae: 0.9048\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.2217 - mse: 2.2217 - mae: 1.0183 - val_loss: 1.2952 - val_mse: 1.2952 - val_mae: 0.9049\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 729us/step - loss: 2.2154 - mse: 2.2154 - mae: 1.0159 - val_loss: 1.2950 - val_mse: 1.2950 - val_mae: 0.9049\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 440us/step - loss: 2.2093 - mse: 2.2093 - mae: 1.0136 - val_loss: 1.2949 - val_mse: 1.2949 - val_mae: 0.9050\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 534us/step - loss: 2.2033 - mse: 2.2033 - mae: 1.0115 - val_loss: 1.2947 - val_mse: 1.2947 - val_mae: 0.9051\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 853us/step - loss: 2.1977 - mse: 2.1977 - mae: 1.0095 - val_loss: 1.2943 - val_mse: 1.2943 - val_mae: 0.9050\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 854us/step - loss: 2.1921 - mse: 2.1921 - mae: 1.0075 - val_loss: 1.2934 - val_mse: 1.2934 - val_mae: 0.9045\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 680us/step - loss: 2.1869 - mse: 2.1869 - mae: 1.0055 - val_loss: 1.2922 - val_mse: 1.2922 - val_mae: 0.9038\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 866us/step - loss: 2.1820 - mse: 2.1820 - mae: 1.0037 - val_loss: 1.2912 - val_mse: 1.2912 - val_mae: 0.9029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 781us/step - loss: 2.1769 - mse: 2.1769 - mae: 1.0020 - val_loss: 1.2901 - val_mse: 1.2901 - val_mae: 0.9020\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 639us/step - loss: 2.1717 - mse: 2.1717 - mae: 1.0003 - val_loss: 1.2885 - val_mse: 1.2885 - val_mae: 0.9006\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 753us/step - loss: 2.1664 - mse: 2.1664 - mae: 0.9985 - val_loss: 1.2868 - val_mse: 1.2868 - val_mae: 0.8990\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 619us/step - loss: 2.1610 - mse: 2.1610 - mae: 0.9967 - val_loss: 1.2846 - val_mse: 1.2846 - val_mae: 0.8972\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1557 - mse: 2.1557 - mae: 0.9948 - val_loss: 1.2816 - val_mse: 1.2816 - val_mae: 0.8949\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 866us/step - loss: 2.1504 - mse: 2.1504 - mae: 0.9927 - val_loss: 1.2787 - val_mse: 1.2787 - val_mae: 0.8938\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.1450 - mse: 2.1450 - mae: 0.9905 - val_loss: 1.2760 - val_mse: 1.2760 - val_mae: 0.8930\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.1396 - mse: 2.1396 - mae: 0.9881 - val_loss: 1.2730 - val_mse: 1.2730 - val_mae: 0.8921\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.1343 - mse: 2.1343 - mae: 0.9858 - val_loss: 1.2701 - val_mse: 1.2701 - val_mae: 0.8912\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 552us/step - loss: 2.1290 - mse: 2.1290 - mae: 0.9836 - val_loss: 1.2673 - val_mse: 1.2673 - val_mae: 0.8906\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 801us/step - loss: 2.1236 - mse: 2.1236 - mae: 0.9814 - val_loss: 1.2649 - val_mse: 1.2649 - val_mae: 0.8902\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 419us/step - loss: 2.1183 - mse: 2.1183 - mae: 0.9794 - val_loss: 1.2632 - val_mse: 1.2632 - val_mae: 0.8900\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 598us/step - loss: 2.1130 - mse: 2.1130 - mae: 0.9776 - val_loss: 1.2627 - val_mse: 1.2627 - val_mae: 0.8902\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 722us/step - loss: 2.1077 - mse: 2.1077 - mae: 0.9761 - val_loss: 1.2624 - val_mse: 1.2624 - val_mae: 0.8908\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 452us/step - loss: 2.1028 - mse: 2.1028 - mae: 0.9747 - val_loss: 1.2616 - val_mse: 1.2616 - val_mae: 0.8915\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 918us/step - loss: 2.0980 - mse: 2.0980 - mae: 0.9730 - val_loss: 1.2606 - val_mse: 1.2606 - val_mae: 0.8921\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 815us/step - loss: 2.0934 - mse: 2.0934 - mae: 0.9714 - val_loss: 1.2594 - val_mse: 1.2594 - val_mae: 0.8923\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 863us/step - loss: 2.0891 - mse: 2.0891 - mae: 0.9698 - val_loss: 1.2574 - val_mse: 1.2574 - val_mae: 0.8920\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.0844 - mse: 2.0844 - mae: 0.9680 - val_loss: 1.2550 - val_mse: 1.2550 - val_mae: 0.8913\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.0801 - mse: 2.0801 - mae: 0.9661 - val_loss: 1.2527 - val_mse: 1.2527 - val_mae: 0.8907\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 833us/step - loss: 2.0758 - mse: 2.0758 - mae: 0.9644 - val_loss: 1.2522 - val_mse: 1.2522 - val_mae: 0.8907\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.0712 - mse: 2.0712 - mae: 0.9626 - val_loss: 1.2514 - val_mse: 1.2514 - val_mae: 0.8908\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.5724 - mse: 3.5724 - mae: 1.070 - 0s 523us/step - loss: 2.0672 - mse: 2.0672 - mae: 0.9608 - val_loss: 1.2494 - val_mse: 1.2494 - val_mae: 0.8904\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 716us/step - loss: 2.0632 - mse: 2.0632 - mae: 0.9590 - val_loss: 1.2479 - val_mse: 1.2479 - val_mae: 0.8900\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 526us/step - loss: 2.0589 - mse: 2.0589 - mae: 0.9572 - val_loss: 1.2468 - val_mse: 1.2468 - val_mae: 0.8896\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 549us/step - loss: 2.0547 - mse: 2.0547 - mae: 0.9555 - val_loss: 1.2453 - val_mse: 1.2453 - val_mae: 0.8890\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 895us/step - loss: 2.0506 - mse: 2.0506 - mae: 0.9537 - val_loss: 1.2432 - val_mse: 1.2432 - val_mae: 0.8885\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.0466 - mse: 2.0466 - mae: 0.9516 - val_loss: 1.2408 - val_mse: 1.2408 - val_mae: 0.8881\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 618us/step - loss: 2.0423 - mse: 2.0423 - mae: 0.9496 - val_loss: 1.2391 - val_mse: 1.2391 - val_mae: 0.8877\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 426us/step - loss: 2.0376 - mse: 2.0376 - mae: 0.9475 - val_loss: 1.2375 - val_mse: 1.2375 - val_mae: 0.8873\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 999us/step - loss: 2.0325 - mse: 2.0325 - mae: 0.9452 - val_loss: 1.2353 - val_mse: 1.2353 - val_mae: 0.8867\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 757us/step - loss: 2.0271 - mse: 2.0271 - mae: 0.9427 - val_loss: 1.2329 - val_mse: 1.2329 - val_mae: 0.8863\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 963us/step - loss: 2.0218 - mse: 2.0218 - mae: 0.9401 - val_loss: 1.2314 - val_mse: 1.2314 - val_mae: 0.8862\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 937us/step - loss: 2.0165 - mse: 2.0165 - mae: 0.9375 - val_loss: 1.2302 - val_mse: 1.2302 - val_mae: 0.8862\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 581us/step - loss: 2.0114 - mse: 2.0114 - mae: 0.9353 - val_loss: 1.2292 - val_mse: 1.2292 - val_mae: 0.8862\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2.0062 - mse: 2.0062 - mae: 0.9332 - val_loss: 1.2284 - val_mse: 1.2284 - val_mae: 0.8859\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 425us/step - loss: 2.0011 - mse: 2.0011 - mae: 0.9311 - val_loss: 1.2285 - val_mse: 1.2285 - val_mae: 0.8860\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 796us/step - loss: 1.9962 - mse: 1.9962 - mae: 0.9293 - val_loss: 1.2277 - val_mse: 1.2277 - val_mae: 0.8855\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 760us/step - loss: 1.9911 - mse: 1.9911 - mae: 0.9272 - val_loss: 1.2266 - val_mse: 1.2266 - val_mae: 0.8852\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 0s 550us/step - loss: 1.9864 - mse: 1.9864 - mae: 0.9253 - val_loss: 1.2269 - val_mse: 1.2269 - val_mae: 0.8855\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 695us/step - loss: 1.9816 - mse: 1.9816 - mae: 0.9237 - val_loss: 1.2269 - val_mse: 1.2269 - val_mae: 0.8856\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 669us/step - loss: 1.9771 - mse: 1.9771 - mae: 0.9221 - val_loss: 1.2258 - val_mse: 1.2258 - val_mae: 0.8852\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 698us/step - loss: 1.9726 - mse: 1.9726 - mae: 0.9206 - val_loss: 1.2261 - val_mse: 1.2261 - val_mae: 0.8854\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1.9680 - mse: 1.9680 - mae: 0.9191 - val_loss: 1.2261 - val_mse: 1.2261 - val_mae: 0.8855\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 571us/step - loss: 1.9635 - mse: 1.9635 - mae: 0.9176 - val_loss: 1.2268 - val_mse: 1.2268 - val_mae: 0.8858\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 626us/step - loss: 1.9592 - mse: 1.9592 - mae: 0.9163 - val_loss: 1.2263 - val_mse: 1.2263 - val_mae: 0.8857\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 609us/step - loss: 1.9549 - mse: 1.9549 - mae: 0.9144 - val_loss: 1.2245 - val_mse: 1.2245 - val_mae: 0.8850\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 657us/step - loss: 1.9510 - mse: 1.9510 - mae: 0.9128 - val_loss: 1.2251 - val_mse: 1.2251 - val_mae: 0.8852\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 805us/step - loss: 1.9465 - mse: 1.9465 - mae: 0.9113 - val_loss: 1.2242 - val_mse: 1.2242 - val_mae: 0.8848\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 764us/step - loss: 1.9420 - mse: 1.9420 - mae: 0.9094 - val_loss: 1.2227 - val_mse: 1.2227 - val_mae: 0.8843\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 770us/step - loss: 1.9375 - mse: 1.9375 - mae: 0.9073 - val_loss: 1.2206 - val_mse: 1.2206 - val_mae: 0.8835\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 674us/step - loss: 1.9325 - mse: 1.9325 - mae: 0.9050 - val_loss: 1.2186 - val_mse: 1.2186 - val_mae: 0.8828\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 745us/step - loss: 1.9274 - mse: 1.9274 - mae: 0.9028 - val_loss: 1.2178 - val_mse: 1.2178 - val_mae: 0.8825\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 842us/step - loss: 1.9225 - mse: 1.9225 - mae: 0.9008 - val_loss: 1.2183 - val_mse: 1.2183 - val_mae: 0.8827\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 756us/step - loss: 1.9170 - mse: 1.9170 - mae: 0.8986 - val_loss: 1.2168 - val_mse: 1.2168 - val_mae: 0.8821\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 678us/step - loss: 1.9109 - mse: 1.9109 - mae: 0.8957 - val_loss: 1.2130 - val_mse: 1.2130 - val_mae: 0.8804\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 852us/step - loss: 1.9047 - mse: 1.9047 - mae: 0.8924 - val_loss: 1.2090 - val_mse: 1.2090 - val_mae: 0.8784\n",
      "91\n",
      "[91]\n",
      "Train on 118 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 6.2556 - mse: 6.2556 - mae: 1.9477 - val_loss: 3.7580 - val_mse: 3.7580 - val_mae: 1.6578\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 0s 489us/step - loss: 4.7882 - mse: 4.7882 - mae: 1.5671 - val_loss: 2.7156 - val_mse: 2.7156 - val_mae: 1.3646\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 0s 542us/step - loss: 3.7975 - mse: 3.7975 - mae: 1.3088 - val_loss: 1.9897 - val_mse: 1.9897 - val_mae: 1.1500\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 0s 529us/step - loss: 3.1767 - mse: 3.1767 - mae: 1.1511 - val_loss: 1.5389 - val_mse: 1.5389 - val_mae: 1.0234\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 0s 650us/step - loss: 2.8305 - mse: 2.8305 - mae: 1.0831 - val_loss: 1.2783 - val_mse: 1.2783 - val_mae: 0.9505\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 0s 762us/step - loss: 2.6503 - mse: 2.6503 - mae: 1.0550 - val_loss: 1.1314 - val_mse: 1.1314 - val_mae: 0.9057\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 0s 566us/step - loss: 2.5662 - mse: 2.5662 - mae: 1.0551 - val_loss: 1.0466 - val_mse: 1.0466 - val_mae: 0.8698\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 0s 594us/step - loss: 2.5324 - mse: 2.5324 - mae: 1.0597 - val_loss: 1.0007 - val_mse: 1.0007 - val_mae: 0.8467\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 0s 547us/step - loss: 2.5141 - mse: 2.5141 - mae: 1.0677 - val_loss: 0.9768 - val_mse: 0.9768 - val_mae: 0.8359\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 0s 699us/step - loss: 2.4941 - mse: 2.4941 - mae: 1.0687 - val_loss: 0.9647 - val_mse: 0.9647 - val_mae: 0.8304\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 0s 571us/step - loss: 2.4670 - mse: 2.4670 - mae: 1.0609 - val_loss: 0.9610 - val_mse: 0.9610 - val_mae: 0.8289\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 0s 606us/step - loss: 2.4363 - mse: 2.4363 - mae: 1.0471 - val_loss: 0.9615 - val_mse: 0.9615 - val_mae: 0.8295\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 0s 651us/step - loss: 2.4082 - mse: 2.4082 - mae: 1.0313 - val_loss: 0.9651 - val_mse: 0.9651 - val_mae: 0.8332\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 0s 607us/step - loss: 2.3833 - mse: 2.3833 - mae: 1.0168 - val_loss: 0.9709 - val_mse: 0.9709 - val_mae: 0.8379\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 0s 631us/step - loss: 2.3606 - mse: 2.3606 - mae: 1.0033 - val_loss: 0.9769 - val_mse: 0.9769 - val_mae: 0.8423\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 0s 644us/step - loss: 2.3407 - mse: 2.3407 - mae: 0.9936 - val_loss: 0.9784 - val_mse: 0.9784 - val_mae: 0.8439\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 0s 696us/step - loss: 2.3217 - mse: 2.3217 - mae: 0.9855 - val_loss: 0.9757 - val_mse: 0.9757 - val_mae: 0.8427\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 0s 625us/step - loss: 2.3028 - mse: 2.3028 - mae: 0.9794 - val_loss: 0.9698 - val_mse: 0.9698 - val_mae: 0.8393\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 0s 886us/step - loss: 2.2816 - mse: 2.2816 - mae: 0.9744 - val_loss: 0.9634 - val_mse: 0.9634 - val_mae: 0.8363\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 0s 632us/step - loss: 2.2612 - mse: 2.2612 - mae: 0.9704 - val_loss: 0.9560 - val_mse: 0.9560 - val_mae: 0.8328\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 0s 680us/step - loss: 2.2414 - mse: 2.2414 - mae: 0.9671 - val_loss: 0.9483 - val_mse: 0.9483 - val_mae: 0.8286\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 0s 559us/step - loss: 2.2231 - mse: 2.2231 - mae: 0.9640 - val_loss: 0.9411 - val_mse: 0.9411 - val_mae: 0.8246\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 0s 555us/step - loss: 2.2053 - mse: 2.2053 - mae: 0.9610 - val_loss: 0.9345 - val_mse: 0.9345 - val_mae: 0.8215\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 0s 716us/step - loss: 2.1878 - mse: 2.1878 - mae: 0.9578 - val_loss: 0.9278 - val_mse: 0.9278 - val_mae: 0.8184\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 0s 892us/step - loss: 2.1710 - mse: 2.1710 - mae: 0.9551 - val_loss: 0.9215 - val_mse: 0.9215 - val_mae: 0.8155\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 0s 616us/step - loss: 2.1553 - mse: 2.1553 - mae: 0.9520 - val_loss: 0.9159 - val_mse: 0.9159 - val_mae: 0.8127\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 0s 491us/step - loss: 2.1421 - mse: 2.1421 - mae: 0.9494 - val_loss: 0.9106 - val_mse: 0.9106 - val_mae: 0.8101\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 0s 450us/step - loss: 2.1290 - mse: 2.1290 - mae: 0.9470 - val_loss: 0.9057 - val_mse: 0.9057 - val_mae: 0.8074\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 0s 917us/step - loss: 2.1165 - mse: 2.1165 - mae: 0.9448 - val_loss: 0.9014 - val_mse: 0.9014 - val_mae: 0.8047\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 0s 932us/step - loss: 2.1046 - mse: 2.1046 - mae: 0.9426 - val_loss: 0.8976 - val_mse: 0.8976 - val_mae: 0.8021\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 0s 657us/step - loss: 2.0938 - mse: 2.0938 - mae: 0.9407 - val_loss: 0.8947 - val_mse: 0.8947 - val_mae: 0.8003\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 0s 606us/step - loss: 2.0830 - mse: 2.0830 - mae: 0.9384 - val_loss: 0.8925 - val_mse: 0.8925 - val_mae: 0.7990\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 0s 497us/step - loss: 2.0721 - mse: 2.0721 - mae: 0.9357 - val_loss: 0.8910 - val_mse: 0.8910 - val_mae: 0.7982\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 0s 690us/step - loss: 2.0616 - mse: 2.0616 - mae: 0.9330 - val_loss: 0.8897 - val_mse: 0.8897 - val_mae: 0.7975\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2.0514 - mse: 2.0514 - mae: 0.9301 - val_loss: 0.8887 - val_mse: 0.8887 - val_mae: 0.7972\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 0s 849us/step - loss: 2.0412 - mse: 2.0412 - mae: 0.9270 - val_loss: 0.8880 - val_mse: 0.8880 - val_mae: 0.7971\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 0s 466us/step - loss: 2.0292 - mse: 2.0292 - mae: 0.9233 - val_loss: 0.8872 - val_mse: 0.8872 - val_mae: 0.7971\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 0s 684us/step - loss: 2.0167 - mse: 2.0167 - mae: 0.9202 - val_loss: 0.8855 - val_mse: 0.8855 - val_mae: 0.7967\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 0s 653us/step - loss: 2.0046 - mse: 2.0046 - mae: 0.9175 - val_loss: 0.8815 - val_mse: 0.8815 - val_mae: 0.7956\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 0s 589us/step - loss: 1.9925 - mse: 1.9925 - mae: 0.9153 - val_loss: 0.8769 - val_mse: 0.8769 - val_mae: 0.7935\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 0s 501us/step - loss: 1.9870 - mse: 1.9870 - mae: 0.9139 - val_loss: 0.8742 - val_mse: 0.8742 - val_mae: 0.7910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "118/118 [==============================] - 0s 684us/step - loss: 1.9764 - mse: 1.9764 - mae: 0.9130 - val_loss: 0.8735 - val_mse: 0.8735 - val_mae: 0.7884\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.9638 - mse: 1.9638 - mae: 0.9129 - val_loss: 0.8748 - val_mse: 0.8748 - val_mae: 0.7864\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 0s 586us/step - loss: 1.9529 - mse: 1.9529 - mae: 0.9135 - val_loss: 0.8747 - val_mse: 0.8747 - val_mae: 0.7855\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 0s 481us/step - loss: 1.9422 - mse: 1.9422 - mae: 0.9109 - val_loss: 0.8734 - val_mse: 0.8734 - val_mae: 0.7854\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - ETA: 0s - loss: 2.0950 - mse: 2.0950 - mae: 0.940 - 0s 868us/step - loss: 1.9312 - mse: 1.9312 - mae: 0.9069 - val_loss: 0.8737 - val_mse: 0.8737 - val_mae: 0.7862\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 0s 759us/step - loss: 1.9216 - mse: 1.9216 - mae: 0.9036 - val_loss: 0.8757 - val_mse: 0.8757 - val_mae: 0.7868\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 0s 501us/step - loss: 1.9128 - mse: 1.9128 - mae: 0.9011 - val_loss: 0.8761 - val_mse: 0.8761 - val_mae: 0.7867\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 0s 369us/step - loss: 1.9027 - mse: 1.9027 - mae: 0.8976 - val_loss: 0.8736 - val_mse: 0.8736 - val_mae: 0.7854\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 0s 722us/step - loss: 1.8968 - mse: 1.8968 - mae: 0.8941 - val_loss: 0.8733 - val_mse: 0.8733 - val_mae: 0.7846\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 0s 351us/step - loss: 1.8889 - mse: 1.8889 - mae: 0.8918 - val_loss: 0.8737 - val_mse: 0.8737 - val_mae: 0.7829\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.8794 - mse: 1.8794 - mae: 0.8904 - val_loss: 0.8743 - val_mse: 0.8743 - val_mae: 0.7810\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 0s 663us/step - loss: 1.8711 - mse: 1.8711 - mae: 0.8886 - val_loss: 0.8730 - val_mse: 0.8730 - val_mae: 0.7800\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 0s 525us/step - loss: 1.8614 - mse: 1.8614 - mae: 0.8851 - val_loss: 0.8702 - val_mse: 0.8702 - val_mae: 0.7797\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 0s 683us/step - loss: 1.8537 - mse: 1.8537 - mae: 0.8813 - val_loss: 0.8682 - val_mse: 0.8682 - val_mae: 0.7783\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 0s 957us/step - loss: 1.8454 - mse: 1.8454 - mae: 0.8792 - val_loss: 0.8679 - val_mse: 0.8679 - val_mae: 0.7762\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 0s 465us/step - loss: 1.8364 - mse: 1.8364 - mae: 0.8777 - val_loss: 0.8671 - val_mse: 0.8671 - val_mae: 0.7744\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 0s 519us/step - loss: 1.8276 - mse: 1.8276 - mae: 0.8748 - val_loss: 0.8664 - val_mse: 0.8664 - val_mae: 0.7751\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 0s 515us/step - loss: 1.8224 - mse: 1.8224 - mae: 0.8721 - val_loss: 0.8667 - val_mse: 0.8667 - val_mae: 0.7746\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.8145 - mse: 1.8145 - mae: 0.8709 - val_loss: 0.8673 - val_mse: 0.8673 - val_mae: 0.7726\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 0s 650us/step - loss: 1.8064 - mse: 1.8064 - mae: 0.8702 - val_loss: 0.8659 - val_mse: 0.8659 - val_mae: 0.7720\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 0s 717us/step - loss: 1.7982 - mse: 1.7982 - mae: 0.8672 - val_loss: 0.8637 - val_mse: 0.8637 - val_mae: 0.7724\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 0s 545us/step - loss: 1.7932 - mse: 1.7932 - mae: 0.8647 - val_loss: 0.8651 - val_mse: 0.8651 - val_mae: 0.7708\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 0s 674us/step - loss: 1.7848 - mse: 1.7848 - mae: 0.8639 - val_loss: 0.8648 - val_mse: 0.8648 - val_mae: 0.7702\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 0s 688us/step - loss: 1.7802 - mse: 1.7802 - mae: 0.8626 - val_loss: 0.8666 - val_mse: 0.8666 - val_mae: 0.7683\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 0s 846us/step - loss: 1.7730 - mse: 1.7730 - mae: 0.8625 - val_loss: 0.8666 - val_mse: 0.8666 - val_mae: 0.7673\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 0s 933us/step - loss: 1.7664 - mse: 1.7664 - mae: 0.8604 - val_loss: 0.8665 - val_mse: 0.8665 - val_mae: 0.7664\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 0s 675us/step - loss: 1.7605 - mse: 1.7605 - mae: 0.8581 - val_loss: 0.8663 - val_mse: 0.8663 - val_mae: 0.7663\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 0s 552us/step - loss: 1.7552 - mse: 1.7552 - mae: 0.8556 - val_loss: 0.8672 - val_mse: 0.8672 - val_mae: 0.7666\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 0s 591us/step - loss: 1.7484 - mse: 1.7484 - mae: 0.8536 - val_loss: 0.8665 - val_mse: 0.8665 - val_mae: 0.7665\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 0s 601us/step - loss: 1.7432 - mse: 1.7432 - mae: 0.8521 - val_loss: 0.8698 - val_mse: 0.8698 - val_mae: 0.7664\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 0s 640us/step - loss: 1.7365 - mse: 1.7365 - mae: 0.8509 - val_loss: 0.8660 - val_mse: 0.8660 - val_mae: 0.7657\n",
      "92\n",
      "[92]\n",
      "Train on 94 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 1.7917 - mse: 1.7917 - mae: 0.9078 - val_loss: 1.3821 - val_mse: 1.3821 - val_mae: 0.9123\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 584us/step - loss: 1.7336 - mse: 1.7336 - mae: 0.9399 - val_loss: 1.2899 - val_mse: 1.2899 - val_mae: 0.8736\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 679us/step - loss: 1.7115 - mse: 1.7115 - mae: 0.9459 - val_loss: 1.3607 - val_mse: 1.3607 - val_mae: 0.9072\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 647us/step - loss: 1.6819 - mse: 1.6819 - mae: 0.9247 - val_loss: 1.4596 - val_mse: 1.4596 - val_mae: 0.9551\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 647us/step - loss: 1.6626 - mse: 1.6626 - mae: 0.9054 - val_loss: 1.4960 - val_mse: 1.4960 - val_mae: 0.9747\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 626us/step - loss: 1.6452 - mse: 1.6452 - mae: 0.8985 - val_loss: 1.4633 - val_mse: 1.4633 - val_mae: 0.9625\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 594us/step - loss: 1.6248 - mse: 1.6248 - mae: 0.9017 - val_loss: 1.4162 - val_mse: 1.4162 - val_mae: 0.9429\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 605us/step - loss: 1.6059 - mse: 1.6059 - mae: 0.9054 - val_loss: 1.4024 - val_mse: 1.4024 - val_mae: 0.9390\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 658us/step - loss: 1.5865 - mse: 1.5865 - mae: 0.9033 - val_loss: 1.4231 - val_mse: 1.4231 - val_mae: 0.9520\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 732us/step - loss: 1.5679 - mse: 1.5679 - mae: 0.8964 - val_loss: 1.4594 - val_mse: 1.4594 - val_mae: 0.9724\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 594us/step - loss: 1.5514 - mse: 1.5514 - mae: 0.8884 - val_loss: 1.4767 - val_mse: 1.4767 - val_mae: 0.9841\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.2890 - mse: 2.2890 - mae: 1.069 - 0s 721us/step - loss: 1.5353 - mse: 1.5353 - mae: 0.8839 - val_loss: 1.4746 - val_mse: 1.4746 - val_mae: 0.9867\n",
      "93\n",
      "[93]\n",
      "Train on 88 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 3.9160 - mse: 3.9160 - mae: 1.7169 - val_loss: 2.1619 - val_mse: 2.1619 - val_mae: 1.2657\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 893us/step - loss: 3.5712 - mse: 3.5712 - mae: 1.6128 - val_loss: 1.9477 - val_mse: 1.9477 - val_mae: 1.1764\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 616us/step - loss: 3.2340 - mse: 3.2340 - mae: 1.5024 - val_loss: 1.7191 - val_mse: 1.7191 - val_mae: 1.0710\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 2.8932 - mse: 2.8932 - mae: 1.3807 - val_loss: 1.4859 - val_mse: 1.4859 - val_mae: 0.9459\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 2.5428 - mse: 2.5428 - mae: 1.2444 - val_loss: 1.2504 - val_mse: 1.2504 - val_mae: 0.8064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 2.2006 - mse: 2.2006 - mae: 1.1088 - val_loss: 1.0430 - val_mse: 1.0430 - val_mae: 0.6605\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 639us/step - loss: 1.8722 - mse: 1.8722 - mae: 0.9797 - val_loss: 0.8752 - val_mse: 0.8752 - val_mae: 0.5386\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 752us/step - loss: 1.5750 - mse: 1.5750 - mae: 0.8694 - val_loss: 0.7491 - val_mse: 0.7491 - val_mae: 0.4766\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 415us/step - loss: 1.3283 - mse: 1.3283 - mae: 0.7751 - val_loss: 0.6758 - val_mse: 0.6758 - val_mae: 0.4904\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 1.1658 - mse: 1.1658 - mae: 0.7292 - val_loss: 0.6539 - val_mse: 0.6539 - val_mae: 0.5234\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.0799 - mse: 1.0799 - mae: 0.7170 - val_loss: 0.6668 - val_mse: 0.6668 - val_mae: 0.5725\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.0497 - mse: 1.0497 - mae: 0.7201 - val_loss: 0.6964 - val_mse: 0.6964 - val_mae: 0.6172\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 764us/step - loss: 1.0544 - mse: 1.0544 - mae: 0.7351 - val_loss: 0.7264 - val_mse: 0.7264 - val_mae: 0.6484\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.0682 - mse: 1.0682 - mae: 0.7528 - val_loss: 0.7426 - val_mse: 0.7426 - val_mae: 0.6639\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 355us/step - loss: 1.0731 - mse: 1.0731 - mae: 0.7604 - val_loss: 0.7391 - val_mse: 0.7391 - val_mae: 0.6617\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 1.0641 - mse: 1.0641 - mae: 0.7549 - val_loss: 0.7218 - val_mse: 0.7218 - val_mae: 0.6453\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.0455 - mse: 1.0455 - mae: 0.7417 - val_loss: 0.6977 - val_mse: 0.6977 - val_mae: 0.6210\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 805us/step - loss: 1.0242 - mse: 1.0242 - mae: 0.7241 - val_loss: 0.6733 - val_mse: 0.6733 - val_mae: 0.5962\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 355us/step - loss: 1.0050 - mse: 1.0050 - mae: 0.7087 - val_loss: 0.6523 - val_mse: 0.6523 - val_mae: 0.5724\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 770us/step - loss: 0.9894 - mse: 0.9894 - mae: 0.6971 - val_loss: 0.6365 - val_mse: 0.6365 - val_mae: 0.5509\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 710us/step - loss: 0.9776 - mse: 0.9776 - mae: 0.6885 - val_loss: 0.6255 - val_mse: 0.6255 - val_mae: 0.5329\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.9686 - mse: 0.9686 - mae: 0.6827 - val_loss: 0.6185 - val_mse: 0.6185 - val_mae: 0.5193\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.9610 - mse: 0.9610 - mae: 0.6792 - val_loss: 0.6134 - val_mse: 0.6134 - val_mae: 0.5110\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 435us/step - loss: 0.9535 - mse: 0.9535 - mae: 0.6762 - val_loss: 0.6104 - val_mse: 0.6104 - val_mae: 0.5077\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 499us/step - loss: 0.9456 - mse: 0.9456 - mae: 0.6738 - val_loss: 0.6094 - val_mse: 0.6094 - val_mae: 0.5068\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 0.9376 - mse: 0.9376 - mae: 0.6717 - val_loss: 0.6099 - val_mse: 0.6099 - val_mae: 0.5071\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 0.9296 - mse: 0.9296 - mae: 0.6704 - val_loss: 0.6114 - val_mse: 0.6114 - val_mae: 0.5081\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 733us/step - loss: 0.9222 - mse: 0.9222 - mae: 0.6700 - val_loss: 0.6137 - val_mse: 0.6137 - val_mae: 0.5138\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 710us/step - loss: 0.9154 - mse: 0.9154 - mae: 0.6698 - val_loss: 0.6159 - val_mse: 0.6159 - val_mae: 0.5208\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 594us/step - loss: 0.9088 - mse: 0.9088 - mae: 0.6691 - val_loss: 0.6175 - val_mse: 0.6175 - val_mae: 0.5266\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 0.9023 - mse: 0.9023 - mae: 0.6676 - val_loss: 0.6177 - val_mse: 0.6177 - val_mae: 0.5302\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 361us/step - loss: 0.8970 - mse: 0.8970 - mae: 0.6660 - val_loss: 0.6188 - val_mse: 0.6188 - val_mae: 0.5336\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 0.8922 - mse: 0.8922 - mae: 0.6641 - val_loss: 0.6205 - val_mse: 0.6205 - val_mae: 0.5362\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 533us/step - loss: 0.8877 - mse: 0.8877 - mae: 0.6622 - val_loss: 0.6208 - val_mse: 0.6208 - val_mae: 0.5366\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 888us/step - loss: 0.8839 - mse: 0.8839 - mae: 0.6597 - val_loss: 0.6199 - val_mse: 0.6199 - val_mae: 0.5352\n",
      "94\n",
      "[94]\n",
      "Train on 85 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 2.6178 - mse: 2.6178 - mae: 1.3681 - val_loss: 2.2369 - val_mse: 2.2369 - val_mae: 1.1673\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 945us/step - loss: 2.0707 - mse: 2.0707 - mae: 1.1599 - val_loss: 1.7857 - val_mse: 1.7857 - val_mae: 0.9902\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 551us/step - loss: 1.6610 - mse: 1.6610 - mae: 0.9872 - val_loss: 1.4634 - val_mse: 1.4634 - val_mae: 0.8519\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 670us/step - loss: 1.3511 - mse: 1.3511 - mae: 0.8510 - val_loss: 1.2038 - val_mse: 1.2038 - val_mae: 0.7676\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 978us/step - loss: 1.1238 - mse: 1.1238 - mae: 0.7377 - val_loss: 1.0411 - val_mse: 1.0411 - val_mae: 0.7054\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 551us/step - loss: 0.9621 - mse: 0.9621 - mae: 0.6539 - val_loss: 0.9421 - val_mse: 0.9421 - val_mae: 0.6652\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 919us/step - loss: 0.8497 - mse: 0.8497 - mae: 0.6023 - val_loss: 0.8860 - val_mse: 0.8860 - val_mae: 0.6434\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 735us/step - loss: 0.7812 - mse: 0.7812 - mae: 0.5724 - val_loss: 0.8740 - val_mse: 0.8740 - val_mae: 0.6403\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.7452 - mse: 0.7452 - mae: 0.5629 - val_loss: 0.8891 - val_mse: 0.8891 - val_mae: 0.6594\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 599us/step - loss: 0.7296 - mse: 0.7296 - mae: 0.5674 - val_loss: 0.9159 - val_mse: 0.9159 - val_mae: 0.6926\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 568us/step - loss: 0.7242 - mse: 0.7242 - mae: 0.5770 - val_loss: 0.9387 - val_mse: 0.9387 - val_mae: 0.7170\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 697us/step - loss: 0.7212 - mse: 0.7212 - mae: 0.5852 - val_loss: 0.9524 - val_mse: 0.9524 - val_mae: 0.7298\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 551us/step - loss: 0.7167 - mse: 0.7167 - mae: 0.5894 - val_loss: 0.9551 - val_mse: 0.9551 - val_mae: 0.7342\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.7109 - mse: 0.7109 - mae: 0.5885 - val_loss: 0.9480 - val_mse: 0.9480 - val_mae: 0.7290\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 622us/step - loss: 0.7022 - mse: 0.7022 - mae: 0.5835 - val_loss: 0.9343 - val_mse: 0.9343 - val_mae: 0.7169\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 751us/step - loss: 0.6922 - mse: 0.6922 - mae: 0.5760 - val_loss: 0.9176 - val_mse: 0.9176 - val_mae: 0.7001\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 716us/step - loss: 0.6823 - mse: 0.6823 - mae: 0.5669 - val_loss: 0.9011 - val_mse: 0.9011 - val_mae: 0.6815\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 704us/step - loss: 0.6736 - mse: 0.6736 - mae: 0.5572 - val_loss: 0.8863 - val_mse: 0.8863 - val_mae: 0.6631\n",
      "95\n",
      "[95]\n",
      "Train on 111 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 7.3580 - mse: 7.3580 - mae: 2.2775 - val_loss: 5.2745 - val_mse: 5.2745 - val_mae: 1.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "111/111 [==============================] - 0s 584us/step - loss: 5.3309 - mse: 5.3309 - mae: 1.8229 - val_loss: 3.6713 - val_mse: 3.6713 - val_mae: 1.4545\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 0s 593us/step - loss: 3.9612 - mse: 3.9612 - mae: 1.5111 - val_loss: 2.6349 - val_mse: 2.6349 - val_mae: 1.1251\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 0s 611us/step - loss: 3.1103 - mse: 3.1103 - mae: 1.3119 - val_loss: 2.0638 - val_mse: 2.0638 - val_mae: 0.9741\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.0157 - mse: 2.0157 - mae: 0.992 - 0s 639us/step - loss: 2.6324 - mse: 2.6324 - mae: 1.1994 - val_loss: 1.7908 - val_mse: 1.7908 - val_mae: 0.9287\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 0s 530us/step - loss: 2.3916 - mse: 2.3916 - mae: 1.1491 - val_loss: 1.6832 - val_mse: 1.6832 - val_mae: 0.9312\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 0s 584us/step - loss: 2.2755 - mse: 2.2755 - mae: 1.1259 - val_loss: 1.6542 - val_mse: 1.6542 - val_mae: 0.9580\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 0s 602us/step - loss: 2.2225 - mse: 2.2225 - mae: 1.1191 - val_loss: 1.6478 - val_mse: 1.6478 - val_mae: 0.9755\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 0s 593us/step - loss: 2.1927 - mse: 2.1927 - mae: 1.1205 - val_loss: 1.6450 - val_mse: 1.6450 - val_mae: 0.9822\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 0s 494us/step - loss: 2.1619 - mse: 2.1619 - mae: 1.1182 - val_loss: 1.6310 - val_mse: 1.6310 - val_mae: 0.9790\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 0s 530us/step - loss: 2.1234 - mse: 2.1234 - mae: 1.1110 - val_loss: 1.6005 - val_mse: 1.6005 - val_mae: 0.9659\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 0s 749us/step - loss: 2.0780 - mse: 2.0780 - mae: 1.0985 - val_loss: 1.5633 - val_mse: 1.5633 - val_mae: 0.9461\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 2.0318 - mse: 2.0318 - mae: 1.0832 - val_loss: 1.5279 - val_mse: 1.5279 - val_mae: 0.9244\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 0s 876us/step - loss: 1.9875 - mse: 1.9875 - mae: 1.0670 - val_loss: 1.4995 - val_mse: 1.4995 - val_mae: 0.9040\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 0s 756us/step - loss: 1.9465 - mse: 1.9465 - mae: 1.0515 - val_loss: 1.4788 - val_mse: 1.4788 - val_mae: 0.8868\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 1.9122 - mse: 1.9122 - mae: 1.0385 - val_loss: 1.4664 - val_mse: 1.4664 - val_mae: 0.8743\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.8825 - mse: 1.8825 - mae: 1.0275 - val_loss: 1.4575 - val_mse: 1.4575 - val_mae: 0.8658\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 0s 729us/step - loss: 1.8564 - mse: 1.8564 - mae: 1.0190 - val_loss: 1.4508 - val_mse: 1.4508 - val_mae: 0.8601\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 0s 354us/step - loss: 1.8325 - mse: 1.8325 - mae: 1.0117 - val_loss: 1.4468 - val_mse: 1.4468 - val_mae: 0.8576\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 0s 616us/step - loss: 1.8098 - mse: 1.8098 - mae: 1.0050 - val_loss: 1.4421 - val_mse: 1.4421 - val_mae: 0.8562\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.7883 - mse: 1.7883 - mae: 0.9997 - val_loss: 1.4351 - val_mse: 1.4351 - val_mae: 0.8550\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 0s 578us/step - loss: 1.7690 - mse: 1.7690 - mae: 0.9949 - val_loss: 1.4295 - val_mse: 1.4295 - val_mae: 0.8544\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.7517 - mse: 1.7517 - mae: 0.9909 - val_loss: 1.4246 - val_mse: 1.4246 - val_mae: 0.8560\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.7359 - mse: 1.7359 - mae: 0.9881 - val_loss: 1.4209 - val_mse: 1.4209 - val_mae: 0.8579\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.7206 - mse: 1.7206 - mae: 0.9849 - val_loss: 1.4175 - val_mse: 1.4175 - val_mae: 0.8590\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 1.7063 - mse: 1.7063 - mae: 0.9820 - val_loss: 1.4148 - val_mse: 1.4148 - val_mae: 0.8594\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 0s 878us/step - loss: 1.6925 - mse: 1.6925 - mae: 0.9790 - val_loss: 1.4122 - val_mse: 1.4122 - val_mae: 0.8595\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.6789 - mse: 1.6789 - mae: 0.9757 - val_loss: 1.4094 - val_mse: 1.4094 - val_mae: 0.8591\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 1.6659 - mse: 1.6659 - mae: 0.9723 - val_loss: 1.4068 - val_mse: 1.4068 - val_mae: 0.8585\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 0s 480us/step - loss: 1.6535 - mse: 1.6535 - mae: 0.9689 - val_loss: 1.4034 - val_mse: 1.4034 - val_mae: 0.8578\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 1.6403 - mse: 1.6403 - mae: 0.9652 - val_loss: 1.3977 - val_mse: 1.3977 - val_mae: 0.8569\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 1.6269 - mse: 1.6269 - mae: 0.9613 - val_loss: 1.3906 - val_mse: 1.3906 - val_mae: 0.8559\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 0s 643us/step - loss: 1.6133 - mse: 1.6133 - mae: 0.9572 - val_loss: 1.3848 - val_mse: 1.3848 - val_mae: 0.8555\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 0s 770us/step - loss: 1.6002 - mse: 1.6002 - mae: 0.9535 - val_loss: 1.3852 - val_mse: 1.3852 - val_mae: 0.8568\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 0s 674us/step - loss: 1.5877 - mse: 1.5877 - mae: 0.9500 - val_loss: 1.3838 - val_mse: 1.3838 - val_mae: 0.8573\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.5771 - mse: 1.5771 - mae: 0.9468 - val_loss: 1.3821 - val_mse: 1.3821 - val_mae: 0.8576\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 0s 844us/step - loss: 1.5670 - mse: 1.5670 - mae: 0.9438 - val_loss: 1.3815 - val_mse: 1.3815 - val_mae: 0.8587\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.5556 - mse: 1.5556 - mae: 0.9405 - val_loss: 1.3830 - val_mse: 1.3830 - val_mae: 0.8608\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 0s 510us/step - loss: 1.5429 - mse: 1.5429 - mae: 0.9373 - val_loss: 1.3882 - val_mse: 1.3882 - val_mae: 0.8632\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 0s 386us/step - loss: 1.5304 - mse: 1.5304 - mae: 0.9336 - val_loss: 1.3926 - val_mse: 1.3926 - val_mae: 0.8655\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 0s 519us/step - loss: 1.5190 - mse: 1.5190 - mae: 0.9297 - val_loss: 1.3960 - val_mse: 1.3960 - val_mae: 0.8685\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 0s 844us/step - loss: 1.5094 - mse: 1.5094 - mae: 0.9268 - val_loss: 1.3982 - val_mse: 1.3982 - val_mae: 0.8740\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 1.5000 - mse: 1.5000 - mae: 0.9250 - val_loss: 1.3995 - val_mse: 1.3995 - val_mae: 0.8803\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 0s 844us/step - loss: 1.4909 - mse: 1.4909 - mae: 0.9237 - val_loss: 1.4009 - val_mse: 1.4009 - val_mae: 0.8852\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 0s 510us/step - loss: 1.4831 - mse: 1.4831 - mae: 0.9223 - val_loss: 1.4028 - val_mse: 1.4028 - val_mae: 0.8869\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 0s 744us/step - loss: 1.4744 - mse: 1.4744 - mae: 0.9195 - val_loss: 1.4035 - val_mse: 1.4035 - val_mae: 0.8853\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.4657 - mse: 1.4657 - mae: 0.9160 - val_loss: 1.4032 - val_mse: 1.4032 - val_mae: 0.8830\n",
      "96\n",
      "[96]\n",
      "Train on 104 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "104/104 [==============================] - 4s 42ms/step - loss: 18.9166 - mse: 18.9166 - mae: 4.0498 - val_loss: 10.6722 - val_mse: 10.6722 - val_mae: 3.0373\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 0s 604us/step - loss: 14.7559 - mse: 14.7559 - mae: 3.5342 - val_loss: 8.5167 - val_mse: 8.5167 - val_mae: 2.6799\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 0s 643us/step - loss: 11.7884 - mse: 11.7884 - mae: 3.1160 - val_loss: 6.9854 - val_mse: 6.9854 - val_mae: 2.3927\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 0s 575us/step - loss: 9.6033 - mse: 9.6033 - mae: 2.7641 - val_loss: 5.7966 - val_mse: 5.7966 - val_mae: 2.1411\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 0s 585us/step - loss: 7.9247 - mse: 7.9247 - mae: 2.4659 - val_loss: 4.9591 - val_mse: 4.9591 - val_mae: 1.9499\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 0s 748us/step - loss: 6.7274 - mse: 6.7274 - mae: 2.2307 - val_loss: 4.3891 - val_mse: 4.3891 - val_mae: 1.8016\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 0s 604us/step - loss: 5.8670 - mse: 5.8670 - mae: 2.0395 - val_loss: 3.8872 - val_mse: 3.8872 - val_mae: 1.6557\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 0s 604us/step - loss: 5.1679 - mse: 5.1679 - mae: 1.8653 - val_loss: 3.4327 - val_mse: 3.4327 - val_mae: 1.5075\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 0s 527us/step - loss: 4.4948 - mse: 4.4948 - mae: 1.6858 - val_loss: 2.9918 - val_mse: 2.9918 - val_mae: 1.3518\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 0s 748us/step - loss: 3.8608 - mse: 3.8608 - mae: 1.5014 - val_loss: 2.5602 - val_mse: 2.5602 - val_mae: 1.2027\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 0s 547us/step - loss: 3.2879 - mse: 3.2879 - mae: 1.3317 - val_loss: 2.1845 - val_mse: 2.1845 - val_mae: 1.0738\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 0s 710us/step - loss: 2.7942 - mse: 2.7942 - mae: 1.1884 - val_loss: 1.8696 - val_mse: 1.8696 - val_mae: 0.9604\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 0s 585us/step - loss: 2.4083 - mse: 2.4083 - mae: 1.0867 - val_loss: 1.6195 - val_mse: 1.6195 - val_mae: 0.8737\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 0s 614us/step - loss: 2.1200 - mse: 2.1200 - mae: 1.0227 - val_loss: 1.4413 - val_mse: 1.4413 - val_mae: 0.8220\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 0s 623us/step - loss: 1.9398 - mse: 1.9398 - mae: 0.9998 - val_loss: 1.3289 - val_mse: 1.3289 - val_mae: 0.7974\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 0s 690us/step - loss: 1.8414 - mse: 1.8414 - mae: 0.9922 - val_loss: 1.2684 - val_mse: 1.2684 - val_mae: 0.7815\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 0s 633us/step - loss: 1.8013 - mse: 1.8013 - mae: 0.9899 - val_loss: 1.2420 - val_mse: 1.2420 - val_mae: 0.7688\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 0s 662us/step - loss: 1.7930 - mse: 1.7930 - mae: 0.9967 - val_loss: 1.2320 - val_mse: 1.2320 - val_mae: 0.7590\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 0s 527us/step - loss: 1.7944 - mse: 1.7944 - mae: 1.0013 - val_loss: 1.2268 - val_mse: 1.2268 - val_mae: 0.7531\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 0s 614us/step - loss: 1.7922 - mse: 1.7922 - mae: 1.0029 - val_loss: 1.2201 - val_mse: 1.2201 - val_mae: 0.7492\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 0s 671us/step - loss: 1.7826 - mse: 1.7826 - mae: 0.9998 - val_loss: 1.2130 - val_mse: 1.2130 - val_mae: 0.7461\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 0s 537us/step - loss: 1.7682 - mse: 1.7682 - mae: 0.9935 - val_loss: 1.2066 - val_mse: 1.2066 - val_mae: 0.7436\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 0s 595us/step - loss: 1.7528 - mse: 1.7528 - mae: 0.9860 - val_loss: 1.2018 - val_mse: 1.2018 - val_mae: 0.7425\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 0s 662us/step - loss: 1.7393 - mse: 1.7393 - mae: 0.9784 - val_loss: 1.1989 - val_mse: 1.1989 - val_mae: 0.7417\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 0s 595us/step - loss: 1.7288 - mse: 1.7288 - mae: 0.9716 - val_loss: 1.1969 - val_mse: 1.1969 - val_mae: 0.7406\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 0s 575us/step - loss: 1.7202 - mse: 1.7202 - mae: 0.9660 - val_loss: 1.1954 - val_mse: 1.1954 - val_mae: 0.7392\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.7125 - mse: 1.7125 - mae: 0.9617 - val_loss: 1.1933 - val_mse: 1.1933 - val_mae: 0.7374\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.7052 - mse: 1.7052 - mae: 0.9585 - val_loss: 1.1907 - val_mse: 1.1907 - val_mae: 0.7354\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 0s 901us/step - loss: 1.6979 - mse: 1.6979 - mae: 0.9557 - val_loss: 1.1876 - val_mse: 1.1876 - val_mae: 0.7332\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 0s 365us/step - loss: 1.6906 - mse: 1.6906 - mae: 0.9534 - val_loss: 1.1844 - val_mse: 1.1844 - val_mae: 0.7311\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 0s 816us/step - loss: 1.6838 - mse: 1.6838 - mae: 0.9514 - val_loss: 1.1814 - val_mse: 1.1814 - val_mae: 0.7292\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.6772 - mse: 1.6772 - mae: 0.9496 - val_loss: 1.1783 - val_mse: 1.1783 - val_mae: 0.7271\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 0s 581us/step - loss: 1.6706 - mse: 1.6706 - mae: 0.9479 - val_loss: 1.1747 - val_mse: 1.1747 - val_mae: 0.7247\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.6637 - mse: 1.6637 - mae: 0.9460 - val_loss: 1.1714 - val_mse: 1.1714 - val_mae: 0.7224\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 0s 882us/step - loss: 1.6569 - mse: 1.6569 - mae: 0.9442 - val_loss: 1.1685 - val_mse: 1.1685 - val_mae: 0.7204\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.6500 - mse: 1.6500 - mae: 0.9423 - val_loss: 1.1660 - val_mse: 1.1660 - val_mae: 0.7186\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 0s 344us/step - loss: 1.6436 - mse: 1.6436 - mae: 0.9403 - val_loss: 1.1637 - val_mse: 1.1637 - val_mae: 0.7169\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.6373 - mse: 1.6373 - mae: 0.9383 - val_loss: 1.1613 - val_mse: 1.1613 - val_mae: 0.7149\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.6310 - mse: 1.6310 - mae: 0.9363 - val_loss: 1.1591 - val_mse: 1.1591 - val_mae: 0.7132\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.6248 - mse: 1.6248 - mae: 0.9342 - val_loss: 1.1573 - val_mse: 1.1573 - val_mae: 0.7117\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 0s 560us/step - loss: 1.6184 - mse: 1.6184 - mae: 0.9321 - val_loss: 1.1553 - val_mse: 1.1553 - val_mae: 0.7100\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 0s 921us/step - loss: 1.6122 - mse: 1.6122 - mae: 0.9299 - val_loss: 1.1534 - val_mse: 1.1534 - val_mae: 0.7083\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 0s 348us/step - loss: 1.6062 - mse: 1.6062 - mae: 0.9278 - val_loss: 1.1516 - val_mse: 1.1516 - val_mae: 0.7069\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 0s 381us/step - loss: 1.6006 - mse: 1.6006 - mae: 0.9259 - val_loss: 1.1505 - val_mse: 1.1505 - val_mae: 0.7062\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5951 - mse: 1.5951 - mae: 0.9242 - val_loss: 1.1494 - val_mse: 1.1494 - val_mae: 0.7055\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5897 - mse: 1.5897 - mae: 0.9225 - val_loss: 1.1483 - val_mse: 1.1483 - val_mae: 0.7046\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5846 - mse: 1.5846 - mae: 0.9210 - val_loss: 1.1471 - val_mse: 1.1471 - val_mae: 0.7036\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 0s 915us/step - loss: 1.5796 - mse: 1.5796 - mae: 0.9194 - val_loss: 1.1461 - val_mse: 1.1461 - val_mae: 0.7029\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5744 - mse: 1.5744 - mae: 0.9178 - val_loss: 1.1450 - val_mse: 1.1450 - val_mae: 0.7021\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 0s 901us/step - loss: 1.5695 - mse: 1.5695 - mae: 0.9160 - val_loss: 1.1442 - val_mse: 1.1442 - val_mae: 0.7016\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.5647 - mse: 1.5647 - mae: 0.9145 - val_loss: 1.1433 - val_mse: 1.1433 - val_mae: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "104/104 [==============================] - 0s 570us/step - loss: 1.5599 - mse: 1.5599 - mae: 0.9130 - val_loss: 1.1423 - val_mse: 1.1423 - val_mae: 0.7001\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.5551 - mse: 1.5551 - mae: 0.9115 - val_loss: 1.1411 - val_mse: 1.1411 - val_mae: 0.6992\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.5507 - mse: 1.5507 - mae: 0.9100 - val_loss: 1.1400 - val_mse: 1.1400 - val_mae: 0.6986\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.5458 - mse: 1.5458 - mae: 0.9085 - val_loss: 1.1392 - val_mse: 1.1392 - val_mae: 0.6982\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5411 - mse: 1.5411 - mae: 0.9071 - val_loss: 1.1384 - val_mse: 1.1384 - val_mae: 0.6978\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 0s 673us/step - loss: 1.5364 - mse: 1.5364 - mae: 0.9057 - val_loss: 1.1371 - val_mse: 1.1371 - val_mae: 0.6971\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 0s 884us/step - loss: 1.5317 - mse: 1.5317 - mae: 0.9043 - val_loss: 1.1355 - val_mse: 1.1355 - val_mae: 0.6963\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 0s 762us/step - loss: 1.5269 - mse: 1.5269 - mae: 0.9028 - val_loss: 1.1338 - val_mse: 1.1338 - val_mae: 0.6954\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5226 - mse: 1.5226 - mae: 0.9015 - val_loss: 1.1326 - val_mse: 1.1326 - val_mae: 0.6948\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5180 - mse: 1.5180 - mae: 0.9003 - val_loss: 1.1318 - val_mse: 1.1318 - val_mae: 0.6946\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 0s 817us/step - loss: 1.5138 - mse: 1.5138 - mae: 0.8994 - val_loss: 1.1312 - val_mse: 1.1312 - val_mae: 0.6944\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 0s 661us/step - loss: 1.5096 - mse: 1.5096 - mae: 0.8984 - val_loss: 1.1306 - val_mse: 1.1306 - val_mae: 0.6941\n",
      "Epoch 64/100\n",
      "104/104 [==============================] - 0s 741us/step - loss: 1.5052 - mse: 1.5052 - mae: 0.8974 - val_loss: 1.1300 - val_mse: 1.1300 - val_mae: 0.6938\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.5009 - mse: 1.5009 - mae: 0.8963 - val_loss: 1.1294 - val_mse: 1.1294 - val_mae: 0.6934\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.4966 - mse: 1.4966 - mae: 0.8951 - val_loss: 1.1287 - val_mse: 1.1287 - val_mae: 0.6929\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 0s 918us/step - loss: 1.4923 - mse: 1.4923 - mae: 0.8939 - val_loss: 1.1279 - val_mse: 1.1279 - val_mae: 0.6922\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 0s 570us/step - loss: 1.4883 - mse: 1.4883 - mae: 0.8925 - val_loss: 1.1273 - val_mse: 1.1273 - val_mae: 0.6917\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 0s 901us/step - loss: 1.4838 - mse: 1.4838 - mae: 0.8912 - val_loss: 1.1271 - val_mse: 1.1271 - val_mae: 0.6916\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.4797 - mse: 1.4797 - mae: 0.8899 - val_loss: 1.1266 - val_mse: 1.1266 - val_mae: 0.6915\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 0s 909us/step - loss: 1.4755 - mse: 1.4755 - mae: 0.8887 - val_loss: 1.1257 - val_mse: 1.1257 - val_mae: 0.6912\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 0s 440us/step - loss: 1.4712 - mse: 1.4712 - mae: 0.8878 - val_loss: 1.1245 - val_mse: 1.1245 - val_mae: 0.6907\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 0s 653us/step - loss: 1.4669 - mse: 1.4669 - mae: 0.8867 - val_loss: 1.1231 - val_mse: 1.1231 - val_mae: 0.6901\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.4625 - mse: 1.4625 - mae: 0.8856 - val_loss: 1.1215 - val_mse: 1.1215 - val_mae: 0.6893\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 0s 601us/step - loss: 1.4581 - mse: 1.4581 - mae: 0.8846 - val_loss: 1.1199 - val_mse: 1.1199 - val_mae: 0.6884\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 0s 901us/step - loss: 1.4537 - mse: 1.4537 - mae: 0.8835 - val_loss: 1.1183 - val_mse: 1.1183 - val_mae: 0.6875\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 0s 602us/step - loss: 1.4497 - mse: 1.4497 - mae: 0.8825 - val_loss: 1.1173 - val_mse: 1.1173 - val_mae: 0.6872\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 0s 800us/step - loss: 1.4452 - mse: 1.4452 - mae: 0.8814 - val_loss: 1.1163 - val_mse: 1.1163 - val_mae: 0.6868\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.4407 - mse: 1.4407 - mae: 0.8801 - val_loss: 1.1151 - val_mse: 1.1151 - val_mae: 0.6861\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.4364 - mse: 1.4364 - mae: 0.8788 - val_loss: 1.1136 - val_mse: 1.1136 - val_mae: 0.6851\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 0s 477us/step - loss: 1.4323 - mse: 1.4323 - mae: 0.8775 - val_loss: 1.1118 - val_mse: 1.1118 - val_mae: 0.6837\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 0s 543us/step - loss: 1.4280 - mse: 1.4280 - mae: 0.8761 - val_loss: 1.1104 - val_mse: 1.1104 - val_mae: 0.6826\n",
      "Epoch 83/100\n",
      "104/104 [==============================] - 0s 659us/step - loss: 1.4236 - mse: 1.4236 - mae: 0.8749 - val_loss: 1.1091 - val_mse: 1.1091 - val_mae: 0.6817\n",
      "Epoch 84/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.4195 - mse: 1.4195 - mae: 0.8738 - val_loss: 1.1085 - val_mse: 1.1085 - val_mae: 0.6812\n",
      "Epoch 85/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.4147 - mse: 1.4147 - mae: 0.8725 - val_loss: 1.1076 - val_mse: 1.1076 - val_mae: 0.6808\n",
      "Epoch 86/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.4104 - mse: 1.4104 - mae: 0.8711 - val_loss: 1.1066 - val_mse: 1.1066 - val_mae: 0.6802\n",
      "Epoch 87/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.4063 - mse: 1.4063 - mae: 0.8697 - val_loss: 1.1055 - val_mse: 1.1055 - val_mae: 0.6794\n",
      "Epoch 88/100\n",
      "104/104 [==============================] - 0s 708us/step - loss: 1.4020 - mse: 1.4020 - mae: 0.8684 - val_loss: 1.1045 - val_mse: 1.1045 - val_mae: 0.6788\n",
      "Epoch 89/100\n",
      "104/104 [==============================] - 0s 507us/step - loss: 1.3976 - mse: 1.3976 - mae: 0.8672 - val_loss: 1.1026 - val_mse: 1.1026 - val_mae: 0.6775\n",
      "Epoch 90/100\n",
      "104/104 [==============================] - 0s 451us/step - loss: 1.3931 - mse: 1.3931 - mae: 0.8658 - val_loss: 1.1012 - val_mse: 1.1012 - val_mae: 0.6766\n",
      "Epoch 91/100\n",
      "104/104 [==============================] - 0s 751us/step - loss: 1.3890 - mse: 1.3890 - mae: 0.8645 - val_loss: 1.0999 - val_mse: 1.0999 - val_mae: 0.6761\n",
      "Epoch 92/100\n",
      "104/104 [==============================] - 0s 580us/step - loss: 1.3848 - mse: 1.3848 - mae: 0.8633 - val_loss: 1.0983 - val_mse: 1.0983 - val_mae: 0.6753\n",
      "Epoch 93/100\n",
      "104/104 [==============================] - 0s 547us/step - loss: 1.3804 - mse: 1.3804 - mae: 0.8620 - val_loss: 1.0976 - val_mse: 1.0976 - val_mae: 0.6750\n",
      "Epoch 94/100\n",
      "104/104 [==============================] - 0s 946us/step - loss: 1.3761 - mse: 1.3761 - mae: 0.8604 - val_loss: 1.0963 - val_mse: 1.0963 - val_mae: 0.6744\n",
      "Epoch 95/100\n",
      "104/104 [==============================] - 0s 464us/step - loss: 1.3718 - mse: 1.3718 - mae: 0.8589 - val_loss: 1.0946 - val_mse: 1.0946 - val_mae: 0.6736\n",
      "Epoch 96/100\n",
      "104/104 [==============================] - 0s 751us/step - loss: 1.3673 - mse: 1.3673 - mae: 0.8574 - val_loss: 1.0923 - val_mse: 1.0923 - val_mae: 0.6725\n",
      "Epoch 97/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.3633 - mse: 1.3633 - mae: 0.8562 - val_loss: 1.0912 - val_mse: 1.0912 - val_mae: 0.6718\n",
      "Epoch 98/100\n",
      "104/104 [==============================] - 0s 432us/step - loss: 1.3586 - mse: 1.3586 - mae: 0.8548 - val_loss: 1.0897 - val_mse: 1.0897 - val_mae: 0.6710\n",
      "Epoch 99/100\n",
      "104/104 [==============================] - 0s 471us/step - loss: 1.3542 - mse: 1.3542 - mae: 0.8533 - val_loss: 1.0878 - val_mse: 1.0878 - val_mae: 0.6700\n",
      "Epoch 100/100\n",
      "104/104 [==============================] - 0s 901us/step - loss: 1.3501 - mse: 1.3501 - mae: 0.8522 - val_loss: 1.0869 - val_mse: 1.0869 - val_mae: 0.6694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "[97]\n",
      "Train on 90 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 6s 68ms/step - loss: 4.5609 - mse: 4.5609 - mae: 1.7050 - val_loss: 1.6595 - val_mse: 1.6595 - val_mae: 0.9690\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 743us/step - loss: 3.5466 - mse: 3.5466 - mae: 1.4472 - val_loss: 1.2993 - val_mse: 1.2993 - val_mae: 0.8420\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 632us/step - loss: 2.7777 - mse: 2.7777 - mae: 1.2766 - val_loss: 1.0631 - val_mse: 1.0631 - val_mae: 0.7696\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 554us/step - loss: 2.2522 - mse: 2.2522 - mae: 1.1776 - val_loss: 0.9358 - val_mse: 0.9358 - val_mae: 0.7137\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 565us/step - loss: 1.9338 - mse: 1.9338 - mae: 1.1119 - val_loss: 0.8965 - val_mse: 0.8965 - val_mae: 0.6919\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 532us/step - loss: 1.8039 - mse: 1.8039 - mae: 1.0765 - val_loss: 0.9215 - val_mse: 0.9215 - val_mae: 0.7051\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 544us/step - loss: 1.7824 - mse: 1.7824 - mae: 1.0668 - val_loss: 0.9675 - val_mse: 0.9675 - val_mae: 0.7279\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 532us/step - loss: 1.7947 - mse: 1.7947 - mae: 1.0668 - val_loss: 0.9908 - val_mse: 0.9908 - val_mae: 0.7401\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 654us/step - loss: 1.7889 - mse: 1.7889 - mae: 1.0624 - val_loss: 0.9821 - val_mse: 0.9821 - val_mae: 0.7406\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 543us/step - loss: 1.7536 - mse: 1.7536 - mae: 1.0488 - val_loss: 0.9458 - val_mse: 0.9458 - val_mae: 0.7208\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 664us/step - loss: 1.6952 - mse: 1.6952 - mae: 1.0277 - val_loss: 0.8984 - val_mse: 0.8984 - val_mae: 0.6918\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 916us/step - loss: 1.6367 - mse: 1.6367 - mae: 1.0035 - val_loss: 0.8523 - val_mse: 0.8523 - val_mae: 0.6693\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 694us/step - loss: 1.5897 - mse: 1.5897 - mae: 0.9823 - val_loss: 0.8138 - val_mse: 0.8138 - val_mae: 0.6481\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.5567 - mse: 1.5567 - mae: 0.9686 - val_loss: 0.7844 - val_mse: 0.7844 - val_mae: 0.6336\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 868us/step - loss: 1.5354 - mse: 1.5354 - mae: 0.9579 - val_loss: 0.7625 - val_mse: 0.7625 - val_mae: 0.6236\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 795us/step - loss: 1.5203 - mse: 1.5203 - mae: 0.9473 - val_loss: 0.7474 - val_mse: 0.7474 - val_mae: 0.6158\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.5065 - mse: 1.5065 - mae: 0.9366 - val_loss: 0.7374 - val_mse: 0.7374 - val_mae: 0.6102\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 709us/step - loss: 1.4929 - mse: 1.4929 - mae: 0.9267 - val_loss: 0.7314 - val_mse: 0.7314 - val_mae: 0.6062\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 790us/step - loss: 1.4778 - mse: 1.4778 - mae: 0.9173 - val_loss: 0.7286 - val_mse: 0.7286 - val_mae: 0.6034\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.4629 - mse: 1.4629 - mae: 0.9102 - val_loss: 0.7285 - val_mse: 0.7285 - val_mae: 0.6018\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 868us/step - loss: 1.4494 - mse: 1.4494 - mae: 0.9040 - val_loss: 0.7288 - val_mse: 0.7288 - val_mae: 0.6003\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 654us/step - loss: 1.4375 - mse: 1.4375 - mae: 0.8989 - val_loss: 0.7294 - val_mse: 0.7294 - val_mae: 0.6009\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 932us/step - loss: 1.4263 - mse: 1.4263 - mae: 0.8947 - val_loss: 0.7294 - val_mse: 0.7294 - val_mae: 0.6013\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.4152 - mse: 1.4152 - mae: 0.8904 - val_loss: 0.7293 - val_mse: 0.7293 - val_mae: 0.6016\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 390us/step - loss: 1.4038 - mse: 1.4038 - mae: 0.8856 - val_loss: 0.7286 - val_mse: 0.7286 - val_mae: 0.6015\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.3926 - mse: 1.3926 - mae: 0.8809 - val_loss: 0.7281 - val_mse: 0.7281 - val_mae: 0.6015\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 694us/step - loss: 1.3823 - mse: 1.3823 - mae: 0.8762 - val_loss: 0.7267 - val_mse: 0.7267 - val_mae: 0.6009\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 324us/step - loss: 1.3728 - mse: 1.3728 - mae: 0.8718 - val_loss: 0.7245 - val_mse: 0.7245 - val_mae: 0.5999\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 581us/step - loss: 1.3639 - mse: 1.3639 - mae: 0.8677 - val_loss: 0.7225 - val_mse: 0.7225 - val_mae: 0.5989\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 630us/step - loss: 1.3554 - mse: 1.3554 - mae: 0.8640 - val_loss: 0.7216 - val_mse: 0.7216 - val_mae: 0.5985\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 694us/step - loss: 1.3472 - mse: 1.3472 - mae: 0.8604 - val_loss: 0.7212 - val_mse: 0.7212 - val_mae: 0.5983\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.3395 - mse: 1.3395 - mae: 0.8568 - val_loss: 0.7217 - val_mse: 0.7217 - val_mae: 0.5981\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.3321 - mse: 1.3321 - mae: 0.8534 - val_loss: 0.7228 - val_mse: 0.7228 - val_mae: 0.5982\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 694us/step - loss: 1.3242 - mse: 1.3242 - mae: 0.8503 - val_loss: 0.7249 - val_mse: 0.7249 - val_mae: 0.5992\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.3165 - mse: 1.3165 - mae: 0.8475 - val_loss: 0.7274 - val_mse: 0.7274 - val_mae: 0.6005\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.3087 - mse: 1.3087 - mae: 0.8452 - val_loss: 0.7302 - val_mse: 0.7302 - val_mae: 0.6019\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 706us/step - loss: 1.3014 - mse: 1.3014 - mae: 0.8434 - val_loss: 0.7325 - val_mse: 0.7325 - val_mae: 0.6031\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.2941 - mse: 1.2941 - mae: 0.8413 - val_loss: 0.7339 - val_mse: 0.7339 - val_mae: 0.6037\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 515us/step - loss: 1.2866 - mse: 1.2866 - mae: 0.8387 - val_loss: 0.7342 - val_mse: 0.7342 - val_mae: 0.6034\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 521us/step - loss: 1.2797 - mse: 1.2797 - mae: 0.8358 - val_loss: 0.7349 - val_mse: 0.7349 - val_mae: 0.6036\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 694us/step - loss: 1.2728 - mse: 1.2728 - mae: 0.8332 - val_loss: 0.7360 - val_mse: 0.7360 - val_mae: 0.6049\n",
      "98\n",
      "[98]\n",
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 5s 47ms/step - loss: 7.1424 - mse: 7.1424 - mae: 2.4045 - val_loss: 5.3141 - val_mse: 5.3141 - val_mae: 2.2119\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 573us/step - loss: 5.9045 - mse: 5.9045 - mae: 2.1243 - val_loss: 4.2387 - val_mse: 4.2387 - val_mae: 1.9410\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 569us/step - loss: 4.8379 - mse: 4.8379 - mae: 1.8623 - val_loss: 3.2522 - val_mse: 3.2522 - val_mae: 1.6579\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 596us/step - loss: 3.8958 - mse: 3.8958 - mae: 1.6151 - val_loss: 2.4205 - val_mse: 2.4205 - val_mae: 1.3784\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 488us/step - loss: 3.1252 - mse: 3.1252 - mae: 1.3734 - val_loss: 1.7355 - val_mse: 1.7355 - val_mae: 1.1242\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 814us/step - loss: 2.5248 - mse: 2.5248 - mae: 1.1722 - val_loss: 1.2430 - val_mse: 1.2430 - val_mae: 0.9188\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 2.0863 - mse: 2.0863 - mae: 1.0399 - val_loss: 0.9089 - val_mse: 0.9089 - val_mae: 0.7460\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.8089 - mse: 1.8089 - mae: 0.9653 - val_loss: 0.7147 - val_mse: 0.7147 - val_mae: 0.6412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 701us/step - loss: 1.6683 - mse: 1.6683 - mae: 0.9365 - val_loss: 0.6260 - val_mse: 0.6260 - val_mae: 0.6103\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 524us/step - loss: 1.6176 - mse: 1.6176 - mae: 0.9418 - val_loss: 0.5970 - val_mse: 0.5970 - val_mae: 0.6127\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.1881 - mse: 1.1881 - mae: 0.892 - 0s 723us/step - loss: 1.6075 - mse: 1.6075 - mae: 0.9581 - val_loss: 0.5904 - val_mse: 0.5904 - val_mae: 0.6227\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 499us/step - loss: 1.6020 - mse: 1.6020 - mae: 0.9653 - val_loss: 0.5858 - val_mse: 0.5858 - val_mae: 0.6231\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 649us/step - loss: 1.5844 - mse: 1.5844 - mae: 0.9609 - val_loss: 0.5764 - val_mse: 0.5764 - val_mae: 0.6152\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 521us/step - loss: 1.5549 - mse: 1.5549 - mae: 0.9490 - val_loss: 0.5653 - val_mse: 0.5653 - val_mae: 0.6022\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 558us/step - loss: 1.5210 - mse: 1.5210 - mae: 0.9329 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.5866\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.4890 - mse: 1.4890 - mae: 0.9164 - val_loss: 0.5494 - val_mse: 0.5494 - val_mae: 0.5758\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.4625 - mse: 1.4625 - mae: 0.9011 - val_loss: 0.5462 - val_mse: 0.5462 - val_mae: 0.5686\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 769us/step - loss: 1.4417 - mse: 1.4417 - mae: 0.8906 - val_loss: 0.5437 - val_mse: 0.5437 - val_mae: 0.5634\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.4232 - mse: 1.4232 - mae: 0.8824 - val_loss: 0.5398 - val_mse: 0.5398 - val_mae: 0.5592\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 488us/step - loss: 1.4028 - mse: 1.4028 - mae: 0.8755 - val_loss: 0.5337 - val_mse: 0.5337 - val_mae: 0.5545\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 976us/step - loss: 1.3813 - mse: 1.3813 - mae: 0.8697 - val_loss: 0.5280 - val_mse: 0.5280 - val_mae: 0.5507\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.3601 - mse: 1.3601 - mae: 0.8646 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.5465\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.3405 - mse: 1.3405 - mae: 0.8606 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5405\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.3219 - mse: 1.3219 - mae: 0.8565 - val_loss: 0.5104 - val_mse: 0.5104 - val_mae: 0.5343\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.3048 - mse: 1.3048 - mae: 0.8527 - val_loss: 0.5056 - val_mse: 0.5056 - val_mae: 0.5293\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 814us/step - loss: 1.2892 - mse: 1.2892 - mae: 0.8485 - val_loss: 0.5016 - val_mse: 0.5016 - val_mae: 0.5253\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.2753 - mse: 1.2753 - mae: 0.8443 - val_loss: 0.4982 - val_mse: 0.4982 - val_mae: 0.5220\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 783us/step - loss: 1.2623 - mse: 1.2623 - mae: 0.8407 - val_loss: 0.4954 - val_mse: 0.4954 - val_mae: 0.5190\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 808us/step - loss: 1.2499 - mse: 1.2499 - mae: 0.8372 - val_loss: 0.4923 - val_mse: 0.4923 - val_mae: 0.5160\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.2381 - mse: 1.2381 - mae: 0.8337 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.5144\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 527us/step - loss: 1.2266 - mse: 1.2266 - mae: 0.8304 - val_loss: 0.4863 - val_mse: 0.4863 - val_mae: 0.5129\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 786us/step - loss: 1.2156 - mse: 1.2156 - mae: 0.8272 - val_loss: 0.4832 - val_mse: 0.4832 - val_mae: 0.5116\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.2049 - mse: 1.2049 - mae: 0.8240 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.5100\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.1951 - mse: 1.1951 - mae: 0.8211 - val_loss: 0.4768 - val_mse: 0.4768 - val_mae: 0.5084\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.1861 - mse: 1.1861 - mae: 0.8183 - val_loss: 0.4738 - val_mse: 0.4738 - val_mae: 0.5068\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 539us/step - loss: 1.1774 - mse: 1.1774 - mae: 0.8157 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.5051\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.1690 - mse: 1.1690 - mae: 0.8131 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.5035\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 941us/step - loss: 1.1610 - mse: 1.1610 - mae: 0.8108 - val_loss: 0.4654 - val_mse: 0.4654 - val_mae: 0.5021\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 735us/step - loss: 1.1533 - mse: 1.1533 - mae: 0.8084 - val_loss: 0.4628 - val_mse: 0.4628 - val_mae: 0.5006\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.1459 - mse: 1.1459 - mae: 0.8059 - val_loss: 0.4604 - val_mse: 0.4604 - val_mae: 0.4993\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 772us/step - loss: 1.1388 - mse: 1.1388 - mae: 0.8034 - val_loss: 0.4583 - val_mse: 0.4583 - val_mae: 0.4983\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 325us/step - loss: 1.1320 - mse: 1.1320 - mae: 0.8010 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.4973\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.1254 - mse: 1.1254 - mae: 0.7986 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4964\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.1188 - mse: 1.1188 - mae: 0.7962 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4955\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.1125 - mse: 1.1125 - mae: 0.7938 - val_loss: 0.4517 - val_mse: 0.4517 - val_mae: 0.4948\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.1069 - mse: 1.1069 - mae: 0.7915 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4942\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 634us/step - loss: 1.1013 - mse: 1.1013 - mae: 0.7899 - val_loss: 0.4495 - val_mse: 0.4495 - val_mae: 0.4933\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 644us/step - loss: 1.0958 - mse: 1.0958 - mae: 0.7885 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.4925\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 654us/step - loss: 1.0905 - mse: 1.0905 - mae: 0.7870 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4919\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 658us/step - loss: 1.0854 - mse: 1.0854 - mae: 0.7855 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.4916\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 488us/step - loss: 1.0805 - mse: 1.0805 - mae: 0.7840 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4915\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 695us/step - loss: 1.0757 - mse: 1.0757 - mae: 0.7824 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.4922\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 665us/step - loss: 1.0710 - mse: 1.0710 - mae: 0.7807 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4933\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 641us/step - loss: 1.0664 - mse: 1.0664 - mae: 0.7789 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4943\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 600us/step - loss: 1.0620 - mse: 1.0620 - mae: 0.7771 - val_loss: 0.4483 - val_mse: 0.4483 - val_mae: 0.4951\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 595us/step - loss: 1.0576 - mse: 1.0576 - mae: 0.7755 - val_loss: 0.4483 - val_mse: 0.4483 - val_mae: 0.4955\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 488us/step - loss: 1.0532 - mse: 1.0532 - mae: 0.7739 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.4959\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.0488 - mse: 1.0488 - mae: 0.7723 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.4966\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 567us/step - loss: 1.0446 - mse: 1.0446 - mae: 0.7706 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4975\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.0405 - mse: 1.0405 - mae: 0.7688 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.4984\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 651us/step - loss: 1.0364 - mse: 1.0364 - mae: 0.7671 - val_loss: 0.4497 - val_mse: 0.4497 - val_mae: 0.4991\n",
      "99\n",
      "[99]\n",
      "Train on 111 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "111/111 [==============================] - 5s 49ms/step - loss: 10.7309 - mse: 10.7309 - mae: 3.0868 - val_loss: 18.0763 - val_mse: 18.0763 - val_mae: 3.9453\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 0s 682us/step - loss: 8.3923 - mse: 8.3923 - mae: 2.6837 - val_loss: 14.2108 - val_mse: 14.2108 - val_mae: 3.4547\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 0s 450us/step - loss: 6.3729 - mse: 6.3729 - mae: 2.2758 - val_loss: 10.6772 - val_mse: 10.6772 - val_mae: 2.9421\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 0s 509us/step - loss: 4.7151 - mse: 4.7151 - mae: 1.8725 - val_loss: 7.7619 - val_mse: 7.7619 - val_mae: 2.4681\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 0s 899us/step - loss: 3.4464 - mse: 3.4464 - mae: 1.5020 - val_loss: 5.4755 - val_mse: 5.4755 - val_mae: 2.0373\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 2.5265 - mse: 2.5265 - mae: 1.1957 - val_loss: 3.8212 - val_mse: 3.8212 - val_mae: 1.6671\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 1.9206 - mse: 1.9206 - mae: 0.9910 - val_loss: 2.7536 - val_mse: 2.7536 - val_mae: 1.3828\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 0s 971us/step - loss: 1.5764 - mse: 1.5764 - mae: 0.8934 - val_loss: 2.0989 - val_mse: 2.0989 - val_mae: 1.1871\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 0s 596us/step - loss: 1.4262 - mse: 1.4262 - mae: 0.8556 - val_loss: 1.7535 - val_mse: 1.7535 - val_mae: 1.0586\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 1.3929 - mse: 1.3929 - mae: 0.8570 - val_loss: 1.6046 - val_mse: 1.6046 - val_mae: 0.9951\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.4062 - mse: 1.4062 - mae: 0.8768 - val_loss: 1.5483 - val_mse: 1.5483 - val_mae: 0.9776\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 0s 545us/step - loss: 1.4223 - mse: 1.4223 - mae: 0.8887 - val_loss: 1.5380 - val_mse: 1.5380 - val_mae: 0.9814\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 0s 531us/step - loss: 1.4211 - mse: 1.4211 - mae: 0.8899 - val_loss: 1.5507 - val_mse: 1.5507 - val_mae: 0.9846\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 0s 475us/step - loss: 1.4034 - mse: 1.4034 - mae: 0.8808 - val_loss: 1.5769 - val_mse: 1.5769 - val_mae: 0.9875\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 0s 563us/step - loss: 1.3789 - mse: 1.3789 - mae: 0.8675 - val_loss: 1.6163 - val_mse: 1.6163 - val_mae: 0.9993\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 1.3555 - mse: 1.3555 - mae: 0.8542 - val_loss: 1.6686 - val_mse: 1.6686 - val_mae: 1.0145\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 1.3377 - mse: 1.3377 - mae: 0.8431 - val_loss: 1.7245 - val_mse: 1.7245 - val_mae: 1.0361\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 0s 884us/step - loss: 1.3241 - mse: 1.3241 - mae: 0.8355 - val_loss: 1.7757 - val_mse: 1.7757 - val_mae: 1.0550\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 0s 942us/step - loss: 1.3109 - mse: 1.3109 - mae: 0.8286 - val_loss: 1.8206 - val_mse: 1.8206 - val_mae: 1.0690\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 1.2985 - mse: 1.2985 - mae: 0.8224 - val_loss: 1.8535 - val_mse: 1.8535 - val_mae: 1.0770\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 0s 704us/step - loss: 1.2868 - mse: 1.2868 - mae: 0.8172 - val_loss: 1.8705 - val_mse: 1.8705 - val_mae: 1.0785\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 0s 422us/step - loss: 1.2752 - mse: 1.2752 - mae: 0.8123 - val_loss: 1.8734 - val_mse: 1.8734 - val_mae: 1.0744\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "from math import sqrt\n",
    "paths_to_folders = ['C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Splited Data s-1 to s-5/STORE__1']\n",
    "x=0\n",
    "for folder in paths_to_folders:\n",
    "   for csv_file in os.listdir(folder):\n",
    "        if  any(dff.File_name ==\"\"+csv_file)==True:\n",
    "       #if len(df.index)>=100:\n",
    "            select_indices=list(np.where(dff[\"File_name\"] == ''+csv_file)[0])\n",
    "            print(select_indices)\n",
    "            df=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Splited Data s-1 to s-5/STORE__1/\"+csv_file,parse_dates=['date'],index_col='date')\n",
    "            df.drop(['id','store_nbr','item_nbr','onpromotion'], axis=1,inplace=True)\n",
    "            k = int(len(df) * 0.8)\n",
    "            train,test = df.values[0:k,:], df.values[k:len(df.values),:]\n",
    "            look_back = 10 #create window size as look_back=10\n",
    "            test = np.append(test,np.repeat(test[-1,], look_back))\n",
    "            train = np.append(train,np.repeat(train[-1,],look_back))\n",
    "            trainX,trainY =convert2matrix(train,look_back)\n",
    "            testX,testY =convert2matrix(test, look_back)\n",
    "            # reshape input to be [samples, window size, features]\n",
    "            trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "            testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "            model=model_rnn(look_back)\n",
    "            history=model.fit(trainX,trainY, epochs=100, batch_size=30, verbose=1, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)\n",
    "            test_predict = model.predict(testX)\n",
    "            rmse = np.sqrt(mean_squared_error(testY,test_predict))\n",
    "            error.loc[x, ['File_name']]=csv_file\n",
    "            error.loc[x, ['RMSE_ERROR_RNN']]=rmse\n",
    "            if len(select_indices)==1:\n",
    "                b=dff.iloc[select_indices[0]]['RMSE_ERROR_LSTM']\n",
    "                d=dff.iloc[select_indices[0]]['RMSE_ERROR_CNN']\n",
    "                c=dff.iloc[select_indices[0]]['RMSE_ERROR_CNN+LSTM']\n",
    "                error.loc[x, ['RMSE_ERROR_LSTM']]=b\n",
    "                error.loc[x, ['RMSE_ERROR_CNN']]=d\n",
    "                error.loc[x, ['RMSE_ERROR_CNN+LSTM']]=c\n",
    "            error.loc[x, ['MSE']]=mean_squared_error(testY,test_predict)\n",
    "            error.loc[x, ['MAPE']]=mean_absolute_percentage_error(testY,test_predict)\n",
    "            x=x+1\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = pd.DataFrame(columns=['File_name','RMSE_ERROR_CNN','RMSE_ERROR_LSTM','RMSE_ERROR_CNN+LSTM','RMSE_ERROR_RNN','MSE','MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>RMSE_ERROR_CNN</th>\n",
       "      <th>RMSE_ERROR_LSTM</th>\n",
       "      <th>RMSE_ERROR_CNN+LSTM</th>\n",
       "      <th>RMSE_ERROR_RNN</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S_1__I_1001305.csv</td>\n",
       "      <td>1.35458</td>\n",
       "      <td>1.10799</td>\n",
       "      <td>1.28191</td>\n",
       "      <td>0.819524</td>\n",
       "      <td>0.67162</td>\n",
       "      <td>39.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S_1__I_1009998.csv</td>\n",
       "      <td>1.47389</td>\n",
       "      <td>1.35859</td>\n",
       "      <td>0.874792</td>\n",
       "      <td>1.08118</td>\n",
       "      <td>1.16896</td>\n",
       "      <td>70.6793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S_1__I_1010752.csv</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>1.00519</td>\n",
       "      <td>1.00439</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.229481</td>\n",
       "      <td>19.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S_1__I_1018617.csv</td>\n",
       "      <td>1.0624</td>\n",
       "      <td>1.35548</td>\n",
       "      <td>1.42294</td>\n",
       "      <td>1.08874</td>\n",
       "      <td>1.18536</td>\n",
       "      <td>48.4652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S_1__I_1040170.csv</td>\n",
       "      <td>1.32738</td>\n",
       "      <td>1.19962</td>\n",
       "      <td>0.95653</td>\n",
       "      <td>0.841786</td>\n",
       "      <td>0.708603</td>\n",
       "      <td>51.4315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            File_name RMSE_ERROR_CNN RMSE_ERROR_LSTM RMSE_ERROR_CNN+LSTM RMSE_ERROR_RNN       MSE     MAPE\n",
       "0  S_1__I_1001305.csv        1.35458         1.10799             1.28191       0.819524   0.67162  39.0878\n",
       "1  S_1__I_1009998.csv        1.47389         1.35859            0.874792        1.08118   1.16896  70.6793\n",
       "2  S_1__I_1010752.csv       0.967724         1.00519             1.00439       0.479042  0.229481   19.399\n",
       "3  S_1__I_1018617.csv         1.0624         1.35548             1.42294        1.08874   1.18536  48.4652\n",
       "4  S_1__I_1040170.csv        1.32738         1.19962             0.95653       0.841786  0.708603  51.4315"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('forecast_error_RNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
