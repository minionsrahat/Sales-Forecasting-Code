{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,RepeatVector\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D,Conv2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import  SimpleRNN\n",
    "from statsmodels.tools.eval_measures import rmse \n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_split(df,ratio):\n",
    "    interval=int(len(df)*ratio)\n",
    "    train = df[:interval]\n",
    "    test = df[interval:]\n",
    "    train.dropna(inplace=True)\n",
    "    test.dropna(inplace=True)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2matrix(data_arr, look_back):\n",
    " X, Y =[], []\n",
    " for i in range(len(data_arr)-look_back):\n",
    "  d=i+look_back  \n",
    "  X.append(data_arr[i:d,0])\n",
    "  Y.append(data_arr[d,0])\n",
    " return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dnn(look_back):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(units=32, input_dim=look_back, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(xtrain):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(xtrain.shape[1], 1)))\n",
    "    model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm(xtrain):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=(xtrain.shape[1], xtrain.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn(look_back):\n",
    "  model=Sequential()\n",
    "  model.add(SimpleRNN(units=32, input_shape=(look_back,1), activation=\"relu\"))\n",
    "  model.add(Dense(8, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n",
    "  return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape3d(data):\n",
    "    return data.reshape(data.shape[0],data.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather(df,scaler):\n",
    "    df=df[['temperatureMax']]\n",
    "    scaler=scaler.fit(df)\n",
    "    df['temperatureMax']=scaler.transform(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_walmart(df,scaler):\n",
    "    df=df.drop(columns=['Store','Dept','IsHoliday'])\n",
    "    scaler=scaler.fit(df)\n",
    "    df['Weekly_Sales']=scaler.transform(df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_grocery(df,scaler):\n",
    "    df.drop(['id','store_nbr','item_nbr','onpromotion'], axis=1,inplace=True)\n",
    "    scaler=scaler.fit(df)\n",
    "    df['unit_sales']=scaler.transform(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - mae: 0.0961\n",
      "Epoch 2/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0916\n",
      "Epoch 3/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0886\n",
      "Epoch 4/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0857\n",
      "Epoch 5/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0833\n",
      "Epoch 6/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0811\n",
      "Epoch 7/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0794\n",
      "Epoch 8/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0779\n",
      "Epoch 9/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0765\n",
      "Epoch 10/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0752\n",
      "Epoch 11/60\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0056 - mse: 0.0056 - mae: 0.057 - 0s 188us/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0743\n",
      "Epoch 12/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0738\n",
      "Epoch 13/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0735\n",
      "Epoch 14/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0732\n",
      "Epoch 15/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0726\n",
      "Epoch 16/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0721\n",
      "Epoch 17/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0716\n",
      "Epoch 18/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0710\n",
      "Epoch 19/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0704\n",
      "Epoch 20/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0699\n",
      "Epoch 21/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0693\n",
      "Epoch 22/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0687\n",
      "Epoch 23/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0682\n",
      "Epoch 24/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0677\n",
      "Epoch 25/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0673\n",
      "Epoch 26/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0671\n",
      "Epoch 27/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0668\n",
      "Epoch 28/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0666\n",
      "Epoch 29/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0663\n",
      "Epoch 30/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0661\n",
      "Epoch 31/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0657\n",
      "Epoch 32/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0654\n",
      "Epoch 33/60\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0058 - mse: 0.0058 - mae: 0.060 - 0s 94us/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0651\n",
      "Epoch 34/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0648\n",
      "Epoch 35/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0645\n",
      "Epoch 36/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0642\n",
      "Epoch 37/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0639\n",
      "Epoch 38/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0637\n",
      "Epoch 39/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0635\n",
      "Epoch 40/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0633\n",
      "Epoch 41/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0631\n",
      "Epoch 42/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0629\n",
      "Epoch 43/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0627\n",
      "Epoch 44/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0626\n",
      "Epoch 45/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0624\n",
      "Epoch 46/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0623\n",
      "Epoch 47/60\n",
      "85/85 [==============================] - 0s 0us/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0621\n",
      "Epoch 48/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0620\n",
      "Epoch 49/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0618\n",
      "Epoch 50/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0617\n",
      "Epoch 51/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0616\n",
      "Epoch 52/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0614\n",
      "Epoch 53/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0613\n",
      "Epoch 54/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0612\n",
      "Epoch 55/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0611\n",
      "Epoch 56/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0609\n",
      "Epoch 57/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0608\n",
      "Epoch 58/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0607\n",
      "Epoch 59/60\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0059 - mse: 0.0059 - mae: 0.059 - 0s 282us/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0606\n",
      "Epoch 60/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0605\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 0.0173 - mse: 0.0173 - mae: 0.0898\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0865\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0839\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0812\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0790\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0773\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0757\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0744\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0739\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0734\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0732\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0729\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0723\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0716\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0707\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0699\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0691\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 470us/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0684\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0677\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0670\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0663\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0658\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0652\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0647\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0641\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0636\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0630\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0625\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0620\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0614\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0608\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0603\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0597\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 470us/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0592\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0586\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0580\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0577\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0574\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0571\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 376us/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0568\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0566\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0563\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0560\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0557\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0553\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0552\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0551\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0547\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0542\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0539\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0538\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0535\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0531\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0528\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0526\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0522\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0518\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0515\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0513\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0511\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0509\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0507\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0503\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0500\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0497\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0497\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0492\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0489\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0488\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 189us/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0488\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0485\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0482\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0482\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0480\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0479\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 189us/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0477\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0476\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0474\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0472\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0472\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0469\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0467\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0467\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0464\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0463\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0456\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0456\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0454\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0452\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0452\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0452\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0449\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0447\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0447\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0446\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0443\n",
      "Epoch 1/60\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 0.0169\n",
      "Epoch 2/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0123\n",
      "Epoch 3/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0106\n",
      "Epoch 4/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0099\n",
      "Epoch 5/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0085\n",
      "Epoch 6/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0080\n",
      "Epoch 7/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0075\n",
      "Epoch 8/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0069\n",
      "Epoch 9/60\n",
      "85/85 [==============================] - 0s 376us/step - loss: 0.0065\n",
      "Epoch 10/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0067\n",
      "Epoch 11/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0062\n",
      "Epoch 12/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0063\n",
      "Epoch 13/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0061\n",
      "Epoch 14/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0059\n",
      "Epoch 15/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0057\n",
      "Epoch 16/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0057\n",
      "Epoch 17/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0057\n",
      "Epoch 18/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0056\n",
      "Epoch 19/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0054\n",
      "Epoch 20/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0055\n",
      "Epoch 21/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0054\n",
      "Epoch 22/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0053\n",
      "Epoch 23/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0050\n",
      "Epoch 24/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0052\n",
      "Epoch 25/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0051\n",
      "Epoch 26/60\n",
      "85/85 [==============================] - 0s 377us/step - loss: 0.0049\n",
      "Epoch 27/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0047\n",
      "Epoch 28/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0048\n",
      "Epoch 29/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0046\n",
      "Epoch 30/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0046\n",
      "Epoch 31/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0045\n",
      "Epoch 32/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0044\n",
      "Epoch 33/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0043\n",
      "Epoch 34/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0042\n",
      "Epoch 35/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0042\n",
      "Epoch 36/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0040\n",
      "Epoch 37/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0041\n",
      "Epoch 38/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0040\n",
      "Epoch 39/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0038\n",
      "Epoch 40/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0038\n",
      "Epoch 41/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0039\n",
      "Epoch 42/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0037\n",
      "Epoch 43/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0036\n",
      "Epoch 44/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0035\n",
      "Epoch 45/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0039\n",
      "Epoch 46/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0040\n",
      "Epoch 47/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034\n",
      "Epoch 48/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0034\n",
      "Epoch 49/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0035\n",
      "Epoch 50/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0033\n",
      "Epoch 51/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0031\n",
      "Epoch 52/60\n",
      "85/85 [==============================] - 0s 94us/step - loss: 0.0034\n",
      "Epoch 53/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0031\n",
      "Epoch 54/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0030\n",
      "Epoch 55/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0029\n",
      "Epoch 56/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0028\n",
      "Epoch 57/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0027\n",
      "Epoch 58/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0028\n",
      "Epoch 59/60\n",
      "85/85 [==============================] - 0s 188us/step - loss: 0.0032\n",
      "Epoch 60/60\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.0031\n",
      "Armenia.csv\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "from math import sqrt\n",
    "paths_to_folders = ['C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Practice/weather']\n",
    "x=0\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# error = pd.DataFrame(columns=['File_name', 'ARIMA_RMSE_ERROR','SES_RMSE_ERROR','SARIMA_RMSE_ERROR','PROPHET_RMSE_ERROR',\n",
    "#                               'HOLT_WINTER_RMSE_ERROR','ARIMA_MAPE_ERROR','SES_MAPE_ERROR','SARIMA_MAPE_ERROR','PROPHET_MAPE_ERROR',\n",
    "#                               'HOLT_WINTER_MAPE_ERROR'])\n",
    "error = pd.DataFrame(columns=['File_name','PROPHET+CNN_MAPE', 'PROPHET+DNN_MAPE','PROPHET+RNN_MAPE','PROPHET+CNN_RMSE','PROPHET+DNN_RMSE','PROPHET+RNN_RMSE'])\n",
    "for folder in paths_to_folders:\n",
    "   for csv_file in os.listdir(folder):\n",
    "#      df=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Practice/weather\"+csv_file,parse_dates=['Date'],index_col='Date')\n",
    "     df=pd.read_csv(\"C:/Users/RAHAT/Downloads/Untitled Folder/Sales_f/data/Practice/weather/\"+csv_file,parse_dates=['time'],index_col='time')\n",
    "     if len(df.index)>=100:\n",
    "         test_predictions=pd.DataFrame()\n",
    "         df=preprocess_weather(df,scaler)\n",
    "         train,test=x_y_split(df,0.8)\n",
    "         interval=int(len(df)*0.8)\n",
    "        \n",
    "         train_prophet=pd.DataFrame()\n",
    "         train_prophet['ds']=train.index\n",
    "         train_prophet['y']=np.array(train['temperatureMax'])\n",
    "        \n",
    "         m1 = Prophet(daily_seasonality=True)\n",
    "         m1.fit(train_prophet)\n",
    "         future1 = m1.make_future_dataframe(periods=len(test.index),freq='D')\n",
    "         forecast1 = m1.predict(future1)\n",
    "         pred=forecast1[['yhat']]\n",
    "         p=pred.iloc[interval:]\n",
    "         actual=np.array(p)\n",
    "         actual=actual.reshape(-1)\n",
    "         df_res=pd.DataFrame(columns=['y'])\n",
    "         df_res=pd.DataFrame(np.array(df['temperatureMax'])-np.array(pred['yhat']))\n",
    "         df_res['y']=df_res\n",
    "         df_res=df_res.loc[:,['y']]\n",
    "            \n",
    "         train_res,test_res=x_y_split(df_res,0.8)\n",
    "         \n",
    "         \n",
    "         timestep=4\n",
    "         xtrain,ytrain=convert2matrix(train_res.values,timestep)\n",
    "         xtest,ytest=convert2matrix(test_res.values,timestep)\n",
    "         test_predictions['actual']=np.array(ytest)\n",
    "        \n",
    "         #DNN MODEL\n",
    "         model = model_dnn(timestep)\n",
    "         model.fit(xtrain,ytrain, epochs=60, batch_size=32, verbose=1,callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)\n",
    "         test_predict = model.predict(xtest)\n",
    "         test_predictions['DNN']=np.array(test_predict)\n",
    "            \n",
    "        \n",
    "         #RNN Model  \n",
    "         model = model_rnn(timestep)\n",
    "         model.fit(reshape3d(xtrain),ytrain,epochs=100, batch_size=30, verbose=1,callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)\n",
    "         test_predict = model.predict(reshape3d(xtest))\n",
    "         test_predictions['RNN']=np.array(test_predict)\n",
    "        \n",
    "            \n",
    "         #CNN MODEL\n",
    "         model=model_cnn(reshape3d(xtrain))\n",
    "         model.fit(reshape3d(xtrain), ytrain, epochs=60, verbose=1)\n",
    "         cnn_preds = model.predict(reshape3d(xtest))\n",
    "         test_predictions['CNN']=np.array(cnn_preds)\n",
    "         \n",
    "       \n",
    "        \n",
    "        \n",
    "         error.loc[x, ['File_name']]=csv_file\n",
    "         error.loc[x, ['PROPHET+DNN_MAPE']]=mean_absolute_percentage_error(np.array(test_predictions['DNN'])+actual[timestep:],np.array(test[timestep:]['temperatureMax']))\n",
    "         error.loc[x, ['PROPHET+CNN_MAPE']]=mean_absolute_percentage_error(np.array(test_predictions['CNN'])+actual[timestep:],np.array(test[timestep:]['temperatureMax']))\n",
    "         error.loc[x, ['PROPHET+RNN_MAPE']]=mean_absolute_percentage_error(np.array(test_predictions['RNN'])+actual[timestep:],np.array(test[timestep:]['temperatureMax']))\n",
    "        \n",
    "        \n",
    "         error.loc[x, ['PROPHET+DNN_RMSE']]=rmse(np.array(test_predictions['DNN'])+actual[timestep:],np.array(test[timestep:]['temperatureMax']))\n",
    "         error.loc[x, ['PROPHET+CNN_RMSE']]=rmse(np.array(test_predictions['CNN'])+actual[timestep:],np.array(test[timestep:]['temperatureMax']))\n",
    "         error.loc[x, ['PROPHET+RNN_RMSE']]=rmse(np.array(test_predictions['RNN'])+actual[timestep:],np.array(test[timestep:]['temperatureMax']))\n",
    "         \n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "         x=x+1\n",
    "         print(csv_file)\n",
    "         print(x)\n",
    "         #print(rmse(test[\"unit_sales\"], predictions))\n",
    "         #print(mean_squared_error(test[\"unit_sales\"], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>PROPHET+CNN_MAPE</th>\n",
       "      <th>PROPHET+DNN_MAPE</th>\n",
       "      <th>PROPHET+RNN_MAPE</th>\n",
       "      <th>PROPHET+CNN_RMSE</th>\n",
       "      <th>PROPHET+DNN_RMSE</th>\n",
       "      <th>PROPHET+RNN_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia.csv</td>\n",
       "      <td>13.3003</td>\n",
       "      <td>12.5559</td>\n",
       "      <td>13.6241</td>\n",
       "      <td>0.116647</td>\n",
       "      <td>0.106376</td>\n",
       "      <td>0.116888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_name PROPHET+CNN_MAPE PROPHET+DNN_MAPE PROPHET+RNN_MAPE  \\\n",
       "0  Armenia.csv          13.3003          12.5559          13.6241   \n",
       "\n",
       "  PROPHET+CNN_RMSE PROPHET+DNN_RMSE PROPHET+RNN_RMSE  \n",
       "0         0.116647         0.106376         0.116888  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('weather-Hybrid-model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(test_predictions['actual'])+np.array(test[4:]['Weekly_Sales']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17547138038238477"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(np.array(test_predictions['DNN'])+actual[timestep:],np.array(test[timestep:]['Weekly_Sales']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51207182, 0.5660495 , 0.51820978, 0.59229423, 0.51694085,\n",
       "       0.49243493, 0.50176779, 0.53905422, 0.55195408, 0.50873519,\n",
       "       0.51976303, 0.51909784, 0.54605435, 0.485287  , 0.46796   ,\n",
       "       0.48637555, 0.56506839, 0.4999135 , 0.47844099, 0.47776161,\n",
       "       0.55201982, 0.58731638, 0.50694631, 0.52127355, 0.46040401])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_predictions['DNN'])+actual[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54042436, 0.66089465, 0.52082436, 0.80236486, 0.80929628,\n",
       "       0.71567443, 0.69627897, 0.70469893, 0.84143192, 0.66314339,\n",
       "       0.54900341, 0.624307  , 0.86845535, 0.69180877, 0.63539386,\n",
       "       0.53683252, 0.7609559 , 0.71133605, 0.58070725, 0.55098852,\n",
       "       0.51873925, 0.8063385 , 0.53399178, 0.73035767, 0.62190941])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test[4:]['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53244452, 0.53301856, 0.53294748, 0.53222145, 0.53085533,\n",
       "       0.52888806, 0.5263813 , 0.52341759, 0.52009773, 0.51653784,\n",
       "       0.51286591, 0.50921811, 0.50573481, 0.50255664, 0.49982044,\n",
       "       0.49765552, 0.49617999, 0.49549757, 0.49569475, 0.49683847,\n",
       "       0.49897443, 0.50212586, 0.50629301, 0.51145327, 0.51756182])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
